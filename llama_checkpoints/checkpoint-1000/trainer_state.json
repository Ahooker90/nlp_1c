{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.19229844719003894,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0,
      "loss": 2.098,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.457374572753906,
      "learning_rate": 4e-05,
      "loss": 2.1917,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7966217994689941,
      "learning_rate": 8e-05,
      "loss": 2.0472,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 8e-05,
      "loss": 2.1569,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.239715099334717,
      "learning_rate": 0.00012,
      "loss": 2.1789,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.806528091430664,
      "learning_rate": 0.00016,
      "loss": 1.9093,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7827303409576416,
      "learning_rate": 0.0002,
      "loss": 1.9295,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7811224460601807,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.9561,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.6722819805145264,
      "learning_rate": 0.00019992300288739173,
      "loss": 2.0285,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1149275302886963,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.6257,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7799516916275024,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.8609,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.874711513519287,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.586,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.246931314468384,
      "learning_rate": 0.00019976900866217518,
      "loss": 1.5202,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0075149536132812,
      "learning_rate": 0.00019973051010587105,
      "loss": 1.2222,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4524502754211426,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.2517,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.251847743988037,
      "learning_rate": 0.00019965351299326277,
      "loss": 1.2791,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.737441062927246,
      "learning_rate": 0.00019961501443695862,
      "loss": 1.2863,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.00286865234375,
      "learning_rate": 0.0001995765158806545,
      "loss": 1.103,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9747,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.114648818969727,
      "learning_rate": 0.00019953801732435037,
      "loss": 1.0495,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.003035545349121,
      "learning_rate": 0.0001994995187680462,
      "loss": 1.1688,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.8911,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.781760215759277,
      "learning_rate": 0.00019946102021174206,
      "loss": 1.0611,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.519819736480713,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.9427,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.247189998626709,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9676,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0819637775421143,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.8659,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0306124687194824,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.9604,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1556403636932373,
      "learning_rate": 0.00019926852743022138,
      "loss": 1.0219,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9903797507286072,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.9448,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8551985025405884,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8887,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9833319783210754,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.9098,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8927335143089294,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.8427,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3464423418045044,
      "learning_rate": 0.00019907603464870067,
      "loss": 0.9411,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1088123321533203,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.8362,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.443970799446106,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7319,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0620180368423462,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.8502,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8205506801605225,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.8464,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.026169776916504,
      "learning_rate": 0.00019888354186718,
      "loss": 0.858,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7239542603492737,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.8742,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8644108772277832,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7656,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6905569434165955,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.8372,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8827759623527527,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.7281,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5555065870285034,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.8572,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42273494601249695,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.8768,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5444644689559937,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.7526,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6326220035552979,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.6473,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6100513935089111,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.7474,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8508883714675903,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.8062,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.555642306804657,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7822,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6031041741371155,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.9466,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.612458348274231,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.8309,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6748793721199036,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.8421,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4463978111743927,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.6661,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6735567450523376,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7187,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5610448122024536,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7486,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.468348890542984,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.9174,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49667859077453613,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.8015,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49677103757858276,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.8764,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5423592329025269,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.8467,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46261122822761536,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.7561,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6421524286270142,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.8461,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.44534018635749817,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.9544,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4680206775665283,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.898,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.48604387044906616,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8691,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5105553269386292,
      "learning_rate": 0.00019784408084696825,
      "loss": 0.7244,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.41934075951576233,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.9266,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4944055676460266,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.7894,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4694783389568329,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.9173,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4923385977745056,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.8264,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.584971010684967,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7067,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.460625022649765,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.7259,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5579990744590759,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.6285,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43484073877334595,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.7982,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.451922208070755,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.8647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5411314964294434,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.7489,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.485877126455307,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.6726,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43625229597091675,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.7847,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4604784846305847,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.6761,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.38421735167503357,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.8093,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47359615564346313,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7767,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48932552337646484,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.6937,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4678775668144226,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.929,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49805936217308044,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.6369,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5964849591255188,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.6874,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5139459371566772,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.9437,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5100282430648804,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.7723,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.606708288192749,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.86,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41680747270584106,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.8129,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4841563403606415,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.923,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6219584345817566,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.7727,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4298764765262604,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.8104,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49360743165016174,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.6325,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4630686640739441,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.898,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5353219509124756,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.8399,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4980505704879761,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7985,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5311594009399414,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.7455,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44213631749153137,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.7094,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5181998014450073,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7528,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5781349539756775,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.8595,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40299394726753235,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9345,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5603666305541992,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.9935,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4508861005306244,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7322,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.453523725271225,
      "learning_rate": 0.000196381135707411,
      "loss": 0.7256,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.698917806148529,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8367,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.526947021484375,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.6431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5315524339675903,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7462,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.528644323348999,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.6622,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4947921633720398,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.7692,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40959012508392334,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.8525,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3968225419521332,
      "learning_rate": 0.000196111645813282,
      "loss": 0.9691,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.461165189743042,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.8075,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43429329991340637,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.7966,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45655712485313416,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.6649,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41561511158943176,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.9817,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5914500951766968,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.6949,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4335707128047943,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.8687,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.517529308795929,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8118,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5489369034767151,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.9189,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5018031001091003,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.7887,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5235357880592346,
      "learning_rate": 0.00019572666025024062,
      "loss": 1.0346,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.373628705739975,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.5875,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.444135844707489,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.7871,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45136335492134094,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.6282,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5306428074836731,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.7564,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4356388747692108,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.6983,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4693934917449951,
      "learning_rate": 0.00019549566891241578,
      "loss": 0.7454,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6450073719024658,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.6905,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4784305989742279,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.6944,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39485329389572144,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.9025,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45148515701293945,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.6443,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4086743891239166,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.8381,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6853803992271423,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.6857,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5018186569213867,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.9565,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38910984992980957,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7023,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47104546427726746,
      "learning_rate": 0.00019514918190567855,
      "loss": 0.7211,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.595535159111023,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.8905,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42830514907836914,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.7955,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4417261779308319,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.692,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42573025822639465,
      "learning_rate": 0.000194995187680462,
      "loss": 0.608,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6163130402565002,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.9331,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47019925713539124,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.7338,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4294617176055908,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.7916,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5744539499282837,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.8113,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4397624135017395,
      "learning_rate": 0.0001948026948989413,
      "loss": 0.8047,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4419170916080475,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.7949,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.408357173204422,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.8878,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3972795903682709,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5689,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.402809202671051,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7868,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46714845299720764,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.904,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4382963180541992,
      "learning_rate": 0.00019457170356111648,
      "loss": 0.7987,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49720799922943115,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.6905,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38201817870140076,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.6079,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3585057854652405,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.8645,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5370497703552246,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.7726,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40534526109695435,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.6871,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40718555450439453,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.8994,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6352331638336182,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.8999,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4231524169445038,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.674,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.51837158203125,
      "learning_rate": 0.0001942252165543792,
      "loss": 0.6869,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43487808108329773,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.8495,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.478048175573349,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6706,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4871412217617035,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.8534,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48025259375572205,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.8734,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.376050740480423,
      "learning_rate": 0.00019403272377285853,
      "loss": 1.0056,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4277438819408417,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.6711,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4798095226287842,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.8112,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4388551712036133,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8392,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.633101224899292,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.7927,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3662850558757782,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7108,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43001875281333923,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.6524,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43889835476875305,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.8804,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.449369341135025,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.9322,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5520343780517578,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.7627,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42789730429649353,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.7097,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5099896788597107,
      "learning_rate": 0.000193609239653513,
      "loss": 0.766,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3890852630138397,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8727,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4030917286872864,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.7714,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5613992810249329,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.9946,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48699212074279785,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.6841,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43229538202285767,
      "learning_rate": 0.0001934167468719923,
      "loss": 0.6469,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46411290764808655,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.7614,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49609866738319397,
      "learning_rate": 0.00019333974975938403,
      "loss": 0.6847,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.33297157287597656,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8576,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5082602500915527,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6907,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.48121577501296997,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.8542,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3946192264556885,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6726,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41997063159942627,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.6866,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4409182369709015,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.7627,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3896368145942688,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.7587,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42079252004623413,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.6828,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4358564019203186,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.7743,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47438254952430725,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7295,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3782908022403717,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7665,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3703530728816986,
      "learning_rate": 0.00019287776708373439,
      "loss": 1.006,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3743325173854828,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.8885,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4332818388938904,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.788,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3522750735282898,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6771,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5323351621627808,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7769,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3655940294265747,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.6001,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4050886034965515,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.9004,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44313961267471313,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.9076,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4808651804924011,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.7876,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4099526107311249,
      "learning_rate": 0.00019253128007699712,
      "loss": 0.7545,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42295604944229126,
      "learning_rate": 0.000192492781520693,
      "loss": 0.6868,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.38039496541023254,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.6882,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.392062246799469,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.8275,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.49568668007850647,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.6282,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3389342129230499,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7987,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.43684521317481995,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.8579,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46228134632110596,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.8268,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.36543259024620056,
      "learning_rate": 0.000192223291626564,
      "loss": 0.8892,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3820000886917114,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7667,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47314170002937317,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.7424,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4986186921596527,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.6653,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40106379985809326,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.6973,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5317052006721497,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.7483,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4519927203655243,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.872,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44930392503738403,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.7127,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5897475481033325,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.9663,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4732646346092224,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7192,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40370991826057434,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.945,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5189063549041748,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.9023,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4453914761543274,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.8568,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4872682988643646,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.6934,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4745577573776245,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.785,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.452533096075058,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.7228,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42025381326675415,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.8885,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.45724043250083923,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.7404,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41045424342155457,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.8384,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4606262743473053,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.6972,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47874921560287476,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.9777,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41982775926589966,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.9483,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46619105339050293,
      "learning_rate": 0.00019137632338787298,
      "loss": 0.7675,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.31501007080078125,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.7628,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45184069871902466,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.686,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3631167411804199,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.8303,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3997798562049866,
      "learning_rate": 0.00019122232916265642,
      "loss": 0.8186,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3641427457332611,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.7384,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3745492696762085,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.9408,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4126112461090088,
      "learning_rate": 0.000191106833493744,
      "loss": 0.7691,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.38452523946762085,
      "learning_rate": 0.00019106833493743986,
      "loss": 0.8933,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4313470423221588,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.717,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4877426326274872,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.9048,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.354559063911438,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.8285,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35648438334465027,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.673,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3589836657047272,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.7923,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3994254469871521,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7671,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4231529235839844,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.6565,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4621272385120392,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.6907,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3945978581905365,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.7,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39729538559913635,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.5096,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42322924733161926,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.78,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.44383230805397034,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.8083,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6045325398445129,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.8649,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4234389662742615,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.7185,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.381877601146698,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8355,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3730185031890869,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.675,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4495980739593506,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.6618,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36406174302101135,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.8693,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5642045736312866,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.661,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3980395197868347,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7259,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.47727033495903015,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.6606,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37292900681495667,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.781,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.33142971992492676,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.621,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4019940197467804,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.8589,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4046827554702759,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.7907,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.40318140387535095,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7672,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.41678452491760254,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7602,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3626757264137268,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.6203,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36802080273628235,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.7684,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35103940963745117,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.828,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4074096381664276,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.7727,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39446142315864563,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.7743,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42152348160743713,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.6711,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37022072076797485,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.8369,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45802485942840576,
      "learning_rate": 0.000189720885466795,
      "loss": 0.6817,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3840475082397461,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.6692,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.397205114364624,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.6124,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46793362498283386,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7995,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3204089105129242,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.8052,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5611957907676697,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.7167,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.530852735042572,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5691,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46891504526138306,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9886,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4694139361381531,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.6444,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39388447999954224,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.7208,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4057823717594147,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.6421,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.446094274520874,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.9129,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4163888394832611,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.9019,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.341553658246994,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.7768,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4768024981021881,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.6762,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.401567280292511,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.8641,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44063693284988403,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.5896,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3412891626358032,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.8354,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3813810348510742,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.708,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39346498250961304,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.799,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4597877264022827,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.7395,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3625764548778534,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.8548,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.47845423221588135,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.7139,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4290001094341278,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8762,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.374828964471817,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.7665,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3916478455066681,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8444,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4357036352157593,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.6959,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41867315769195557,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.854,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4803310036659241,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.6415,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4232359230518341,
      "learning_rate": 0.000188604427333975,
      "loss": 0.8127,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3427557647228241,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.8764,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4120095670223236,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.7613,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44978073239326477,
      "learning_rate": 0.00018848893166506256,
      "loss": 0.6352,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3201029598712921,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.7237,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44953957200050354,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.6487,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4061507284641266,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.6154,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4792279005050659,
      "learning_rate": 0.000188334937439846,
      "loss": 0.8293,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3731112480163574,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6101,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4615262448787689,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.7616,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36472374200820923,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.6681,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4000975489616394,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.6767,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4342329800128937,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.8626,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.43993252515792847,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.7314,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36972469091415405,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.7895,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4726084768772125,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.6262,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5106558203697205,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.7688,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3342224955558777,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.8441,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.42816826701164246,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6327,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.34864041209220886,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.7377,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3308842182159424,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.6719,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4306331276893616,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.6301,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39399442076683044,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.7529,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4262602925300598,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.8004,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5589942336082458,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.8591,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.45510587096214294,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.8667,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41702696681022644,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.837,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49357858300209045,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.6308,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49088579416275024,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.8118,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4575938582420349,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7499,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5084648132324219,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.9495,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4152742922306061,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.6591,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.410138875246048,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.6558,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3992723822593689,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.8139,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4198096990585327,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8063,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4146757423877716,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.5979,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3692832291126251,
      "learning_rate": 0.000187218479307026,
      "loss": 0.8527,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37799060344696045,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8657,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3419437110424042,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7457,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4123936593532562,
      "learning_rate": 0.00018710298363811359,
      "loss": 0.6015,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3556390404701233,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.952,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.43549832701683044,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.7719,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44564804434776306,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7465,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4578996002674103,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.7318,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5829522609710693,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6746,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.618412435054779,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6612,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.45777198672294617,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.744,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47281530499458313,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.7054,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933841288089752,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8044,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4211621582508087,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.7529,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.504000186920166,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.6154,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.40663763880729675,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7715,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3982800543308258,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.8856,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39105480909347534,
      "learning_rate": 0.00018656400384985564,
      "loss": 0.5879,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4311503469944,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.7208,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.46843230724334717,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.8434,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37112879753112793,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.7895,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3782634139060974,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.71,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.411615788936615,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.692,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4585183262825012,
      "learning_rate": 0.0001863330125120308,
      "loss": 0.699,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3210856020450592,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.8301,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47548168897628784,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6627,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42618703842163086,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.8115,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4956449270248413,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.7461,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.373945415019989,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.7387,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5128307342529297,
      "learning_rate": 0.000186102021174206,
      "loss": 0.8675,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39190107583999634,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.7088,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4019525647163391,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.7208,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6033728122711182,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.6698,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933517634868622,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.8102,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4288349747657776,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.8585,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42410892248153687,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.7242,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4902440309524536,
      "learning_rate": 0.000185832531280077,
      "loss": 0.5965,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.36604270339012146,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.6267,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4615339934825897,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.9455,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4348839223384857,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.8513,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4273621737957001,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.617,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41383039951324463,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.8803,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5040608048439026,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7583,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.33960476517677307,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.7595,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44689905643463135,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.7853,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41154545545578003,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.7136,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.27520662546157837,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.7979,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5478206276893616,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.8095,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4509338438510895,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7044,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4331468939781189,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.7175,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3315088450908661,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8649,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38282105326652527,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7978,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4138413071632385,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7269,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37460705637931824,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.6528,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34590426087379456,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.9164,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.32010602951049805,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.8575,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37327438592910767,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.8753,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.316778302192688,
      "learning_rate": 0.0001850240615976901,
      "loss": 0.6793,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.403444766998291,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7541,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.491682767868042,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6667,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3501006066799164,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.6655,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41489213705062866,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.8568,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4158405065536499,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.6591,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38367748260498047,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.7529,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4363219141960144,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.7413,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4521339237689972,
      "learning_rate": 0.000184716073147257,
      "loss": 0.5389,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.43186765909194946,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7304,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.40286019444465637,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.865,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3767046630382538,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.8971,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3247160017490387,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.7793,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39206525683403015,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.6463,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3634454011917114,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.7576,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34959307312965393,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8257,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5340710282325745,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.9475,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5003661513328552,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.6891,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39330339431762695,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.6483,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.35932329297065735,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6431,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4380384385585785,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.8178,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37227070331573486,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.8105,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41952013969421387,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.7825,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3422773778438568,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.9381,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3683087229728699,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6737,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3993309736251831,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7685,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39145129919052124,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.6952,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41825953125953674,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.7473,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4179387092590332,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.8116,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.45485833287239075,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5701,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4862624704837799,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.8575,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4824470281600952,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.884,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4922899305820465,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.6477,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4879881739616394,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.7551,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5233360528945923,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.7343,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5586115717887878,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6556,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4199840724468231,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.7226,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.397352397441864,
      "learning_rate": 0.00018359961501443698,
      "loss": 1.0078,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4226352274417877,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.8804,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4273151159286499,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.7279,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4946306347846985,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7425,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38384705781936646,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.8422,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3904738426208496,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7058,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3637390732765198,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.8168,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41314783692359924,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.8248,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.30208462476730347,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.7856,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3953840136528015,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.7159,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37532252073287964,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.668,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3895621597766876,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.7619,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4008345305919647,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.9235,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37399378418922424,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.8747,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44646504521369934,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7659,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40955376625061035,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.7648,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3704189360141754,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.7595,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4268467426300049,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.732,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3477902412414551,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.7803,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3642955720424652,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.8426,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3884435296058655,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.7273,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37005576491355896,
      "learning_rate": 0.00018279114533205007,
      "loss": 0.8231,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4093822240829468,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8097,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4333754777908325,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5244,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38456860184669495,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.9002,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40615877509117126,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.8228,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3670360743999481,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.5899,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38076573610305786,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.7756,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4119761884212494,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.6556,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4783891439437866,
      "learning_rate": 0.00018248315688161696,
      "loss": 1.0189,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40097832679748535,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7869,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3726452887058258,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7804,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3413650393486023,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8006,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4379594027996063,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.7684,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37378251552581787,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.7102,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37973713874816895,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.8109,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.33865559101104736,
      "learning_rate": 0.000182213666987488,
      "loss": 0.7206,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.49138644337654114,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.8076,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5017513632774353,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.9111,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4073384702205658,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8147,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.47447335720062256,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.6633,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.406205952167511,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.684,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.613382875919342,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7979,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4507606625556946,
      "learning_rate": 0.000181944177093359,
      "loss": 0.8019,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4662131667137146,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8455,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3832371234893799,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.6721,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4184776246547699,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.8355,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.31751248240470886,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.8333,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4122768044471741,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.8156,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.365533709526062,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7284,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5359499454498291,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8517,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3743586540222168,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.8607,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40984785556793213,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.8798,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.41061532497406006,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.7626,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5130647420883179,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.6745,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3531906008720398,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.7948,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4617935121059418,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7451,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4042561650276184,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.85,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44275152683258057,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.7308,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4530651569366455,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.7625,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.519067645072937,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.7081,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39324527978897095,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.7552,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3819272518157959,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.9068,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4451203942298889,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.8031,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39822861552238464,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8524,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4579085409641266,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6518,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.35329708456993103,
      "learning_rate": 0.0001810587102983638,
      "loss": 0.6251,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4679481089115143,
      "learning_rate": 0.00018102021174205968,
      "loss": 0.8123,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4190986156463623,
      "learning_rate": 0.00018098171318575555,
      "loss": 0.8069,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4447309374809265,
      "learning_rate": 0.0001809432146294514,
      "loss": 0.7957,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3945259749889374,
      "learning_rate": 0.00018090471607314727,
      "loss": 0.8608,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4472101926803589,
      "learning_rate": 0.00018086621751684312,
      "loss": 0.6545,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.399156391620636,
      "learning_rate": 0.000180827718960539,
      "loss": 0.8384,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.45613279938697815,
      "learning_rate": 0.00018078922040423484,
      "loss": 0.7321,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40805959701538086,
      "learning_rate": 0.00018075072184793072,
      "loss": 0.7444,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.42769765853881836,
      "learning_rate": 0.0001807122232916266,
      "loss": 0.8028,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33644768595695496,
      "learning_rate": 0.00018067372473532244,
      "loss": 0.8101,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.44442418217658997,
      "learning_rate": 0.00018063522617901828,
      "loss": 0.7858,
      "step": 512
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3666957914829254,
      "learning_rate": 0.00018059672762271416,
      "loss": 0.8682,
      "step": 513
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40631023049354553,
      "learning_rate": 0.00018055822906641003,
      "loss": 0.8666,
      "step": 514
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3566116392612457,
      "learning_rate": 0.00018051973051010588,
      "loss": 0.8075,
      "step": 515
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40891098976135254,
      "learning_rate": 0.00018048123195380173,
      "loss": 0.7326,
      "step": 516
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4189295470714569,
      "learning_rate": 0.0001804427333974976,
      "loss": 0.7031,
      "step": 517
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37940719723701477,
      "learning_rate": 0.00018040423484119348,
      "loss": 0.8974,
      "step": 518
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.47053778171539307,
      "learning_rate": 0.00018036573628488933,
      "loss": 0.6617,
      "step": 519
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4119088053703308,
      "learning_rate": 0.0001803272377285852,
      "loss": 0.8485,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4901687502861023,
      "learning_rate": 0.00018028873917228105,
      "loss": 0.7554,
      "step": 521
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3938004970550537,
      "learning_rate": 0.0001802502406159769,
      "loss": 0.7201,
      "step": 522
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4453965425491333,
      "learning_rate": 0.00018021174205967277,
      "loss": 0.9134,
      "step": 523
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4919692575931549,
      "learning_rate": 0.00018017324350336864,
      "loss": 0.6673,
      "step": 524
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4813697040081024,
      "learning_rate": 0.0001801347449470645,
      "loss": 0.7451,
      "step": 525
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4028126895427704,
      "learning_rate": 0.00018009624639076034,
      "loss": 0.7807,
      "step": 526
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4498790502548218,
      "learning_rate": 0.0001800577478344562,
      "loss": 0.8194,
      "step": 527
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4789945185184479,
      "learning_rate": 0.0001800192492781521,
      "loss": 0.6132,
      "step": 528
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5399003624916077,
      "learning_rate": 0.00017998075072184794,
      "loss": 0.8553,
      "step": 529
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4275045394897461,
      "learning_rate": 0.00017994225216554378,
      "loss": 0.7398,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40307727456092834,
      "learning_rate": 0.00017990375360923966,
      "loss": 0.8353,
      "step": 531
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37099727988243103,
      "learning_rate": 0.00017986525505293553,
      "loss": 0.8753,
      "step": 532
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3537798821926117,
      "learning_rate": 0.00017982675649663138,
      "loss": 0.7497,
      "step": 533
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41050562262535095,
      "learning_rate": 0.00017978825794032725,
      "loss": 0.6499,
      "step": 534
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.38062337040901184,
      "learning_rate": 0.0001797497593840231,
      "loss": 0.8393,
      "step": 535
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.48728129267692566,
      "learning_rate": 0.00017971126082771898,
      "loss": 0.7913,
      "step": 536
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41124552488327026,
      "learning_rate": 0.00017967276227141482,
      "loss": 0.8473,
      "step": 537
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4975420832633972,
      "learning_rate": 0.0001796342637151107,
      "loss": 0.6603,
      "step": 538
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39639201760292053,
      "learning_rate": 0.00017959576515880657,
      "loss": 0.8181,
      "step": 539
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33978918194770813,
      "learning_rate": 0.0001795572666025024,
      "loss": 0.5651,
      "step": 540
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39304712414741516,
      "learning_rate": 0.00017951876804619827,
      "loss": 0.7266,
      "step": 541
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41755804419517517,
      "learning_rate": 0.00017948026948989414,
      "loss": 0.8439,
      "step": 542
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4548015296459198,
      "learning_rate": 0.00017944177093359002,
      "loss": 0.6774,
      "step": 543
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3938901722431183,
      "learning_rate": 0.00017940327237728586,
      "loss": 0.8082,
      "step": 544
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3671741485595703,
      "learning_rate": 0.0001793647738209817,
      "loss": 0.7709,
      "step": 545
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39431828260421753,
      "learning_rate": 0.00017932627526467759,
      "loss": 0.7623,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3910527229309082,
      "learning_rate": 0.00017928777670837343,
      "loss": 0.6227,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5204810500144958,
      "learning_rate": 0.0001792492781520693,
      "loss": 0.7134,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4552685022354126,
      "learning_rate": 0.00017921077959576518,
      "loss": 0.7792,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42712152004241943,
      "learning_rate": 0.00017917228103946103,
      "loss": 1.0187,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.40982896089553833,
      "learning_rate": 0.00017913378248315688,
      "loss": 0.8407,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.38555216789245605,
      "learning_rate": 0.00017909528392685275,
      "loss": 0.8532,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3626030683517456,
      "learning_rate": 0.00017905678537054863,
      "loss": 0.7091,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.44306764006614685,
      "learning_rate": 0.00017901828681424447,
      "loss": 0.8067,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4466676712036133,
      "learning_rate": 0.00017897978825794032,
      "loss": 0.6057,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.403406023979187,
      "learning_rate": 0.0001789412897016362,
      "loss": 0.6674,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4458920955657959,
      "learning_rate": 0.00017890279114533207,
      "loss": 0.6795,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3888542056083679,
      "learning_rate": 0.00017886429258902792,
      "loss": 0.7303,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4329482614994049,
      "learning_rate": 0.0001788257940327238,
      "loss": 0.6602,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4150072932243347,
      "learning_rate": 0.00017878729547641964,
      "loss": 0.7572,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.46370017528533936,
      "learning_rate": 0.0001787487969201155,
      "loss": 0.7198,
      "step": 561
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.40281912684440613,
      "learning_rate": 0.00017871029836381136,
      "loss": 0.8659,
      "step": 562
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42040666937828064,
      "learning_rate": 0.00017867179980750724,
      "loss": 0.6713,
      "step": 563
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3968161344528198,
      "learning_rate": 0.00017863330125120308,
      "loss": 0.723,
      "step": 564
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3881441056728363,
      "learning_rate": 0.00017859480269489896,
      "loss": 0.7526,
      "step": 565
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3257398307323456,
      "learning_rate": 0.0001785563041385948,
      "loss": 0.9035,
      "step": 566
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3617190718650818,
      "learning_rate": 0.00017851780558229068,
      "loss": 0.6702,
      "step": 567
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3779655992984772,
      "learning_rate": 0.00017847930702598655,
      "loss": 0.6569,
      "step": 568
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.41719603538513184,
      "learning_rate": 0.00017844080846968237,
      "loss": 0.8573,
      "step": 569
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3839716911315918,
      "learning_rate": 0.00017840230991337825,
      "loss": 0.7409,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3557591140270233,
      "learning_rate": 0.00017836381135707412,
      "loss": 0.8895,
      "step": 571
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4740881621837616,
      "learning_rate": 0.00017832531280076997,
      "loss": 0.6805,
      "step": 572
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4512026309967041,
      "learning_rate": 0.00017828681424446585,
      "loss": 0.786,
      "step": 573
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.45799720287323,
      "learning_rate": 0.0001782483156881617,
      "loss": 0.8067,
      "step": 574
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42661893367767334,
      "learning_rate": 0.00017820981713185757,
      "loss": 0.7418,
      "step": 575
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4891342222690582,
      "learning_rate": 0.00017817131857555341,
      "loss": 0.8071,
      "step": 576
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4712083637714386,
      "learning_rate": 0.0001781328200192493,
      "loss": 0.7291,
      "step": 577
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.44885143637657166,
      "learning_rate": 0.00017809432146294516,
      "loss": 0.8356,
      "step": 578
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36697036027908325,
      "learning_rate": 0.000178055822906641,
      "loss": 0.6563,
      "step": 579
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5198047757148743,
      "learning_rate": 0.00017801732435033686,
      "loss": 0.7868,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3903001844882965,
      "learning_rate": 0.00017797882579403273,
      "loss": 0.7775,
      "step": 581
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3861727714538574,
      "learning_rate": 0.0001779403272377286,
      "loss": 0.7176,
      "step": 582
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3334764242172241,
      "learning_rate": 0.00017790182868142445,
      "loss": 0.9657,
      "step": 583
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4170445203781128,
      "learning_rate": 0.0001778633301251203,
      "loss": 0.765,
      "step": 584
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3677545189857483,
      "learning_rate": 0.00017782483156881618,
      "loss": 0.8061,
      "step": 585
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5148152709007263,
      "learning_rate": 0.00017778633301251205,
      "loss": 0.8903,
      "step": 586
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3851109743118286,
      "learning_rate": 0.0001777478344562079,
      "loss": 0.5751,
      "step": 587
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3523044288158417,
      "learning_rate": 0.00017770933589990377,
      "loss": 0.7858,
      "step": 588
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.427933007478714,
      "learning_rate": 0.00017767083734359962,
      "loss": 0.9746,
      "step": 589
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36992552876472473,
      "learning_rate": 0.0001776323387872955,
      "loss": 0.8219,
      "step": 590
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3327391743659973,
      "learning_rate": 0.00017759384023099134,
      "loss": 0.8739,
      "step": 591
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4296494722366333,
      "learning_rate": 0.00017755534167468722,
      "loss": 0.7948,
      "step": 592
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.37695109844207764,
      "learning_rate": 0.00017751684311838306,
      "loss": 0.8366,
      "step": 593
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4121188521385193,
      "learning_rate": 0.0001774783445620789,
      "loss": 0.9157,
      "step": 594
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4559638500213623,
      "learning_rate": 0.0001774398460057748,
      "loss": 0.6274,
      "step": 595
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.48433220386505127,
      "learning_rate": 0.00017740134744947066,
      "loss": 0.729,
      "step": 596
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3838486671447754,
      "learning_rate": 0.0001773628488931665,
      "loss": 0.7394,
      "step": 597
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.448947012424469,
      "learning_rate": 0.00017732435033686236,
      "loss": 0.8636,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.34840279817581177,
      "learning_rate": 0.00017728585178055823,
      "loss": 0.8343,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.44666817784309387,
      "learning_rate": 0.0001772473532242541,
      "loss": 0.8453,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41129618883132935,
      "learning_rate": 0.00017720885466794995,
      "loss": 0.6779,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4049602448940277,
      "learning_rate": 0.00017717035611164583,
      "loss": 0.954,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38343897461891174,
      "learning_rate": 0.00017713185755534167,
      "loss": 0.7214,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4270513951778412,
      "learning_rate": 0.00017709335899903755,
      "loss": 0.7222,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3907594382762909,
      "learning_rate": 0.0001770548604427334,
      "loss": 0.8616,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3287070393562317,
      "learning_rate": 0.00017701636188642927,
      "loss": 0.8017,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4289465546607971,
      "learning_rate": 0.00017697786333012515,
      "loss": 0.6481,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.40701785683631897,
      "learning_rate": 0.000176939364773821,
      "loss": 0.8361,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4191131591796875,
      "learning_rate": 0.00017690086621751684,
      "loss": 0.7557,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4570298194885254,
      "learning_rate": 0.00017686236766121271,
      "loss": 0.8935,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4185386002063751,
      "learning_rate": 0.0001768238691049086,
      "loss": 0.6673,
      "step": 611
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4229338467121124,
      "learning_rate": 0.00017678537054860444,
      "loss": 0.8806,
      "step": 612
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.39359912276268005,
      "learning_rate": 0.00017674687199230028,
      "loss": 0.664,
      "step": 613
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3372077941894531,
      "learning_rate": 0.00017670837343599616,
      "loss": 0.8618,
      "step": 614
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3153285086154938,
      "learning_rate": 0.00017666987487969203,
      "loss": 0.768,
      "step": 615
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37482786178588867,
      "learning_rate": 0.00017663137632338788,
      "loss": 0.7711,
      "step": 616
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.35621148347854614,
      "learning_rate": 0.00017659287776708376,
      "loss": 0.6685,
      "step": 617
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.43296071887016296,
      "learning_rate": 0.0001765543792107796,
      "loss": 0.7611,
      "step": 618
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.45684507489204407,
      "learning_rate": 0.00017651588065447545,
      "loss": 0.5118,
      "step": 619
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3735063076019287,
      "learning_rate": 0.00017647738209817132,
      "loss": 0.7152,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.42290157079696655,
      "learning_rate": 0.0001764388835418672,
      "loss": 0.6485,
      "step": 621
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46688735485076904,
      "learning_rate": 0.00017640038498556307,
      "loss": 0.6683,
      "step": 622
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38138657808303833,
      "learning_rate": 0.0001763618864292589,
      "loss": 0.7274,
      "step": 623
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.39618390798568726,
      "learning_rate": 0.00017632338787295477,
      "loss": 0.8839,
      "step": 624
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.444378137588501,
      "learning_rate": 0.00017628488931665064,
      "loss": 0.7364,
      "step": 625
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.36690178513526917,
      "learning_rate": 0.0001762463907603465,
      "loss": 0.8898,
      "step": 626
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.40035420656204224,
      "learning_rate": 0.00017620789220404234,
      "loss": 0.7846,
      "step": 627
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3317468762397766,
      "learning_rate": 0.0001761693936477382,
      "loss": 0.8477,
      "step": 628
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4218446910381317,
      "learning_rate": 0.0001761308950914341,
      "loss": 0.7423,
      "step": 629
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38181713223457336,
      "learning_rate": 0.00017609239653512993,
      "loss": 0.8511,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5051924586296082,
      "learning_rate": 0.0001760538979788258,
      "loss": 0.7208,
      "step": 631
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3627151548862457,
      "learning_rate": 0.00017601539942252166,
      "loss": 0.8558,
      "step": 632
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5386068224906921,
      "learning_rate": 0.00017597690086621753,
      "loss": 0.7498,
      "step": 633
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4204239547252655,
      "learning_rate": 0.00017593840230991338,
      "loss": 0.7845,
      "step": 634
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3822893798351288,
      "learning_rate": 0.00017589990375360925,
      "loss": 0.816,
      "step": 635
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.48055341839790344,
      "learning_rate": 0.00017586140519730513,
      "loss": 0.8331,
      "step": 636
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46601784229278564,
      "learning_rate": 0.00017582290664100097,
      "loss": 0.7306,
      "step": 637
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5342617034912109,
      "learning_rate": 0.00017578440808469682,
      "loss": 0.6888,
      "step": 638
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4277246296405792,
      "learning_rate": 0.0001757459095283927,
      "loss": 0.7462,
      "step": 639
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41329824924468994,
      "learning_rate": 0.00017570741097208857,
      "loss": 0.7003,
      "step": 640
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.43545401096343994,
      "learning_rate": 0.00017566891241578442,
      "loss": 1.059,
      "step": 641
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37881138920783997,
      "learning_rate": 0.00017563041385948027,
      "loss": 0.732,
      "step": 642
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.34206023812294006,
      "learning_rate": 0.00017559191530317614,
      "loss": 1.0778,
      "step": 643
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.35784947872161865,
      "learning_rate": 0.000175553416746872,
      "loss": 0.6666,
      "step": 644
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3838137984275818,
      "learning_rate": 0.00017551491819056786,
      "loss": 0.7739,
      "step": 645
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5151283144950867,
      "learning_rate": 0.00017547641963426374,
      "loss": 0.772,
      "step": 646
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46383512020111084,
      "learning_rate": 0.00017543792107795958,
      "loss": 0.8412,
      "step": 647
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5041674971580505,
      "learning_rate": 0.00017539942252165543,
      "loss": 0.7372,
      "step": 648
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4784582853317261,
      "learning_rate": 0.0001753609239653513,
      "loss": 0.8203,
      "step": 649
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38770371675491333,
      "learning_rate": 0.00017532242540904718,
      "loss": 0.7772,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4724113643169403,
      "learning_rate": 0.00017528392685274303,
      "loss": 0.8073,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35377320647239685,
      "learning_rate": 0.00017524542829643888,
      "loss": 0.7301,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.47636106610298157,
      "learning_rate": 0.00017520692974013475,
      "loss": 0.6617,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.42795759439468384,
      "learning_rate": 0.00017516843118383063,
      "loss": 0.7154,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4345453679561615,
      "learning_rate": 0.00017512993262752647,
      "loss": 0.733,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39994534850120544,
      "learning_rate": 0.00017509143407122232,
      "loss": 0.5779,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4123230576515198,
      "learning_rate": 0.0001750529355149182,
      "loss": 0.6915,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3561868369579315,
      "learning_rate": 0.00017501443695861407,
      "loss": 0.7782,
      "step": 658
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4212721884250641,
      "learning_rate": 0.00017497593840230992,
      "loss": 0.7503,
      "step": 659
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.332350492477417,
      "learning_rate": 0.0001749374398460058,
      "loss": 0.9183,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.53046715259552,
      "learning_rate": 0.00017489894128970164,
      "loss": 0.9709,
      "step": 661
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.43777701258659363,
      "learning_rate": 0.0001748604427333975,
      "loss": 1.0169,
      "step": 662
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4565688967704773,
      "learning_rate": 0.00017482194417709336,
      "loss": 0.7592,
      "step": 663
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.38864171504974365,
      "learning_rate": 0.00017478344562078923,
      "loss": 0.8752,
      "step": 664
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3984103202819824,
      "learning_rate": 0.0001747449470644851,
      "loss": 0.7577,
      "step": 665
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5659173727035522,
      "learning_rate": 0.00017470644850818093,
      "loss": 0.8482,
      "step": 666
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3943690359592438,
      "learning_rate": 0.0001746679499518768,
      "loss": 0.859,
      "step": 667
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4091321527957916,
      "learning_rate": 0.00017462945139557268,
      "loss": 0.7477,
      "step": 668
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.37893542647361755,
      "learning_rate": 0.00017459095283926855,
      "loss": 0.7329,
      "step": 669
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3407520055770874,
      "learning_rate": 0.0001745524542829644,
      "loss": 0.7824,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.40860164165496826,
      "learning_rate": 0.00017451395572666025,
      "loss": 0.8027,
      "step": 671
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3064686954021454,
      "learning_rate": 0.00017447545717035612,
      "loss": 0.9002,
      "step": 672
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3411509692668915,
      "learning_rate": 0.00017443695861405197,
      "loss": 0.8394,
      "step": 673
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3462003171443939,
      "learning_rate": 0.00017439846005774784,
      "loss": 0.8784,
      "step": 674
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3487083613872528,
      "learning_rate": 0.00017435996150144372,
      "loss": 0.8504,
      "step": 675
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3693464398384094,
      "learning_rate": 0.00017432146294513957,
      "loss": 0.6981,
      "step": 676
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35222914814949036,
      "learning_rate": 0.00017428296438883541,
      "loss": 0.8873,
      "step": 677
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4253406226634979,
      "learning_rate": 0.0001742444658325313,
      "loss": 0.7945,
      "step": 678
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.34643346071243286,
      "learning_rate": 0.00017420596727622716,
      "loss": 0.7229,
      "step": 679
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.43851718306541443,
      "learning_rate": 0.000174167468719923,
      "loss": 0.7922,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3920727074146271,
      "learning_rate": 0.00017412897016361886,
      "loss": 0.7859,
      "step": 681
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3976938724517822,
      "learning_rate": 0.00017409047160731473,
      "loss": 0.6974,
      "step": 682
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4204944372177124,
      "learning_rate": 0.0001740519730510106,
      "loss": 0.8564,
      "step": 683
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35586726665496826,
      "learning_rate": 0.00017401347449470645,
      "loss": 0.8635,
      "step": 684
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4737916588783264,
      "learning_rate": 0.00017397497593840233,
      "loss": 0.7866,
      "step": 685
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3748070299625397,
      "learning_rate": 0.00017393647738209818,
      "loss": 0.695,
      "step": 686
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36548924446105957,
      "learning_rate": 0.00017389797882579405,
      "loss": 0.716,
      "step": 687
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39750754833221436,
      "learning_rate": 0.0001738594802694899,
      "loss": 0.7952,
      "step": 688
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4891696274280548,
      "learning_rate": 0.00017382098171318577,
      "loss": 0.8809,
      "step": 689
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3966465890407562,
      "learning_rate": 0.00017378248315688162,
      "loss": 1.0013,
      "step": 690
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.47586390376091003,
      "learning_rate": 0.00017374398460057747,
      "loss": 0.7774,
      "step": 691
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4218079149723053,
      "learning_rate": 0.00017370548604427334,
      "loss": 0.9365,
      "step": 692
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4154198467731476,
      "learning_rate": 0.00017366698748796922,
      "loss": 0.8346,
      "step": 693
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4187276363372803,
      "learning_rate": 0.0001736284889316651,
      "loss": 0.676,
      "step": 694
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3848455548286438,
      "learning_rate": 0.0001735899903753609,
      "loss": 0.794,
      "step": 695
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3735641837120056,
      "learning_rate": 0.00017355149181905679,
      "loss": 0.9179,
      "step": 696
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4032048285007477,
      "learning_rate": 0.00017351299326275266,
      "loss": 0.8329,
      "step": 697
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35270655155181885,
      "learning_rate": 0.0001734744947064485,
      "loss": 0.7328,
      "step": 698
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3051532804965973,
      "learning_rate": 0.00017343599615014438,
      "loss": 0.6793,
      "step": 699
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.40052488446235657,
      "learning_rate": 0.00017339749759384023,
      "loss": 0.7087,
      "step": 700
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45748668909072876,
      "learning_rate": 0.0001733589990375361,
      "loss": 0.9148,
      "step": 701
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36851558089256287,
      "learning_rate": 0.00017332050048123195,
      "loss": 0.6898,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34142744541168213,
      "learning_rate": 0.00017328200192492783,
      "loss": 0.8012,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38720953464508057,
      "learning_rate": 0.0001732435033686237,
      "loss": 0.8193,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3785306215286255,
      "learning_rate": 0.00017320500481231955,
      "loss": 0.8876,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.342033326625824,
      "learning_rate": 0.0001731665062560154,
      "loss": 0.9271,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.41306832432746887,
      "learning_rate": 0.00017312800769971127,
      "loss": 0.7448,
      "step": 707
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4203263819217682,
      "learning_rate": 0.00017308950914340715,
      "loss": 0.7572,
      "step": 708
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4670791029930115,
      "learning_rate": 0.000173051010587103,
      "loss": 0.617,
      "step": 709
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5887750387191772,
      "learning_rate": 0.00017301251203079884,
      "loss": 0.8054,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37040165066719055,
      "learning_rate": 0.00017297401347449471,
      "loss": 0.821,
      "step": 711
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3870273530483246,
      "learning_rate": 0.0001729355149181906,
      "loss": 0.8355,
      "step": 712
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.387721985578537,
      "learning_rate": 0.00017289701636188644,
      "loss": 0.5159,
      "step": 713
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3844657838344574,
      "learning_rate": 0.0001728585178055823,
      "loss": 0.7561,
      "step": 714
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3874747157096863,
      "learning_rate": 0.00017282001924927816,
      "loss": 0.6783,
      "step": 715
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34984755516052246,
      "learning_rate": 0.00017278152069297403,
      "loss": 0.785,
      "step": 716
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5564412474632263,
      "learning_rate": 0.00017274302213666988,
      "loss": 0.6845,
      "step": 717
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3845653533935547,
      "learning_rate": 0.00017270452358036575,
      "loss": 0.8413,
      "step": 718
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34572526812553406,
      "learning_rate": 0.0001726660250240616,
      "loss": 0.7811,
      "step": 719
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4227907359600067,
      "learning_rate": 0.00017262752646775745,
      "loss": 0.581,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40575093030929565,
      "learning_rate": 0.00017258902791145332,
      "loss": 0.7286,
      "step": 721
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3517785668373108,
      "learning_rate": 0.0001725505293551492,
      "loss": 0.7326,
      "step": 722
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40482303500175476,
      "learning_rate": 0.00017251203079884505,
      "loss": 0.9867,
      "step": 723
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3650476634502411,
      "learning_rate": 0.0001724735322425409,
      "loss": 0.6963,
      "step": 724
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33829617500305176,
      "learning_rate": 0.00017243503368623677,
      "loss": 0.9104,
      "step": 725
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.35361653566360474,
      "learning_rate": 0.00017239653512993264,
      "loss": 0.5383,
      "step": 726
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.45061513781547546,
      "learning_rate": 0.0001723580365736285,
      "loss": 0.7023,
      "step": 727
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4981588125228882,
      "learning_rate": 0.00017231953801732436,
      "loss": 0.8044,
      "step": 728
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.387322336435318,
      "learning_rate": 0.0001722810394610202,
      "loss": 0.992,
      "step": 729
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5148512721061707,
      "learning_rate": 0.0001722425409047161,
      "loss": 0.7358,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4733924865722656,
      "learning_rate": 0.00017220404234841193,
      "loss": 0.7849,
      "step": 731
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.36829113960266113,
      "learning_rate": 0.0001721655437921078,
      "loss": 0.8421,
      "step": 732
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39594176411628723,
      "learning_rate": 0.00017212704523580368,
      "loss": 0.677,
      "step": 733
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4709170162677765,
      "learning_rate": 0.00017208854667949953,
      "loss": 0.7163,
      "step": 734
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39583051204681396,
      "learning_rate": 0.00017205004812319538,
      "loss": 0.6279,
      "step": 735
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3525935411453247,
      "learning_rate": 0.00017201154956689125,
      "loss": 0.5868,
      "step": 736
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37443339824676514,
      "learning_rate": 0.00017197305101058713,
      "loss": 0.8093,
      "step": 737
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3746035695075989,
      "learning_rate": 0.00017193455245428297,
      "loss": 0.7446,
      "step": 738
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.49442774057388306,
      "learning_rate": 0.00017189605389797882,
      "loss": 0.6681,
      "step": 739
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40556401014328003,
      "learning_rate": 0.0001718575553416747,
      "loss": 0.7086,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38675662875175476,
      "learning_rate": 0.00017181905678537057,
      "loss": 0.8154,
      "step": 741
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6102035641670227,
      "learning_rate": 0.00017178055822906642,
      "loss": 0.6516,
      "step": 742
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.42935019731521606,
      "learning_rate": 0.0001717420596727623,
      "loss": 0.6763,
      "step": 743
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3748353123664856,
      "learning_rate": 0.00017170356111645814,
      "loss": 0.8223,
      "step": 744
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39062535762786865,
      "learning_rate": 0.000171665062560154,
      "loss": 0.6919,
      "step": 745
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38968580961227417,
      "learning_rate": 0.00017162656400384986,
      "loss": 0.7257,
      "step": 746
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.366832971572876,
      "learning_rate": 0.00017158806544754574,
      "loss": 0.8199,
      "step": 747
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4036370515823364,
      "learning_rate": 0.00017154956689124158,
      "loss": 0.9641,
      "step": 748
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39626967906951904,
      "learning_rate": 0.00017151106833493743,
      "loss": 0.8073,
      "step": 749
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4744478464126587,
      "learning_rate": 0.0001714725697786333,
      "loss": 0.7205,
      "step": 750
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3473556935787201,
      "learning_rate": 0.00017143407122232918,
      "loss": 0.893,
      "step": 751
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5023140907287598,
      "learning_rate": 0.00017139557266602503,
      "loss": 0.6788,
      "step": 752
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4513726532459259,
      "learning_rate": 0.00017135707410972088,
      "loss": 0.7294,
      "step": 753
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38579440116882324,
      "learning_rate": 0.00017131857555341675,
      "loss": 0.6912,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.35996872186660767,
      "learning_rate": 0.00017128007699711262,
      "loss": 0.8075,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48586297035217285,
      "learning_rate": 0.00017124157844080847,
      "loss": 0.8389,
      "step": 756
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.335565447807312,
      "learning_rate": 0.00017120307988450435,
      "loss": 0.8229,
      "step": 757
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.42499786615371704,
      "learning_rate": 0.0001711645813282002,
      "loss": 0.8287,
      "step": 758
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47522956132888794,
      "learning_rate": 0.00017112608277189607,
      "loss": 0.7809,
      "step": 759
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47940245270729065,
      "learning_rate": 0.00017108758421559192,
      "loss": 0.5907,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.36606478691101074,
      "learning_rate": 0.0001710490856592878,
      "loss": 0.7638,
      "step": 761
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4483763575553894,
      "learning_rate": 0.00017101058710298366,
      "loss": 0.7139,
      "step": 762
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37084662914276123,
      "learning_rate": 0.00017097208854667949,
      "loss": 0.8148,
      "step": 763
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38737088441848755,
      "learning_rate": 0.00017093358999037536,
      "loss": 0.767,
      "step": 764
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3940127193927765,
      "learning_rate": 0.00017089509143407123,
      "loss": 0.7881,
      "step": 765
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43775805830955505,
      "learning_rate": 0.0001708565928777671,
      "loss": 0.716,
      "step": 766
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4488811194896698,
      "learning_rate": 0.00017081809432146296,
      "loss": 0.6087,
      "step": 767
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43547001481056213,
      "learning_rate": 0.0001707795957651588,
      "loss": 0.7073,
      "step": 768
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43893900513648987,
      "learning_rate": 0.00017074109720885468,
      "loss": 0.8044,
      "step": 769
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.372728556394577,
      "learning_rate": 0.00017070259865255053,
      "loss": 0.6557,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38425034284591675,
      "learning_rate": 0.0001706641000962464,
      "loss": 0.6982,
      "step": 771
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5710627436637878,
      "learning_rate": 0.00017062560153994227,
      "loss": 0.5981,
      "step": 772
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4812089800834656,
      "learning_rate": 0.00017058710298363812,
      "loss": 0.7884,
      "step": 773
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3855699300765991,
      "learning_rate": 0.00017054860442733397,
      "loss": 0.6755,
      "step": 774
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4562559425830841,
      "learning_rate": 0.00017051010587102984,
      "loss": 0.8575,
      "step": 775
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4128674864768982,
      "learning_rate": 0.00017047160731472572,
      "loss": 0.8621,
      "step": 776
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.42607802152633667,
      "learning_rate": 0.00017043310875842157,
      "loss": 0.7904,
      "step": 777
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39994102716445923,
      "learning_rate": 0.0001703946102021174,
      "loss": 0.7393,
      "step": 778
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47832953929901123,
      "learning_rate": 0.0001703561116458133,
      "loss": 0.8006,
      "step": 779
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4949307143688202,
      "learning_rate": 0.00017031761308950916,
      "loss": 0.7873,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3823389410972595,
      "learning_rate": 0.000170279114533205,
      "loss": 0.5423,
      "step": 781
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3938881456851959,
      "learning_rate": 0.00017024061597690086,
      "loss": 0.9979,
      "step": 782
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.36748114228248596,
      "learning_rate": 0.00017020211742059673,
      "loss": 0.7439,
      "step": 783
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3931972086429596,
      "learning_rate": 0.0001701636188642926,
      "loss": 0.8697,
      "step": 784
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.40968993306159973,
      "learning_rate": 0.00017012512030798845,
      "loss": 0.6604,
      "step": 785
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4315906763076782,
      "learning_rate": 0.00017008662175168433,
      "loss": 0.8288,
      "step": 786
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48962411284446716,
      "learning_rate": 0.00017004812319538018,
      "loss": 0.656,
      "step": 787
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3448035418987274,
      "learning_rate": 0.00017000962463907605,
      "loss": 0.9156,
      "step": 788
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32758450508117676,
      "learning_rate": 0.0001699711260827719,
      "loss": 0.6861,
      "step": 789
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32477089762687683,
      "learning_rate": 0.00016993262752646777,
      "loss": 0.9073,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3972192406654358,
      "learning_rate": 0.00016989412897016365,
      "loss": 0.8017,
      "step": 791
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3958989977836609,
      "learning_rate": 0.00016985563041385947,
      "loss": 0.7159,
      "step": 792
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37689006328582764,
      "learning_rate": 0.00016981713185755534,
      "loss": 0.6752,
      "step": 793
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.46549999713897705,
      "learning_rate": 0.00016977863330125122,
      "loss": 0.8251,
      "step": 794
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.45690783858299255,
      "learning_rate": 0.00016974013474494706,
      "loss": 0.7659,
      "step": 795
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3844454884529114,
      "learning_rate": 0.00016970163618864294,
      "loss": 0.8525,
      "step": 796
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37870171666145325,
      "learning_rate": 0.00016966313763233879,
      "loss": 0.6468,
      "step": 797
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4335814416408539,
      "learning_rate": 0.00016962463907603466,
      "loss": 0.7656,
      "step": 798
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.468999445438385,
      "learning_rate": 0.0001695861405197305,
      "loss": 0.8356,
      "step": 799
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3232964277267456,
      "learning_rate": 0.00016954764196342638,
      "loss": 0.8176,
      "step": 800
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4696967303752899,
      "learning_rate": 0.00016950914340712226,
      "loss": 0.7953,
      "step": 801
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3871324062347412,
      "learning_rate": 0.0001694706448508181,
      "loss": 0.6848,
      "step": 802
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4112791121006012,
      "learning_rate": 0.00016943214629451395,
      "loss": 0.708,
      "step": 803
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39461207389831543,
      "learning_rate": 0.00016939364773820983,
      "loss": 0.692,
      "step": 804
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4254642426967621,
      "learning_rate": 0.0001693551491819057,
      "loss": 0.7218,
      "step": 805
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4372923672199249,
      "learning_rate": 0.00016931665062560155,
      "loss": 0.8679,
      "step": 806
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3410716950893402,
      "learning_rate": 0.0001692781520692974,
      "loss": 0.6845,
      "step": 807
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39188075065612793,
      "learning_rate": 0.00016923965351299327,
      "loss": 0.9276,
      "step": 808
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3984350264072418,
      "learning_rate": 0.00016920115495668914,
      "loss": 0.9317,
      "step": 809
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4146293103694916,
      "learning_rate": 0.000169162656400385,
      "loss": 0.7863,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5660368800163269,
      "learning_rate": 0.00016912415784408087,
      "loss": 0.8132,
      "step": 811
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4297594428062439,
      "learning_rate": 0.00016908565928777671,
      "loss": 0.6906,
      "step": 812
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43333521485328674,
      "learning_rate": 0.0001690471607314726,
      "loss": 0.8655,
      "step": 813
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5511271953582764,
      "learning_rate": 0.00016900866217516844,
      "loss": 0.7373,
      "step": 814
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3771804869174957,
      "learning_rate": 0.0001689701636188643,
      "loss": 0.6566,
      "step": 815
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4080510139465332,
      "learning_rate": 0.00016893166506256016,
      "loss": 1.1367,
      "step": 816
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4585743844509125,
      "learning_rate": 0.000168893166506256,
      "loss": 0.6489,
      "step": 817
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3603699207305908,
      "learning_rate": 0.00016885466794995188,
      "loss": 0.804,
      "step": 818
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3835907578468323,
      "learning_rate": 0.00016881616939364775,
      "loss": 0.6746,
      "step": 819
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42422178387641907,
      "learning_rate": 0.00016877767083734363,
      "loss": 0.8467,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39354193210601807,
      "learning_rate": 0.00016873917228103945,
      "loss": 0.7838,
      "step": 821
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3793525695800781,
      "learning_rate": 0.00016870067372473532,
      "loss": 0.7369,
      "step": 822
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3221934735774994,
      "learning_rate": 0.0001686621751684312,
      "loss": 0.8031,
      "step": 823
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3444366455078125,
      "learning_rate": 0.00016862367661212705,
      "loss": 0.7385,
      "step": 824
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44286707043647766,
      "learning_rate": 0.00016858517805582292,
      "loss": 0.8558,
      "step": 825
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3785991370677948,
      "learning_rate": 0.00016854667949951877,
      "loss": 0.6804,
      "step": 826
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35703325271606445,
      "learning_rate": 0.00016850818094321464,
      "loss": 0.8319,
      "step": 827
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3548316955566406,
      "learning_rate": 0.0001684696823869105,
      "loss": 0.9741,
      "step": 828
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4017500579357147,
      "learning_rate": 0.00016843118383060636,
      "loss": 0.8069,
      "step": 829
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42583325505256653,
      "learning_rate": 0.00016839268527430224,
      "loss": 0.811,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43312227725982666,
      "learning_rate": 0.00016835418671799809,
      "loss": 0.8757,
      "step": 831
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40539172291755676,
      "learning_rate": 0.00016831568816169393,
      "loss": 0.981,
      "step": 832
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41632556915283203,
      "learning_rate": 0.0001682771896053898,
      "loss": 0.7313,
      "step": 833
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.532879114151001,
      "learning_rate": 0.00016823869104908568,
      "loss": 0.6457,
      "step": 834
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40394964814186096,
      "learning_rate": 0.00016820019249278153,
      "loss": 0.6489,
      "step": 835
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4110960364341736,
      "learning_rate": 0.00016816169393647738,
      "loss": 1.0254,
      "step": 836
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4686180353164673,
      "learning_rate": 0.00016812319538017325,
      "loss": 0.6832,
      "step": 837
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31215232610702515,
      "learning_rate": 0.00016808469682386913,
      "loss": 0.7572,
      "step": 838
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44114914536476135,
      "learning_rate": 0.00016804619826756497,
      "loss": 0.7516,
      "step": 839
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4628466069698334,
      "learning_rate": 0.00016800769971126085,
      "loss": 0.8312,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.402778685092926,
      "learning_rate": 0.0001679692011549567,
      "loss": 0.6082,
      "step": 841
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4084111750125885,
      "learning_rate": 0.00016793070259865254,
      "loss": 0.857,
      "step": 842
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43011507391929626,
      "learning_rate": 0.00016789220404234842,
      "loss": 0.5912,
      "step": 843
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3666722774505615,
      "learning_rate": 0.0001678537054860443,
      "loss": 0.8075,
      "step": 844
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4387371838092804,
      "learning_rate": 0.00016781520692974014,
      "loss": 0.7016,
      "step": 845
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4301617443561554,
      "learning_rate": 0.000167776708373436,
      "loss": 0.8587,
      "step": 846
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.45435237884521484,
      "learning_rate": 0.00016773820981713186,
      "loss": 0.9283,
      "step": 847
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42567750811576843,
      "learning_rate": 0.00016769971126082774,
      "loss": 0.8345,
      "step": 848
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5085536241531372,
      "learning_rate": 0.00016766121270452358,
      "loss": 0.6658,
      "step": 849
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41667377948760986,
      "learning_rate": 0.00016762271414821943,
      "loss": 0.8367,
      "step": 850
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43233269453048706,
      "learning_rate": 0.0001675842155919153,
      "loss": 0.8026,
      "step": 851
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32341477274894714,
      "learning_rate": 0.00016754571703561118,
      "loss": 0.8264,
      "step": 852
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4784422218799591,
      "learning_rate": 0.00016750721847930703,
      "loss": 0.7404,
      "step": 853
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40146604180336,
      "learning_rate": 0.0001674687199230029,
      "loss": 0.608,
      "step": 854
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3967956602573395,
      "learning_rate": 0.00016743022136669875,
      "loss": 0.7052,
      "step": 855
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43092501163482666,
      "learning_rate": 0.00016739172281039462,
      "loss": 0.8695,
      "step": 856
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3058846592903137,
      "learning_rate": 0.00016735322425409047,
      "loss": 0.9303,
      "step": 857
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3126014173030853,
      "learning_rate": 0.00016731472569778635,
      "loss": 0.7962,
      "step": 858
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4519258141517639,
      "learning_rate": 0.00016727622714148222,
      "loss": 0.9278,
      "step": 859
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3694867193698883,
      "learning_rate": 0.00016723772858517807,
      "loss": 0.8799,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36224937438964844,
      "learning_rate": 0.00016719923002887392,
      "loss": 0.7982,
      "step": 861
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3871414065361023,
      "learning_rate": 0.0001671607314725698,
      "loss": 0.8308,
      "step": 862
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35750070214271545,
      "learning_rate": 0.00016712223291626566,
      "loss": 0.9408,
      "step": 863
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36376670002937317,
      "learning_rate": 0.0001670837343599615,
      "loss": 0.5507,
      "step": 864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.44785165786743164,
      "learning_rate": 0.00016704523580365736,
      "loss": 0.7235,
      "step": 865
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3633347451686859,
      "learning_rate": 0.00016700673724735323,
      "loss": 0.8807,
      "step": 866
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3864636719226837,
      "learning_rate": 0.0001669682386910491,
      "loss": 0.7263,
      "step": 867
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.411888062953949,
      "learning_rate": 0.00016692974013474496,
      "loss": 0.9225,
      "step": 868
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3231404423713684,
      "learning_rate": 0.00016689124157844083,
      "loss": 0.9061,
      "step": 869
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4525030553340912,
      "learning_rate": 0.00016685274302213668,
      "loss": 0.6509,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40726369619369507,
      "learning_rate": 0.00016681424446583253,
      "loss": 0.7813,
      "step": 871
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4267323613166809,
      "learning_rate": 0.0001667757459095284,
      "loss": 0.7504,
      "step": 872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.41709521412849426,
      "learning_rate": 0.00016673724735322427,
      "loss": 0.6476,
      "step": 873
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37306755781173706,
      "learning_rate": 0.00016669874879692012,
      "loss": 0.7741,
      "step": 874
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39880815148353577,
      "learning_rate": 0.00016666025024061597,
      "loss": 0.5553,
      "step": 875
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3532627522945404,
      "learning_rate": 0.00016662175168431184,
      "loss": 0.7507,
      "step": 876
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4160521626472473,
      "learning_rate": 0.00016658325312800772,
      "loss": 0.9009,
      "step": 877
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4004802405834198,
      "learning_rate": 0.00016654475457170357,
      "loss": 0.8608,
      "step": 878
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3720623254776001,
      "learning_rate": 0.0001665062560153994,
      "loss": 0.7846,
      "step": 879
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43344712257385254,
      "learning_rate": 0.0001664677574590953,
      "loss": 0.7161,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35037553310394287,
      "learning_rate": 0.00016642925890279116,
      "loss": 0.7835,
      "step": 881
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4126090407371521,
      "learning_rate": 0.000166390760346487,
      "loss": 0.7939,
      "step": 882
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3827371299266815,
      "learning_rate": 0.00016635226179018288,
      "loss": 0.7974,
      "step": 883
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4822234511375427,
      "learning_rate": 0.00016631376323387873,
      "loss": 0.6339,
      "step": 884
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3417407274246216,
      "learning_rate": 0.0001662752646775746,
      "loss": 0.8654,
      "step": 885
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35460445284843445,
      "learning_rate": 0.00016623676612127045,
      "loss": 0.5415,
      "step": 886
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3304254114627838,
      "learning_rate": 0.00016619826756496633,
      "loss": 0.694,
      "step": 887
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3509129285812378,
      "learning_rate": 0.0001661597690086622,
      "loss": 0.7794,
      "step": 888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3687591254711151,
      "learning_rate": 0.00016612127045235802,
      "loss": 0.9093,
      "step": 889
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3833083510398865,
      "learning_rate": 0.0001660827718960539,
      "loss": 0.7691,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3668593168258667,
      "learning_rate": 0.00016604427333974977,
      "loss": 0.7972,
      "step": 891
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38549745082855225,
      "learning_rate": 0.00016600577478344565,
      "loss": 0.7949,
      "step": 892
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4266708195209503,
      "learning_rate": 0.0001659672762271415,
      "loss": 0.8721,
      "step": 893
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39876678586006165,
      "learning_rate": 0.00016592877767083734,
      "loss": 0.763,
      "step": 894
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.445230096578598,
      "learning_rate": 0.00016589027911453322,
      "loss": 0.7947,
      "step": 895
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4430351257324219,
      "learning_rate": 0.00016585178055822906,
      "loss": 0.7779,
      "step": 896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4220488965511322,
      "learning_rate": 0.00016581328200192494,
      "loss": 0.7641,
      "step": 897
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.45670175552368164,
      "learning_rate": 0.0001657747834456208,
      "loss": 0.5795,
      "step": 898
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.34386640787124634,
      "learning_rate": 0.00016573628488931666,
      "loss": 0.9229,
      "step": 899
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4725986123085022,
      "learning_rate": 0.0001656977863330125,
      "loss": 0.7,
      "step": 900
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39845186471939087,
      "learning_rate": 0.00016565928777670838,
      "loss": 0.8275,
      "step": 901
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3908142149448395,
      "learning_rate": 0.00016562078922040426,
      "loss": 0.7597,
      "step": 902
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38814297318458557,
      "learning_rate": 0.0001655822906641001,
      "loss": 0.8163,
      "step": 903
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5420342087745667,
      "learning_rate": 0.00016554379210779595,
      "loss": 0.7512,
      "step": 904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43442463874816895,
      "learning_rate": 0.00016550529355149183,
      "loss": 0.6853,
      "step": 905
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3723842203617096,
      "learning_rate": 0.0001654667949951877,
      "loss": 0.7244,
      "step": 906
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39102187752723694,
      "learning_rate": 0.00016542829643888355,
      "loss": 0.6404,
      "step": 907
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4673289954662323,
      "learning_rate": 0.0001653897978825794,
      "loss": 0.7157,
      "step": 908
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3619476854801178,
      "learning_rate": 0.00016535129932627527,
      "loss": 0.6714,
      "step": 909
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35128358006477356,
      "learning_rate": 0.00016531280076997114,
      "loss": 0.7696,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4009929597377777,
      "learning_rate": 0.000165274302213667,
      "loss": 0.6706,
      "step": 911
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4207339882850647,
      "learning_rate": 0.00016523580365736287,
      "loss": 0.7959,
      "step": 912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3549601137638092,
      "learning_rate": 0.0001651973051010587,
      "loss": 0.8371,
      "step": 913
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3207203447818756,
      "learning_rate": 0.00016515880654475456,
      "loss": 0.8151,
      "step": 914
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3994414806365967,
      "learning_rate": 0.00016512030798845044,
      "loss": 0.65,
      "step": 915
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3931208550930023,
      "learning_rate": 0.0001650818094321463,
      "loss": 0.704,
      "step": 916
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3657586872577667,
      "learning_rate": 0.00016504331087584218,
      "loss": 0.7944,
      "step": 917
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.49718624353408813,
      "learning_rate": 0.000165004812319538,
      "loss": 0.8918,
      "step": 918
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4042849838733673,
      "learning_rate": 0.00016496631376323388,
      "loss": 0.7726,
      "step": 919
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43885496258735657,
      "learning_rate": 0.00016492781520692975,
      "loss": 0.7369,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.395626038312912,
      "learning_rate": 0.0001648893166506256,
      "loss": 0.7727,
      "step": 921
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3479551672935486,
      "learning_rate": 0.00016485081809432148,
      "loss": 0.7626,
      "step": 922
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4263276755809784,
      "learning_rate": 0.00016481231953801732,
      "loss": 0.6324,
      "step": 923
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4631369709968567,
      "learning_rate": 0.0001647738209817132,
      "loss": 0.7791,
      "step": 924
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4488198459148407,
      "learning_rate": 0.00016473532242540905,
      "loss": 0.8926,
      "step": 925
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3350141942501068,
      "learning_rate": 0.00016469682386910492,
      "loss": 0.8875,
      "step": 926
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39391931891441345,
      "learning_rate": 0.0001646583253128008,
      "loss": 0.7004,
      "step": 927
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4591343402862549,
      "learning_rate": 0.00016461982675649664,
      "loss": 0.7825,
      "step": 928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.38827601075172424,
      "learning_rate": 0.0001645813282001925,
      "loss": 0.6996,
      "step": 929
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5408360958099365,
      "learning_rate": 0.00016454282964388836,
      "loss": 0.7021,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4326247274875641,
      "learning_rate": 0.00016450433108758424,
      "loss": 0.6435,
      "step": 931
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4867457449436188,
      "learning_rate": 0.00016446583253128009,
      "loss": 0.7597,
      "step": 932
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3760989308357239,
      "learning_rate": 0.00016442733397497593,
      "loss": 0.6706,
      "step": 933
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3735730051994324,
      "learning_rate": 0.0001643888354186718,
      "loss": 0.7442,
      "step": 934
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.38337427377700806,
      "learning_rate": 0.00016435033686236768,
      "loss": 0.7391,
      "step": 935
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5188639163970947,
      "learning_rate": 0.00016431183830606353,
      "loss": 0.7199,
      "step": 936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.37170079350471497,
      "learning_rate": 0.0001642733397497594,
      "loss": 0.7128,
      "step": 937
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.36097222566604614,
      "learning_rate": 0.00016423484119345525,
      "loss": 0.8414,
      "step": 938
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43014106154441833,
      "learning_rate": 0.00016419634263715113,
      "loss": 0.7604,
      "step": 939
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4507324695587158,
      "learning_rate": 0.00016415784408084697,
      "loss": 0.8167,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4373815655708313,
      "learning_rate": 0.00016411934552454285,
      "loss": 0.7081,
      "step": 941
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40306782722473145,
      "learning_rate": 0.0001640808469682387,
      "loss": 0.6262,
      "step": 942
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4570135176181793,
      "learning_rate": 0.00016404234841193454,
      "loss": 0.7642,
      "step": 943
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46375465393066406,
      "learning_rate": 0.00016400384985563042,
      "loss": 0.7348,
      "step": 944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5628307461738586,
      "learning_rate": 0.0001639653512993263,
      "loss": 0.4934,
      "step": 945
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3285540044307709,
      "learning_rate": 0.00016392685274302214,
      "loss": 0.7409,
      "step": 946
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4342636466026306,
      "learning_rate": 0.000163888354186718,
      "loss": 0.6037,
      "step": 947
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46476995944976807,
      "learning_rate": 0.00016384985563041386,
      "loss": 0.7684,
      "step": 948
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.384127140045166,
      "learning_rate": 0.00016381135707410974,
      "loss": 0.722,
      "step": 949
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3942120373249054,
      "learning_rate": 0.00016377285851780558,
      "loss": 0.8695,
      "step": 950
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.352477103471756,
      "learning_rate": 0.00016373435996150146,
      "loss": 0.8088,
      "step": 951
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.35834285616874695,
      "learning_rate": 0.0001636958614051973,
      "loss": 0.7048,
      "step": 952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4362132251262665,
      "learning_rate": 0.00016365736284889318,
      "loss": 0.7584,
      "step": 953
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5655164122581482,
      "learning_rate": 0.00016361886429258903,
      "loss": 0.7591,
      "step": 954
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3786676824092865,
      "learning_rate": 0.0001635803657362849,
      "loss": 0.7533,
      "step": 955
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.432732492685318,
      "learning_rate": 0.00016354186717998078,
      "loss": 0.8608,
      "step": 956
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5503681898117065,
      "learning_rate": 0.00016350336862367662,
      "loss": 0.8209,
      "step": 957
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3569778800010681,
      "learning_rate": 0.00016346487006737247,
      "loss": 0.9292,
      "step": 958
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4056509733200073,
      "learning_rate": 0.00016342637151106835,
      "loss": 0.771,
      "step": 959
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.397250235080719,
      "learning_rate": 0.00016338787295476422,
      "loss": 0.8156,
      "step": 960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.401607483625412,
      "learning_rate": 0.00016334937439846007,
      "loss": 0.9892,
      "step": 961
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4879361093044281,
      "learning_rate": 0.00016331087584215591,
      "loss": 0.6769,
      "step": 962
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5391526222229004,
      "learning_rate": 0.0001632723772858518,
      "loss": 0.8177,
      "step": 963
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49405503273010254,
      "learning_rate": 0.00016323387872954766,
      "loss": 0.8344,
      "step": 964
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4291273057460785,
      "learning_rate": 0.0001631953801732435,
      "loss": 0.7129,
      "step": 965
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4620632827281952,
      "learning_rate": 0.00016315688161693939,
      "loss": 0.6563,
      "step": 966
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4600706100463867,
      "learning_rate": 0.00016311838306063523,
      "loss": 0.7658,
      "step": 967
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41418954730033875,
      "learning_rate": 0.00016307988450433108,
      "loss": 0.9749,
      "step": 968
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.31654787063598633,
      "learning_rate": 0.00016304138594802696,
      "loss": 0.802,
      "step": 969
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3953390121459961,
      "learning_rate": 0.00016300288739172283,
      "loss": 0.7323,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45991116762161255,
      "learning_rate": 0.00016296438883541868,
      "loss": 0.637,
      "step": 971
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.31873950362205505,
      "learning_rate": 0.00016292589027911452,
      "loss": 0.6832,
      "step": 972
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4046448767185211,
      "learning_rate": 0.0001628873917228104,
      "loss": 0.7325,
      "step": 973
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37110888957977295,
      "learning_rate": 0.00016284889316650627,
      "loss": 0.8734,
      "step": 974
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44934526085853577,
      "learning_rate": 0.00016281039461020212,
      "loss": 0.8081,
      "step": 975
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35538485646247864,
      "learning_rate": 0.00016277189605389797,
      "loss": 0.9444,
      "step": 976
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3702569007873535,
      "learning_rate": 0.00016273339749759384,
      "loss": 0.6102,
      "step": 977
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.32300740480422974,
      "learning_rate": 0.00016269489894128972,
      "loss": 0.7059,
      "step": 978
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.38859209418296814,
      "learning_rate": 0.00016265640038498556,
      "loss": 0.6427,
      "step": 979
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4092036187648773,
      "learning_rate": 0.00016261790182868144,
      "loss": 0.7174,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3881808817386627,
      "learning_rate": 0.0001625794032723773,
      "loss": 0.7007,
      "step": 981
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3992134630680084,
      "learning_rate": 0.00016254090471607316,
      "loss": 0.8398,
      "step": 982
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.46422716975212097,
      "learning_rate": 0.000162502406159769,
      "loss": 0.769,
      "step": 983
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.43485212326049805,
      "learning_rate": 0.00016246390760346488,
      "loss": 0.7374,
      "step": 984
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48495355248451233,
      "learning_rate": 0.00016242540904716076,
      "loss": 0.8433,
      "step": 985
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3639756739139557,
      "learning_rate": 0.0001623869104908566,
      "loss": 0.7457,
      "step": 986
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40549436211586,
      "learning_rate": 0.00016234841193455245,
      "loss": 0.596,
      "step": 987
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.36418217420578003,
      "learning_rate": 0.00016230991337824833,
      "loss": 0.742,
      "step": 988
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40171492099761963,
      "learning_rate": 0.0001622714148219442,
      "loss": 0.6389,
      "step": 989
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37999212741851807,
      "learning_rate": 0.00016223291626564005,
      "loss": 0.8567,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35829946398735046,
      "learning_rate": 0.0001621944177093359,
      "loss": 0.7595,
      "step": 991
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41418832540512085,
      "learning_rate": 0.00016215591915303177,
      "loss": 0.7844,
      "step": 992
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.33283162117004395,
      "learning_rate": 0.00016211742059672762,
      "loss": 0.7621,
      "step": 993
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41083329916000366,
      "learning_rate": 0.0001620789220404235,
      "loss": 0.7489,
      "step": 994
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4054572880268097,
      "learning_rate": 0.00016204042348411937,
      "loss": 0.9847,
      "step": 995
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48309609293937683,
      "learning_rate": 0.00016200192492781522,
      "loss": 0.7008,
      "step": 996
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3439509868621826,
      "learning_rate": 0.00016196342637151106,
      "loss": 0.8005,
      "step": 997
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4324743449687958,
      "learning_rate": 0.00016192492781520694,
      "loss": 0.8275,
      "step": 998
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41427528858184814,
      "learning_rate": 0.0001618864292589028,
      "loss": 0.6806,
      "step": 999
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4183162450790405,
      "learning_rate": 0.00016184793070259866,
      "loss": 0.8269,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 5.410716022972416e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

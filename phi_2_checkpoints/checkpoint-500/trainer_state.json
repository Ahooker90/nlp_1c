{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.09614922359501947,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.9766390323638916,
      "learning_rate": 4e-05,
      "loss": 1.7634,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.435124397277832,
      "learning_rate": 8e-05,
      "loss": 1.6829,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.5236518383026123,
      "learning_rate": 0.00012,
      "loss": 1.6805,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1257619857788086,
      "learning_rate": 0.00016,
      "loss": 1.7545,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.0642006397247314,
      "learning_rate": 0.0002,
      "loss": 1.6766,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.411266565322876,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.5088,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.639124631881714,
      "learning_rate": 0.00019992300288739173,
      "loss": 1.2468,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2554538249969482,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.0573,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1159424781799316,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.182,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9325945377349854,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.0295,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9144940376281738,
      "learning_rate": 0.00019976900866217518,
      "loss": 0.8971,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.706571340560913,
      "learning_rate": 0.00019973051010587105,
      "loss": 0.7713,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.6338694095611572,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.0035,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.232801079750061,
      "learning_rate": 0.00019965351299326277,
      "loss": 0.8582,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3732980489730835,
      "learning_rate": 0.00019961501443695862,
      "loss": 0.6596,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1462560892105103,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9916,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0849612951278687,
      "learning_rate": 0.00019953801732435037,
      "loss": 0.8837,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2592130899429321,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.9541,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2652932405471802,
      "learning_rate": 0.00019946102021174206,
      "loss": 0.9224,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3635163307189941,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.7145,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.273509979248047,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9682,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0948615074157715,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.6891,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.515223979949951,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.7041,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4680339097976685,
      "learning_rate": 0.00019926852743022138,
      "loss": 0.83,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2920639514923096,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.7418,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4675650596618652,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8998,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.405659794807434,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.5813,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2196124792099,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.7399,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.995840072631836,
      "learning_rate": 0.00019907603464870067,
      "loss": 1.1377,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8859715461730957,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.6972,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2927278280258179,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7877,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2092667818069458,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.924,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0641872882843018,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.844,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2754861116409302,
      "learning_rate": 0.00019888354186718,
      "loss": 0.833,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4720009565353394,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.6683,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1312196254730225,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7498,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4843389987945557,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.6933,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.737054467201233,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.8828,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.621341347694397,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.9389,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.10187566280365,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.6188,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1402729749679565,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.705,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.300221562385559,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.7825,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.351014494895935,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.691,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.7262177467346191,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.7756,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4864147901535034,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7574,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5389310121536255,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.7553,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6697019338607788,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.4816,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8021868467330933,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.5162,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5151989459991455,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.8018,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4660720825195312,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7437,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4324597120285034,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7255,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3882066011428833,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.7743,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1289256811141968,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.5449,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6433510780334473,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.615,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0964218378067017,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.9441,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0598076581954956,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.599,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1570210456848145,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.9157,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3224908113479614,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.757,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.027965545654297,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.9405,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0639221668243408,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8265,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3123269081115723,
      "learning_rate": 0.00019784408084696825,
      "loss": 1.1054,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0593514442443848,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.6289,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.927435576915741,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.8563,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.122362732887268,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.7896,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4112809896469116,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.6135,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1536827087402344,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7691,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2973562479019165,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.662,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1758365631103516,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.5567,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4415098428726196,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.6663,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4505945444107056,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.83,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0297611951828003,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.9364,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3291810750961304,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.5379,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4843671321868896,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.6709,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2337127923965454,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.4647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9915568828582764,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.6439,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1892094612121582,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7327,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4218144416809082,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.7468,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8900254964828491,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.5615,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2152378559112549,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.5918,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1518409252166748,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.7118,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9143003225326538,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.8193,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0710068941116333,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.5147,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.87776780128479,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.8635,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2822787761688232,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.6298,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.026825189590454,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.9106,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1366348266601562,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.9373,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3177250623703003,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.7351,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2249926328659058,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.5835,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.808040738105774,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.6813,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.277226209640503,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.5897,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3442306518554688,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7905,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1461127996444702,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.8015,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9360058903694153,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.8105,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2209837436676025,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7686,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0291593074798584,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.9542,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8803523182868958,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9003,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8462835550308228,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.6453,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.5406043529510498,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7514,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.086790084838867,
      "learning_rate": 0.000196381135707411,
      "loss": 0.6565,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8038688898086548,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8815,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7158440351486206,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.7875,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2155958414077759,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7357,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.961394727230072,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.8628,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.96473228931427,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.6931,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9059011340141296,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.7431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.253554344177246,
      "learning_rate": 0.000196111645813282,
      "loss": 0.716,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8613760471343994,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.9859,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2081166505813599,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.6575,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0867011547088623,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.7505,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1116654872894287,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.492,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4465603828430176,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.7577,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.988479733467102,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.6687,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8707459568977356,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8801,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4584712982177734,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.7284,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1217535734176636,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.6554,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6862573623657227,
      "learning_rate": 0.00019572666025024062,
      "loss": 0.7971,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4024852514266968,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.395,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3252756595611572,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.6865,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.124302864074707,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.4668,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1343193054199219,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.5322,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6102299690246582,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.575,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9591246843338013,
      "learning_rate": 0.00019549566891241578,
      "loss": 1.023,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0329092741012573,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.8113,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0736831426620483,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.4766,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9227723479270935,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.5173,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8723241090774536,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.8905,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6511275768280029,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.7647,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.005831003189087,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.7374,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8661340475082397,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.669,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7919161915779114,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7387,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0209808349609375,
      "learning_rate": 0.00019514918190567855,
      "loss": 1.0741,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.164157748222351,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.7856,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9031721949577332,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.6197,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9569196105003357,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.8645,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0174713134765625,
      "learning_rate": 0.000194995187680462,
      "loss": 0.793,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0296181440353394,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.7721,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8890597820281982,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.5771,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8176144957542419,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.9459,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8257383704185486,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.6564,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7403143644332886,
      "learning_rate": 0.0001948026948989413,
      "loss": 1.0655,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0076433420181274,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.517,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8821527361869812,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.7529,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": Infinity,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.9055,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.923977255821228,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5808,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8217901587486267,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7364,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9798531532287598,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.6119,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6735888719558716,
      "learning_rate": 0.00019457170356111648,
      "loss": 1.0526,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7803233861923218,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.8075,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1770597696304321,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.8079,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0164283514022827,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.4754,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9601749777793884,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.6892,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8489695191383362,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.5216,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7636417746543884,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.6582,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1955299377441406,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.4717,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8320456147193909,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.7358,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0133183002471924,
      "learning_rate": 0.0001942252165543792,
      "loss": 1.0343,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0720036029815674,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.5315,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0775949954986572,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6193,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7920546531677246,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.7595,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3015785217285156,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.9733,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8165020942687988,
      "learning_rate": 0.00019403272377285853,
      "loss": 0.7597,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4158751964569092,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.568,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.2686575651168823,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.6968,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3919662237167358,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8041,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9166744351387024,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.6156,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.136273741722107,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7026,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8245551586151123,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.8833,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9562796950340271,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.7529,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9529739022254944,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.8045,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4480829238891602,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.6155,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0233687162399292,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.6041,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7334891557693481,
      "learning_rate": 0.000193609239653513,
      "loss": 0.9663,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7895396947860718,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8324,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7623308300971985,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.8914,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8783438205718994,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.5553,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8427506685256958,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.5809,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.565274715423584,
      "learning_rate": 0.0001934167468719923,
      "loss": 1.1704,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8487130403518677,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.8637,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7599690556526184,
      "learning_rate": 0.00019333974975938403,
      "loss": 1.0428,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6733267307281494,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8145,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8760805130004883,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6674,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7678978443145752,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.6376,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7904714941978455,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6513,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7921337485313416,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.5813,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9006468057632446,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.8312,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9150775671005249,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.5722,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9657385349273682,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.7529,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.839449405670166,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.6083,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1582216024398804,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7123,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.140467882156372,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7309,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9428714513778687,
      "learning_rate": 0.00019287776708373439,
      "loss": 0.6775,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1014231443405151,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.4118,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0334292650222778,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.65,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1933209896087646,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6013,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8265478610992432,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7071,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8585402369499207,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.5727,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.787067711353302,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.7735,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1874279975891113,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.7179,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.971271276473999,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.6993,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.236193895339966,
      "learning_rate": 0.00019253128007699712,
      "loss": 1.0061,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9123310446739197,
      "learning_rate": 0.000192492781520693,
      "loss": 0.8033,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6489309072494507,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.7415,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0011146068572998,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.5747,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8328598737716675,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.5537,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.791504442691803,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7737,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7130611538887024,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.6439,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7929614186286926,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.755,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8132526278495789,
      "learning_rate": 0.000192223291626564,
      "loss": 0.6144,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9258521795272827,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7335,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9880536794662476,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.5069,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8288092613220215,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.7903,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9645191431045532,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.5626,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.09334397315979,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.5528,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7808449268341064,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.6246,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9576950073242188,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.552,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8885469436645508,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.6746,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9373623728752136,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7364,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6853724122047424,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.8125,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9469802975654602,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.6254,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0501898527145386,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.6862,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8763583302497864,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.8578,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.920737087726593,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.8214,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6409149765968323,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.6631,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8207921385765076,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.6582,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0325123071670532,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.5805,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9549276828765869,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.5267,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2399728298187256,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.7764,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7685335874557495,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.7752,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9186263680458069,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.6403,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1575677394866943,
      "learning_rate": 0.00019137632338787298,
      "loss": 1.0128,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6230560541152954,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.8143,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6135293841362,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.9284,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9068969488143921,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.7929,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0303515195846558,
      "learning_rate": 0.00019122232916265642,
      "loss": 1.0166,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8789127469062805,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.828,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.932952880859375,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.7154,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3748090267181396,
      "learning_rate": 0.000191106833493744,
      "loss": 0.4858,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7238903641700745,
      "learning_rate": 0.00019106833493743986,
      "loss": 1.0197,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8612135052680969,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.6402,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0058850049972534,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.5625,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7587082982063293,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.7146,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8537068963050842,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.6575,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8969892263412476,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.6438,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6655741333961487,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7692,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6944710612297058,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.8478,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8596721887588501,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.5002,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.586476445198059,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.5461,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0440481901168823,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.6742,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8207206726074219,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.6833,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0530555248260498,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.5616,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7683369517326355,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.5294,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0457940101623535,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.6963,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6145095825195312,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8594,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8121146559715271,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.6559,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.220907211303711,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.5442,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7089275121688843,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.7317,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9419508576393127,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.8281,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.628293514251709,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7145,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7072062492370605,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.683,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7283824682235718,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.8467,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1346855163574219,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.6207,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7329082489013672,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.6492,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7539021372795105,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.5169,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6919435262680054,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7795,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9497821927070618,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7684,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7363495230674744,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.7672,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7237761616706848,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.6591,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6229631304740906,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.8745,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.452817440032959,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.6145,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6157515048980713,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.744,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9306153059005737,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.4724,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1150598526000977,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.9032,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8624481558799744,
      "learning_rate": 0.000189720885466795,
      "loss": 0.7131,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7226539850234985,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.8181,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7369751930236816,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.7088,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8418794274330139,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7236,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.08870530128479,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.5989,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7107866406440735,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.6236,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9303227066993713,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5213,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6057505011558533,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9274,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7860249876976013,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.5527,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8407137393951416,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.438,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.788601279258728,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.5906,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7538231015205383,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.4701,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7311952710151672,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.6179,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0561766624450684,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.4345,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6438183188438416,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.8134,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.743452250957489,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.536,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5953269600868225,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.7504,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6800954341888428,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.5422,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7698876857757568,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.4952,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7443271279335022,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.8343,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2300752401351929,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.6186,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8002804517745972,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.5712,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0497325658798218,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.845,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6107672452926636,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8377,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7461987137794495,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.8034,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7233768105506897,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8044,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9682684540748596,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.8155,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0884222984313965,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.8066,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8505268692970276,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.4212,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8903761506080627,
      "learning_rate": 0.000188604427333975,
      "loss": 0.4617,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8329160213470459,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.646,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7580491900444031,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.6545,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5973345041275024,
      "learning_rate": 0.00018848893166506256,
      "loss": 1.0677,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7318881750106812,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.6773,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7885010838508606,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.7792,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8507166504859924,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.9515,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6224185824394226,
      "learning_rate": 0.000188334937439846,
      "loss": 0.793,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.718784511089325,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6929,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8589291572570801,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.8126,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8662039637565613,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.4193,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5792511701583862,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.5858,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8806815147399902,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.5773,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8599536418914795,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.6636,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5740275979042053,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.9467,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6886740326881409,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.8395,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9049243330955505,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.6245,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7558502554893494,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.688,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8135894536972046,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6968,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8597134947776794,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.5344,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6497805714607239,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.7432,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.624045193195343,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.5921,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7488207817077637,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.9047,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2660577297210693,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.5851,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1815978288650513,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.5468,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6585094928741455,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.5055,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6599869728088379,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.8755,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8747279644012451,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.9256,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0177969932556152,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.2889,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8498440980911255,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7156,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6891127228736877,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.7287,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7740240693092346,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.8368,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7449020743370056,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.4807,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4376306533813477,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.9404,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.736077070236206,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8668,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6683731079101562,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.6029,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7797954082489014,
      "learning_rate": 0.000187218479307026,
      "loss": 0.5901,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5687959790229797,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8516,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6512517333030701,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7347,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.565966010093689,
      "learning_rate": 0.00018710298363811359,
      "loss": 1.0649,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9909862279891968,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.4288,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7884112596511841,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.6397,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7323040962219238,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7309,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7657570242881775,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.8031,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8743228316307068,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6299,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9807490110397339,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6752,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7816490530967712,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.7282,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6959101557731628,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.6651,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7261993288993835,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8877,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6144199371337891,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.8319,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6571177244186401,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.7135,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0807875394821167,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7566,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8185086846351624,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.5601,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6865718960762024,
      "learning_rate": 0.00018656400384985564,
      "loss": 1.1941,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7527123689651489,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.6283,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.633386492729187,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.7949,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7434275150299072,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.749,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3395079374313354,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.9689,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6887421011924744,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.7547,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5965858697891235,
      "learning_rate": 0.0001863330125120308,
      "loss": 1.0431,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9297249913215637,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.809,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5710415244102478,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6837,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.623849093914032,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.7247,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9221763014793396,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.518,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.48956894874572754,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.8311,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5858659744262695,
      "learning_rate": 0.000186102021174206,
      "loss": 0.7148,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9408402442932129,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.6661,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8599625825881958,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.4558,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6531791090965271,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.7232,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7258799076080322,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.6838,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7172141671180725,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.6849,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5655890107154846,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.8398,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5579836964607239,
      "learning_rate": 0.000185832531280077,
      "loss": 0.8208,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8500748872756958,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.7686,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7076826095581055,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.646,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.750829815864563,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.5834,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7004405856132507,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.6413,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6903966665267944,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.6479,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.628515362739563,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7402,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.009565830230713,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.5636,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.736901044845581,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.6898,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8011174201965332,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.9058,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5748683214187622,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.684,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6112973093986511,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.6892,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8286272883415222,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7102,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.933481752872467,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.4317,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7664060592651367,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8973,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.57676100730896,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7021,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7917118668556213,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7848,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9117770791053772,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.456,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8564830422401428,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.3618,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9490712285041809,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.5153,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7518885731697083,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.7539,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7193209528923035,
      "learning_rate": 0.0001850240615976901,
      "loss": 1.0002,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7111209034919739,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7467,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9438728094100952,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6184,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8447867631912231,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.9111,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5188901424407959,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.6593,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7598814368247986,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.881,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5978820323944092,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.6949,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7871193885803223,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.5207,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7425273060798645,
      "learning_rate": 0.000184716073147257,
      "loss": 0.8033,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5325318574905396,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7403,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6582126021385193,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.6868,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5985537767410278,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.704,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8908801674842834,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.719,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7575201392173767,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.7543,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8175365328788757,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.6602,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6037975549697876,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8361,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5509572625160217,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.4216,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7482405304908752,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.3945,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8625118136405945,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.7002,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7192174792289734,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6841,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7142515182495117,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.6865,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7495271563529968,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.7471,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7775553464889526,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.6908,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5583651065826416,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.5281,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7792724370956421,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6543,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6158411502838135,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7052,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7116422653198242,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.8469,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2091479301452637,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.687,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8763923048973083,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.701,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7194721102714539,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5902,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.622972846031189,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.7281,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8785674571990967,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.7788,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.561694860458374,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.7398,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5931367874145508,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.9208,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8336869478225708,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.4492,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7663393616676331,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6691,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6989089846611023,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.8855,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5969981551170349,
      "learning_rate": 0.00018359961501443698,
      "loss": 0.8035,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.556025505065918,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.9405,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5868527293205261,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.927,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.747269332408905,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7711,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5778203010559082,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.5097,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7665207982063293,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7753,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6795540452003479,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.6638,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7306339144706726,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.4294,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.641844630241394,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.6496,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.660853385925293,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.5296,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7177244424819946,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.4683,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2018318176269531,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.9297,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8318695425987244,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.6177,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5980833172798157,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.5037,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7439042329788208,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7146,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8085542917251587,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.6122,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6640565395355225,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.5139,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0524460077285767,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.7783,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.617692232131958,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.9802,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.122811198234558,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.6802,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8143771290779114,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.6618,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6935192346572876,
      "learning_rate": 0.00018279114533205007,
      "loss": 1.1362,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7444424033164978,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8607,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5704548358917236,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5804,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5939321517944336,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.7454,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.974220335483551,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.5903,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.843052864074707,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.6173,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6161561012268066,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.5802,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8895635008811951,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.3974,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5754928588867188,
      "learning_rate": 0.00018248315688161696,
      "loss": 0.7096,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7855966091156006,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7746,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6445358395576477,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7296,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5740096569061279,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8779,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7613345384597778,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.5638,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7333557605743408,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.5855,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7124179005622864,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.7167,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.638280987739563,
      "learning_rate": 0.000182213666987488,
      "loss": 0.9548,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9654234051704407,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.7242,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7197368144989014,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.6723,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5494047999382019,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8031,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5353728532791138,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.8029,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6315490007400513,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.5837,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7555389404296875,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7125,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8384435772895813,
      "learning_rate": 0.000181944177093359,
      "loss": 0.5034,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5619967579841614,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8396,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7444220185279846,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.8219,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5551384091377258,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.7687,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7309958338737488,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.6539,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.614891767501831,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.5977,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7716305255889893,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7605,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7078102827072144,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8178,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7726227641105652,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.7639,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.777751624584198,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.6402,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9366869926452637,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.8419,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7884979248046875,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.4486,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8710904121398926,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.5999,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6384978294372559,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7706,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7797781825065613,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.5892,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6219421029090881,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.6704,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9979626536369324,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.4893,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6125726699829102,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.5604,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6936690807342529,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.6456,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6553232073783875,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.8872,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7319735288619995,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.5098,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6700308918952942,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8333,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8183261156082153,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6948,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9010966420173645,
      "learning_rate": 0.0001810587102983638,
      "loss": 0.3522,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9813642501831055,
      "learning_rate": 0.00018102021174205968,
      "loss": 0.5139,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.735927939414978,
      "learning_rate": 0.00018098171318575555,
      "loss": 0.9666,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 9448464251842560.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9614922359501947,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0,
      "loss": 2.098,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.457374572753906,
      "learning_rate": 4e-05,
      "loss": 2.1917,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7966217994689941,
      "learning_rate": 8e-05,
      "loss": 2.0472,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 8e-05,
      "loss": 2.1569,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.239715099334717,
      "learning_rate": 0.00012,
      "loss": 2.1789,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.806528091430664,
      "learning_rate": 0.00016,
      "loss": 1.9093,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7827303409576416,
      "learning_rate": 0.0002,
      "loss": 1.9295,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7811224460601807,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.9561,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.6722819805145264,
      "learning_rate": 0.00019992300288739173,
      "loss": 2.0285,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1149275302886963,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.6257,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7799516916275024,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.8609,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.874711513519287,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.586,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.246931314468384,
      "learning_rate": 0.00019976900866217518,
      "loss": 1.5202,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0075149536132812,
      "learning_rate": 0.00019973051010587105,
      "loss": 1.2222,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4524502754211426,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.2517,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.251847743988037,
      "learning_rate": 0.00019965351299326277,
      "loss": 1.2791,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.737441062927246,
      "learning_rate": 0.00019961501443695862,
      "loss": 1.2863,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.00286865234375,
      "learning_rate": 0.0001995765158806545,
      "loss": 1.103,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9747,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.114648818969727,
      "learning_rate": 0.00019953801732435037,
      "loss": 1.0495,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.003035545349121,
      "learning_rate": 0.0001994995187680462,
      "loss": 1.1688,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.8911,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.781760215759277,
      "learning_rate": 0.00019946102021174206,
      "loss": 1.0611,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.519819736480713,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.9427,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.247189998626709,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9676,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0819637775421143,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.8659,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0306124687194824,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.9604,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1556403636932373,
      "learning_rate": 0.00019926852743022138,
      "loss": 1.0219,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9903797507286072,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.9448,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8551985025405884,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8887,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9833319783210754,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.9098,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8927335143089294,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.8427,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3464423418045044,
      "learning_rate": 0.00019907603464870067,
      "loss": 0.9411,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1088123321533203,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.8362,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.443970799446106,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7319,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0620180368423462,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.8502,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8205506801605225,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.8464,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.026169776916504,
      "learning_rate": 0.00019888354186718,
      "loss": 0.858,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7239542603492737,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.8742,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8644108772277832,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7656,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6905569434165955,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.8372,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8827759623527527,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.7281,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5555065870285034,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.8572,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42273494601249695,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.8768,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5444644689559937,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.7526,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6326220035552979,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.6473,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6100513935089111,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.7474,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8508883714675903,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.8062,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.555642306804657,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7822,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6031041741371155,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.9466,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.612458348274231,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.8309,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6748793721199036,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.8421,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4463978111743927,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.6661,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6735567450523376,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7187,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5610448122024536,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7486,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.468348890542984,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.9174,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49667859077453613,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.8015,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49677103757858276,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.8764,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5423592329025269,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.8467,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46261122822761536,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.7561,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6421524286270142,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.8461,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.44534018635749817,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.9544,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4680206775665283,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.898,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.48604387044906616,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8691,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5105553269386292,
      "learning_rate": 0.00019784408084696825,
      "loss": 0.7244,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.41934075951576233,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.9266,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4944055676460266,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.7894,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4694783389568329,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.9173,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4923385977745056,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.8264,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.584971010684967,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7067,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.460625022649765,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.7259,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5579990744590759,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.6285,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43484073877334595,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.7982,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.451922208070755,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.8647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5411314964294434,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.7489,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.485877126455307,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.6726,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43625229597091675,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.7847,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4604784846305847,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.6761,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.38421735167503357,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.8093,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47359615564346313,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7767,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48932552337646484,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.6937,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4678775668144226,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.929,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49805936217308044,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.6369,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5964849591255188,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.6874,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5139459371566772,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.9437,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5100282430648804,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.7723,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.606708288192749,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.86,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41680747270584106,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.8129,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4841563403606415,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.923,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6219584345817566,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.7727,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4298764765262604,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.8104,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49360743165016174,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.6325,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4630686640739441,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.898,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5353219509124756,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.8399,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4980505704879761,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7985,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5311594009399414,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.7455,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44213631749153137,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.7094,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5181998014450073,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7528,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5781349539756775,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.8595,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40299394726753235,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9345,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5603666305541992,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.9935,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4508861005306244,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7322,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.453523725271225,
      "learning_rate": 0.000196381135707411,
      "loss": 0.7256,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.698917806148529,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8367,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.526947021484375,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.6431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5315524339675903,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7462,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.528644323348999,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.6622,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4947921633720398,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.7692,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40959012508392334,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.8525,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3968225419521332,
      "learning_rate": 0.000196111645813282,
      "loss": 0.9691,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.461165189743042,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.8075,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43429329991340637,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.7966,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45655712485313416,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.6649,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41561511158943176,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.9817,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5914500951766968,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.6949,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4335707128047943,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.8687,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.517529308795929,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8118,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5489369034767151,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.9189,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5018031001091003,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.7887,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5235357880592346,
      "learning_rate": 0.00019572666025024062,
      "loss": 1.0346,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.373628705739975,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.5875,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.444135844707489,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.7871,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45136335492134094,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.6282,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5306428074836731,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.7564,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4356388747692108,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.6983,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4693934917449951,
      "learning_rate": 0.00019549566891241578,
      "loss": 0.7454,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6450073719024658,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.6905,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4784305989742279,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.6944,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39485329389572144,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.9025,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45148515701293945,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.6443,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4086743891239166,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.8381,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6853803992271423,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.6857,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5018186569213867,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.9565,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38910984992980957,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7023,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47104546427726746,
      "learning_rate": 0.00019514918190567855,
      "loss": 0.7211,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.595535159111023,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.8905,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42830514907836914,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.7955,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4417261779308319,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.692,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42573025822639465,
      "learning_rate": 0.000194995187680462,
      "loss": 0.608,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6163130402565002,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.9331,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47019925713539124,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.7338,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4294617176055908,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.7916,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5744539499282837,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.8113,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4397624135017395,
      "learning_rate": 0.0001948026948989413,
      "loss": 0.8047,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4419170916080475,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.7949,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.408357173204422,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.8878,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3972795903682709,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5689,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.402809202671051,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7868,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46714845299720764,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.904,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4382963180541992,
      "learning_rate": 0.00019457170356111648,
      "loss": 0.7987,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49720799922943115,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.6905,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38201817870140076,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.6079,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3585057854652405,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.8645,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5370497703552246,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.7726,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40534526109695435,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.6871,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40718555450439453,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.8994,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6352331638336182,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.8999,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4231524169445038,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.674,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.51837158203125,
      "learning_rate": 0.0001942252165543792,
      "loss": 0.6869,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43487808108329773,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.8495,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.478048175573349,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6706,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4871412217617035,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.8534,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48025259375572205,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.8734,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.376050740480423,
      "learning_rate": 0.00019403272377285853,
      "loss": 1.0056,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4277438819408417,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.6711,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4798095226287842,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.8112,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4388551712036133,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8392,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.633101224899292,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.7927,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3662850558757782,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7108,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43001875281333923,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.6524,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43889835476875305,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.8804,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.449369341135025,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.9322,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5520343780517578,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.7627,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42789730429649353,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.7097,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5099896788597107,
      "learning_rate": 0.000193609239653513,
      "loss": 0.766,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3890852630138397,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8727,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4030917286872864,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.7714,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5613992810249329,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.9946,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48699212074279785,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.6841,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43229538202285767,
      "learning_rate": 0.0001934167468719923,
      "loss": 0.6469,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46411290764808655,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.7614,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49609866738319397,
      "learning_rate": 0.00019333974975938403,
      "loss": 0.6847,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.33297157287597656,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8576,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5082602500915527,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6907,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.48121577501296997,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.8542,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3946192264556885,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6726,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41997063159942627,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.6866,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4409182369709015,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.7627,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3896368145942688,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.7587,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42079252004623413,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.6828,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4358564019203186,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.7743,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47438254952430725,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7295,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3782908022403717,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7665,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3703530728816986,
      "learning_rate": 0.00019287776708373439,
      "loss": 1.006,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3743325173854828,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.8885,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4332818388938904,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.788,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3522750735282898,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6771,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5323351621627808,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7769,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3655940294265747,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.6001,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4050886034965515,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.9004,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44313961267471313,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.9076,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4808651804924011,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.7876,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4099526107311249,
      "learning_rate": 0.00019253128007699712,
      "loss": 0.7545,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42295604944229126,
      "learning_rate": 0.000192492781520693,
      "loss": 0.6868,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.38039496541023254,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.6882,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.392062246799469,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.8275,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.49568668007850647,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.6282,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3389342129230499,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7987,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.43684521317481995,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.8579,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46228134632110596,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.8268,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.36543259024620056,
      "learning_rate": 0.000192223291626564,
      "loss": 0.8892,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3820000886917114,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7667,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47314170002937317,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.7424,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4986186921596527,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.6653,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40106379985809326,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.6973,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5317052006721497,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.7483,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4519927203655243,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.872,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44930392503738403,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.7127,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5897475481033325,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.9663,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4732646346092224,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7192,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40370991826057434,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.945,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5189063549041748,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.9023,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4453914761543274,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.8568,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4872682988643646,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.6934,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4745577573776245,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.785,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.452533096075058,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.7228,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42025381326675415,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.8885,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.45724043250083923,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.7404,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41045424342155457,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.8384,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4606262743473053,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.6972,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47874921560287476,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.9777,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41982775926589966,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.9483,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46619105339050293,
      "learning_rate": 0.00019137632338787298,
      "loss": 0.7675,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.31501007080078125,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.7628,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45184069871902466,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.686,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3631167411804199,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.8303,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3997798562049866,
      "learning_rate": 0.00019122232916265642,
      "loss": 0.8186,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3641427457332611,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.7384,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3745492696762085,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.9408,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4126112461090088,
      "learning_rate": 0.000191106833493744,
      "loss": 0.7691,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.38452523946762085,
      "learning_rate": 0.00019106833493743986,
      "loss": 0.8933,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4313470423221588,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.717,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4877426326274872,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.9048,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.354559063911438,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.8285,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35648438334465027,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.673,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3589836657047272,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.7923,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3994254469871521,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7671,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4231529235839844,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.6565,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4621272385120392,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.6907,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3945978581905365,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.7,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39729538559913635,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.5096,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42322924733161926,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.78,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.44383230805397034,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.8083,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6045325398445129,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.8649,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4234389662742615,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.7185,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.381877601146698,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8355,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3730185031890869,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.675,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4495980739593506,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.6618,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36406174302101135,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.8693,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5642045736312866,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.661,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3980395197868347,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7259,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.47727033495903015,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.6606,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37292900681495667,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.781,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.33142971992492676,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.621,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4019940197467804,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.8589,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4046827554702759,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.7907,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.40318140387535095,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7672,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.41678452491760254,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7602,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3626757264137268,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.6203,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36802080273628235,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.7684,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35103940963745117,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.828,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4074096381664276,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.7727,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39446142315864563,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.7743,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42152348160743713,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.6711,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37022072076797485,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.8369,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45802485942840576,
      "learning_rate": 0.000189720885466795,
      "loss": 0.6817,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3840475082397461,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.6692,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.397205114364624,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.6124,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46793362498283386,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7995,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3204089105129242,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.8052,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5611957907676697,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.7167,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.530852735042572,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5691,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46891504526138306,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9886,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4694139361381531,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.6444,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39388447999954224,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.7208,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4057823717594147,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.6421,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.446094274520874,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.9129,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4163888394832611,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.9019,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.341553658246994,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.7768,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4768024981021881,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.6762,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.401567280292511,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.8641,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44063693284988403,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.5896,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3412891626358032,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.8354,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3813810348510742,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.708,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39346498250961304,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.799,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4597877264022827,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.7395,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3625764548778534,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.8548,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.47845423221588135,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.7139,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4290001094341278,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8762,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.374828964471817,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.7665,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3916478455066681,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8444,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4357036352157593,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.6959,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41867315769195557,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.854,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4803310036659241,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.6415,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4232359230518341,
      "learning_rate": 0.000188604427333975,
      "loss": 0.8127,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3427557647228241,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.8764,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4120095670223236,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.7613,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44978073239326477,
      "learning_rate": 0.00018848893166506256,
      "loss": 0.6352,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3201029598712921,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.7237,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44953957200050354,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.6487,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4061507284641266,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.6154,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4792279005050659,
      "learning_rate": 0.000188334937439846,
      "loss": 0.8293,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3731112480163574,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6101,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4615262448787689,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.7616,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36472374200820923,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.6681,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4000975489616394,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.6767,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4342329800128937,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.8626,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.43993252515792847,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.7314,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36972469091415405,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.7895,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4726084768772125,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.6262,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5106558203697205,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.7688,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3342224955558777,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.8441,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.42816826701164246,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6327,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.34864041209220886,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.7377,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3308842182159424,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.6719,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4306331276893616,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.6301,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39399442076683044,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.7529,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4262602925300598,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.8004,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5589942336082458,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.8591,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.45510587096214294,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.8667,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41702696681022644,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.837,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49357858300209045,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.6308,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49088579416275024,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.8118,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4575938582420349,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7499,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5084648132324219,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.9495,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4152742922306061,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.6591,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.410138875246048,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.6558,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3992723822593689,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.8139,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4198096990585327,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8063,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4146757423877716,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.5979,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3692832291126251,
      "learning_rate": 0.000187218479307026,
      "loss": 0.8527,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37799060344696045,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8657,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3419437110424042,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7457,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4123936593532562,
      "learning_rate": 0.00018710298363811359,
      "loss": 0.6015,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3556390404701233,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.952,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.43549832701683044,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.7719,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44564804434776306,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7465,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4578996002674103,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.7318,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5829522609710693,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6746,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.618412435054779,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6612,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.45777198672294617,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.744,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47281530499458313,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.7054,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933841288089752,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8044,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4211621582508087,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.7529,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.504000186920166,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.6154,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.40663763880729675,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7715,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3982800543308258,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.8856,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39105480909347534,
      "learning_rate": 0.00018656400384985564,
      "loss": 0.5879,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4311503469944,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.7208,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.46843230724334717,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.8434,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37112879753112793,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.7895,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3782634139060974,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.71,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.411615788936615,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.692,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4585183262825012,
      "learning_rate": 0.0001863330125120308,
      "loss": 0.699,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3210856020450592,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.8301,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47548168897628784,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6627,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42618703842163086,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.8115,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4956449270248413,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.7461,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.373945415019989,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.7387,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5128307342529297,
      "learning_rate": 0.000186102021174206,
      "loss": 0.8675,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39190107583999634,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.7088,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4019525647163391,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.7208,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6033728122711182,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.6698,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933517634868622,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.8102,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4288349747657776,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.8585,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42410892248153687,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.7242,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4902440309524536,
      "learning_rate": 0.000185832531280077,
      "loss": 0.5965,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.36604270339012146,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.6267,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4615339934825897,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.9455,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4348839223384857,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.8513,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4273621737957001,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.617,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41383039951324463,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.8803,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5040608048439026,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7583,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.33960476517677307,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.7595,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44689905643463135,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.7853,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41154545545578003,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.7136,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.27520662546157837,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.7979,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5478206276893616,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.8095,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4509338438510895,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7044,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4331468939781189,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.7175,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3315088450908661,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8649,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38282105326652527,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7978,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4138413071632385,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7269,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37460705637931824,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.6528,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34590426087379456,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.9164,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.32010602951049805,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.8575,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37327438592910767,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.8753,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.316778302192688,
      "learning_rate": 0.0001850240615976901,
      "loss": 0.6793,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.403444766998291,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7541,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.491682767868042,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6667,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3501006066799164,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.6655,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41489213705062866,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.8568,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4158405065536499,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.6591,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38367748260498047,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.7529,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4363219141960144,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.7413,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4521339237689972,
      "learning_rate": 0.000184716073147257,
      "loss": 0.5389,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.43186765909194946,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7304,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.40286019444465637,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.865,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3767046630382538,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.8971,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3247160017490387,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.7793,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39206525683403015,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.6463,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3634454011917114,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.7576,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34959307312965393,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8257,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5340710282325745,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.9475,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5003661513328552,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.6891,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39330339431762695,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.6483,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.35932329297065735,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6431,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4380384385585785,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.8178,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37227070331573486,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.8105,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41952013969421387,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.7825,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3422773778438568,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.9381,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3683087229728699,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6737,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3993309736251831,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7685,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39145129919052124,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.6952,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41825953125953674,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.7473,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4179387092590332,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.8116,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.45485833287239075,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5701,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4862624704837799,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.8575,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4824470281600952,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.884,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4922899305820465,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.6477,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4879881739616394,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.7551,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5233360528945923,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.7343,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5586115717887878,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6556,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4199840724468231,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.7226,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.397352397441864,
      "learning_rate": 0.00018359961501443698,
      "loss": 1.0078,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4226352274417877,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.8804,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4273151159286499,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.7279,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4946306347846985,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7425,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38384705781936646,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.8422,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3904738426208496,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7058,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3637390732765198,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.8168,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41314783692359924,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.8248,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.30208462476730347,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.7856,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3953840136528015,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.7159,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37532252073287964,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.668,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3895621597766876,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.7619,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4008345305919647,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.9235,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37399378418922424,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.8747,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44646504521369934,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7659,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40955376625061035,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.7648,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3704189360141754,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.7595,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4268467426300049,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.732,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3477902412414551,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.7803,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3642955720424652,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.8426,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3884435296058655,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.7273,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37005576491355896,
      "learning_rate": 0.00018279114533205007,
      "loss": 0.8231,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4093822240829468,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8097,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4333754777908325,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5244,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38456860184669495,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.9002,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40615877509117126,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.8228,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3670360743999481,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.5899,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38076573610305786,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.7756,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4119761884212494,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.6556,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4783891439437866,
      "learning_rate": 0.00018248315688161696,
      "loss": 1.0189,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40097832679748535,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7869,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3726452887058258,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7804,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3413650393486023,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8006,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4379594027996063,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.7684,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37378251552581787,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.7102,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37973713874816895,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.8109,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.33865559101104736,
      "learning_rate": 0.000182213666987488,
      "loss": 0.7206,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.49138644337654114,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.8076,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5017513632774353,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.9111,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4073384702205658,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8147,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.47447335720062256,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.6633,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.406205952167511,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.684,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.613382875919342,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7979,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4507606625556946,
      "learning_rate": 0.000181944177093359,
      "loss": 0.8019,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4662131667137146,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8455,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3832371234893799,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.6721,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4184776246547699,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.8355,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.31751248240470886,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.8333,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4122768044471741,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.8156,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.365533709526062,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7284,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5359499454498291,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8517,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3743586540222168,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.8607,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40984785556793213,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.8798,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.41061532497406006,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.7626,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5130647420883179,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.6745,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3531906008720398,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.7948,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4617935121059418,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7451,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4042561650276184,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.85,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44275152683258057,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.7308,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4530651569366455,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.7625,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.519067645072937,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.7081,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39324527978897095,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.7552,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3819272518157959,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.9068,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4451203942298889,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.8031,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39822861552238464,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8524,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4579085409641266,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6518,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.35329708456993103,
      "learning_rate": 0.0001810587102983638,
      "loss": 0.6251,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4679481089115143,
      "learning_rate": 0.00018102021174205968,
      "loss": 0.8123,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4190986156463623,
      "learning_rate": 0.00018098171318575555,
      "loss": 0.8069,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4447309374809265,
      "learning_rate": 0.0001809432146294514,
      "loss": 0.7957,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3945259749889374,
      "learning_rate": 0.00018090471607314727,
      "loss": 0.8608,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4472101926803589,
      "learning_rate": 0.00018086621751684312,
      "loss": 0.6545,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.399156391620636,
      "learning_rate": 0.000180827718960539,
      "loss": 0.8384,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.45613279938697815,
      "learning_rate": 0.00018078922040423484,
      "loss": 0.7321,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40805959701538086,
      "learning_rate": 0.00018075072184793072,
      "loss": 0.7444,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.42769765853881836,
      "learning_rate": 0.0001807122232916266,
      "loss": 0.8028,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33644768595695496,
      "learning_rate": 0.00018067372473532244,
      "loss": 0.8101,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.44442418217658997,
      "learning_rate": 0.00018063522617901828,
      "loss": 0.7858,
      "step": 512
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3666957914829254,
      "learning_rate": 0.00018059672762271416,
      "loss": 0.8682,
      "step": 513
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40631023049354553,
      "learning_rate": 0.00018055822906641003,
      "loss": 0.8666,
      "step": 514
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3566116392612457,
      "learning_rate": 0.00018051973051010588,
      "loss": 0.8075,
      "step": 515
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40891098976135254,
      "learning_rate": 0.00018048123195380173,
      "loss": 0.7326,
      "step": 516
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4189295470714569,
      "learning_rate": 0.0001804427333974976,
      "loss": 0.7031,
      "step": 517
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37940719723701477,
      "learning_rate": 0.00018040423484119348,
      "loss": 0.8974,
      "step": 518
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.47053778171539307,
      "learning_rate": 0.00018036573628488933,
      "loss": 0.6617,
      "step": 519
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4119088053703308,
      "learning_rate": 0.0001803272377285852,
      "loss": 0.8485,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4901687502861023,
      "learning_rate": 0.00018028873917228105,
      "loss": 0.7554,
      "step": 521
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3938004970550537,
      "learning_rate": 0.0001802502406159769,
      "loss": 0.7201,
      "step": 522
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4453965425491333,
      "learning_rate": 0.00018021174205967277,
      "loss": 0.9134,
      "step": 523
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4919692575931549,
      "learning_rate": 0.00018017324350336864,
      "loss": 0.6673,
      "step": 524
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4813697040081024,
      "learning_rate": 0.0001801347449470645,
      "loss": 0.7451,
      "step": 525
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4028126895427704,
      "learning_rate": 0.00018009624639076034,
      "loss": 0.7807,
      "step": 526
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4498790502548218,
      "learning_rate": 0.0001800577478344562,
      "loss": 0.8194,
      "step": 527
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4789945185184479,
      "learning_rate": 0.0001800192492781521,
      "loss": 0.6132,
      "step": 528
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5399003624916077,
      "learning_rate": 0.00017998075072184794,
      "loss": 0.8553,
      "step": 529
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4275045394897461,
      "learning_rate": 0.00017994225216554378,
      "loss": 0.7398,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40307727456092834,
      "learning_rate": 0.00017990375360923966,
      "loss": 0.8353,
      "step": 531
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37099727988243103,
      "learning_rate": 0.00017986525505293553,
      "loss": 0.8753,
      "step": 532
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3537798821926117,
      "learning_rate": 0.00017982675649663138,
      "loss": 0.7497,
      "step": 533
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41050562262535095,
      "learning_rate": 0.00017978825794032725,
      "loss": 0.6499,
      "step": 534
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.38062337040901184,
      "learning_rate": 0.0001797497593840231,
      "loss": 0.8393,
      "step": 535
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.48728129267692566,
      "learning_rate": 0.00017971126082771898,
      "loss": 0.7913,
      "step": 536
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41124552488327026,
      "learning_rate": 0.00017967276227141482,
      "loss": 0.8473,
      "step": 537
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4975420832633972,
      "learning_rate": 0.0001796342637151107,
      "loss": 0.6603,
      "step": 538
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39639201760292053,
      "learning_rate": 0.00017959576515880657,
      "loss": 0.8181,
      "step": 539
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33978918194770813,
      "learning_rate": 0.0001795572666025024,
      "loss": 0.5651,
      "step": 540
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39304712414741516,
      "learning_rate": 0.00017951876804619827,
      "loss": 0.7266,
      "step": 541
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41755804419517517,
      "learning_rate": 0.00017948026948989414,
      "loss": 0.8439,
      "step": 542
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4548015296459198,
      "learning_rate": 0.00017944177093359002,
      "loss": 0.6774,
      "step": 543
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3938901722431183,
      "learning_rate": 0.00017940327237728586,
      "loss": 0.8082,
      "step": 544
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3671741485595703,
      "learning_rate": 0.0001793647738209817,
      "loss": 0.7709,
      "step": 545
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39431828260421753,
      "learning_rate": 0.00017932627526467759,
      "loss": 0.7623,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3910527229309082,
      "learning_rate": 0.00017928777670837343,
      "loss": 0.6227,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5204810500144958,
      "learning_rate": 0.0001792492781520693,
      "loss": 0.7134,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4552685022354126,
      "learning_rate": 0.00017921077959576518,
      "loss": 0.7792,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42712152004241943,
      "learning_rate": 0.00017917228103946103,
      "loss": 1.0187,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.40982896089553833,
      "learning_rate": 0.00017913378248315688,
      "loss": 0.8407,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.38555216789245605,
      "learning_rate": 0.00017909528392685275,
      "loss": 0.8532,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3626030683517456,
      "learning_rate": 0.00017905678537054863,
      "loss": 0.7091,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.44306764006614685,
      "learning_rate": 0.00017901828681424447,
      "loss": 0.8067,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4466676712036133,
      "learning_rate": 0.00017897978825794032,
      "loss": 0.6057,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.403406023979187,
      "learning_rate": 0.0001789412897016362,
      "loss": 0.6674,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4458920955657959,
      "learning_rate": 0.00017890279114533207,
      "loss": 0.6795,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3888542056083679,
      "learning_rate": 0.00017886429258902792,
      "loss": 0.7303,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4329482614994049,
      "learning_rate": 0.0001788257940327238,
      "loss": 0.6602,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4150072932243347,
      "learning_rate": 0.00017878729547641964,
      "loss": 0.7572,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.46370017528533936,
      "learning_rate": 0.0001787487969201155,
      "loss": 0.7198,
      "step": 561
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.40281912684440613,
      "learning_rate": 0.00017871029836381136,
      "loss": 0.8659,
      "step": 562
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42040666937828064,
      "learning_rate": 0.00017867179980750724,
      "loss": 0.6713,
      "step": 563
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3968161344528198,
      "learning_rate": 0.00017863330125120308,
      "loss": 0.723,
      "step": 564
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3881441056728363,
      "learning_rate": 0.00017859480269489896,
      "loss": 0.7526,
      "step": 565
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3257398307323456,
      "learning_rate": 0.0001785563041385948,
      "loss": 0.9035,
      "step": 566
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3617190718650818,
      "learning_rate": 0.00017851780558229068,
      "loss": 0.6702,
      "step": 567
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3779655992984772,
      "learning_rate": 0.00017847930702598655,
      "loss": 0.6569,
      "step": 568
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.41719603538513184,
      "learning_rate": 0.00017844080846968237,
      "loss": 0.8573,
      "step": 569
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3839716911315918,
      "learning_rate": 0.00017840230991337825,
      "loss": 0.7409,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3557591140270233,
      "learning_rate": 0.00017836381135707412,
      "loss": 0.8895,
      "step": 571
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4740881621837616,
      "learning_rate": 0.00017832531280076997,
      "loss": 0.6805,
      "step": 572
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4512026309967041,
      "learning_rate": 0.00017828681424446585,
      "loss": 0.786,
      "step": 573
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.45799720287323,
      "learning_rate": 0.0001782483156881617,
      "loss": 0.8067,
      "step": 574
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42661893367767334,
      "learning_rate": 0.00017820981713185757,
      "loss": 0.7418,
      "step": 575
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4891342222690582,
      "learning_rate": 0.00017817131857555341,
      "loss": 0.8071,
      "step": 576
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4712083637714386,
      "learning_rate": 0.0001781328200192493,
      "loss": 0.7291,
      "step": 577
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.44885143637657166,
      "learning_rate": 0.00017809432146294516,
      "loss": 0.8356,
      "step": 578
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36697036027908325,
      "learning_rate": 0.000178055822906641,
      "loss": 0.6563,
      "step": 579
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5198047757148743,
      "learning_rate": 0.00017801732435033686,
      "loss": 0.7868,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3903001844882965,
      "learning_rate": 0.00017797882579403273,
      "loss": 0.7775,
      "step": 581
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3861727714538574,
      "learning_rate": 0.0001779403272377286,
      "loss": 0.7176,
      "step": 582
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3334764242172241,
      "learning_rate": 0.00017790182868142445,
      "loss": 0.9657,
      "step": 583
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4170445203781128,
      "learning_rate": 0.0001778633301251203,
      "loss": 0.765,
      "step": 584
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3677545189857483,
      "learning_rate": 0.00017782483156881618,
      "loss": 0.8061,
      "step": 585
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5148152709007263,
      "learning_rate": 0.00017778633301251205,
      "loss": 0.8903,
      "step": 586
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3851109743118286,
      "learning_rate": 0.0001777478344562079,
      "loss": 0.5751,
      "step": 587
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3523044288158417,
      "learning_rate": 0.00017770933589990377,
      "loss": 0.7858,
      "step": 588
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.427933007478714,
      "learning_rate": 0.00017767083734359962,
      "loss": 0.9746,
      "step": 589
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36992552876472473,
      "learning_rate": 0.0001776323387872955,
      "loss": 0.8219,
      "step": 590
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3327391743659973,
      "learning_rate": 0.00017759384023099134,
      "loss": 0.8739,
      "step": 591
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4296494722366333,
      "learning_rate": 0.00017755534167468722,
      "loss": 0.7948,
      "step": 592
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.37695109844207764,
      "learning_rate": 0.00017751684311838306,
      "loss": 0.8366,
      "step": 593
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4121188521385193,
      "learning_rate": 0.0001774783445620789,
      "loss": 0.9157,
      "step": 594
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4559638500213623,
      "learning_rate": 0.0001774398460057748,
      "loss": 0.6274,
      "step": 595
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.48433220386505127,
      "learning_rate": 0.00017740134744947066,
      "loss": 0.729,
      "step": 596
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3838486671447754,
      "learning_rate": 0.0001773628488931665,
      "loss": 0.7394,
      "step": 597
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.448947012424469,
      "learning_rate": 0.00017732435033686236,
      "loss": 0.8636,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.34840279817581177,
      "learning_rate": 0.00017728585178055823,
      "loss": 0.8343,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.44666817784309387,
      "learning_rate": 0.0001772473532242541,
      "loss": 0.8453,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41129618883132935,
      "learning_rate": 0.00017720885466794995,
      "loss": 0.6779,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4049602448940277,
      "learning_rate": 0.00017717035611164583,
      "loss": 0.954,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38343897461891174,
      "learning_rate": 0.00017713185755534167,
      "loss": 0.7214,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4270513951778412,
      "learning_rate": 0.00017709335899903755,
      "loss": 0.7222,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3907594382762909,
      "learning_rate": 0.0001770548604427334,
      "loss": 0.8616,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3287070393562317,
      "learning_rate": 0.00017701636188642927,
      "loss": 0.8017,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4289465546607971,
      "learning_rate": 0.00017697786333012515,
      "loss": 0.6481,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.40701785683631897,
      "learning_rate": 0.000176939364773821,
      "loss": 0.8361,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4191131591796875,
      "learning_rate": 0.00017690086621751684,
      "loss": 0.7557,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4570298194885254,
      "learning_rate": 0.00017686236766121271,
      "loss": 0.8935,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4185386002063751,
      "learning_rate": 0.0001768238691049086,
      "loss": 0.6673,
      "step": 611
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4229338467121124,
      "learning_rate": 0.00017678537054860444,
      "loss": 0.8806,
      "step": 612
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.39359912276268005,
      "learning_rate": 0.00017674687199230028,
      "loss": 0.664,
      "step": 613
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3372077941894531,
      "learning_rate": 0.00017670837343599616,
      "loss": 0.8618,
      "step": 614
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3153285086154938,
      "learning_rate": 0.00017666987487969203,
      "loss": 0.768,
      "step": 615
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37482786178588867,
      "learning_rate": 0.00017663137632338788,
      "loss": 0.7711,
      "step": 616
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.35621148347854614,
      "learning_rate": 0.00017659287776708376,
      "loss": 0.6685,
      "step": 617
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.43296071887016296,
      "learning_rate": 0.0001765543792107796,
      "loss": 0.7611,
      "step": 618
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.45684507489204407,
      "learning_rate": 0.00017651588065447545,
      "loss": 0.5118,
      "step": 619
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3735063076019287,
      "learning_rate": 0.00017647738209817132,
      "loss": 0.7152,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.42290157079696655,
      "learning_rate": 0.0001764388835418672,
      "loss": 0.6485,
      "step": 621
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46688735485076904,
      "learning_rate": 0.00017640038498556307,
      "loss": 0.6683,
      "step": 622
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38138657808303833,
      "learning_rate": 0.0001763618864292589,
      "loss": 0.7274,
      "step": 623
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.39618390798568726,
      "learning_rate": 0.00017632338787295477,
      "loss": 0.8839,
      "step": 624
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.444378137588501,
      "learning_rate": 0.00017628488931665064,
      "loss": 0.7364,
      "step": 625
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.36690178513526917,
      "learning_rate": 0.0001762463907603465,
      "loss": 0.8898,
      "step": 626
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.40035420656204224,
      "learning_rate": 0.00017620789220404234,
      "loss": 0.7846,
      "step": 627
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3317468762397766,
      "learning_rate": 0.0001761693936477382,
      "loss": 0.8477,
      "step": 628
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4218446910381317,
      "learning_rate": 0.0001761308950914341,
      "loss": 0.7423,
      "step": 629
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38181713223457336,
      "learning_rate": 0.00017609239653512993,
      "loss": 0.8511,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5051924586296082,
      "learning_rate": 0.0001760538979788258,
      "loss": 0.7208,
      "step": 631
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3627151548862457,
      "learning_rate": 0.00017601539942252166,
      "loss": 0.8558,
      "step": 632
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5386068224906921,
      "learning_rate": 0.00017597690086621753,
      "loss": 0.7498,
      "step": 633
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4204239547252655,
      "learning_rate": 0.00017593840230991338,
      "loss": 0.7845,
      "step": 634
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3822893798351288,
      "learning_rate": 0.00017589990375360925,
      "loss": 0.816,
      "step": 635
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.48055341839790344,
      "learning_rate": 0.00017586140519730513,
      "loss": 0.8331,
      "step": 636
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46601784229278564,
      "learning_rate": 0.00017582290664100097,
      "loss": 0.7306,
      "step": 637
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5342617034912109,
      "learning_rate": 0.00017578440808469682,
      "loss": 0.6888,
      "step": 638
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4277246296405792,
      "learning_rate": 0.0001757459095283927,
      "loss": 0.7462,
      "step": 639
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41329824924468994,
      "learning_rate": 0.00017570741097208857,
      "loss": 0.7003,
      "step": 640
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.43545401096343994,
      "learning_rate": 0.00017566891241578442,
      "loss": 1.059,
      "step": 641
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37881138920783997,
      "learning_rate": 0.00017563041385948027,
      "loss": 0.732,
      "step": 642
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.34206023812294006,
      "learning_rate": 0.00017559191530317614,
      "loss": 1.0778,
      "step": 643
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.35784947872161865,
      "learning_rate": 0.000175553416746872,
      "loss": 0.6666,
      "step": 644
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3838137984275818,
      "learning_rate": 0.00017551491819056786,
      "loss": 0.7739,
      "step": 645
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5151283144950867,
      "learning_rate": 0.00017547641963426374,
      "loss": 0.772,
      "step": 646
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46383512020111084,
      "learning_rate": 0.00017543792107795958,
      "loss": 0.8412,
      "step": 647
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5041674971580505,
      "learning_rate": 0.00017539942252165543,
      "loss": 0.7372,
      "step": 648
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4784582853317261,
      "learning_rate": 0.0001753609239653513,
      "loss": 0.8203,
      "step": 649
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38770371675491333,
      "learning_rate": 0.00017532242540904718,
      "loss": 0.7772,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4724113643169403,
      "learning_rate": 0.00017528392685274303,
      "loss": 0.8073,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35377320647239685,
      "learning_rate": 0.00017524542829643888,
      "loss": 0.7301,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.47636106610298157,
      "learning_rate": 0.00017520692974013475,
      "loss": 0.6617,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.42795759439468384,
      "learning_rate": 0.00017516843118383063,
      "loss": 0.7154,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4345453679561615,
      "learning_rate": 0.00017512993262752647,
      "loss": 0.733,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39994534850120544,
      "learning_rate": 0.00017509143407122232,
      "loss": 0.5779,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4123230576515198,
      "learning_rate": 0.0001750529355149182,
      "loss": 0.6915,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3561868369579315,
      "learning_rate": 0.00017501443695861407,
      "loss": 0.7782,
      "step": 658
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4212721884250641,
      "learning_rate": 0.00017497593840230992,
      "loss": 0.7503,
      "step": 659
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.332350492477417,
      "learning_rate": 0.0001749374398460058,
      "loss": 0.9183,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.53046715259552,
      "learning_rate": 0.00017489894128970164,
      "loss": 0.9709,
      "step": 661
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.43777701258659363,
      "learning_rate": 0.0001748604427333975,
      "loss": 1.0169,
      "step": 662
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4565688967704773,
      "learning_rate": 0.00017482194417709336,
      "loss": 0.7592,
      "step": 663
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.38864171504974365,
      "learning_rate": 0.00017478344562078923,
      "loss": 0.8752,
      "step": 664
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3984103202819824,
      "learning_rate": 0.0001747449470644851,
      "loss": 0.7577,
      "step": 665
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5659173727035522,
      "learning_rate": 0.00017470644850818093,
      "loss": 0.8482,
      "step": 666
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3943690359592438,
      "learning_rate": 0.0001746679499518768,
      "loss": 0.859,
      "step": 667
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4091321527957916,
      "learning_rate": 0.00017462945139557268,
      "loss": 0.7477,
      "step": 668
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.37893542647361755,
      "learning_rate": 0.00017459095283926855,
      "loss": 0.7329,
      "step": 669
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3407520055770874,
      "learning_rate": 0.0001745524542829644,
      "loss": 0.7824,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.40860164165496826,
      "learning_rate": 0.00017451395572666025,
      "loss": 0.8027,
      "step": 671
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3064686954021454,
      "learning_rate": 0.00017447545717035612,
      "loss": 0.9002,
      "step": 672
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3411509692668915,
      "learning_rate": 0.00017443695861405197,
      "loss": 0.8394,
      "step": 673
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3462003171443939,
      "learning_rate": 0.00017439846005774784,
      "loss": 0.8784,
      "step": 674
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3487083613872528,
      "learning_rate": 0.00017435996150144372,
      "loss": 0.8504,
      "step": 675
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3693464398384094,
      "learning_rate": 0.00017432146294513957,
      "loss": 0.6981,
      "step": 676
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35222914814949036,
      "learning_rate": 0.00017428296438883541,
      "loss": 0.8873,
      "step": 677
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4253406226634979,
      "learning_rate": 0.0001742444658325313,
      "loss": 0.7945,
      "step": 678
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.34643346071243286,
      "learning_rate": 0.00017420596727622716,
      "loss": 0.7229,
      "step": 679
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.43851718306541443,
      "learning_rate": 0.000174167468719923,
      "loss": 0.7922,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3920727074146271,
      "learning_rate": 0.00017412897016361886,
      "loss": 0.7859,
      "step": 681
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3976938724517822,
      "learning_rate": 0.00017409047160731473,
      "loss": 0.6974,
      "step": 682
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4204944372177124,
      "learning_rate": 0.0001740519730510106,
      "loss": 0.8564,
      "step": 683
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35586726665496826,
      "learning_rate": 0.00017401347449470645,
      "loss": 0.8635,
      "step": 684
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4737916588783264,
      "learning_rate": 0.00017397497593840233,
      "loss": 0.7866,
      "step": 685
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3748070299625397,
      "learning_rate": 0.00017393647738209818,
      "loss": 0.695,
      "step": 686
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36548924446105957,
      "learning_rate": 0.00017389797882579405,
      "loss": 0.716,
      "step": 687
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39750754833221436,
      "learning_rate": 0.0001738594802694899,
      "loss": 0.7952,
      "step": 688
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4891696274280548,
      "learning_rate": 0.00017382098171318577,
      "loss": 0.8809,
      "step": 689
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3966465890407562,
      "learning_rate": 0.00017378248315688162,
      "loss": 1.0013,
      "step": 690
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.47586390376091003,
      "learning_rate": 0.00017374398460057747,
      "loss": 0.7774,
      "step": 691
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4218079149723053,
      "learning_rate": 0.00017370548604427334,
      "loss": 0.9365,
      "step": 692
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4154198467731476,
      "learning_rate": 0.00017366698748796922,
      "loss": 0.8346,
      "step": 693
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4187276363372803,
      "learning_rate": 0.0001736284889316651,
      "loss": 0.676,
      "step": 694
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3848455548286438,
      "learning_rate": 0.0001735899903753609,
      "loss": 0.794,
      "step": 695
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3735641837120056,
      "learning_rate": 0.00017355149181905679,
      "loss": 0.9179,
      "step": 696
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4032048285007477,
      "learning_rate": 0.00017351299326275266,
      "loss": 0.8329,
      "step": 697
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35270655155181885,
      "learning_rate": 0.0001734744947064485,
      "loss": 0.7328,
      "step": 698
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3051532804965973,
      "learning_rate": 0.00017343599615014438,
      "loss": 0.6793,
      "step": 699
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.40052488446235657,
      "learning_rate": 0.00017339749759384023,
      "loss": 0.7087,
      "step": 700
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45748668909072876,
      "learning_rate": 0.0001733589990375361,
      "loss": 0.9148,
      "step": 701
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36851558089256287,
      "learning_rate": 0.00017332050048123195,
      "loss": 0.6898,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34142744541168213,
      "learning_rate": 0.00017328200192492783,
      "loss": 0.8012,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38720953464508057,
      "learning_rate": 0.0001732435033686237,
      "loss": 0.8193,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3785306215286255,
      "learning_rate": 0.00017320500481231955,
      "loss": 0.8876,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.342033326625824,
      "learning_rate": 0.0001731665062560154,
      "loss": 0.9271,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.41306832432746887,
      "learning_rate": 0.00017312800769971127,
      "loss": 0.7448,
      "step": 707
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4203263819217682,
      "learning_rate": 0.00017308950914340715,
      "loss": 0.7572,
      "step": 708
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4670791029930115,
      "learning_rate": 0.000173051010587103,
      "loss": 0.617,
      "step": 709
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5887750387191772,
      "learning_rate": 0.00017301251203079884,
      "loss": 0.8054,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37040165066719055,
      "learning_rate": 0.00017297401347449471,
      "loss": 0.821,
      "step": 711
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3870273530483246,
      "learning_rate": 0.0001729355149181906,
      "loss": 0.8355,
      "step": 712
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.387721985578537,
      "learning_rate": 0.00017289701636188644,
      "loss": 0.5159,
      "step": 713
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3844657838344574,
      "learning_rate": 0.0001728585178055823,
      "loss": 0.7561,
      "step": 714
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3874747157096863,
      "learning_rate": 0.00017282001924927816,
      "loss": 0.6783,
      "step": 715
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34984755516052246,
      "learning_rate": 0.00017278152069297403,
      "loss": 0.785,
      "step": 716
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5564412474632263,
      "learning_rate": 0.00017274302213666988,
      "loss": 0.6845,
      "step": 717
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3845653533935547,
      "learning_rate": 0.00017270452358036575,
      "loss": 0.8413,
      "step": 718
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34572526812553406,
      "learning_rate": 0.0001726660250240616,
      "loss": 0.7811,
      "step": 719
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4227907359600067,
      "learning_rate": 0.00017262752646775745,
      "loss": 0.581,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40575093030929565,
      "learning_rate": 0.00017258902791145332,
      "loss": 0.7286,
      "step": 721
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3517785668373108,
      "learning_rate": 0.0001725505293551492,
      "loss": 0.7326,
      "step": 722
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40482303500175476,
      "learning_rate": 0.00017251203079884505,
      "loss": 0.9867,
      "step": 723
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3650476634502411,
      "learning_rate": 0.0001724735322425409,
      "loss": 0.6963,
      "step": 724
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33829617500305176,
      "learning_rate": 0.00017243503368623677,
      "loss": 0.9104,
      "step": 725
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.35361653566360474,
      "learning_rate": 0.00017239653512993264,
      "loss": 0.5383,
      "step": 726
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.45061513781547546,
      "learning_rate": 0.0001723580365736285,
      "loss": 0.7023,
      "step": 727
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4981588125228882,
      "learning_rate": 0.00017231953801732436,
      "loss": 0.8044,
      "step": 728
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.387322336435318,
      "learning_rate": 0.0001722810394610202,
      "loss": 0.992,
      "step": 729
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5148512721061707,
      "learning_rate": 0.0001722425409047161,
      "loss": 0.7358,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4733924865722656,
      "learning_rate": 0.00017220404234841193,
      "loss": 0.7849,
      "step": 731
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.36829113960266113,
      "learning_rate": 0.0001721655437921078,
      "loss": 0.8421,
      "step": 732
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39594176411628723,
      "learning_rate": 0.00017212704523580368,
      "loss": 0.677,
      "step": 733
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4709170162677765,
      "learning_rate": 0.00017208854667949953,
      "loss": 0.7163,
      "step": 734
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39583051204681396,
      "learning_rate": 0.00017205004812319538,
      "loss": 0.6279,
      "step": 735
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3525935411453247,
      "learning_rate": 0.00017201154956689125,
      "loss": 0.5868,
      "step": 736
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37443339824676514,
      "learning_rate": 0.00017197305101058713,
      "loss": 0.8093,
      "step": 737
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3746035695075989,
      "learning_rate": 0.00017193455245428297,
      "loss": 0.7446,
      "step": 738
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.49442774057388306,
      "learning_rate": 0.00017189605389797882,
      "loss": 0.6681,
      "step": 739
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40556401014328003,
      "learning_rate": 0.0001718575553416747,
      "loss": 0.7086,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38675662875175476,
      "learning_rate": 0.00017181905678537057,
      "loss": 0.8154,
      "step": 741
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6102035641670227,
      "learning_rate": 0.00017178055822906642,
      "loss": 0.6516,
      "step": 742
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.42935019731521606,
      "learning_rate": 0.0001717420596727623,
      "loss": 0.6763,
      "step": 743
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3748353123664856,
      "learning_rate": 0.00017170356111645814,
      "loss": 0.8223,
      "step": 744
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39062535762786865,
      "learning_rate": 0.000171665062560154,
      "loss": 0.6919,
      "step": 745
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38968580961227417,
      "learning_rate": 0.00017162656400384986,
      "loss": 0.7257,
      "step": 746
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.366832971572876,
      "learning_rate": 0.00017158806544754574,
      "loss": 0.8199,
      "step": 747
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4036370515823364,
      "learning_rate": 0.00017154956689124158,
      "loss": 0.9641,
      "step": 748
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39626967906951904,
      "learning_rate": 0.00017151106833493743,
      "loss": 0.8073,
      "step": 749
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4744478464126587,
      "learning_rate": 0.0001714725697786333,
      "loss": 0.7205,
      "step": 750
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3473556935787201,
      "learning_rate": 0.00017143407122232918,
      "loss": 0.893,
      "step": 751
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5023140907287598,
      "learning_rate": 0.00017139557266602503,
      "loss": 0.6788,
      "step": 752
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4513726532459259,
      "learning_rate": 0.00017135707410972088,
      "loss": 0.7294,
      "step": 753
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38579440116882324,
      "learning_rate": 0.00017131857555341675,
      "loss": 0.6912,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.35996872186660767,
      "learning_rate": 0.00017128007699711262,
      "loss": 0.8075,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48586297035217285,
      "learning_rate": 0.00017124157844080847,
      "loss": 0.8389,
      "step": 756
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.335565447807312,
      "learning_rate": 0.00017120307988450435,
      "loss": 0.8229,
      "step": 757
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.42499786615371704,
      "learning_rate": 0.0001711645813282002,
      "loss": 0.8287,
      "step": 758
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47522956132888794,
      "learning_rate": 0.00017112608277189607,
      "loss": 0.7809,
      "step": 759
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47940245270729065,
      "learning_rate": 0.00017108758421559192,
      "loss": 0.5907,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.36606478691101074,
      "learning_rate": 0.0001710490856592878,
      "loss": 0.7638,
      "step": 761
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4483763575553894,
      "learning_rate": 0.00017101058710298366,
      "loss": 0.7139,
      "step": 762
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37084662914276123,
      "learning_rate": 0.00017097208854667949,
      "loss": 0.8148,
      "step": 763
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38737088441848755,
      "learning_rate": 0.00017093358999037536,
      "loss": 0.767,
      "step": 764
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3940127193927765,
      "learning_rate": 0.00017089509143407123,
      "loss": 0.7881,
      "step": 765
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43775805830955505,
      "learning_rate": 0.0001708565928777671,
      "loss": 0.716,
      "step": 766
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4488811194896698,
      "learning_rate": 0.00017081809432146296,
      "loss": 0.6087,
      "step": 767
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43547001481056213,
      "learning_rate": 0.0001707795957651588,
      "loss": 0.7073,
      "step": 768
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43893900513648987,
      "learning_rate": 0.00017074109720885468,
      "loss": 0.8044,
      "step": 769
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.372728556394577,
      "learning_rate": 0.00017070259865255053,
      "loss": 0.6557,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38425034284591675,
      "learning_rate": 0.0001706641000962464,
      "loss": 0.6982,
      "step": 771
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5710627436637878,
      "learning_rate": 0.00017062560153994227,
      "loss": 0.5981,
      "step": 772
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4812089800834656,
      "learning_rate": 0.00017058710298363812,
      "loss": 0.7884,
      "step": 773
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3855699300765991,
      "learning_rate": 0.00017054860442733397,
      "loss": 0.6755,
      "step": 774
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4562559425830841,
      "learning_rate": 0.00017051010587102984,
      "loss": 0.8575,
      "step": 775
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4128674864768982,
      "learning_rate": 0.00017047160731472572,
      "loss": 0.8621,
      "step": 776
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.42607802152633667,
      "learning_rate": 0.00017043310875842157,
      "loss": 0.7904,
      "step": 777
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39994102716445923,
      "learning_rate": 0.0001703946102021174,
      "loss": 0.7393,
      "step": 778
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47832953929901123,
      "learning_rate": 0.0001703561116458133,
      "loss": 0.8006,
      "step": 779
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4949307143688202,
      "learning_rate": 0.00017031761308950916,
      "loss": 0.7873,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3823389410972595,
      "learning_rate": 0.000170279114533205,
      "loss": 0.5423,
      "step": 781
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3938881456851959,
      "learning_rate": 0.00017024061597690086,
      "loss": 0.9979,
      "step": 782
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.36748114228248596,
      "learning_rate": 0.00017020211742059673,
      "loss": 0.7439,
      "step": 783
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3931972086429596,
      "learning_rate": 0.0001701636188642926,
      "loss": 0.8697,
      "step": 784
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.40968993306159973,
      "learning_rate": 0.00017012512030798845,
      "loss": 0.6604,
      "step": 785
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4315906763076782,
      "learning_rate": 0.00017008662175168433,
      "loss": 0.8288,
      "step": 786
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48962411284446716,
      "learning_rate": 0.00017004812319538018,
      "loss": 0.656,
      "step": 787
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3448035418987274,
      "learning_rate": 0.00017000962463907605,
      "loss": 0.9156,
      "step": 788
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32758450508117676,
      "learning_rate": 0.0001699711260827719,
      "loss": 0.6861,
      "step": 789
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32477089762687683,
      "learning_rate": 0.00016993262752646777,
      "loss": 0.9073,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3972192406654358,
      "learning_rate": 0.00016989412897016365,
      "loss": 0.8017,
      "step": 791
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3958989977836609,
      "learning_rate": 0.00016985563041385947,
      "loss": 0.7159,
      "step": 792
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37689006328582764,
      "learning_rate": 0.00016981713185755534,
      "loss": 0.6752,
      "step": 793
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.46549999713897705,
      "learning_rate": 0.00016977863330125122,
      "loss": 0.8251,
      "step": 794
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.45690783858299255,
      "learning_rate": 0.00016974013474494706,
      "loss": 0.7659,
      "step": 795
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3844454884529114,
      "learning_rate": 0.00016970163618864294,
      "loss": 0.8525,
      "step": 796
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37870171666145325,
      "learning_rate": 0.00016966313763233879,
      "loss": 0.6468,
      "step": 797
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4335814416408539,
      "learning_rate": 0.00016962463907603466,
      "loss": 0.7656,
      "step": 798
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.468999445438385,
      "learning_rate": 0.0001695861405197305,
      "loss": 0.8356,
      "step": 799
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3232964277267456,
      "learning_rate": 0.00016954764196342638,
      "loss": 0.8176,
      "step": 800
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4696967303752899,
      "learning_rate": 0.00016950914340712226,
      "loss": 0.7953,
      "step": 801
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3871324062347412,
      "learning_rate": 0.0001694706448508181,
      "loss": 0.6848,
      "step": 802
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4112791121006012,
      "learning_rate": 0.00016943214629451395,
      "loss": 0.708,
      "step": 803
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39461207389831543,
      "learning_rate": 0.00016939364773820983,
      "loss": 0.692,
      "step": 804
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4254642426967621,
      "learning_rate": 0.0001693551491819057,
      "loss": 0.7218,
      "step": 805
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4372923672199249,
      "learning_rate": 0.00016931665062560155,
      "loss": 0.8679,
      "step": 806
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3410716950893402,
      "learning_rate": 0.0001692781520692974,
      "loss": 0.6845,
      "step": 807
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39188075065612793,
      "learning_rate": 0.00016923965351299327,
      "loss": 0.9276,
      "step": 808
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3984350264072418,
      "learning_rate": 0.00016920115495668914,
      "loss": 0.9317,
      "step": 809
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4146293103694916,
      "learning_rate": 0.000169162656400385,
      "loss": 0.7863,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5660368800163269,
      "learning_rate": 0.00016912415784408087,
      "loss": 0.8132,
      "step": 811
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4297594428062439,
      "learning_rate": 0.00016908565928777671,
      "loss": 0.6906,
      "step": 812
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43333521485328674,
      "learning_rate": 0.0001690471607314726,
      "loss": 0.8655,
      "step": 813
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5511271953582764,
      "learning_rate": 0.00016900866217516844,
      "loss": 0.7373,
      "step": 814
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3771804869174957,
      "learning_rate": 0.0001689701636188643,
      "loss": 0.6566,
      "step": 815
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4080510139465332,
      "learning_rate": 0.00016893166506256016,
      "loss": 1.1367,
      "step": 816
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4585743844509125,
      "learning_rate": 0.000168893166506256,
      "loss": 0.6489,
      "step": 817
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3603699207305908,
      "learning_rate": 0.00016885466794995188,
      "loss": 0.804,
      "step": 818
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3835907578468323,
      "learning_rate": 0.00016881616939364775,
      "loss": 0.6746,
      "step": 819
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42422178387641907,
      "learning_rate": 0.00016877767083734363,
      "loss": 0.8467,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39354193210601807,
      "learning_rate": 0.00016873917228103945,
      "loss": 0.7838,
      "step": 821
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3793525695800781,
      "learning_rate": 0.00016870067372473532,
      "loss": 0.7369,
      "step": 822
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3221934735774994,
      "learning_rate": 0.0001686621751684312,
      "loss": 0.8031,
      "step": 823
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3444366455078125,
      "learning_rate": 0.00016862367661212705,
      "loss": 0.7385,
      "step": 824
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44286707043647766,
      "learning_rate": 0.00016858517805582292,
      "loss": 0.8558,
      "step": 825
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3785991370677948,
      "learning_rate": 0.00016854667949951877,
      "loss": 0.6804,
      "step": 826
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35703325271606445,
      "learning_rate": 0.00016850818094321464,
      "loss": 0.8319,
      "step": 827
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3548316955566406,
      "learning_rate": 0.0001684696823869105,
      "loss": 0.9741,
      "step": 828
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4017500579357147,
      "learning_rate": 0.00016843118383060636,
      "loss": 0.8069,
      "step": 829
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42583325505256653,
      "learning_rate": 0.00016839268527430224,
      "loss": 0.811,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43312227725982666,
      "learning_rate": 0.00016835418671799809,
      "loss": 0.8757,
      "step": 831
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40539172291755676,
      "learning_rate": 0.00016831568816169393,
      "loss": 0.981,
      "step": 832
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41632556915283203,
      "learning_rate": 0.0001682771896053898,
      "loss": 0.7313,
      "step": 833
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.532879114151001,
      "learning_rate": 0.00016823869104908568,
      "loss": 0.6457,
      "step": 834
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40394964814186096,
      "learning_rate": 0.00016820019249278153,
      "loss": 0.6489,
      "step": 835
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4110960364341736,
      "learning_rate": 0.00016816169393647738,
      "loss": 1.0254,
      "step": 836
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4686180353164673,
      "learning_rate": 0.00016812319538017325,
      "loss": 0.6832,
      "step": 837
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31215232610702515,
      "learning_rate": 0.00016808469682386913,
      "loss": 0.7572,
      "step": 838
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44114914536476135,
      "learning_rate": 0.00016804619826756497,
      "loss": 0.7516,
      "step": 839
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4628466069698334,
      "learning_rate": 0.00016800769971126085,
      "loss": 0.8312,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.402778685092926,
      "learning_rate": 0.0001679692011549567,
      "loss": 0.6082,
      "step": 841
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4084111750125885,
      "learning_rate": 0.00016793070259865254,
      "loss": 0.857,
      "step": 842
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43011507391929626,
      "learning_rate": 0.00016789220404234842,
      "loss": 0.5912,
      "step": 843
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3666722774505615,
      "learning_rate": 0.0001678537054860443,
      "loss": 0.8075,
      "step": 844
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4387371838092804,
      "learning_rate": 0.00016781520692974014,
      "loss": 0.7016,
      "step": 845
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4301617443561554,
      "learning_rate": 0.000167776708373436,
      "loss": 0.8587,
      "step": 846
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.45435237884521484,
      "learning_rate": 0.00016773820981713186,
      "loss": 0.9283,
      "step": 847
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42567750811576843,
      "learning_rate": 0.00016769971126082774,
      "loss": 0.8345,
      "step": 848
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5085536241531372,
      "learning_rate": 0.00016766121270452358,
      "loss": 0.6658,
      "step": 849
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41667377948760986,
      "learning_rate": 0.00016762271414821943,
      "loss": 0.8367,
      "step": 850
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43233269453048706,
      "learning_rate": 0.0001675842155919153,
      "loss": 0.8026,
      "step": 851
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32341477274894714,
      "learning_rate": 0.00016754571703561118,
      "loss": 0.8264,
      "step": 852
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4784422218799591,
      "learning_rate": 0.00016750721847930703,
      "loss": 0.7404,
      "step": 853
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40146604180336,
      "learning_rate": 0.0001674687199230029,
      "loss": 0.608,
      "step": 854
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3967956602573395,
      "learning_rate": 0.00016743022136669875,
      "loss": 0.7052,
      "step": 855
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43092501163482666,
      "learning_rate": 0.00016739172281039462,
      "loss": 0.8695,
      "step": 856
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3058846592903137,
      "learning_rate": 0.00016735322425409047,
      "loss": 0.9303,
      "step": 857
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3126014173030853,
      "learning_rate": 0.00016731472569778635,
      "loss": 0.7962,
      "step": 858
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4519258141517639,
      "learning_rate": 0.00016727622714148222,
      "loss": 0.9278,
      "step": 859
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3694867193698883,
      "learning_rate": 0.00016723772858517807,
      "loss": 0.8799,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36224937438964844,
      "learning_rate": 0.00016719923002887392,
      "loss": 0.7982,
      "step": 861
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3871414065361023,
      "learning_rate": 0.0001671607314725698,
      "loss": 0.8308,
      "step": 862
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35750070214271545,
      "learning_rate": 0.00016712223291626566,
      "loss": 0.9408,
      "step": 863
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36376670002937317,
      "learning_rate": 0.0001670837343599615,
      "loss": 0.5507,
      "step": 864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.44785165786743164,
      "learning_rate": 0.00016704523580365736,
      "loss": 0.7235,
      "step": 865
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3633347451686859,
      "learning_rate": 0.00016700673724735323,
      "loss": 0.8807,
      "step": 866
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3864636719226837,
      "learning_rate": 0.0001669682386910491,
      "loss": 0.7263,
      "step": 867
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.411888062953949,
      "learning_rate": 0.00016692974013474496,
      "loss": 0.9225,
      "step": 868
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3231404423713684,
      "learning_rate": 0.00016689124157844083,
      "loss": 0.9061,
      "step": 869
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4525030553340912,
      "learning_rate": 0.00016685274302213668,
      "loss": 0.6509,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40726369619369507,
      "learning_rate": 0.00016681424446583253,
      "loss": 0.7813,
      "step": 871
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4267323613166809,
      "learning_rate": 0.0001667757459095284,
      "loss": 0.7504,
      "step": 872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.41709521412849426,
      "learning_rate": 0.00016673724735322427,
      "loss": 0.6476,
      "step": 873
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37306755781173706,
      "learning_rate": 0.00016669874879692012,
      "loss": 0.7741,
      "step": 874
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39880815148353577,
      "learning_rate": 0.00016666025024061597,
      "loss": 0.5553,
      "step": 875
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3532627522945404,
      "learning_rate": 0.00016662175168431184,
      "loss": 0.7507,
      "step": 876
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4160521626472473,
      "learning_rate": 0.00016658325312800772,
      "loss": 0.9009,
      "step": 877
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4004802405834198,
      "learning_rate": 0.00016654475457170357,
      "loss": 0.8608,
      "step": 878
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3720623254776001,
      "learning_rate": 0.0001665062560153994,
      "loss": 0.7846,
      "step": 879
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43344712257385254,
      "learning_rate": 0.0001664677574590953,
      "loss": 0.7161,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35037553310394287,
      "learning_rate": 0.00016642925890279116,
      "loss": 0.7835,
      "step": 881
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4126090407371521,
      "learning_rate": 0.000166390760346487,
      "loss": 0.7939,
      "step": 882
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3827371299266815,
      "learning_rate": 0.00016635226179018288,
      "loss": 0.7974,
      "step": 883
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4822234511375427,
      "learning_rate": 0.00016631376323387873,
      "loss": 0.6339,
      "step": 884
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3417407274246216,
      "learning_rate": 0.0001662752646775746,
      "loss": 0.8654,
      "step": 885
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35460445284843445,
      "learning_rate": 0.00016623676612127045,
      "loss": 0.5415,
      "step": 886
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3304254114627838,
      "learning_rate": 0.00016619826756496633,
      "loss": 0.694,
      "step": 887
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3509129285812378,
      "learning_rate": 0.0001661597690086622,
      "loss": 0.7794,
      "step": 888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3687591254711151,
      "learning_rate": 0.00016612127045235802,
      "loss": 0.9093,
      "step": 889
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3833083510398865,
      "learning_rate": 0.0001660827718960539,
      "loss": 0.7691,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3668593168258667,
      "learning_rate": 0.00016604427333974977,
      "loss": 0.7972,
      "step": 891
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38549745082855225,
      "learning_rate": 0.00016600577478344565,
      "loss": 0.7949,
      "step": 892
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4266708195209503,
      "learning_rate": 0.0001659672762271415,
      "loss": 0.8721,
      "step": 893
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39876678586006165,
      "learning_rate": 0.00016592877767083734,
      "loss": 0.763,
      "step": 894
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.445230096578598,
      "learning_rate": 0.00016589027911453322,
      "loss": 0.7947,
      "step": 895
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4430351257324219,
      "learning_rate": 0.00016585178055822906,
      "loss": 0.7779,
      "step": 896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4220488965511322,
      "learning_rate": 0.00016581328200192494,
      "loss": 0.7641,
      "step": 897
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.45670175552368164,
      "learning_rate": 0.0001657747834456208,
      "loss": 0.5795,
      "step": 898
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.34386640787124634,
      "learning_rate": 0.00016573628488931666,
      "loss": 0.9229,
      "step": 899
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4725986123085022,
      "learning_rate": 0.0001656977863330125,
      "loss": 0.7,
      "step": 900
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39845186471939087,
      "learning_rate": 0.00016565928777670838,
      "loss": 0.8275,
      "step": 901
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3908142149448395,
      "learning_rate": 0.00016562078922040426,
      "loss": 0.7597,
      "step": 902
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38814297318458557,
      "learning_rate": 0.0001655822906641001,
      "loss": 0.8163,
      "step": 903
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5420342087745667,
      "learning_rate": 0.00016554379210779595,
      "loss": 0.7512,
      "step": 904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43442463874816895,
      "learning_rate": 0.00016550529355149183,
      "loss": 0.6853,
      "step": 905
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3723842203617096,
      "learning_rate": 0.0001654667949951877,
      "loss": 0.7244,
      "step": 906
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39102187752723694,
      "learning_rate": 0.00016542829643888355,
      "loss": 0.6404,
      "step": 907
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4673289954662323,
      "learning_rate": 0.0001653897978825794,
      "loss": 0.7157,
      "step": 908
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3619476854801178,
      "learning_rate": 0.00016535129932627527,
      "loss": 0.6714,
      "step": 909
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35128358006477356,
      "learning_rate": 0.00016531280076997114,
      "loss": 0.7696,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4009929597377777,
      "learning_rate": 0.000165274302213667,
      "loss": 0.6706,
      "step": 911
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4207339882850647,
      "learning_rate": 0.00016523580365736287,
      "loss": 0.7959,
      "step": 912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3549601137638092,
      "learning_rate": 0.0001651973051010587,
      "loss": 0.8371,
      "step": 913
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3207203447818756,
      "learning_rate": 0.00016515880654475456,
      "loss": 0.8151,
      "step": 914
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3994414806365967,
      "learning_rate": 0.00016512030798845044,
      "loss": 0.65,
      "step": 915
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3931208550930023,
      "learning_rate": 0.0001650818094321463,
      "loss": 0.704,
      "step": 916
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3657586872577667,
      "learning_rate": 0.00016504331087584218,
      "loss": 0.7944,
      "step": 917
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.49718624353408813,
      "learning_rate": 0.000165004812319538,
      "loss": 0.8918,
      "step": 918
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4042849838733673,
      "learning_rate": 0.00016496631376323388,
      "loss": 0.7726,
      "step": 919
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43885496258735657,
      "learning_rate": 0.00016492781520692975,
      "loss": 0.7369,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.395626038312912,
      "learning_rate": 0.0001648893166506256,
      "loss": 0.7727,
      "step": 921
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3479551672935486,
      "learning_rate": 0.00016485081809432148,
      "loss": 0.7626,
      "step": 922
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4263276755809784,
      "learning_rate": 0.00016481231953801732,
      "loss": 0.6324,
      "step": 923
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4631369709968567,
      "learning_rate": 0.0001647738209817132,
      "loss": 0.7791,
      "step": 924
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4488198459148407,
      "learning_rate": 0.00016473532242540905,
      "loss": 0.8926,
      "step": 925
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3350141942501068,
      "learning_rate": 0.00016469682386910492,
      "loss": 0.8875,
      "step": 926
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39391931891441345,
      "learning_rate": 0.0001646583253128008,
      "loss": 0.7004,
      "step": 927
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4591343402862549,
      "learning_rate": 0.00016461982675649664,
      "loss": 0.7825,
      "step": 928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.38827601075172424,
      "learning_rate": 0.0001645813282001925,
      "loss": 0.6996,
      "step": 929
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5408360958099365,
      "learning_rate": 0.00016454282964388836,
      "loss": 0.7021,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4326247274875641,
      "learning_rate": 0.00016450433108758424,
      "loss": 0.6435,
      "step": 931
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4867457449436188,
      "learning_rate": 0.00016446583253128009,
      "loss": 0.7597,
      "step": 932
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3760989308357239,
      "learning_rate": 0.00016442733397497593,
      "loss": 0.6706,
      "step": 933
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3735730051994324,
      "learning_rate": 0.0001643888354186718,
      "loss": 0.7442,
      "step": 934
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.38337427377700806,
      "learning_rate": 0.00016435033686236768,
      "loss": 0.7391,
      "step": 935
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5188639163970947,
      "learning_rate": 0.00016431183830606353,
      "loss": 0.7199,
      "step": 936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.37170079350471497,
      "learning_rate": 0.0001642733397497594,
      "loss": 0.7128,
      "step": 937
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.36097222566604614,
      "learning_rate": 0.00016423484119345525,
      "loss": 0.8414,
      "step": 938
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43014106154441833,
      "learning_rate": 0.00016419634263715113,
      "loss": 0.7604,
      "step": 939
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4507324695587158,
      "learning_rate": 0.00016415784408084697,
      "loss": 0.8167,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4373815655708313,
      "learning_rate": 0.00016411934552454285,
      "loss": 0.7081,
      "step": 941
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40306782722473145,
      "learning_rate": 0.0001640808469682387,
      "loss": 0.6262,
      "step": 942
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4570135176181793,
      "learning_rate": 0.00016404234841193454,
      "loss": 0.7642,
      "step": 943
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46375465393066406,
      "learning_rate": 0.00016400384985563042,
      "loss": 0.7348,
      "step": 944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5628307461738586,
      "learning_rate": 0.0001639653512993263,
      "loss": 0.4934,
      "step": 945
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3285540044307709,
      "learning_rate": 0.00016392685274302214,
      "loss": 0.7409,
      "step": 946
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4342636466026306,
      "learning_rate": 0.000163888354186718,
      "loss": 0.6037,
      "step": 947
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46476995944976807,
      "learning_rate": 0.00016384985563041386,
      "loss": 0.7684,
      "step": 948
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.384127140045166,
      "learning_rate": 0.00016381135707410974,
      "loss": 0.722,
      "step": 949
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3942120373249054,
      "learning_rate": 0.00016377285851780558,
      "loss": 0.8695,
      "step": 950
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.352477103471756,
      "learning_rate": 0.00016373435996150146,
      "loss": 0.8088,
      "step": 951
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.35834285616874695,
      "learning_rate": 0.0001636958614051973,
      "loss": 0.7048,
      "step": 952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4362132251262665,
      "learning_rate": 0.00016365736284889318,
      "loss": 0.7584,
      "step": 953
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5655164122581482,
      "learning_rate": 0.00016361886429258903,
      "loss": 0.7591,
      "step": 954
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3786676824092865,
      "learning_rate": 0.0001635803657362849,
      "loss": 0.7533,
      "step": 955
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.432732492685318,
      "learning_rate": 0.00016354186717998078,
      "loss": 0.8608,
      "step": 956
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5503681898117065,
      "learning_rate": 0.00016350336862367662,
      "loss": 0.8209,
      "step": 957
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3569778800010681,
      "learning_rate": 0.00016346487006737247,
      "loss": 0.9292,
      "step": 958
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4056509733200073,
      "learning_rate": 0.00016342637151106835,
      "loss": 0.771,
      "step": 959
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.397250235080719,
      "learning_rate": 0.00016338787295476422,
      "loss": 0.8156,
      "step": 960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.401607483625412,
      "learning_rate": 0.00016334937439846007,
      "loss": 0.9892,
      "step": 961
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4879361093044281,
      "learning_rate": 0.00016331087584215591,
      "loss": 0.6769,
      "step": 962
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5391526222229004,
      "learning_rate": 0.0001632723772858518,
      "loss": 0.8177,
      "step": 963
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49405503273010254,
      "learning_rate": 0.00016323387872954766,
      "loss": 0.8344,
      "step": 964
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4291273057460785,
      "learning_rate": 0.0001631953801732435,
      "loss": 0.7129,
      "step": 965
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4620632827281952,
      "learning_rate": 0.00016315688161693939,
      "loss": 0.6563,
      "step": 966
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4600706100463867,
      "learning_rate": 0.00016311838306063523,
      "loss": 0.7658,
      "step": 967
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41418954730033875,
      "learning_rate": 0.00016307988450433108,
      "loss": 0.9749,
      "step": 968
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.31654787063598633,
      "learning_rate": 0.00016304138594802696,
      "loss": 0.802,
      "step": 969
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3953390121459961,
      "learning_rate": 0.00016300288739172283,
      "loss": 0.7323,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45991116762161255,
      "learning_rate": 0.00016296438883541868,
      "loss": 0.637,
      "step": 971
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.31873950362205505,
      "learning_rate": 0.00016292589027911452,
      "loss": 0.6832,
      "step": 972
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4046448767185211,
      "learning_rate": 0.0001628873917228104,
      "loss": 0.7325,
      "step": 973
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37110888957977295,
      "learning_rate": 0.00016284889316650627,
      "loss": 0.8734,
      "step": 974
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44934526085853577,
      "learning_rate": 0.00016281039461020212,
      "loss": 0.8081,
      "step": 975
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35538485646247864,
      "learning_rate": 0.00016277189605389797,
      "loss": 0.9444,
      "step": 976
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3702569007873535,
      "learning_rate": 0.00016273339749759384,
      "loss": 0.6102,
      "step": 977
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.32300740480422974,
      "learning_rate": 0.00016269489894128972,
      "loss": 0.7059,
      "step": 978
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.38859209418296814,
      "learning_rate": 0.00016265640038498556,
      "loss": 0.6427,
      "step": 979
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4092036187648773,
      "learning_rate": 0.00016261790182868144,
      "loss": 0.7174,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3881808817386627,
      "learning_rate": 0.0001625794032723773,
      "loss": 0.7007,
      "step": 981
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3992134630680084,
      "learning_rate": 0.00016254090471607316,
      "loss": 0.8398,
      "step": 982
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.46422716975212097,
      "learning_rate": 0.000162502406159769,
      "loss": 0.769,
      "step": 983
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.43485212326049805,
      "learning_rate": 0.00016246390760346488,
      "loss": 0.7374,
      "step": 984
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48495355248451233,
      "learning_rate": 0.00016242540904716076,
      "loss": 0.8433,
      "step": 985
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3639756739139557,
      "learning_rate": 0.0001623869104908566,
      "loss": 0.7457,
      "step": 986
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40549436211586,
      "learning_rate": 0.00016234841193455245,
      "loss": 0.596,
      "step": 987
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.36418217420578003,
      "learning_rate": 0.00016230991337824833,
      "loss": 0.742,
      "step": 988
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40171492099761963,
      "learning_rate": 0.0001622714148219442,
      "loss": 0.6389,
      "step": 989
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37999212741851807,
      "learning_rate": 0.00016223291626564005,
      "loss": 0.8567,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35829946398735046,
      "learning_rate": 0.0001621944177093359,
      "loss": 0.7595,
      "step": 991
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41418832540512085,
      "learning_rate": 0.00016215591915303177,
      "loss": 0.7844,
      "step": 992
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.33283162117004395,
      "learning_rate": 0.00016211742059672762,
      "loss": 0.7621,
      "step": 993
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41083329916000366,
      "learning_rate": 0.0001620789220404235,
      "loss": 0.7489,
      "step": 994
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4054572880268097,
      "learning_rate": 0.00016204042348411937,
      "loss": 0.9847,
      "step": 995
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48309609293937683,
      "learning_rate": 0.00016200192492781522,
      "loss": 0.7008,
      "step": 996
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3439509868621826,
      "learning_rate": 0.00016196342637151106,
      "loss": 0.8005,
      "step": 997
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4324743449687958,
      "learning_rate": 0.00016192492781520694,
      "loss": 0.8275,
      "step": 998
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41427528858184814,
      "learning_rate": 0.0001618864292589028,
      "loss": 0.6806,
      "step": 999
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4183162450790405,
      "learning_rate": 0.00016184793070259866,
      "loss": 0.8269,
      "step": 1000
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5142911672592163,
      "learning_rate": 0.0001618094321462945,
      "loss": 0.8053,
      "step": 1001
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4092613756656647,
      "learning_rate": 0.00016177093358999038,
      "loss": 0.7476,
      "step": 1002
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.38816404342651367,
      "learning_rate": 0.00016173243503368626,
      "loss": 0.59,
      "step": 1003
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.361930251121521,
      "learning_rate": 0.0001616939364773821,
      "loss": 0.7135,
      "step": 1004
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3976987898349762,
      "learning_rate": 0.00016165543792107795,
      "loss": 0.8899,
      "step": 1005
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.47700369358062744,
      "learning_rate": 0.00016161693936477382,
      "loss": 0.8206,
      "step": 1006
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.42015111446380615,
      "learning_rate": 0.0001615784408084697,
      "loss": 0.6419,
      "step": 1007
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.322148859500885,
      "learning_rate": 0.00016153994225216555,
      "loss": 0.8123,
      "step": 1008
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4050061106681824,
      "learning_rate": 0.00016150144369586142,
      "loss": 0.6976,
      "step": 1009
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35987138748168945,
      "learning_rate": 0.00016146294513955727,
      "loss": 0.8419,
      "step": 1010
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.33031243085861206,
      "learning_rate": 0.00016142444658325314,
      "loss": 0.7068,
      "step": 1011
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37613943219184875,
      "learning_rate": 0.000161385948026949,
      "loss": 0.6742,
      "step": 1012
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.30047333240509033,
      "learning_rate": 0.00016134744947064487,
      "loss": 0.9531,
      "step": 1013
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41578543186187744,
      "learning_rate": 0.00016130895091434074,
      "loss": 0.7668,
      "step": 1014
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3834519386291504,
      "learning_rate": 0.00016127045235803656,
      "loss": 0.6452,
      "step": 1015
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4907706677913666,
      "learning_rate": 0.00016123195380173243,
      "loss": 0.7805,
      "step": 1016
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4117744565010071,
      "learning_rate": 0.0001611934552454283,
      "loss": 0.7221,
      "step": 1017
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.37471017241477966,
      "learning_rate": 0.00016115495668912418,
      "loss": 0.5763,
      "step": 1018
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.40107065439224243,
      "learning_rate": 0.00016111645813282003,
      "loss": 0.6287,
      "step": 1019
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.34944072365760803,
      "learning_rate": 0.00016107795957651588,
      "loss": 0.7101,
      "step": 1020
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.37754085659980774,
      "learning_rate": 0.00016103946102021175,
      "loss": 0.8282,
      "step": 1021
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3539876639842987,
      "learning_rate": 0.0001610009624639076,
      "loss": 0.7358,
      "step": 1022
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3631936311721802,
      "learning_rate": 0.00016096246390760348,
      "loss": 0.6122,
      "step": 1023
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47914162278175354,
      "learning_rate": 0.00016092396535129935,
      "loss": 0.691,
      "step": 1024
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4048551023006439,
      "learning_rate": 0.0001608854667949952,
      "loss": 0.7443,
      "step": 1025
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6048703789710999,
      "learning_rate": 0.00016084696823869104,
      "loss": 0.8451,
      "step": 1026
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35409149527549744,
      "learning_rate": 0.00016080846968238692,
      "loss": 0.7463,
      "step": 1027
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.42525529861450195,
      "learning_rate": 0.0001607699711260828,
      "loss": 0.8458,
      "step": 1028
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4068790078163147,
      "learning_rate": 0.00016073147256977864,
      "loss": 0.6435,
      "step": 1029
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4333082139492035,
      "learning_rate": 0.0001606929740134745,
      "loss": 0.8844,
      "step": 1030
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4256124794483185,
      "learning_rate": 0.00016065447545717036,
      "loss": 0.7161,
      "step": 1031
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.36612895131111145,
      "learning_rate": 0.00016061597690086624,
      "loss": 0.6555,
      "step": 1032
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4030144214630127,
      "learning_rate": 0.00016057747834456208,
      "loss": 0.6805,
      "step": 1033
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4624347686767578,
      "learning_rate": 0.00016053897978825793,
      "loss": 0.682,
      "step": 1034
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4160405695438385,
      "learning_rate": 0.0001605004812319538,
      "loss": 0.809,
      "step": 1035
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6042136549949646,
      "learning_rate": 0.00016046198267564968,
      "loss": 0.7938,
      "step": 1036
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3848523795604706,
      "learning_rate": 0.00016042348411934553,
      "loss": 0.7986,
      "step": 1037
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4119400084018707,
      "learning_rate": 0.0001603849855630414,
      "loss": 0.7507,
      "step": 1038
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38147005438804626,
      "learning_rate": 0.00016034648700673725,
      "loss": 0.7639,
      "step": 1039
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38466325402259827,
      "learning_rate": 0.0001603079884504331,
      "loss": 0.5987,
      "step": 1040
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35815778374671936,
      "learning_rate": 0.00016026948989412897,
      "loss": 0.8265,
      "step": 1041
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4350082278251648,
      "learning_rate": 0.00016023099133782485,
      "loss": 0.8239,
      "step": 1042
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3755597770214081,
      "learning_rate": 0.00016019249278152072,
      "loss": 0.6357,
      "step": 1043
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3866950571537018,
      "learning_rate": 0.00016015399422521654,
      "loss": 0.7056,
      "step": 1044
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.39442890882492065,
      "learning_rate": 0.00016011549566891242,
      "loss": 0.6839,
      "step": 1045
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38096630573272705,
      "learning_rate": 0.0001600769971126083,
      "loss": 0.8712,
      "step": 1046
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.41441237926483154,
      "learning_rate": 0.00016003849855630414,
      "loss": 0.6685,
      "step": 1047
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3981308043003082,
      "learning_rate": 0.00016,
      "loss": 0.6351,
      "step": 1048
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.45708170533180237,
      "learning_rate": 0.00015996150144369586,
      "loss": 0.7258,
      "step": 1049
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38272976875305176,
      "learning_rate": 0.00015992300288739174,
      "loss": 0.789,
      "step": 1050
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.39918795228004456,
      "learning_rate": 0.00015988450433108758,
      "loss": 0.7441,
      "step": 1051
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3819565176963806,
      "learning_rate": 0.00015984600577478346,
      "loss": 0.9613,
      "step": 1052
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3901863992214203,
      "learning_rate": 0.00015980750721847933,
      "loss": 0.7707,
      "step": 1053
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4171031415462494,
      "learning_rate": 0.00015976900866217518,
      "loss": 0.859,
      "step": 1054
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35221830010414124,
      "learning_rate": 0.00015973051010587103,
      "loss": 0.7238,
      "step": 1055
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3382309377193451,
      "learning_rate": 0.0001596920115495669,
      "loss": 0.8949,
      "step": 1056
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43097177147865295,
      "learning_rate": 0.00015965351299326278,
      "loss": 0.6984,
      "step": 1057
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.523605465888977,
      "learning_rate": 0.00015961501443695862,
      "loss": 0.8488,
      "step": 1058
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3962565064430237,
      "learning_rate": 0.00015957651588065447,
      "loss": 0.832,
      "step": 1059
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4559690058231354,
      "learning_rate": 0.00015953801732435034,
      "loss": 0.6859,
      "step": 1060
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4435402452945709,
      "learning_rate": 0.00015949951876804622,
      "loss": 0.6989,
      "step": 1061
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.41022989153862,
      "learning_rate": 0.00015946102021174207,
      "loss": 0.8035,
      "step": 1062
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3245035409927368,
      "learning_rate": 0.00015942252165543794,
      "loss": 0.6999,
      "step": 1063
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3887791633605957,
      "learning_rate": 0.0001593840230991338,
      "loss": 0.857,
      "step": 1064
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43856510519981384,
      "learning_rate": 0.00015934552454282964,
      "loss": 0.792,
      "step": 1065
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4955058693885803,
      "learning_rate": 0.0001593070259865255,
      "loss": 0.6905,
      "step": 1066
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4128498435020447,
      "learning_rate": 0.00015926852743022139,
      "loss": 0.7242,
      "step": 1067
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.46775028109550476,
      "learning_rate": 0.00015923002887391723,
      "loss": 0.7838,
      "step": 1068
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4442056119441986,
      "learning_rate": 0.00015919153031761308,
      "loss": 0.9226,
      "step": 1069
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4513077735900879,
      "learning_rate": 0.00015915303176130895,
      "loss": 0.7096,
      "step": 1070
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.37649473547935486,
      "learning_rate": 0.00015911453320500483,
      "loss": 0.8549,
      "step": 1071
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3761226236820221,
      "learning_rate": 0.00015907603464870068,
      "loss": 0.6773,
      "step": 1072
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.44938531517982483,
      "learning_rate": 0.00015903753609239652,
      "loss": 0.8688,
      "step": 1073
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3570939004421234,
      "learning_rate": 0.0001589990375360924,
      "loss": 0.6599,
      "step": 1074
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.391732782125473,
      "learning_rate": 0.00015896053897978827,
      "loss": 0.8761,
      "step": 1075
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3916613757610321,
      "learning_rate": 0.00015892204042348412,
      "loss": 0.907,
      "step": 1076
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49295851588249207,
      "learning_rate": 0.00015888354186718,
      "loss": 0.8555,
      "step": 1077
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5562530159950256,
      "learning_rate": 0.00015884504331087584,
      "loss": 0.6782,
      "step": 1078
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49062034487724304,
      "learning_rate": 0.00015880654475457172,
      "loss": 0.7649,
      "step": 1079
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3299710750579834,
      "learning_rate": 0.00015876804619826756,
      "loss": 0.6624,
      "step": 1080
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.45431676506996155,
      "learning_rate": 0.00015872954764196344,
      "loss": 0.7707,
      "step": 1081
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4144875109195709,
      "learning_rate": 0.0001586910490856593,
      "loss": 0.8769,
      "step": 1082
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4578436315059662,
      "learning_rate": 0.00015865255052935516,
      "loss": 0.8283,
      "step": 1083
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4305632710456848,
      "learning_rate": 0.000158614051973051,
      "loss": 0.8501,
      "step": 1084
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.36283501982688904,
      "learning_rate": 0.00015857555341674688,
      "loss": 0.6244,
      "step": 1085
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.38496094942092896,
      "learning_rate": 0.00015853705486044276,
      "loss": 0.8103,
      "step": 1086
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.43834495544433594,
      "learning_rate": 0.0001584985563041386,
      "loss": 0.8195,
      "step": 1087
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3856014609336853,
      "learning_rate": 0.00015846005774783445,
      "loss": 0.7114,
      "step": 1088
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.33795177936553955,
      "learning_rate": 0.00015842155919153033,
      "loss": 0.7954,
      "step": 1089
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.376462459564209,
      "learning_rate": 0.0001583830606352262,
      "loss": 0.7439,
      "step": 1090
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.48316308856010437,
      "learning_rate": 0.00015834456207892205,
      "loss": 0.7894,
      "step": 1091
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4347042739391327,
      "learning_rate": 0.00015830606352261792,
      "loss": 0.8222,
      "step": 1092
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3903662860393524,
      "learning_rate": 0.00015826756496631377,
      "loss": 0.7958,
      "step": 1093
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.34410256147384644,
      "learning_rate": 0.00015822906641000962,
      "loss": 0.7444,
      "step": 1094
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.34057170152664185,
      "learning_rate": 0.0001581905678537055,
      "loss": 1.0525,
      "step": 1095
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.39681077003479004,
      "learning_rate": 0.00015815206929740137,
      "loss": 0.8238,
      "step": 1096
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.42502957582473755,
      "learning_rate": 0.00015811357074109721,
      "loss": 0.6958,
      "step": 1097
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.43412235379219055,
      "learning_rate": 0.00015807507218479306,
      "loss": 0.8056,
      "step": 1098
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4639730155467987,
      "learning_rate": 0.00015803657362848894,
      "loss": 0.8045,
      "step": 1099
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3501754403114319,
      "learning_rate": 0.0001579980750721848,
      "loss": 0.9637,
      "step": 1100
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4487448036670685,
      "learning_rate": 0.00015795957651588066,
      "loss": 0.7817,
      "step": 1101
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3290480077266693,
      "learning_rate": 0.0001579210779595765,
      "loss": 0.6841,
      "step": 1102
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3948013186454773,
      "learning_rate": 0.00015788257940327238,
      "loss": 0.7926,
      "step": 1103
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3786340057849884,
      "learning_rate": 0.00015784408084696825,
      "loss": 0.7677,
      "step": 1104
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.40259552001953125,
      "learning_rate": 0.0001578055822906641,
      "loss": 0.7114,
      "step": 1105
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.41371214389801025,
      "learning_rate": 0.00015776708373435998,
      "loss": 0.6498,
      "step": 1106
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.36139020323753357,
      "learning_rate": 0.00015772858517805582,
      "loss": 0.6922,
      "step": 1107
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3744065761566162,
      "learning_rate": 0.0001576900866217517,
      "loss": 0.8142,
      "step": 1108
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4204704463481903,
      "learning_rate": 0.00015765158806544755,
      "loss": 1.0868,
      "step": 1109
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.36215659976005554,
      "learning_rate": 0.00015761308950914342,
      "loss": 0.6075,
      "step": 1110
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.530100405216217,
      "learning_rate": 0.0001575745909528393,
      "loss": 0.9125,
      "step": 1111
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4111427366733551,
      "learning_rate": 0.00015753609239653512,
      "loss": 0.7786,
      "step": 1112
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4359910786151886,
      "learning_rate": 0.000157497593840231,
      "loss": 0.7531,
      "step": 1113
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.39710521697998047,
      "learning_rate": 0.00015745909528392686,
      "loss": 0.6205,
      "step": 1114
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3554534614086151,
      "learning_rate": 0.00015742059672762274,
      "loss": 0.8446,
      "step": 1115
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4166891574859619,
      "learning_rate": 0.0001573820981713186,
      "loss": 0.672,
      "step": 1116
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4184480607509613,
      "learning_rate": 0.00015734359961501443,
      "loss": 0.6638,
      "step": 1117
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.37945467233657837,
      "learning_rate": 0.0001573051010587103,
      "loss": 0.7022,
      "step": 1118
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3724149465560913,
      "learning_rate": 0.00015726660250240616,
      "loss": 0.7179,
      "step": 1119
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.36571890115737915,
      "learning_rate": 0.00015722810394610203,
      "loss": 0.8142,
      "step": 1120
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43435412645339966,
      "learning_rate": 0.0001571896053897979,
      "loss": 0.5344,
      "step": 1121
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43020376563072205,
      "learning_rate": 0.00015715110683349375,
      "loss": 0.8112,
      "step": 1122
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3460918962955475,
      "learning_rate": 0.0001571126082771896,
      "loss": 0.7552,
      "step": 1123
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3977578282356262,
      "learning_rate": 0.00015707410972088547,
      "loss": 0.6842,
      "step": 1124
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.48570865392684937,
      "learning_rate": 0.00015703561116458135,
      "loss": 0.7387,
      "step": 1125
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.40693992376327515,
      "learning_rate": 0.0001569971126082772,
      "loss": 0.777,
      "step": 1126
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4439678192138672,
      "learning_rate": 0.00015695861405197304,
      "loss": 0.7193,
      "step": 1127
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46327605843544006,
      "learning_rate": 0.00015692011549566892,
      "loss": 0.7203,
      "step": 1128
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3540477156639099,
      "learning_rate": 0.0001568816169393648,
      "loss": 0.6745,
      "step": 1129
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.38922786712646484,
      "learning_rate": 0.00015684311838306064,
      "loss": 0.6775,
      "step": 1130
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5611504912376404,
      "learning_rate": 0.0001568046198267565,
      "loss": 0.7527,
      "step": 1131
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.31474006175994873,
      "learning_rate": 0.00015676612127045236,
      "loss": 0.6399,
      "step": 1132
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.44689998030662537,
      "learning_rate": 0.00015672762271414824,
      "loss": 0.8319,
      "step": 1133
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.32527533173561096,
      "learning_rate": 0.00015668912415784408,
      "loss": 0.7247,
      "step": 1134
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42637091875076294,
      "learning_rate": 0.00015665062560153996,
      "loss": 0.7363,
      "step": 1135
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.37939783930778503,
      "learning_rate": 0.0001566121270452358,
      "loss": 0.8506,
      "step": 1136
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.38763850927352905,
      "learning_rate": 0.00015657362848893168,
      "loss": 0.7845,
      "step": 1137
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.35469725728034973,
      "learning_rate": 0.00015653512993262753,
      "loss": 0.6412,
      "step": 1138
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42117586731910706,
      "learning_rate": 0.0001564966313763234,
      "loss": 0.7159,
      "step": 1139
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39332911372184753,
      "learning_rate": 0.00015645813282001928,
      "loss": 0.807,
      "step": 1140
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4328210949897766,
      "learning_rate": 0.0001564196342637151,
      "loss": 0.8745,
      "step": 1141
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3921777307987213,
      "learning_rate": 0.00015638113570741097,
      "loss": 0.8571,
      "step": 1142
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4740988314151764,
      "learning_rate": 0.00015634263715110685,
      "loss": 0.7963,
      "step": 1143
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.44173067808151245,
      "learning_rate": 0.0001563041385948027,
      "loss": 0.757,
      "step": 1144
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.32797256112098694,
      "learning_rate": 0.00015626564003849857,
      "loss": 0.7753,
      "step": 1145
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39528781175613403,
      "learning_rate": 0.00015622714148219442,
      "loss": 0.7109,
      "step": 1146
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39863264560699463,
      "learning_rate": 0.0001561886429258903,
      "loss": 0.7359,
      "step": 1147
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42865288257598877,
      "learning_rate": 0.00015615014436958614,
      "loss": 0.9774,
      "step": 1148
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.40217769145965576,
      "learning_rate": 0.000156111645813282,
      "loss": 0.7529,
      "step": 1149
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3679961860179901,
      "learning_rate": 0.0001560731472569779,
      "loss": 0.7246,
      "step": 1150
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3621695041656494,
      "learning_rate": 0.00015603464870067373,
      "loss": 0.809,
      "step": 1151
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.35603639483451843,
      "learning_rate": 0.00015599615014436958,
      "loss": 0.6261,
      "step": 1152
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46975716948509216,
      "learning_rate": 0.00015595765158806546,
      "loss": 0.7644,
      "step": 1153
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.40510255098342896,
      "learning_rate": 0.00015591915303176133,
      "loss": 0.661,
      "step": 1154
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46312135457992554,
      "learning_rate": 0.00015588065447545718,
      "loss": 0.7586,
      "step": 1155
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42839890718460083,
      "learning_rate": 0.00015584215591915303,
      "loss": 0.9198,
      "step": 1156
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5583325028419495,
      "learning_rate": 0.0001558036573628489,
      "loss": 0.8399,
      "step": 1157
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4485267698764801,
      "learning_rate": 0.00015576515880654477,
      "loss": 0.8856,
      "step": 1158
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4484996199607849,
      "learning_rate": 0.00015572666025024062,
      "loss": 0.82,
      "step": 1159
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.37229499220848083,
      "learning_rate": 0.00015568816169393647,
      "loss": 0.8151,
      "step": 1160
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3836243748664856,
      "learning_rate": 0.00015564966313763234,
      "loss": 0.7787,
      "step": 1161
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3747301995754242,
      "learning_rate": 0.00015561116458132822,
      "loss": 0.7317,
      "step": 1162
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4159163534641266,
      "learning_rate": 0.00015557266602502407,
      "loss": 0.7757,
      "step": 1163
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.35848599672317505,
      "learning_rate": 0.00015553416746871994,
      "loss": 0.7005,
      "step": 1164
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.38598203659057617,
      "learning_rate": 0.0001554956689124158,
      "loss": 0.6347,
      "step": 1165
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43064266443252563,
      "learning_rate": 0.00015545717035611164,
      "loss": 0.7328,
      "step": 1166
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4102381765842438,
      "learning_rate": 0.0001554186717998075,
      "loss": 0.7664,
      "step": 1167
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42717429995536804,
      "learning_rate": 0.00015538017324350338,
      "loss": 0.7261,
      "step": 1168
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3969756066799164,
      "learning_rate": 0.00015534167468719926,
      "loss": 0.988,
      "step": 1169
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4277059733867645,
      "learning_rate": 0.00015530317613089508,
      "loss": 0.8142,
      "step": 1170
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3972422182559967,
      "learning_rate": 0.00015526467757459095,
      "loss": 0.6252,
      "step": 1171
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.42406436800956726,
      "learning_rate": 0.00015522617901828683,
      "loss": 0.6827,
      "step": 1172
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.38090869784355164,
      "learning_rate": 0.00015518768046198268,
      "loss": 0.635,
      "step": 1173
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5245205760002136,
      "learning_rate": 0.00015514918190567855,
      "loss": 0.6449,
      "step": 1174
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3738233745098114,
      "learning_rate": 0.0001551106833493744,
      "loss": 0.7073,
      "step": 1175
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.42204442620277405,
      "learning_rate": 0.00015507218479307027,
      "loss": 0.6876,
      "step": 1176
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.413811057806015,
      "learning_rate": 0.00015503368623676612,
      "loss": 0.7898,
      "step": 1177
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4465698003768921,
      "learning_rate": 0.000154995187680462,
      "loss": 0.6242,
      "step": 1178
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4211638569831848,
      "learning_rate": 0.00015495668912415787,
      "loss": 0.6734,
      "step": 1179
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39296627044677734,
      "learning_rate": 0.00015491819056785372,
      "loss": 0.8385,
      "step": 1180
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.45707204937934875,
      "learning_rate": 0.00015487969201154956,
      "loss": 0.7797,
      "step": 1181
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5070324540138245,
      "learning_rate": 0.00015484119345524544,
      "loss": 0.8437,
      "step": 1182
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.44024863839149475,
      "learning_rate": 0.0001548026948989413,
      "loss": 0.8795,
      "step": 1183
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37814775109291077,
      "learning_rate": 0.00015476419634263716,
      "loss": 0.7748,
      "step": 1184
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37040790915489197,
      "learning_rate": 0.000154725697786333,
      "loss": 0.8153,
      "step": 1185
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.36610615253448486,
      "learning_rate": 0.00015468719923002888,
      "loss": 0.7506,
      "step": 1186
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.41679295897483826,
      "learning_rate": 0.00015464870067372476,
      "loss": 0.8521,
      "step": 1187
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.40299808979034424,
      "learning_rate": 0.0001546102021174206,
      "loss": 0.7421,
      "step": 1188
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3856588900089264,
      "learning_rate": 0.00015457170356111648,
      "loss": 0.8437,
      "step": 1189
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.35787302255630493,
      "learning_rate": 0.00015453320500481233,
      "loss": 0.8506,
      "step": 1190
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.34523940086364746,
      "learning_rate": 0.00015449470644850817,
      "loss": 0.8485,
      "step": 1191
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.38170987367630005,
      "learning_rate": 0.00015445620789220405,
      "loss": 0.6814,
      "step": 1192
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37243613600730896,
      "learning_rate": 0.00015441770933589992,
      "loss": 0.8571,
      "step": 1193
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39110085368156433,
      "learning_rate": 0.00015437921077959577,
      "loss": 0.7967,
      "step": 1194
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.46120139956474304,
      "learning_rate": 0.00015434071222329162,
      "loss": 0.7616,
      "step": 1195
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.491585373878479,
      "learning_rate": 0.0001543022136669875,
      "loss": 0.6762,
      "step": 1196
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3828129172325134,
      "learning_rate": 0.00015426371511068337,
      "loss": 0.8359,
      "step": 1197
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3328189253807068,
      "learning_rate": 0.00015422521655437921,
      "loss": 0.591,
      "step": 1198
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3250027000904083,
      "learning_rate": 0.00015418671799807506,
      "loss": 0.7838,
      "step": 1199
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.35278844833374023,
      "learning_rate": 0.00015414821944177094,
      "loss": 0.8331,
      "step": 1200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.35219067335128784,
      "learning_rate": 0.0001541097208854668,
      "loss": 0.7183,
      "step": 1201
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4565924108028412,
      "learning_rate": 0.00015407122232916266,
      "loss": 0.7753,
      "step": 1202
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3913572430610657,
      "learning_rate": 0.00015403272377285853,
      "loss": 0.7035,
      "step": 1203
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3244643807411194,
      "learning_rate": 0.00015399422521655438,
      "loss": 0.7814,
      "step": 1204
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.41972634196281433,
      "learning_rate": 0.00015395572666025025,
      "loss": 0.5791,
      "step": 1205
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4282330274581909,
      "learning_rate": 0.0001539172281039461,
      "loss": 0.7852,
      "step": 1206
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4206712543964386,
      "learning_rate": 0.00015387872954764198,
      "loss": 0.8797,
      "step": 1207
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3925241529941559,
      "learning_rate": 0.00015384023099133785,
      "loss": 0.8628,
      "step": 1208
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.46385809779167175,
      "learning_rate": 0.0001538017324350337,
      "loss": 0.7358,
      "step": 1209
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4132677912712097,
      "learning_rate": 0.00015376323387872955,
      "loss": 0.6425,
      "step": 1210
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3206253945827484,
      "learning_rate": 0.00015372473532242542,
      "loss": 0.9339,
      "step": 1211
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6679430603981018,
      "learning_rate": 0.0001536862367661213,
      "loss": 0.8193,
      "step": 1212
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5866867303848267,
      "learning_rate": 0.00015364773820981714,
      "loss": 0.8315,
      "step": 1213
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.503413736820221,
      "learning_rate": 0.000153609239653513,
      "loss": 0.6992,
      "step": 1214
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3816224932670593,
      "learning_rate": 0.00015357074109720886,
      "loss": 0.667,
      "step": 1215
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4119608402252197,
      "learning_rate": 0.0001535322425409047,
      "loss": 0.7139,
      "step": 1216
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3772684931755066,
      "learning_rate": 0.00015349374398460059,
      "loss": 0.6538,
      "step": 1217
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.331874281167984,
      "learning_rate": 0.00015345524542829646,
      "loss": 0.7934,
      "step": 1218
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37601643800735474,
      "learning_rate": 0.0001534167468719923,
      "loss": 0.9004,
      "step": 1219
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39214855432510376,
      "learning_rate": 0.00015337824831568816,
      "loss": 0.7811,
      "step": 1220
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4096325635910034,
      "learning_rate": 0.00015333974975938403,
      "loss": 0.4574,
      "step": 1221
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5163927674293518,
      "learning_rate": 0.0001533012512030799,
      "loss": 0.7136,
      "step": 1222
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.378543496131897,
      "learning_rate": 0.00015326275264677575,
      "loss": 0.7433,
      "step": 1223
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35357967019081116,
      "learning_rate": 0.0001532242540904716,
      "loss": 0.948,
      "step": 1224
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.39216411113739014,
      "learning_rate": 0.00015318575553416747,
      "loss": 0.8092,
      "step": 1225
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.34394603967666626,
      "learning_rate": 0.00015314725697786335,
      "loss": 0.8093,
      "step": 1226
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.34032198786735535,
      "learning_rate": 0.0001531087584215592,
      "loss": 0.8504,
      "step": 1227
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.38798490166664124,
      "learning_rate": 0.00015307025986525504,
      "loss": 0.8131,
      "step": 1228
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.359995037317276,
      "learning_rate": 0.00015303176130895092,
      "loss": 0.8589,
      "step": 1229
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.36750391125679016,
      "learning_rate": 0.0001529932627526468,
      "loss": 0.5993,
      "step": 1230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.39933866262435913,
      "learning_rate": 0.00015295476419634264,
      "loss": 0.8306,
      "step": 1231
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3552697002887726,
      "learning_rate": 0.00015291626564003851,
      "loss": 0.7849,
      "step": 1232
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4225974380970001,
      "learning_rate": 0.00015287776708373436,
      "loss": 0.8307,
      "step": 1233
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4953029155731201,
      "learning_rate": 0.00015283926852743024,
      "loss": 0.8045,
      "step": 1234
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3827214539051056,
      "learning_rate": 0.00015280076997112608,
      "loss": 0.7014,
      "step": 1235
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35699954628944397,
      "learning_rate": 0.00015276227141482196,
      "loss": 0.8127,
      "step": 1236
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.41991326212882996,
      "learning_rate": 0.00015272377285851783,
      "loss": 0.7286,
      "step": 1237
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33881086111068726,
      "learning_rate": 0.00015268527430221365,
      "loss": 0.7056,
      "step": 1238
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4219568967819214,
      "learning_rate": 0.00015264677574590953,
      "loss": 0.7692,
      "step": 1239
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.39442741870880127,
      "learning_rate": 0.0001526082771896054,
      "loss": 0.7731,
      "step": 1240
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.38032737374305725,
      "learning_rate": 0.00015256977863330128,
      "loss": 0.7972,
      "step": 1241
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33482059836387634,
      "learning_rate": 0.00015253128007699712,
      "loss": 0.9594,
      "step": 1242
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4163847863674164,
      "learning_rate": 0.00015249278152069297,
      "loss": 0.8304,
      "step": 1243
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3635527491569519,
      "learning_rate": 0.00015245428296438885,
      "loss": 0.6583,
      "step": 1244
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3936399519443512,
      "learning_rate": 0.0001524157844080847,
      "loss": 0.8757,
      "step": 1245
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3429082930088043,
      "learning_rate": 0.00015237728585178057,
      "loss": 0.8626,
      "step": 1246
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3856114149093628,
      "learning_rate": 0.00015233878729547644,
      "loss": 0.7019,
      "step": 1247
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.42772915959358215,
      "learning_rate": 0.0001523002887391723,
      "loss": 0.6167,
      "step": 1248
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4032495319843292,
      "learning_rate": 0.00015226179018286814,
      "loss": 0.7146,
      "step": 1249
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.46012309193611145,
      "learning_rate": 0.000152223291626564,
      "loss": 0.7841,
      "step": 1250
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5377299189567566,
      "learning_rate": 0.0001521847930702599,
      "loss": 0.7606,
      "step": 1251
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3929075598716736,
      "learning_rate": 0.00015214629451395573,
      "loss": 0.7055,
      "step": 1252
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.40822258591651917,
      "learning_rate": 0.00015210779595765158,
      "loss": 0.8892,
      "step": 1253
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3492578864097595,
      "learning_rate": 0.00015206929740134746,
      "loss": 0.756,
      "step": 1254
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3978988528251648,
      "learning_rate": 0.00015203079884504333,
      "loss": 0.6632,
      "step": 1255
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4819571375846863,
      "learning_rate": 0.00015199230028873918,
      "loss": 0.8676,
      "step": 1256
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3063124716281891,
      "learning_rate": 0.00015195380173243503,
      "loss": 0.7955,
      "step": 1257
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35990455746650696,
      "learning_rate": 0.0001519153031761309,
      "loss": 0.7876,
      "step": 1258
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33189907670021057,
      "learning_rate": 0.00015187680461982677,
      "loss": 0.6341,
      "step": 1259
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4079800546169281,
      "learning_rate": 0.00015183830606352262,
      "loss": 0.5807,
      "step": 1260
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.38647302985191345,
      "learning_rate": 0.0001517998075072185,
      "loss": 0.7393,
      "step": 1261
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.32732075452804565,
      "learning_rate": 0.00015176130895091434,
      "loss": 0.9882,
      "step": 1262
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4003913998603821,
      "learning_rate": 0.0001517228103946102,
      "loss": 0.5764,
      "step": 1263
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4388103485107422,
      "learning_rate": 0.00015168431183830607,
      "loss": 0.9495,
      "step": 1264
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3771224617958069,
      "learning_rate": 0.00015164581328200194,
      "loss": 0.7242,
      "step": 1265
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4223957061767578,
      "learning_rate": 0.00015160731472569781,
      "loss": 0.6648,
      "step": 1266
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3785272538661957,
      "learning_rate": 0.00015156881616939364,
      "loss": 0.8301,
      "step": 1267
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4131834805011749,
      "learning_rate": 0.0001515303176130895,
      "loss": 0.6521,
      "step": 1268
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35808467864990234,
      "learning_rate": 0.00015149181905678538,
      "loss": 0.6403,
      "step": 1269
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3442893922328949,
      "learning_rate": 0.00015145332050048123,
      "loss": 0.7729,
      "step": 1270
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3319410979747772,
      "learning_rate": 0.0001514148219441771,
      "loss": 0.9186,
      "step": 1271
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5436779260635376,
      "learning_rate": 0.00015137632338787295,
      "loss": 0.6794,
      "step": 1272
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.36657291650772095,
      "learning_rate": 0.00015133782483156883,
      "loss": 0.7594,
      "step": 1273
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3963451683521271,
      "learning_rate": 0.00015129932627526468,
      "loss": 0.6555,
      "step": 1274
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36523380875587463,
      "learning_rate": 0.00015126082771896055,
      "loss": 0.9055,
      "step": 1275
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3812717795372009,
      "learning_rate": 0.00015122232916265642,
      "loss": 0.8134,
      "step": 1276
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36425143480300903,
      "learning_rate": 0.00015118383060635227,
      "loss": 0.9836,
      "step": 1277
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4338679909706116,
      "learning_rate": 0.00015114533205004812,
      "loss": 0.7289,
      "step": 1278
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.35821253061294556,
      "learning_rate": 0.000151106833493744,
      "loss": 0.6587,
      "step": 1279
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.39651304483413696,
      "learning_rate": 0.00015106833493743987,
      "loss": 0.7677,
      "step": 1280
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4540548622608185,
      "learning_rate": 0.00015102983638113572,
      "loss": 0.684,
      "step": 1281
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.39740437269210815,
      "learning_rate": 0.00015099133782483156,
      "loss": 0.9521,
      "step": 1282
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4487561583518982,
      "learning_rate": 0.00015095283926852744,
      "loss": 0.7924,
      "step": 1283
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.37519922852516174,
      "learning_rate": 0.0001509143407122233,
      "loss": 0.7147,
      "step": 1284
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.41145941615104675,
      "learning_rate": 0.00015087584215591916,
      "loss": 0.8579,
      "step": 1285
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.38699883222579956,
      "learning_rate": 0.000150837343599615,
      "loss": 0.5547,
      "step": 1286
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.399982213973999,
      "learning_rate": 0.00015079884504331088,
      "loss": 0.7378,
      "step": 1287
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4065243899822235,
      "learning_rate": 0.00015076034648700676,
      "loss": 0.774,
      "step": 1288
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36400336027145386,
      "learning_rate": 0.0001507218479307026,
      "loss": 0.8186,
      "step": 1289
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36938580870628357,
      "learning_rate": 0.00015068334937439848,
      "loss": 0.6065,
      "step": 1290
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.39676472544670105,
      "learning_rate": 0.00015064485081809433,
      "loss": 0.7417,
      "step": 1291
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4532395601272583,
      "learning_rate": 0.00015060635226179017,
      "loss": 0.669,
      "step": 1292
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.49923408031463623,
      "learning_rate": 0.00015056785370548605,
      "loss": 0.8594,
      "step": 1293
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.364364892244339,
      "learning_rate": 0.00015052935514918192,
      "loss": 0.82,
      "step": 1294
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.47290465235710144,
      "learning_rate": 0.00015049085659287777,
      "loss": 0.6214,
      "step": 1295
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4195459485054016,
      "learning_rate": 0.00015045235803657362,
      "loss": 0.787,
      "step": 1296
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.32194480299949646,
      "learning_rate": 0.0001504138594802695,
      "loss": 0.6495,
      "step": 1297
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.41045573353767395,
      "learning_rate": 0.00015037536092396537,
      "loss": 0.744,
      "step": 1298
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3946152329444885,
      "learning_rate": 0.0001503368623676612,
      "loss": 0.8691,
      "step": 1299
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.40465399622917175,
      "learning_rate": 0.0001502983638113571,
      "loss": 0.7805,
      "step": 1300
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.44865813851356506,
      "learning_rate": 0.00015025986525505294,
      "loss": 0.7461,
      "step": 1301
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.37946686148643494,
      "learning_rate": 0.0001502213666987488,
      "loss": 0.7111,
      "step": 1302
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3577534854412079,
      "learning_rate": 0.00015018286814244466,
      "loss": 0.7652,
      "step": 1303
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5187150239944458,
      "learning_rate": 0.00015014436958614053,
      "loss": 0.847,
      "step": 1304
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4189605712890625,
      "learning_rate": 0.0001501058710298364,
      "loss": 0.8358,
      "step": 1305
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.46004951000213623,
      "learning_rate": 0.00015006737247353225,
      "loss": 0.7122,
      "step": 1306
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5376541614532471,
      "learning_rate": 0.0001500288739172281,
      "loss": 0.7888,
      "step": 1307
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4360598027706146,
      "learning_rate": 0.00014999037536092398,
      "loss": 0.8056,
      "step": 1308
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4408196806907654,
      "learning_rate": 0.00014995187680461985,
      "loss": 0.4963,
      "step": 1309
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36642003059387207,
      "learning_rate": 0.0001499133782483157,
      "loss": 0.6631,
      "step": 1310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3815830945968628,
      "learning_rate": 0.00014987487969201155,
      "loss": 0.5837,
      "step": 1311
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4319801330566406,
      "learning_rate": 0.00014983638113570742,
      "loss": 0.8688,
      "step": 1312
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.34592485427856445,
      "learning_rate": 0.0001497978825794033,
      "loss": 0.8808,
      "step": 1313
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.33562999963760376,
      "learning_rate": 0.00014975938402309914,
      "loss": 0.607,
      "step": 1314
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5357721447944641,
      "learning_rate": 0.00014972088546679502,
      "loss": 0.6738,
      "step": 1315
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4042273461818695,
      "learning_rate": 0.00014968238691049086,
      "loss": 0.7079,
      "step": 1316
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.38334885239601135,
      "learning_rate": 0.0001496438883541867,
      "loss": 0.6879,
      "step": 1317
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3976695239543915,
      "learning_rate": 0.00014960538979788259,
      "loss": 0.7409,
      "step": 1318
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3541370630264282,
      "learning_rate": 0.00014956689124157846,
      "loss": 0.7507,
      "step": 1319
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.44518333673477173,
      "learning_rate": 0.0001495283926852743,
      "loss": 0.9043,
      "step": 1320
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36753326654434204,
      "learning_rate": 0.00014948989412897015,
      "loss": 0.8128,
      "step": 1321
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4933098256587982,
      "learning_rate": 0.00014945139557266603,
      "loss": 0.6383,
      "step": 1322
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.38790324330329895,
      "learning_rate": 0.0001494128970163619,
      "loss": 0.7678,
      "step": 1323
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4183103144168854,
      "learning_rate": 0.00014937439846005775,
      "loss": 0.7539,
      "step": 1324
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3307812809944153,
      "learning_rate": 0.0001493358999037536,
      "loss": 0.7851,
      "step": 1325
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.43115413188934326,
      "learning_rate": 0.00014929740134744947,
      "loss": 0.6899,
      "step": 1326
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42638832330703735,
      "learning_rate": 0.00014925890279114535,
      "loss": 0.7085,
      "step": 1327
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.44743022322654724,
      "learning_rate": 0.0001492204042348412,
      "loss": 0.655,
      "step": 1328
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4563879072666168,
      "learning_rate": 0.00014918190567853707,
      "loss": 0.8687,
      "step": 1329
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.45011451840400696,
      "learning_rate": 0.00014914340712223292,
      "loss": 0.718,
      "step": 1330
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.41595086455345154,
      "learning_rate": 0.0001491049085659288,
      "loss": 0.76,
      "step": 1331
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.36162069439888,
      "learning_rate": 0.00014906641000962464,
      "loss": 0.6916,
      "step": 1332
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4033454954624176,
      "learning_rate": 0.00014902791145332051,
      "loss": 0.7686,
      "step": 1333
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3447574973106384,
      "learning_rate": 0.0001489894128970164,
      "loss": 0.6239,
      "step": 1334
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.35008230805397034,
      "learning_rate": 0.0001489509143407122,
      "loss": 0.801,
      "step": 1335
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4806738793849945,
      "learning_rate": 0.00014891241578440808,
      "loss": 0.7814,
      "step": 1336
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38083821535110474,
      "learning_rate": 0.00014887391722810396,
      "loss": 0.702,
      "step": 1337
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4168788492679596,
      "learning_rate": 0.00014883541867179983,
      "loss": 0.6303,
      "step": 1338
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.448809951543808,
      "learning_rate": 0.00014879692011549568,
      "loss": 0.6932,
      "step": 1339
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3728683292865753,
      "learning_rate": 0.00014875842155919153,
      "loss": 0.7047,
      "step": 1340
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34912964701652527,
      "learning_rate": 0.0001487199230028874,
      "loss": 0.7607,
      "step": 1341
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4390076696872711,
      "learning_rate": 0.00014868142444658325,
      "loss": 0.6729,
      "step": 1342
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4820930063724518,
      "learning_rate": 0.00014864292589027912,
      "loss": 0.7259,
      "step": 1343
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5697134733200073,
      "learning_rate": 0.000148604427333975,
      "loss": 0.8682,
      "step": 1344
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38294899463653564,
      "learning_rate": 0.00014856592877767085,
      "loss": 0.7792,
      "step": 1345
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3923616111278534,
      "learning_rate": 0.0001485274302213667,
      "loss": 0.5965,
      "step": 1346
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34692272543907166,
      "learning_rate": 0.00014848893166506257,
      "loss": 0.7801,
      "step": 1347
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3724518120288849,
      "learning_rate": 0.00014845043310875844,
      "loss": 0.6863,
      "step": 1348
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.40255510807037354,
      "learning_rate": 0.0001484119345524543,
      "loss": 0.6725,
      "step": 1349
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3815781772136688,
      "learning_rate": 0.00014837343599615014,
      "loss": 0.6842,
      "step": 1350
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3960299491882324,
      "learning_rate": 0.000148334937439846,
      "loss": 0.6186,
      "step": 1351
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4321020841598511,
      "learning_rate": 0.00014829643888354189,
      "loss": 0.6603,
      "step": 1352
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.41685959696769714,
      "learning_rate": 0.00014825794032723773,
      "loss": 0.6641,
      "step": 1353
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4112638235092163,
      "learning_rate": 0.00014821944177093358,
      "loss": 0.9039,
      "step": 1354
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4214073419570923,
      "learning_rate": 0.00014818094321462946,
      "loss": 0.787,
      "step": 1355
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3562779426574707,
      "learning_rate": 0.00014814244465832533,
      "loss": 0.7769,
      "step": 1356
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.41511768102645874,
      "learning_rate": 0.00014810394610202118,
      "loss": 0.625,
      "step": 1357
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4222041368484497,
      "learning_rate": 0.00014806544754571705,
      "loss": 0.872,
      "step": 1358
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42403388023376465,
      "learning_rate": 0.0001480269489894129,
      "loss": 0.6557,
      "step": 1359
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38504841923713684,
      "learning_rate": 0.00014798845043310877,
      "loss": 0.691,
      "step": 1360
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.39949023723602295,
      "learning_rate": 0.00014794995187680462,
      "loss": 0.7854,
      "step": 1361
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42830222845077515,
      "learning_rate": 0.0001479114533205005,
      "loss": 0.7633,
      "step": 1362
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3392801880836487,
      "learning_rate": 0.00014787295476419637,
      "loss": 0.7135,
      "step": 1363
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.37388575077056885,
      "learning_rate": 0.0001478344562078922,
      "loss": 0.8847,
      "step": 1364
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2918330132961273,
      "learning_rate": 0.00014779595765158807,
      "loss": 0.8779,
      "step": 1365
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3693550229072571,
      "learning_rate": 0.00014775745909528394,
      "loss": 0.6318,
      "step": 1366
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.49290362000465393,
      "learning_rate": 0.0001477189605389798,
      "loss": 1.1533,
      "step": 1367
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34949061274528503,
      "learning_rate": 0.00014768046198267566,
      "loss": 0.685,
      "step": 1368
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4122130870819092,
      "learning_rate": 0.0001476419634263715,
      "loss": 0.806,
      "step": 1369
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.31010496616363525,
      "learning_rate": 0.00014760346487006738,
      "loss": 0.8315,
      "step": 1370
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38803523778915405,
      "learning_rate": 0.00014756496631376323,
      "loss": 0.6647,
      "step": 1371
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5058902502059937,
      "learning_rate": 0.0001475264677574591,
      "loss": 0.6566,
      "step": 1372
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4917807877063751,
      "learning_rate": 0.00014748796920115498,
      "loss": 0.8042,
      "step": 1373
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4750266373157501,
      "learning_rate": 0.00014744947064485083,
      "loss": 0.7286,
      "step": 1374
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4035465121269226,
      "learning_rate": 0.00014741097208854667,
      "loss": 0.7336,
      "step": 1375
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3939807415008545,
      "learning_rate": 0.00014737247353224255,
      "loss": 0.7624,
      "step": 1376
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4695783853530884,
      "learning_rate": 0.00014733397497593842,
      "loss": 0.8309,
      "step": 1377
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.36802953481674194,
      "learning_rate": 0.00014729547641963427,
      "loss": 0.6282,
      "step": 1378
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5804331302642822,
      "learning_rate": 0.00014725697786333012,
      "loss": 0.7663,
      "step": 1379
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45228201150894165,
      "learning_rate": 0.000147218479307026,
      "loss": 0.8354,
      "step": 1380
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36549699306488037,
      "learning_rate": 0.00014717998075072187,
      "loss": 0.771,
      "step": 1381
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3613891303539276,
      "learning_rate": 0.00014714148219441772,
      "loss": 0.9783,
      "step": 1382
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3905031383037567,
      "learning_rate": 0.00014710298363811356,
      "loss": 0.8148,
      "step": 1383
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45058301091194153,
      "learning_rate": 0.00014706448508180944,
      "loss": 0.7772,
      "step": 1384
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4114459753036499,
      "learning_rate": 0.0001470259865255053,
      "loss": 0.8144,
      "step": 1385
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.35647010803222656,
      "learning_rate": 0.00014698748796920116,
      "loss": 0.7109,
      "step": 1386
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.380900502204895,
      "learning_rate": 0.00014694898941289703,
      "loss": 0.8889,
      "step": 1387
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3947020173072815,
      "learning_rate": 0.00014691049085659288,
      "loss": 0.7986,
      "step": 1388
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4376294016838074,
      "learning_rate": 0.00014687199230028873,
      "loss": 0.7973,
      "step": 1389
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36957886815071106,
      "learning_rate": 0.0001468334937439846,
      "loss": 0.6679,
      "step": 1390
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.33011212944984436,
      "learning_rate": 0.00014679499518768048,
      "loss": 0.7851,
      "step": 1391
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.439411461353302,
      "learning_rate": 0.00014675649663137635,
      "loss": 0.8618,
      "step": 1392
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.37056806683540344,
      "learning_rate": 0.00014671799807507217,
      "loss": 0.7904,
      "step": 1393
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3330939710140228,
      "learning_rate": 0.00014667949951876805,
      "loss": 0.9421,
      "step": 1394
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3836989104747772,
      "learning_rate": 0.00014664100096246392,
      "loss": 0.7415,
      "step": 1395
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3616684079170227,
      "learning_rate": 0.00014660250240615977,
      "loss": 0.6191,
      "step": 1396
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.39104169607162476,
      "learning_rate": 0.00014656400384985564,
      "loss": 0.7924,
      "step": 1397
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3929220139980316,
      "learning_rate": 0.0001465255052935515,
      "loss": 0.6647,
      "step": 1398
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4051583707332611,
      "learning_rate": 0.00014648700673724737,
      "loss": 0.6997,
      "step": 1399
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.40521901845932007,
      "learning_rate": 0.0001464485081809432,
      "loss": 0.8465,
      "step": 1400
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3338389992713928,
      "learning_rate": 0.0001464100096246391,
      "loss": 0.8263,
      "step": 1401
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9067260026931763,
      "learning_rate": 0.00014637151106833496,
      "loss": 0.667,
      "step": 1402
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36239001154899597,
      "learning_rate": 0.0001463330125120308,
      "loss": 0.7062,
      "step": 1403
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3442286252975464,
      "learning_rate": 0.00014629451395572666,
      "loss": 0.8372,
      "step": 1404
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4096972942352295,
      "learning_rate": 0.00014625601539942253,
      "loss": 0.7832,
      "step": 1405
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4285643398761749,
      "learning_rate": 0.0001462175168431184,
      "loss": 0.7835,
      "step": 1406
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4272938072681427,
      "learning_rate": 0.00014617901828681425,
      "loss": 0.6545,
      "step": 1407
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3899366855621338,
      "learning_rate": 0.0001461405197305101,
      "loss": 0.6489,
      "step": 1408
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4704456031322479,
      "learning_rate": 0.00014610202117420598,
      "loss": 0.7336,
      "step": 1409
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.49960318207740784,
      "learning_rate": 0.00014606352261790185,
      "loss": 0.9843,
      "step": 1410
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3949795365333557,
      "learning_rate": 0.0001460250240615977,
      "loss": 0.8413,
      "step": 1411
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.397896945476532,
      "learning_rate": 0.00014598652550529354,
      "loss": 0.6761,
      "step": 1412
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4075417220592499,
      "learning_rate": 0.00014594802694898942,
      "loss": 0.7756,
      "step": 1413
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.39533472061157227,
      "learning_rate": 0.00014590952839268527,
      "loss": 0.7518,
      "step": 1414
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.39690345525741577,
      "learning_rate": 0.00014587102983638114,
      "loss": 0.7712,
      "step": 1415
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3817249834537506,
      "learning_rate": 0.00014583253128007702,
      "loss": 0.7178,
      "step": 1416
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4509667158126831,
      "learning_rate": 0.00014579403272377286,
      "loss": 0.5949,
      "step": 1417
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4072791635990143,
      "learning_rate": 0.0001457555341674687,
      "loss": 0.8177,
      "step": 1418
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4277591407299042,
      "learning_rate": 0.00014571703561116459,
      "loss": 0.6932,
      "step": 1419
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5568979382514954,
      "learning_rate": 0.00014567853705486046,
      "loss": 0.8833,
      "step": 1420
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3296930193901062,
      "learning_rate": 0.0001456400384985563,
      "loss": 0.5665,
      "step": 1421
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45492345094680786,
      "learning_rate": 0.00014560153994225215,
      "loss": 0.8541,
      "step": 1422
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.44894662499427795,
      "learning_rate": 0.00014556304138594803,
      "loss": 0.715,
      "step": 1423
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.315621018409729,
      "learning_rate": 0.0001455245428296439,
      "loss": 0.7897,
      "step": 1424
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3242446184158325,
      "learning_rate": 0.00014548604427333975,
      "loss": 0.7757,
      "step": 1425
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.42096954584121704,
      "learning_rate": 0.00014544754571703563,
      "loss": 0.5912,
      "step": 1426
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.38086050748825073,
      "learning_rate": 0.00014540904716073147,
      "loss": 0.7865,
      "step": 1427
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3793252408504486,
      "learning_rate": 0.00014537054860442735,
      "loss": 0.7235,
      "step": 1428
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4386788308620453,
      "learning_rate": 0.0001453320500481232,
      "loss": 0.6725,
      "step": 1429
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3798370659351349,
      "learning_rate": 0.00014529355149181907,
      "loss": 0.724,
      "step": 1430
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3301912546157837,
      "learning_rate": 0.00014525505293551494,
      "loss": 0.793,
      "step": 1431
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.40447521209716797,
      "learning_rate": 0.0001452165543792108,
      "loss": 0.9264,
      "step": 1432
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.31495293974876404,
      "learning_rate": 0.00014517805582290664,
      "loss": 0.7181,
      "step": 1433
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38305938243865967,
      "learning_rate": 0.0001451395572666025,
      "loss": 0.7778,
      "step": 1434
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4211389124393463,
      "learning_rate": 0.0001451010587102984,
      "loss": 0.7262,
      "step": 1435
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38681021332740784,
      "learning_rate": 0.00014506256015399424,
      "loss": 0.7883,
      "step": 1436
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4423278272151947,
      "learning_rate": 0.00014502406159769008,
      "loss": 0.6095,
      "step": 1437
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4545987546443939,
      "learning_rate": 0.00014498556304138596,
      "loss": 0.9278,
      "step": 1438
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.36197930574417114,
      "learning_rate": 0.00014494706448508183,
      "loss": 0.8498,
      "step": 1439
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.31141743063926697,
      "learning_rate": 0.00014490856592877768,
      "loss": 0.7077,
      "step": 1440
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4672178626060486,
      "learning_rate": 0.00014487006737247355,
      "loss": 0.7634,
      "step": 1441
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37700971961021423,
      "learning_rate": 0.0001448315688161694,
      "loss": 0.6998,
      "step": 1442
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4863782823085785,
      "learning_rate": 0.00014479307025986525,
      "loss": 0.9295,
      "step": 1443
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6989641785621643,
      "learning_rate": 0.00014475457170356112,
      "loss": 0.7656,
      "step": 1444
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.42613303661346436,
      "learning_rate": 0.000144716073147257,
      "loss": 0.7561,
      "step": 1445
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3764442205429077,
      "learning_rate": 0.00014467757459095285,
      "loss": 0.903,
      "step": 1446
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4822099804878235,
      "learning_rate": 0.0001446390760346487,
      "loss": 0.8782,
      "step": 1447
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35899126529693604,
      "learning_rate": 0.00014460057747834457,
      "loss": 0.6256,
      "step": 1448
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3341224491596222,
      "learning_rate": 0.00014456207892204044,
      "loss": 0.861,
      "step": 1449
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4075356125831604,
      "learning_rate": 0.0001445235803657363,
      "loss": 0.5969,
      "step": 1450
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.348312109708786,
      "learning_rate": 0.00014448508180943214,
      "loss": 0.6692,
      "step": 1451
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38794782757759094,
      "learning_rate": 0.000144446583253128,
      "loss": 1.0655,
      "step": 1452
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4974254369735718,
      "learning_rate": 0.00014440808469682389,
      "loss": 0.7471,
      "step": 1453
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.40620991587638855,
      "learning_rate": 0.00014436958614051973,
      "loss": 0.7293,
      "step": 1454
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34577950835227966,
      "learning_rate": 0.0001443310875842156,
      "loss": 0.8827,
      "step": 1455
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.41349712014198303,
      "learning_rate": 0.00014429258902791145,
      "loss": 0.807,
      "step": 1456
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4491455554962158,
      "learning_rate": 0.00014425409047160733,
      "loss": 0.7327,
      "step": 1457
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38804686069488525,
      "learning_rate": 0.00014421559191530318,
      "loss": 0.8029,
      "step": 1458
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4248674809932709,
      "learning_rate": 0.00014417709335899905,
      "loss": 0.6416,
      "step": 1459
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.39156201481819153,
      "learning_rate": 0.00014413859480269493,
      "loss": 0.6094,
      "step": 1460
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37789207696914673,
      "learning_rate": 0.00014410009624639075,
      "loss": 0.7831,
      "step": 1461
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34010049700737,
      "learning_rate": 0.00014406159769008662,
      "loss": 0.7759,
      "step": 1462
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.45237600803375244,
      "learning_rate": 0.0001440230991337825,
      "loss": 0.7271,
      "step": 1463
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4482605755329132,
      "learning_rate": 0.00014398460057747837,
      "loss": 0.5984,
      "step": 1464
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4071075916290283,
      "learning_rate": 0.00014394610202117422,
      "loss": 0.8859,
      "step": 1465
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3312879800796509,
      "learning_rate": 0.00014390760346487006,
      "loss": 0.6294,
      "step": 1466
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.36655864119529724,
      "learning_rate": 0.00014386910490856594,
      "loss": 0.7265,
      "step": 1467
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4301626980304718,
      "learning_rate": 0.0001438306063522618,
      "loss": 0.5964,
      "step": 1468
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4448874890804291,
      "learning_rate": 0.00014379210779595766,
      "loss": 0.8078,
      "step": 1469
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4087071418762207,
      "learning_rate": 0.00014375360923965354,
      "loss": 0.7209,
      "step": 1470
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3637138307094574,
      "learning_rate": 0.00014371511068334938,
      "loss": 0.6961,
      "step": 1471
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4455239772796631,
      "learning_rate": 0.00014367661212704523,
      "loss": 0.8222,
      "step": 1472
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.44182777404785156,
      "learning_rate": 0.0001436381135707411,
      "loss": 0.8756,
      "step": 1473
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3474278151988983,
      "learning_rate": 0.00014359961501443698,
      "loss": 0.8,
      "step": 1474
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35048046708106995,
      "learning_rate": 0.00014356111645813283,
      "loss": 0.7333,
      "step": 1475
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3475911617279053,
      "learning_rate": 0.00014352261790182867,
      "loss": 0.7226,
      "step": 1476
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.47619014978408813,
      "learning_rate": 0.00014348411934552455,
      "loss": 0.8568,
      "step": 1477
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4496539533138275,
      "learning_rate": 0.00014344562078922042,
      "loss": 0.8339,
      "step": 1478
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37419551610946655,
      "learning_rate": 0.00014340712223291627,
      "loss": 0.7501,
      "step": 1479
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.41199633479118347,
      "learning_rate": 0.00014336862367661212,
      "loss": 0.8488,
      "step": 1480
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35677751898765564,
      "learning_rate": 0.000143330125120308,
      "loss": 0.8064,
      "step": 1481
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4203978180885315,
      "learning_rate": 0.00014329162656400387,
      "loss": 0.7048,
      "step": 1482
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3763902485370636,
      "learning_rate": 0.00014325312800769971,
      "loss": 0.8048,
      "step": 1483
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4642752707004547,
      "learning_rate": 0.0001432146294513956,
      "loss": 0.7182,
      "step": 1484
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.46929505467414856,
      "learning_rate": 0.00014317613089509144,
      "loss": 0.964,
      "step": 1485
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.421288400888443,
      "learning_rate": 0.00014313763233878728,
      "loss": 0.8306,
      "step": 1486
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4062874913215637,
      "learning_rate": 0.00014309913378248316,
      "loss": 0.5158,
      "step": 1487
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.36967363953590393,
      "learning_rate": 0.00014306063522617903,
      "loss": 0.5516,
      "step": 1488
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.30587831139564514,
      "learning_rate": 0.0001430221366698749,
      "loss": 0.7265,
      "step": 1489
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4581137001514435,
      "learning_rate": 0.00014298363811357073,
      "loss": 0.7567,
      "step": 1490
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40735504031181335,
      "learning_rate": 0.0001429451395572666,
      "loss": 0.7432,
      "step": 1491
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4151352643966675,
      "learning_rate": 0.00014290664100096248,
      "loss": 0.5734,
      "step": 1492
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.35428139567375183,
      "learning_rate": 0.00014286814244465832,
      "loss": 0.8179,
      "step": 1493
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3373424708843231,
      "learning_rate": 0.0001428296438883542,
      "loss": 0.9254,
      "step": 1494
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5742853879928589,
      "learning_rate": 0.00014279114533205005,
      "loss": 0.7709,
      "step": 1495
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4647940695285797,
      "learning_rate": 0.00014275264677574592,
      "loss": 0.6927,
      "step": 1496
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3951655328273773,
      "learning_rate": 0.00014271414821944177,
      "loss": 0.6119,
      "step": 1497
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.33660322427749634,
      "learning_rate": 0.00014267564966313764,
      "loss": 0.5598,
      "step": 1498
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.44055283069610596,
      "learning_rate": 0.00014263715110683352,
      "loss": 0.7511,
      "step": 1499
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3654673099517822,
      "learning_rate": 0.00014259865255052936,
      "loss": 0.7278,
      "step": 1500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.41724953055381775,
      "learning_rate": 0.0001425601539942252,
      "loss": 0.7196,
      "step": 1501
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4162159860134125,
      "learning_rate": 0.0001425216554379211,
      "loss": 0.8592,
      "step": 1502
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4276358187198639,
      "learning_rate": 0.00014248315688161696,
      "loss": 0.7127,
      "step": 1503
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3896994888782501,
      "learning_rate": 0.0001424446583253128,
      "loss": 0.7715,
      "step": 1504
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3976505994796753,
      "learning_rate": 0.00014240615976900866,
      "loss": 0.5733,
      "step": 1505
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.48588672280311584,
      "learning_rate": 0.00014236766121270453,
      "loss": 0.7738,
      "step": 1506
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.36408373713493347,
      "learning_rate": 0.0001423291626564004,
      "loss": 0.6836,
      "step": 1507
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.37173113226890564,
      "learning_rate": 0.00014229066410009625,
      "loss": 0.4156,
      "step": 1508
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3982970118522644,
      "learning_rate": 0.0001422521655437921,
      "loss": 0.6794,
      "step": 1509
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40614432096481323,
      "learning_rate": 0.00014221366698748797,
      "loss": 0.8574,
      "step": 1510
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5904964804649353,
      "learning_rate": 0.00014217516843118385,
      "loss": 0.6801,
      "step": 1511
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3360234200954437,
      "learning_rate": 0.0001421366698748797,
      "loss": 0.7951,
      "step": 1512
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4758772552013397,
      "learning_rate": 0.00014209817131857557,
      "loss": 0.5487,
      "step": 1513
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6033499836921692,
      "learning_rate": 0.00014205967276227142,
      "loss": 0.6944,
      "step": 1514
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3756484091281891,
      "learning_rate": 0.00014202117420596727,
      "loss": 0.7468,
      "step": 1515
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.44715380668640137,
      "learning_rate": 0.00014198267564966314,
      "loss": 0.8043,
      "step": 1516
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.39437007904052734,
      "learning_rate": 0.00014194417709335902,
      "loss": 0.6732,
      "step": 1517
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40290215611457825,
      "learning_rate": 0.00014190567853705486,
      "loss": 0.9011,
      "step": 1518
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4189807176589966,
      "learning_rate": 0.0001418671799807507,
      "loss": 0.6499,
      "step": 1519
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.44964954257011414,
      "learning_rate": 0.00014182868142444658,
      "loss": 0.9259,
      "step": 1520
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.41791167855262756,
      "learning_rate": 0.00014179018286814246,
      "loss": 0.7014,
      "step": 1521
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.35916003584861755,
      "learning_rate": 0.0001417516843118383,
      "loss": 0.6969,
      "step": 1522
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4154624342918396,
      "learning_rate": 0.00014171318575553418,
      "loss": 0.7409,
      "step": 1523
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4520215690135956,
      "learning_rate": 0.00014167468719923003,
      "loss": 0.7235,
      "step": 1524
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.37761420011520386,
      "learning_rate": 0.0001416361886429259,
      "loss": 0.7625,
      "step": 1525
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.36252060532569885,
      "learning_rate": 0.00014159769008662175,
      "loss": 0.8218,
      "step": 1526
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.369446724653244,
      "learning_rate": 0.00014155919153031762,
      "loss": 0.9081,
      "step": 1527
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4098937213420868,
      "learning_rate": 0.0001415206929740135,
      "loss": 0.5824,
      "step": 1528
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3583468198776245,
      "learning_rate": 0.00014148219441770935,
      "loss": 0.5531,
      "step": 1529
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.45929133892059326,
      "learning_rate": 0.0001414436958614052,
      "loss": 0.7474,
      "step": 1530
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3951960504055023,
      "learning_rate": 0.00014140519730510107,
      "loss": 0.705,
      "step": 1531
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4227710962295532,
      "learning_rate": 0.00014136669874879694,
      "loss": 0.6957,
      "step": 1532
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4815373122692108,
      "learning_rate": 0.0001413282001924928,
      "loss": 0.9581,
      "step": 1533
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3978879749774933,
      "learning_rate": 0.00014128970163618864,
      "loss": 0.7452,
      "step": 1534
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.37745559215545654,
      "learning_rate": 0.0001412512030798845,
      "loss": 0.6166,
      "step": 1535
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3817947804927826,
      "learning_rate": 0.0001412127045235804,
      "loss": 0.8564,
      "step": 1536
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.35810956358909607,
      "learning_rate": 0.00014117420596727623,
      "loss": 0.7771,
      "step": 1537
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3649432957172394,
      "learning_rate": 0.00014113570741097208,
      "loss": 0.8107,
      "step": 1538
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4325377941131592,
      "learning_rate": 0.00014109720885466796,
      "loss": 0.8919,
      "step": 1539
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3856835961341858,
      "learning_rate": 0.0001410587102983638,
      "loss": 0.7702,
      "step": 1540
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.39901483058929443,
      "learning_rate": 0.00014102021174205968,
      "loss": 0.8541,
      "step": 1541
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4366486966609955,
      "learning_rate": 0.00014098171318575555,
      "loss": 0.6337,
      "step": 1542
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.34462934732437134,
      "learning_rate": 0.0001409432146294514,
      "loss": 0.7409,
      "step": 1543
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4649198651313782,
      "learning_rate": 0.00014090471607314725,
      "loss": 0.7314,
      "step": 1544
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4359591603279114,
      "learning_rate": 0.00014086621751684312,
      "loss": 0.6783,
      "step": 1545
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.34206679463386536,
      "learning_rate": 0.000140827718960539,
      "loss": 0.575,
      "step": 1546
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3956718444824219,
      "learning_rate": 0.00014078922040423484,
      "loss": 0.7121,
      "step": 1547
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4198899269104004,
      "learning_rate": 0.0001407507218479307,
      "loss": 0.6773,
      "step": 1548
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3591337502002716,
      "learning_rate": 0.00014071222329162657,
      "loss": 0.7062,
      "step": 1549
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.389431357383728,
      "learning_rate": 0.00014067372473532244,
      "loss": 0.6872,
      "step": 1550
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3773740828037262,
      "learning_rate": 0.0001406352261790183,
      "loss": 0.642,
      "step": 1551
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.41725844144821167,
      "learning_rate": 0.00014059672762271416,
      "loss": 0.7525,
      "step": 1552
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40896517038345337,
      "learning_rate": 0.00014055822906641,
      "loss": 0.699,
      "step": 1553
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38491711020469666,
      "learning_rate": 0.00014051973051010588,
      "loss": 0.8159,
      "step": 1554
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.46520179510116577,
      "learning_rate": 0.00014048123195380173,
      "loss": 0.8423,
      "step": 1555
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.45521703362464905,
      "learning_rate": 0.0001404427333974976,
      "loss": 0.6166,
      "step": 1556
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3531140983104706,
      "learning_rate": 0.00014040423484119348,
      "loss": 0.9282,
      "step": 1557
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3878195285797119,
      "learning_rate": 0.00014036573628488933,
      "loss": 0.9745,
      "step": 1558
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3718041181564331,
      "learning_rate": 0.00014032723772858518,
      "loss": 0.6256,
      "step": 1559
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40025416016578674,
      "learning_rate": 0.00014028873917228105,
      "loss": 0.8713,
      "step": 1560
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3893404006958008,
      "learning_rate": 0.00014025024061597693,
      "loss": 0.7639,
      "step": 1561
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3467596173286438,
      "learning_rate": 0.00014021174205967277,
      "loss": 0.8959,
      "step": 1562
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.37525826692581177,
      "learning_rate": 0.00014017324350336862,
      "loss": 0.7342,
      "step": 1563
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40908414125442505,
      "learning_rate": 0.0001401347449470645,
      "loss": 0.7127,
      "step": 1564
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.42671966552734375,
      "learning_rate": 0.00014009624639076034,
      "loss": 0.6568,
      "step": 1565
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4422747492790222,
      "learning_rate": 0.00014005774783445622,
      "loss": 0.6942,
      "step": 1566
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4033370316028595,
      "learning_rate": 0.0001400192492781521,
      "loss": 0.7971,
      "step": 1567
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40380024909973145,
      "learning_rate": 0.00013998075072184794,
      "loss": 0.7051,
      "step": 1568
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4109905958175659,
      "learning_rate": 0.00013994225216554379,
      "loss": 0.702,
      "step": 1569
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.33700740337371826,
      "learning_rate": 0.00013990375360923966,
      "loss": 0.7846,
      "step": 1570
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38873425126075745,
      "learning_rate": 0.00013986525505293554,
      "loss": 0.7136,
      "step": 1571
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3607983887195587,
      "learning_rate": 0.00013982675649663138,
      "loss": 0.7545,
      "step": 1572
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4194868206977844,
      "learning_rate": 0.00013978825794032723,
      "loss": 0.7186,
      "step": 1573
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.318489134311676,
      "learning_rate": 0.0001397497593840231,
      "loss": 0.6699,
      "step": 1574
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.33481407165527344,
      "learning_rate": 0.00013971126082771898,
      "loss": 0.8222,
      "step": 1575
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38473716378211975,
      "learning_rate": 0.00013967276227141483,
      "loss": 0.6969,
      "step": 1576
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5189446806907654,
      "learning_rate": 0.00013963426371511067,
      "loss": 0.7413,
      "step": 1577
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3741241991519928,
      "learning_rate": 0.00013959576515880655,
      "loss": 0.7479,
      "step": 1578
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3304726481437683,
      "learning_rate": 0.00013955726660250242,
      "loss": 0.8581,
      "step": 1579
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3825192153453827,
      "learning_rate": 0.00013951876804619827,
      "loss": 0.7555,
      "step": 1580
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4167601466178894,
      "learning_rate": 0.00013948026948989414,
      "loss": 0.5336,
      "step": 1581
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.41052860021591187,
      "learning_rate": 0.00013944177093359,
      "loss": 0.7376,
      "step": 1582
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4525925815105438,
      "learning_rate": 0.00013940327237728587,
      "loss": 0.6835,
      "step": 1583
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.35832083225250244,
      "learning_rate": 0.00013936477382098171,
      "loss": 0.7489,
      "step": 1584
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.42001453042030334,
      "learning_rate": 0.0001393262752646776,
      "loss": 0.6521,
      "step": 1585
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4241701066493988,
      "learning_rate": 0.00013928777670837346,
      "loss": 0.7484,
      "step": 1586
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4400090277194977,
      "learning_rate": 0.00013924927815206928,
      "loss": 0.6373,
      "step": 1587
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3897201418876648,
      "learning_rate": 0.00013921077959576516,
      "loss": 0.6789,
      "step": 1588
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.37175726890563965,
      "learning_rate": 0.00013917228103946103,
      "loss": 0.7265,
      "step": 1589
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.42509186267852783,
      "learning_rate": 0.0001391337824831569,
      "loss": 0.6711,
      "step": 1590
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.447003573179245,
      "learning_rate": 0.00013909528392685275,
      "loss": 0.7685,
      "step": 1591
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.39999517798423767,
      "learning_rate": 0.0001390567853705486,
      "loss": 0.823,
      "step": 1592
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.45550888776779175,
      "learning_rate": 0.00013901828681424448,
      "loss": 0.9152,
      "step": 1593
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.48399633169174194,
      "learning_rate": 0.00013897978825794032,
      "loss": 0.8666,
      "step": 1594
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4638347625732422,
      "learning_rate": 0.0001389412897016362,
      "loss": 0.8066,
      "step": 1595
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36556369066238403,
      "learning_rate": 0.00013890279114533207,
      "loss": 0.64,
      "step": 1596
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4849199056625366,
      "learning_rate": 0.00013886429258902792,
      "loss": 0.7804,
      "step": 1597
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3687591254711151,
      "learning_rate": 0.00013882579403272377,
      "loss": 0.7187,
      "step": 1598
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.37151700258255005,
      "learning_rate": 0.00013878729547641964,
      "loss": 0.7048,
      "step": 1599
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3591022193431854,
      "learning_rate": 0.00013874879692011552,
      "loss": 0.6494,
      "step": 1600
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3878302276134491,
      "learning_rate": 0.00013871029836381136,
      "loss": 0.7105,
      "step": 1601
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.38657182455062866,
      "learning_rate": 0.0001386717998075072,
      "loss": 0.7981,
      "step": 1602
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3327498435974121,
      "learning_rate": 0.00013863330125120309,
      "loss": 0.8506,
      "step": 1603
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36444342136383057,
      "learning_rate": 0.00013859480269489896,
      "loss": 0.7725,
      "step": 1604
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4166974723339081,
      "learning_rate": 0.0001385563041385948,
      "loss": 0.7432,
      "step": 1605
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.44543522596359253,
      "learning_rate": 0.00013851780558229066,
      "loss": 0.6599,
      "step": 1606
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.43636053800582886,
      "learning_rate": 0.00013847930702598653,
      "loss": 0.8209,
      "step": 1607
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8520939946174622,
      "learning_rate": 0.0001384408084696824,
      "loss": 0.6589,
      "step": 1608
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4298171401023865,
      "learning_rate": 0.00013840230991337825,
      "loss": 0.7514,
      "step": 1609
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4358583986759186,
      "learning_rate": 0.00013836381135707413,
      "loss": 0.6972,
      "step": 1610
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4079870581626892,
      "learning_rate": 0.00013832531280076997,
      "loss": 0.8511,
      "step": 1611
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3052898347377777,
      "learning_rate": 0.00013828681424446582,
      "loss": 0.8268,
      "step": 1612
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.348302960395813,
      "learning_rate": 0.0001382483156881617,
      "loss": 0.7085,
      "step": 1613
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3869578242301941,
      "learning_rate": 0.00013820981713185757,
      "loss": 0.8189,
      "step": 1614
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4317513108253479,
      "learning_rate": 0.00013817131857555345,
      "loss": 0.8862,
      "step": 1615
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36576372385025024,
      "learning_rate": 0.00013813282001924927,
      "loss": 0.8001,
      "step": 1616
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4591612219810486,
      "learning_rate": 0.00013809432146294514,
      "loss": 0.7567,
      "step": 1617
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4079863727092743,
      "learning_rate": 0.00013805582290664101,
      "loss": 0.8334,
      "step": 1618
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.49138230085372925,
      "learning_rate": 0.00013801732435033686,
      "loss": 0.7302,
      "step": 1619
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3142023980617523,
      "learning_rate": 0.00013797882579403274,
      "loss": 0.645,
      "step": 1620
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36179131269454956,
      "learning_rate": 0.00013794032723772858,
      "loss": 0.7214,
      "step": 1621
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4722699224948883,
      "learning_rate": 0.00013790182868142446,
      "loss": 0.6476,
      "step": 1622
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.45480406284332275,
      "learning_rate": 0.0001378633301251203,
      "loss": 0.7992,
      "step": 1623
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4382063150405884,
      "learning_rate": 0.00013782483156881618,
      "loss": 0.7281,
      "step": 1624
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4131746292114258,
      "learning_rate": 0.00013778633301251205,
      "loss": 0.7312,
      "step": 1625
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.40822479128837585,
      "learning_rate": 0.0001377478344562079,
      "loss": 0.7642,
      "step": 1626
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.43784642219543457,
      "learning_rate": 0.00013770933589990375,
      "loss": 0.8063,
      "step": 1627
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3665948808193207,
      "learning_rate": 0.00013767083734359962,
      "loss": 0.7785,
      "step": 1628
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.31331223249435425,
      "learning_rate": 0.0001376323387872955,
      "loss": 0.8009,
      "step": 1629
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3922223150730133,
      "learning_rate": 0.00013759384023099135,
      "loss": 0.736,
      "step": 1630
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3547876179218292,
      "learning_rate": 0.0001375553416746872,
      "loss": 0.7224,
      "step": 1631
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.34876400232315063,
      "learning_rate": 0.00013751684311838307,
      "loss": 0.7778,
      "step": 1632
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.43214476108551025,
      "learning_rate": 0.00013747834456207894,
      "loss": 0.7012,
      "step": 1633
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3520866930484772,
      "learning_rate": 0.0001374398460057748,
      "loss": 0.7684,
      "step": 1634
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.450449138879776,
      "learning_rate": 0.00013740134744947064,
      "loss": 0.842,
      "step": 1635
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4036320149898529,
      "learning_rate": 0.0001373628488931665,
      "loss": 0.8512,
      "step": 1636
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.39650535583496094,
      "learning_rate": 0.00013732435033686236,
      "loss": 0.7149,
      "step": 1637
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3623286783695221,
      "learning_rate": 0.00013728585178055823,
      "loss": 0.7136,
      "step": 1638
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4080308973789215,
      "learning_rate": 0.0001372473532242541,
      "loss": 0.6199,
      "step": 1639
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3572975993156433,
      "learning_rate": 0.00013720885466794996,
      "loss": 0.5816,
      "step": 1640
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37198346853256226,
      "learning_rate": 0.0001371703561116458,
      "loss": 0.7439,
      "step": 1641
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3775167465209961,
      "learning_rate": 0.00013713185755534168,
      "loss": 0.8065,
      "step": 1642
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3811580240726471,
      "learning_rate": 0.00013709335899903755,
      "loss": 0.7252,
      "step": 1643
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.40203985571861267,
      "learning_rate": 0.0001370548604427334,
      "loss": 0.7031,
      "step": 1644
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39736074209213257,
      "learning_rate": 0.00013701636188642925,
      "loss": 0.7453,
      "step": 1645
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.43544846773147583,
      "learning_rate": 0.00013697786333012512,
      "loss": 0.768,
      "step": 1646
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44889792799949646,
      "learning_rate": 0.000136939364773821,
      "loss": 0.7432,
      "step": 1647
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4444977045059204,
      "learning_rate": 0.00013690086621751684,
      "loss": 0.7652,
      "step": 1648
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.49672436714172363,
      "learning_rate": 0.00013686236766121272,
      "loss": 0.5914,
      "step": 1649
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39710909128189087,
      "learning_rate": 0.00013682386910490857,
      "loss": 0.6395,
      "step": 1650
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3436446189880371,
      "learning_rate": 0.00013678537054860444,
      "loss": 0.7844,
      "step": 1651
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3933045566082001,
      "learning_rate": 0.0001367468719923003,
      "loss": 0.7613,
      "step": 1652
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37771138548851013,
      "learning_rate": 0.00013670837343599616,
      "loss": 0.9281,
      "step": 1653
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.48370689153671265,
      "learning_rate": 0.00013666987487969204,
      "loss": 0.9259,
      "step": 1654
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.38230767846107483,
      "learning_rate": 0.00013663137632338788,
      "loss": 0.6707,
      "step": 1655
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.38562604784965515,
      "learning_rate": 0.00013659287776708373,
      "loss": 0.8062,
      "step": 1656
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37056785821914673,
      "learning_rate": 0.0001365543792107796,
      "loss": 0.7078,
      "step": 1657
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3348903954029083,
      "learning_rate": 0.00013651588065447548,
      "loss": 0.7176,
      "step": 1658
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42055249214172363,
      "learning_rate": 0.00013647738209817133,
      "loss": 0.6816,
      "step": 1659
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4233472943305969,
      "learning_rate": 0.00013643888354186718,
      "loss": 0.8808,
      "step": 1660
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.36042603850364685,
      "learning_rate": 0.00013640038498556305,
      "loss": 0.6623,
      "step": 1661
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4092336595058441,
      "learning_rate": 0.00013636188642925892,
      "loss": 0.7483,
      "step": 1662
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.377438485622406,
      "learning_rate": 0.00013632338787295477,
      "loss": 0.8286,
      "step": 1663
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.38256514072418213,
      "learning_rate": 0.00013628488931665062,
      "loss": 0.6785,
      "step": 1664
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42399805784225464,
      "learning_rate": 0.0001362463907603465,
      "loss": 0.6691,
      "step": 1665
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39225995540618896,
      "learning_rate": 0.00013620789220404234,
      "loss": 0.7567,
      "step": 1666
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4014180600643158,
      "learning_rate": 0.00013616939364773822,
      "loss": 0.7883,
      "step": 1667
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4168412387371063,
      "learning_rate": 0.0001361308950914341,
      "loss": 0.9683,
      "step": 1668
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4391365051269531,
      "learning_rate": 0.00013609239653512994,
      "loss": 0.739,
      "step": 1669
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4245762825012207,
      "learning_rate": 0.00013605389797882579,
      "loss": 0.8638,
      "step": 1670
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.48266762495040894,
      "learning_rate": 0.00013601539942252166,
      "loss": 0.8876,
      "step": 1671
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3626275062561035,
      "learning_rate": 0.00013597690086621753,
      "loss": 0.7757,
      "step": 1672
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.46704331040382385,
      "learning_rate": 0.00013593840230991338,
      "loss": 0.7822,
      "step": 1673
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3691776692867279,
      "learning_rate": 0.00013589990375360923,
      "loss": 0.7527,
      "step": 1674
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.40746834874153137,
      "learning_rate": 0.0001358614051973051,
      "loss": 0.6621,
      "step": 1675
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37663254141807556,
      "learning_rate": 0.00013582290664100098,
      "loss": 0.6908,
      "step": 1676
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.45758894085884094,
      "learning_rate": 0.00013578440808469683,
      "loss": 0.8669,
      "step": 1677
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3463422358036041,
      "learning_rate": 0.0001357459095283927,
      "loss": 0.5698,
      "step": 1678
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3434551954269409,
      "learning_rate": 0.00013570741097208855,
      "loss": 0.6038,
      "step": 1679
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39206233620643616,
      "learning_rate": 0.00013566891241578442,
      "loss": 0.6378,
      "step": 1680
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3318312168121338,
      "learning_rate": 0.00013563041385948027,
      "loss": 0.8374,
      "step": 1681
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.32353538274765015,
      "learning_rate": 0.00013559191530317614,
      "loss": 0.8738,
      "step": 1682
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.36158666014671326,
      "learning_rate": 0.00013555341674687202,
      "loss": 0.7062,
      "step": 1683
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.41721609234809875,
      "learning_rate": 0.00013551491819056784,
      "loss": 0.8962,
      "step": 1684
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.35123276710510254,
      "learning_rate": 0.00013547641963426371,
      "loss": 0.8678,
      "step": 1685
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3866021931171417,
      "learning_rate": 0.0001354379210779596,
      "loss": 0.5729,
      "step": 1686
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3580552935600281,
      "learning_rate": 0.00013539942252165546,
      "loss": 0.8675,
      "step": 1687
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3900417685508728,
      "learning_rate": 0.0001353609239653513,
      "loss": 0.7664,
      "step": 1688
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3078082501888275,
      "learning_rate": 0.00013532242540904716,
      "loss": 0.8107,
      "step": 1689
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3757234513759613,
      "learning_rate": 0.00013528392685274303,
      "loss": 0.7898,
      "step": 1690
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39455416798591614,
      "learning_rate": 0.00013524542829643888,
      "loss": 0.7326,
      "step": 1691
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38055068254470825,
      "learning_rate": 0.00013520692974013475,
      "loss": 0.6816,
      "step": 1692
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4642220735549927,
      "learning_rate": 0.00013516843118383063,
      "loss": 0.7931,
      "step": 1693
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.45477095246315,
      "learning_rate": 0.00013512993262752648,
      "loss": 0.8108,
      "step": 1694
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3501637279987335,
      "learning_rate": 0.00013509143407122232,
      "loss": 0.6283,
      "step": 1695
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.2790762484073639,
      "learning_rate": 0.0001350529355149182,
      "loss": 0.9388,
      "step": 1696
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4281442165374756,
      "learning_rate": 0.00013501443695861407,
      "loss": 0.6854,
      "step": 1697
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3663672208786011,
      "learning_rate": 0.00013497593840230992,
      "loss": 0.7257,
      "step": 1698
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.42238500714302063,
      "learning_rate": 0.00013493743984600577,
      "loss": 0.7815,
      "step": 1699
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.361511766910553,
      "learning_rate": 0.00013489894128970164,
      "loss": 0.7914,
      "step": 1700
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.44551175832748413,
      "learning_rate": 0.00013486044273339752,
      "loss": 0.5944,
      "step": 1701
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.322598397731781,
      "learning_rate": 0.00013482194417709336,
      "loss": 0.7393,
      "step": 1702
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.44727233052253723,
      "learning_rate": 0.0001347834456207892,
      "loss": 0.7253,
      "step": 1703
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47983914613723755,
      "learning_rate": 0.00013474494706448509,
      "loss": 0.6959,
      "step": 1704
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.42858752608299255,
      "learning_rate": 0.00013470644850818096,
      "loss": 0.6486,
      "step": 1705
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4047139286994934,
      "learning_rate": 0.0001346679499518768,
      "loss": 0.615,
      "step": 1706
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.426738440990448,
      "learning_rate": 0.00013462945139557268,
      "loss": 0.9417,
      "step": 1707
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3421737849712372,
      "learning_rate": 0.00013459095283926853,
      "loss": 0.8984,
      "step": 1708
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.37582096457481384,
      "learning_rate": 0.0001345524542829644,
      "loss": 0.629,
      "step": 1709
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4053765833377838,
      "learning_rate": 0.00013451395572666025,
      "loss": 0.7527,
      "step": 1710
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4354304373264313,
      "learning_rate": 0.00013447545717035613,
      "loss": 0.8466,
      "step": 1711
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38102301955223083,
      "learning_rate": 0.000134436958614052,
      "loss": 0.8259,
      "step": 1712
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4141985774040222,
      "learning_rate": 0.00013439846005774782,
      "loss": 0.7802,
      "step": 1713
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4680878818035126,
      "learning_rate": 0.0001343599615014437,
      "loss": 0.7206,
      "step": 1714
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38156476616859436,
      "learning_rate": 0.00013432146294513957,
      "loss": 0.8254,
      "step": 1715
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3689975440502167,
      "learning_rate": 0.00013428296438883542,
      "loss": 0.704,
      "step": 1716
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.33749666810035706,
      "learning_rate": 0.0001342444658325313,
      "loss": 0.8921,
      "step": 1717
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4280622899532318,
      "learning_rate": 0.00013420596727622714,
      "loss": 0.7264,
      "step": 1718
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4112262427806854,
      "learning_rate": 0.00013416746871992301,
      "loss": 0.8334,
      "step": 1719
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.36519521474838257,
      "learning_rate": 0.00013412897016361886,
      "loss": 0.7789,
      "step": 1720
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4080885648727417,
      "learning_rate": 0.00013409047160731474,
      "loss": 0.8359,
      "step": 1721
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3179738223552704,
      "learning_rate": 0.0001340519730510106,
      "loss": 0.7983,
      "step": 1722
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38401511311531067,
      "learning_rate": 0.00013401347449470646,
      "loss": 0.6919,
      "step": 1723
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39707523584365845,
      "learning_rate": 0.0001339749759384023,
      "loss": 0.7107,
      "step": 1724
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3825884461402893,
      "learning_rate": 0.00013393647738209818,
      "loss": 0.6284,
      "step": 1725
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3741552233695984,
      "learning_rate": 0.00013389797882579405,
      "loss": 0.5956,
      "step": 1726
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3510701656341553,
      "learning_rate": 0.0001338594802694899,
      "loss": 0.7413,
      "step": 1727
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47350308299064636,
      "learning_rate": 0.00013382098171318575,
      "loss": 0.6876,
      "step": 1728
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3953753113746643,
      "learning_rate": 0.00013378248315688162,
      "loss": 0.8057,
      "step": 1729
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5187188982963562,
      "learning_rate": 0.0001337439846005775,
      "loss": 1.0065,
      "step": 1730
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4302092492580414,
      "learning_rate": 0.00013370548604427335,
      "loss": 0.6424,
      "step": 1731
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3670450747013092,
      "learning_rate": 0.0001336669874879692,
      "loss": 0.7948,
      "step": 1732
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.46210038661956787,
      "learning_rate": 0.00013362848893166507,
      "loss": 0.8077,
      "step": 1733
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4794730842113495,
      "learning_rate": 0.00013358999037536094,
      "loss": 0.8104,
      "step": 1734
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3713834583759308,
      "learning_rate": 0.0001335514918190568,
      "loss": 0.677,
      "step": 1735
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.428555965423584,
      "learning_rate": 0.00013351299326275266,
      "loss": 0.7721,
      "step": 1736
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4205116927623749,
      "learning_rate": 0.0001334744947064485,
      "loss": 0.8177,
      "step": 1737
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.32891568541526794,
      "learning_rate": 0.00013343599615014436,
      "loss": 0.9035,
      "step": 1738
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.331065833568573,
      "learning_rate": 0.00013339749759384023,
      "loss": 0.7236,
      "step": 1739
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.41253137588500977,
      "learning_rate": 0.0001333589990375361,
      "loss": 0.8883,
      "step": 1740
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.35336944460868835,
      "learning_rate": 0.00013332050048123198,
      "loss": 0.7508,
      "step": 1741
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39538848400115967,
      "learning_rate": 0.0001332820019249278,
      "loss": 0.8261,
      "step": 1742
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39146655797958374,
      "learning_rate": 0.00013324350336862368,
      "loss": 0.8598,
      "step": 1743
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4060017168521881,
      "learning_rate": 0.00013320500481231955,
      "loss": 0.5726,
      "step": 1744
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.489631712436676,
      "learning_rate": 0.0001331665062560154,
      "loss": 0.6755,
      "step": 1745
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.466908723115921,
      "learning_rate": 0.00013312800769971127,
      "loss": 0.8257,
      "step": 1746
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3647698163986206,
      "learning_rate": 0.00013308950914340712,
      "loss": 0.9009,
      "step": 1747
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4265061914920807,
      "learning_rate": 0.000133051010587103,
      "loss": 0.8946,
      "step": 1748
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4608971178531647,
      "learning_rate": 0.00013301251203079884,
      "loss": 0.7449,
      "step": 1749
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4591614902019501,
      "learning_rate": 0.00013297401347449472,
      "loss": 0.8035,
      "step": 1750
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4120148718357086,
      "learning_rate": 0.0001329355149181906,
      "loss": 0.8999,
      "step": 1751
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.36881500482559204,
      "learning_rate": 0.00013289701636188644,
      "loss": 0.818,
      "step": 1752
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4361303448677063,
      "learning_rate": 0.0001328585178055823,
      "loss": 0.7597,
      "step": 1753
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4416385591030121,
      "learning_rate": 0.00013282001924927816,
      "loss": 0.8448,
      "step": 1754
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3966282904148102,
      "learning_rate": 0.00013278152069297404,
      "loss": 0.6749,
      "step": 1755
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39678123593330383,
      "learning_rate": 0.00013274302213666988,
      "loss": 0.9125,
      "step": 1756
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.476730614900589,
      "learning_rate": 0.00013270452358036573,
      "loss": 0.5797,
      "step": 1757
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3988790512084961,
      "learning_rate": 0.0001326660250240616,
      "loss": 0.8358,
      "step": 1758
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.44026172161102295,
      "learning_rate": 0.00013262752646775748,
      "loss": 0.6879,
      "step": 1759
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.37759459018707275,
      "learning_rate": 0.00013258902791145333,
      "loss": 0.873,
      "step": 1760
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4016784727573395,
      "learning_rate": 0.00013255052935514918,
      "loss": 0.7861,
      "step": 1761
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39727985858917236,
      "learning_rate": 0.00013251203079884505,
      "loss": 0.6474,
      "step": 1762
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41534146666526794,
      "learning_rate": 0.0001324735322425409,
      "loss": 0.6465,
      "step": 1763
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.49826428294181824,
      "learning_rate": 0.00013243503368623677,
      "loss": 0.5081,
      "step": 1764
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.36738163232803345,
      "learning_rate": 0.00013239653512993265,
      "loss": 0.6787,
      "step": 1765
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41939955949783325,
      "learning_rate": 0.0001323580365736285,
      "loss": 0.7143,
      "step": 1766
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.35710862278938293,
      "learning_rate": 0.00013231953801732434,
      "loss": 0.7635,
      "step": 1767
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4553787112236023,
      "learning_rate": 0.00013228103946102022,
      "loss": 0.8108,
      "step": 1768
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3743007481098175,
      "learning_rate": 0.0001322425409047161,
      "loss": 0.8004,
      "step": 1769
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3668770492076874,
      "learning_rate": 0.00013220404234841194,
      "loss": 0.7373,
      "step": 1770
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4216722846031189,
      "learning_rate": 0.00013216554379210778,
      "loss": 0.6837,
      "step": 1771
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.44769206643104553,
      "learning_rate": 0.00013212704523580366,
      "loss": 0.7184,
      "step": 1772
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3925091028213501,
      "learning_rate": 0.00013208854667949953,
      "loss": 0.8648,
      "step": 1773
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.40613749623298645,
      "learning_rate": 0.00013205004812319538,
      "loss": 0.8594,
      "step": 1774
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4309766888618469,
      "learning_rate": 0.00013201154956689126,
      "loss": 0.7611,
      "step": 1775
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.38581958413124084,
      "learning_rate": 0.0001319730510105871,
      "loss": 0.8555,
      "step": 1776
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.37257885932922363,
      "learning_rate": 0.00013193455245428298,
      "loss": 0.9002,
      "step": 1777
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3504149615764618,
      "learning_rate": 0.00013189605389797883,
      "loss": 0.8699,
      "step": 1778
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4043499529361725,
      "learning_rate": 0.0001318575553416747,
      "loss": 0.8993,
      "step": 1779
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.35383516550064087,
      "learning_rate": 0.00013181905678537057,
      "loss": 0.7492,
      "step": 1780
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3652566373348236,
      "learning_rate": 0.00013178055822906642,
      "loss": 0.6588,
      "step": 1781
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.44949468970298767,
      "learning_rate": 0.00013174205967276227,
      "loss": 0.8642,
      "step": 1782
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3907475769519806,
      "learning_rate": 0.00013170356111645814,
      "loss": 0.8488,
      "step": 1783
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.45091649889945984,
      "learning_rate": 0.00013166506256015402,
      "loss": 0.8131,
      "step": 1784
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3817487955093384,
      "learning_rate": 0.00013162656400384987,
      "loss": 0.768,
      "step": 1785
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4341089427471161,
      "learning_rate": 0.0001315880654475457,
      "loss": 0.8932,
      "step": 1786
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4040856957435608,
      "learning_rate": 0.0001315495668912416,
      "loss": 0.8677,
      "step": 1787
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.48962685465812683,
      "learning_rate": 0.00013151106833493744,
      "loss": 0.581,
      "step": 1788
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4897845685482025,
      "learning_rate": 0.0001314725697786333,
      "loss": 0.7564,
      "step": 1789
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4242686331272125,
      "learning_rate": 0.00013143407122232916,
      "loss": 0.8015,
      "step": 1790
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4992380738258362,
      "learning_rate": 0.00013139557266602503,
      "loss": 0.7852,
      "step": 1791
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39378622174263,
      "learning_rate": 0.00013135707410972088,
      "loss": 0.801,
      "step": 1792
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3587026596069336,
      "learning_rate": 0.00013131857555341675,
      "loss": 0.665,
      "step": 1793
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41467753052711487,
      "learning_rate": 0.00013128007699711263,
      "loss": 0.7087,
      "step": 1794
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3516363501548767,
      "learning_rate": 0.00013124157844080848,
      "loss": 0.6985,
      "step": 1795
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4346103072166443,
      "learning_rate": 0.00013120307988450432,
      "loss": 0.6885,
      "step": 1796
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42545539140701294,
      "learning_rate": 0.0001311645813282002,
      "loss": 0.8076,
      "step": 1797
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3634584844112396,
      "learning_rate": 0.00013112608277189607,
      "loss": 0.7379,
      "step": 1798
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3166871666908264,
      "learning_rate": 0.00013108758421559192,
      "loss": 0.803,
      "step": 1799
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4216887354850769,
      "learning_rate": 0.00013104908565928777,
      "loss": 0.9611,
      "step": 1800
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.37665343284606934,
      "learning_rate": 0.00013101058710298364,
      "loss": 0.736,
      "step": 1801
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3316784203052521,
      "learning_rate": 0.00013097208854667952,
      "loss": 0.8301,
      "step": 1802
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3948574662208557,
      "learning_rate": 0.00013093358999037536,
      "loss": 0.7948,
      "step": 1803
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42535287141799927,
      "learning_rate": 0.00013089509143407124,
      "loss": 0.6082,
      "step": 1804
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45145320892333984,
      "learning_rate": 0.00013085659287776709,
      "loss": 0.8258,
      "step": 1805
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.41247326135635376,
      "learning_rate": 0.00013081809432146296,
      "loss": 0.7861,
      "step": 1806
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3567247688770294,
      "learning_rate": 0.0001307795957651588,
      "loss": 0.5375,
      "step": 1807
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.38506612181663513,
      "learning_rate": 0.00013074109720885468,
      "loss": 0.7448,
      "step": 1808
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.40983420610427856,
      "learning_rate": 0.00013070259865255056,
      "loss": 0.6629,
      "step": 1809
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3984203040599823,
      "learning_rate": 0.00013066410009624638,
      "loss": 0.6575,
      "step": 1810
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4499220550060272,
      "learning_rate": 0.00013062560153994225,
      "loss": 0.7661,
      "step": 1811
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3570815920829773,
      "learning_rate": 0.00013058710298363813,
      "loss": 0.6938,
      "step": 1812
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4945443868637085,
      "learning_rate": 0.000130548604427334,
      "loss": 0.814,
      "step": 1813
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.425142377614975,
      "learning_rate": 0.00013051010587102985,
      "loss": 0.8694,
      "step": 1814
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.35842636227607727,
      "learning_rate": 0.0001304716073147257,
      "loss": 0.8498,
      "step": 1815
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3513905107975006,
      "learning_rate": 0.00013043310875842157,
      "loss": 0.7484,
      "step": 1816
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3908533453941345,
      "learning_rate": 0.00013039461020211742,
      "loss": 0.6165,
      "step": 1817
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3497600257396698,
      "learning_rate": 0.0001303561116458133,
      "loss": 0.9604,
      "step": 1818
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.31747105717658997,
      "learning_rate": 0.00013031761308950917,
      "loss": 0.8938,
      "step": 1819
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.421970009803772,
      "learning_rate": 0.000130279114533205,
      "loss": 0.7894,
      "step": 1820
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.37083736062049866,
      "learning_rate": 0.00013024061597690086,
      "loss": 0.8704,
      "step": 1821
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4444059133529663,
      "learning_rate": 0.00013020211742059674,
      "loss": 0.8286,
      "step": 1822
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39304319024086,
      "learning_rate": 0.0001301636188642926,
      "loss": 0.6972,
      "step": 1823
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3517228066921234,
      "learning_rate": 0.00013012512030798846,
      "loss": 0.6674,
      "step": 1824
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45172977447509766,
      "learning_rate": 0.0001300866217516843,
      "loss": 0.9044,
      "step": 1825
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45259156823158264,
      "learning_rate": 0.00013004812319538018,
      "loss": 0.67,
      "step": 1826
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.40611517429351807,
      "learning_rate": 0.00013000962463907605,
      "loss": 0.7879,
      "step": 1827
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.342877060174942,
      "learning_rate": 0.0001299711260827719,
      "loss": 0.6913,
      "step": 1828
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.360265851020813,
      "learning_rate": 0.00012993262752646775,
      "loss": 0.7195,
      "step": 1829
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4196864068508148,
      "learning_rate": 0.00012989412897016362,
      "loss": 0.822,
      "step": 1830
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.36162206530570984,
      "learning_rate": 0.0001298556304138595,
      "loss": 0.7965,
      "step": 1831
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4311762750148773,
      "learning_rate": 0.00012981713185755535,
      "loss": 0.96,
      "step": 1832
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.46204665303230286,
      "learning_rate": 0.00012977863330125122,
      "loss": 0.8514,
      "step": 1833
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4710827171802521,
      "learning_rate": 0.00012974013474494707,
      "loss": 0.613,
      "step": 1834
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39967840909957886,
      "learning_rate": 0.00012970163618864291,
      "loss": 0.7719,
      "step": 1835
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4258590340614319,
      "learning_rate": 0.0001296631376323388,
      "loss": 0.6707,
      "step": 1836
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3759515583515167,
      "learning_rate": 0.00012962463907603466,
      "loss": 0.7592,
      "step": 1837
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3703937232494354,
      "learning_rate": 0.00012958614051973054,
      "loss": 0.8268,
      "step": 1838
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4929504990577698,
      "learning_rate": 0.00012954764196342636,
      "loss": 0.7373,
      "step": 1839
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3643803894519806,
      "learning_rate": 0.00012950914340712223,
      "loss": 0.773,
      "step": 1840
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4126928746700287,
      "learning_rate": 0.0001294706448508181,
      "loss": 0.8195,
      "step": 1841
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39850255846977234,
      "learning_rate": 0.00012943214629451395,
      "loss": 0.7887,
      "step": 1842
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4216155707836151,
      "learning_rate": 0.00012939364773820983,
      "loss": 0.6158,
      "step": 1843
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3541860282421112,
      "learning_rate": 0.00012935514918190568,
      "loss": 0.6684,
      "step": 1844
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3919277489185333,
      "learning_rate": 0.00012931665062560155,
      "loss": 0.7254,
      "step": 1845
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.44354334473609924,
      "learning_rate": 0.0001292781520692974,
      "loss": 0.7323,
      "step": 1846
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3782220482826233,
      "learning_rate": 0.00012923965351299327,
      "loss": 0.9516,
      "step": 1847
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38252702355384827,
      "learning_rate": 0.00012920115495668915,
      "loss": 0.5062,
      "step": 1848
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3897949159145355,
      "learning_rate": 0.000129162656400385,
      "loss": 0.794,
      "step": 1849
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4504038989543915,
      "learning_rate": 0.00012912415784408084,
      "loss": 0.7374,
      "step": 1850
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5358611941337585,
      "learning_rate": 0.00012908565928777672,
      "loss": 0.7077,
      "step": 1851
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.37403053045272827,
      "learning_rate": 0.0001290471607314726,
      "loss": 0.9128,
      "step": 1852
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3812733590602875,
      "learning_rate": 0.00012900866217516844,
      "loss": 0.7707,
      "step": 1853
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3871363401412964,
      "learning_rate": 0.0001289701636188643,
      "loss": 0.6346,
      "step": 1854
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3475709855556488,
      "learning_rate": 0.00012893166506256016,
      "loss": 0.9545,
      "step": 1855
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.44716084003448486,
      "learning_rate": 0.00012889316650625604,
      "loss": 0.7429,
      "step": 1856
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3908954858779907,
      "learning_rate": 0.00012885466794995188,
      "loss": 0.7284,
      "step": 1857
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3515625596046448,
      "learning_rate": 0.00012881616939364773,
      "loss": 0.6963,
      "step": 1858
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3920833170413971,
      "learning_rate": 0.0001287776708373436,
      "loss": 0.681,
      "step": 1859
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3983509838581085,
      "learning_rate": 0.00012873917228103948,
      "loss": 0.8387,
      "step": 1860
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38083890080451965,
      "learning_rate": 0.00012870067372473533,
      "loss": 0.8664,
      "step": 1861
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4730418622493744,
      "learning_rate": 0.0001286621751684312,
      "loss": 0.7216,
      "step": 1862
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.39920854568481445,
      "learning_rate": 0.00012862367661212705,
      "loss": 0.7624,
      "step": 1863
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4217352867126465,
      "learning_rate": 0.0001285851780558229,
      "loss": 0.6897,
      "step": 1864
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38850855827331543,
      "learning_rate": 0.00012854667949951877,
      "loss": 0.7508,
      "step": 1865
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.43991467356681824,
      "learning_rate": 0.00012850818094321465,
      "loss": 0.8173,
      "step": 1866
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.31125056743621826,
      "learning_rate": 0.0001284696823869105,
      "loss": 0.7721,
      "step": 1867
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3797193169593811,
      "learning_rate": 0.00012843118383060634,
      "loss": 0.9471,
      "step": 1868
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4224429130554199,
      "learning_rate": 0.00012839268527430221,
      "loss": 0.6935,
      "step": 1869
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5061063170433044,
      "learning_rate": 0.0001283541867179981,
      "loss": 0.7046,
      "step": 1870
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.48780766129493713,
      "learning_rate": 0.00012831568816169394,
      "loss": 0.7875,
      "step": 1871
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4205755293369293,
      "learning_rate": 0.0001282771896053898,
      "loss": 0.5716,
      "step": 1872
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5090664625167847,
      "learning_rate": 0.00012823869104908566,
      "loss": 0.6772,
      "step": 1873
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.45707517862319946,
      "learning_rate": 0.00012820019249278153,
      "loss": 0.7296,
      "step": 1874
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.48018398880958557,
      "learning_rate": 0.00012816169393647738,
      "loss": 0.8971,
      "step": 1875
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3644025921821594,
      "learning_rate": 0.00012812319538017326,
      "loss": 0.8381,
      "step": 1876
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3494745194911957,
      "learning_rate": 0.00012808469682386913,
      "loss": 0.7066,
      "step": 1877
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.41221722960472107,
      "learning_rate": 0.00012804619826756498,
      "loss": 0.7723,
      "step": 1878
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3453875780105591,
      "learning_rate": 0.00012800769971126082,
      "loss": 0.962,
      "step": 1879
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.47477832436561584,
      "learning_rate": 0.0001279692011549567,
      "loss": 0.6965,
      "step": 1880
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.37314528226852417,
      "learning_rate": 0.00012793070259865257,
      "loss": 0.7089,
      "step": 1881
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.47785308957099915,
      "learning_rate": 0.00012789220404234842,
      "loss": 0.8714,
      "step": 1882
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38032662868499756,
      "learning_rate": 0.00012785370548604427,
      "loss": 0.6457,
      "step": 1883
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3759020268917084,
      "learning_rate": 0.00012781520692974014,
      "loss": 0.7573,
      "step": 1884
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3873295485973358,
      "learning_rate": 0.00012777670837343602,
      "loss": 0.8732,
      "step": 1885
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.35442495346069336,
      "learning_rate": 0.00012773820981713187,
      "loss": 0.8167,
      "step": 1886
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38815587759017944,
      "learning_rate": 0.0001276997112608277,
      "loss": 0.6467,
      "step": 1887
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4207095801830292,
      "learning_rate": 0.0001276612127045236,
      "loss": 0.6392,
      "step": 1888
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4079640209674835,
      "learning_rate": 0.00012762271414821943,
      "loss": 0.6505,
      "step": 1889
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.475057989358902,
      "learning_rate": 0.0001275842155919153,
      "loss": 0.7512,
      "step": 1890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.48418885469436646,
      "learning_rate": 0.00012754571703561118,
      "loss": 0.5987,
      "step": 1891
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3562620282173157,
      "learning_rate": 0.00012750721847930703,
      "loss": 0.8723,
      "step": 1892
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.43781307339668274,
      "learning_rate": 0.00012746871992300288,
      "loss": 0.7518,
      "step": 1893
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4474557638168335,
      "learning_rate": 0.00012743022136669875,
      "loss": 0.6934,
      "step": 1894
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.42306774854660034,
      "learning_rate": 0.00012739172281039463,
      "loss": 0.8038,
      "step": 1895
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4244105815887451,
      "learning_rate": 0.00012735322425409047,
      "loss": 0.7325,
      "step": 1896
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3509678542613983,
      "learning_rate": 0.00012731472569778632,
      "loss": 0.7208,
      "step": 1897
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.39639490842819214,
      "learning_rate": 0.0001272762271414822,
      "loss": 0.8663,
      "step": 1898
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3530687987804413,
      "learning_rate": 0.00012723772858517807,
      "loss": 0.731,
      "step": 1899
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.32869061827659607,
      "learning_rate": 0.00012719923002887392,
      "loss": 0.7454,
      "step": 1900
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.380421906709671,
      "learning_rate": 0.0001271607314725698,
      "loss": 0.7217,
      "step": 1901
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.38393357396125793,
      "learning_rate": 0.00012712223291626564,
      "loss": 0.9215,
      "step": 1902
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3520403504371643,
      "learning_rate": 0.00012708373435996152,
      "loss": 0.7156,
      "step": 1903
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4328886568546295,
      "learning_rate": 0.00012704523580365736,
      "loss": 0.6459,
      "step": 1904
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.36250337958335876,
      "learning_rate": 0.00012700673724735324,
      "loss": 0.8772,
      "step": 1905
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.33598798513412476,
      "learning_rate": 0.0001269682386910491,
      "loss": 0.9344,
      "step": 1906
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40680235624313354,
      "learning_rate": 0.00012692974013474493,
      "loss": 0.8163,
      "step": 1907
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3694469928741455,
      "learning_rate": 0.0001268912415784408,
      "loss": 0.7975,
      "step": 1908
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3503014147281647,
      "learning_rate": 0.00012685274302213668,
      "loss": 0.7764,
      "step": 1909
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4201619327068329,
      "learning_rate": 0.00012681424446583256,
      "loss": 0.7064,
      "step": 1910
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.41038116812705994,
      "learning_rate": 0.0001267757459095284,
      "loss": 0.8704,
      "step": 1911
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.45049744844436646,
      "learning_rate": 0.00012673724735322425,
      "loss": 0.6221,
      "step": 1912
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.36259254813194275,
      "learning_rate": 0.00012669874879692013,
      "loss": 0.7693,
      "step": 1913
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.35794588923454285,
      "learning_rate": 0.00012666025024061597,
      "loss": 0.7066,
      "step": 1914
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3778039216995239,
      "learning_rate": 0.00012662175168431185,
      "loss": 0.6526,
      "step": 1915
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4403374195098877,
      "learning_rate": 0.0001265832531280077,
      "loss": 0.6521,
      "step": 1916
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.37176060676574707,
      "learning_rate": 0.00012654475457170357,
      "loss": 0.7329,
      "step": 1917
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5037533044815063,
      "learning_rate": 0.00012650625601539942,
      "loss": 0.7895,
      "step": 1918
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4459839463233948,
      "learning_rate": 0.0001264677574590953,
      "loss": 0.8182,
      "step": 1919
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4781947135925293,
      "learning_rate": 0.00012642925890279117,
      "loss": 0.8062,
      "step": 1920
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3782847225666046,
      "learning_rate": 0.000126390760346487,
      "loss": 0.641,
      "step": 1921
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.45465216040611267,
      "learning_rate": 0.00012635226179018286,
      "loss": 0.8257,
      "step": 1922
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40369531512260437,
      "learning_rate": 0.00012631376323387873,
      "loss": 0.7442,
      "step": 1923
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.39407670497894287,
      "learning_rate": 0.0001262752646775746,
      "loss": 0.5818,
      "step": 1924
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.35491541028022766,
      "learning_rate": 0.00012623676612127046,
      "loss": 0.7069,
      "step": 1925
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.41069719195365906,
      "learning_rate": 0.0001261982675649663,
      "loss": 0.6938,
      "step": 1926
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.38464608788490295,
      "learning_rate": 0.00012615976900866218,
      "loss": 0.8208,
      "step": 1927
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3080153465270996,
      "learning_rate": 0.00012612127045235805,
      "loss": 0.8452,
      "step": 1928
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4448833465576172,
      "learning_rate": 0.0001260827718960539,
      "loss": 0.6547,
      "step": 1929
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3585502803325653,
      "learning_rate": 0.00012604427333974978,
      "loss": 0.7322,
      "step": 1930
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4916130006313324,
      "learning_rate": 0.00012600577478344562,
      "loss": 0.6263,
      "step": 1931
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3735608160495758,
      "learning_rate": 0.0001259672762271415,
      "loss": 0.844,
      "step": 1932
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4147472083568573,
      "learning_rate": 0.00012592877767083734,
      "loss": 0.6432,
      "step": 1933
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4596444070339203,
      "learning_rate": 0.00012589027911453322,
      "loss": 0.6794,
      "step": 1934
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4263108968734741,
      "learning_rate": 0.0001258517805582291,
      "loss": 0.9283,
      "step": 1935
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40343740582466125,
      "learning_rate": 0.00012581328200192491,
      "loss": 0.8047,
      "step": 1936
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3231755495071411,
      "learning_rate": 0.0001257747834456208,
      "loss": 0.7539,
      "step": 1937
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3559107482433319,
      "learning_rate": 0.00012573628488931666,
      "loss": 0.6522,
      "step": 1938
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3448850214481354,
      "learning_rate": 0.0001256977863330125,
      "loss": 0.7133,
      "step": 1939
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.35919106006622314,
      "learning_rate": 0.00012565928777670839,
      "loss": 0.6377,
      "step": 1940
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3644396960735321,
      "learning_rate": 0.00012562078922040423,
      "loss": 0.641,
      "step": 1941
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3526782989501953,
      "learning_rate": 0.0001255822906641001,
      "loss": 0.7777,
      "step": 1942
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.42084801197052,
      "learning_rate": 0.00012554379210779595,
      "loss": 0.613,
      "step": 1943
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4135233759880066,
      "learning_rate": 0.00012550529355149183,
      "loss": 0.7808,
      "step": 1944
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4561818838119507,
      "learning_rate": 0.0001254667949951877,
      "loss": 0.8051,
      "step": 1945
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.389324426651001,
      "learning_rate": 0.00012542829643888355,
      "loss": 0.9359,
      "step": 1946
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.42289772629737854,
      "learning_rate": 0.0001253897978825794,
      "loss": 0.8507,
      "step": 1947
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40204256772994995,
      "learning_rate": 0.00012535129932627527,
      "loss": 0.7511,
      "step": 1948
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.41630515456199646,
      "learning_rate": 0.00012531280076997115,
      "loss": 0.7576,
      "step": 1949
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4155476689338684,
      "learning_rate": 0.000125274302213667,
      "loss": 0.8898,
      "step": 1950
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3869580030441284,
      "learning_rate": 0.00012523580365736284,
      "loss": 0.7584,
      "step": 1951
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4416559934616089,
      "learning_rate": 0.00012519730510105872,
      "loss": 0.677,
      "step": 1952
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3612990975379944,
      "learning_rate": 0.0001251588065447546,
      "loss": 0.822,
      "step": 1953
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5051171779632568,
      "learning_rate": 0.00012512030798845044,
      "loss": 0.7683,
      "step": 1954
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.44406336545944214,
      "learning_rate": 0.00012508180943214629,
      "loss": 0.5896,
      "step": 1955
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4227225184440613,
      "learning_rate": 0.00012504331087584216,
      "loss": 0.6263,
      "step": 1956
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4141536056995392,
      "learning_rate": 0.00012500481231953804,
      "loss": 0.8355,
      "step": 1957
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.38118410110473633,
      "learning_rate": 0.00012496631376323388,
      "loss": 0.7593,
      "step": 1958
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5263524651527405,
      "learning_rate": 0.00012492781520692976,
      "loss": 0.9206,
      "step": 1959
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.43957844376564026,
      "learning_rate": 0.0001248893166506256,
      "loss": 0.7309,
      "step": 1960
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.35311853885650635,
      "learning_rate": 0.00012485081809432145,
      "loss": 0.7148,
      "step": 1961
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.38100552558898926,
      "learning_rate": 0.00012481231953801733,
      "loss": 0.6235,
      "step": 1962
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.37844735383987427,
      "learning_rate": 0.0001247738209817132,
      "loss": 0.7104,
      "step": 1963
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3697439730167389,
      "learning_rate": 0.00012473532242540908,
      "loss": 0.9466,
      "step": 1964
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3669210374355316,
      "learning_rate": 0.0001246968238691049,
      "loss": 0.6652,
      "step": 1965
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.40461626648902893,
      "learning_rate": 0.00012465832531280077,
      "loss": 0.6421,
      "step": 1966
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.43144533038139343,
      "learning_rate": 0.00012461982675649665,
      "loss": 0.7366,
      "step": 1967
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4194335639476776,
      "learning_rate": 0.0001245813282001925,
      "loss": 0.7724,
      "step": 1968
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.36216244101524353,
      "learning_rate": 0.00012454282964388837,
      "loss": 0.8686,
      "step": 1969
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4813291132450104,
      "learning_rate": 0.00012450433108758421,
      "loss": 0.77,
      "step": 1970
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41711923480033875,
      "learning_rate": 0.0001244658325312801,
      "loss": 0.6592,
      "step": 1971
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3906590938568115,
      "learning_rate": 0.00012442733397497594,
      "loss": 0.8117,
      "step": 1972
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4016876816749573,
      "learning_rate": 0.0001243888354186718,
      "loss": 0.7499,
      "step": 1973
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.42538028955459595,
      "learning_rate": 0.00012435033686236769,
      "loss": 0.7417,
      "step": 1974
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.42690616846084595,
      "learning_rate": 0.00012431183830606353,
      "loss": 0.6353,
      "step": 1975
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4209519624710083,
      "learning_rate": 0.00012427333974975938,
      "loss": 0.7598,
      "step": 1976
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.39313405752182007,
      "learning_rate": 0.00012423484119345525,
      "loss": 0.7792,
      "step": 1977
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41112396121025085,
      "learning_rate": 0.00012419634263715113,
      "loss": 0.7569,
      "step": 1978
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.42747482657432556,
      "learning_rate": 0.00012415784408084698,
      "loss": 0.7651,
      "step": 1979
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4339894652366638,
      "learning_rate": 0.00012411934552454282,
      "loss": 0.8933,
      "step": 1980
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3783250153064728,
      "learning_rate": 0.0001240808469682387,
      "loss": 0.7773,
      "step": 1981
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41081398725509644,
      "learning_rate": 0.00012404234841193457,
      "loss": 0.8325,
      "step": 1982
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4031309485435486,
      "learning_rate": 0.00012400384985563042,
      "loss": 0.8742,
      "step": 1983
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3886183202266693,
      "learning_rate": 0.00012396535129932627,
      "loss": 0.608,
      "step": 1984
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.34317609667778015,
      "learning_rate": 0.00012392685274302214,
      "loss": 0.5327,
      "step": 1985
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3442971408367157,
      "learning_rate": 0.000123888354186718,
      "loss": 0.7692,
      "step": 1986
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5018425583839417,
      "learning_rate": 0.00012384985563041386,
      "loss": 0.7431,
      "step": 1987
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3479405343532562,
      "learning_rate": 0.00012381135707410974,
      "loss": 0.7589,
      "step": 1988
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.37875115871429443,
      "learning_rate": 0.0001237728585178056,
      "loss": 0.7109,
      "step": 1989
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.465097039937973,
      "learning_rate": 0.00012373435996150143,
      "loss": 0.71,
      "step": 1990
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.34705832600593567,
      "learning_rate": 0.0001236958614051973,
      "loss": 0.8524,
      "step": 1991
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.38421595096588135,
      "learning_rate": 0.00012365736284889318,
      "loss": 0.6837,
      "step": 1992
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4191231429576874,
      "learning_rate": 0.00012361886429258903,
      "loss": 0.7636,
      "step": 1993
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3516117036342621,
      "learning_rate": 0.00012358036573628488,
      "loss": 0.6487,
      "step": 1994
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.35605189204216003,
      "learning_rate": 0.00012354186717998075,
      "loss": 0.7462,
      "step": 1995
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4098813235759735,
      "learning_rate": 0.00012350336862367663,
      "loss": 0.8966,
      "step": 1996
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3889295160770416,
      "learning_rate": 0.00012346487006737247,
      "loss": 0.7043,
      "step": 1997
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3662413954734802,
      "learning_rate": 0.00012342637151106835,
      "loss": 0.9537,
      "step": 1998
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3967229127883911,
      "learning_rate": 0.0001233878729547642,
      "loss": 0.8657,
      "step": 1999
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5388762950897217,
      "learning_rate": 0.00012334937439846007,
      "loss": 0.6561,
      "step": 2000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.408794641494751,
      "learning_rate": 0.00012331087584215592,
      "loss": 0.6652,
      "step": 2001
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4102582037448883,
      "learning_rate": 0.0001232723772858518,
      "loss": 1.0117,
      "step": 2002
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5139148235321045,
      "learning_rate": 0.00012323387872954767,
      "loss": 0.8468,
      "step": 2003
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.41571664810180664,
      "learning_rate": 0.00012319538017324351,
      "loss": 0.646,
      "step": 2004
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.47189584374427795,
      "learning_rate": 0.00012315688161693936,
      "loss": 0.6784,
      "step": 2005
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4329637587070465,
      "learning_rate": 0.00012311838306063524,
      "loss": 0.7658,
      "step": 2006
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4125763773918152,
      "learning_rate": 0.0001230798845043311,
      "loss": 0.676,
      "step": 2007
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.41062551736831665,
      "learning_rate": 0.00012304138594802696,
      "loss": 0.8575,
      "step": 2008
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3988594114780426,
      "learning_rate": 0.0001230028873917228,
      "loss": 0.8454,
      "step": 2009
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4611331820487976,
      "learning_rate": 0.00012296438883541868,
      "loss": 0.7585,
      "step": 2010
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4567878246307373,
      "learning_rate": 0.00012292589027911456,
      "loss": 0.6421,
      "step": 2011
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3517627716064453,
      "learning_rate": 0.0001228873917228104,
      "loss": 0.7759,
      "step": 2012
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.37134552001953125,
      "learning_rate": 0.00012284889316650625,
      "loss": 0.6598,
      "step": 2013
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5732856392860413,
      "learning_rate": 0.00012281039461020212,
      "loss": 0.7999,
      "step": 2014
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4829562306404114,
      "learning_rate": 0.00012277189605389797,
      "loss": 0.6875,
      "step": 2015
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.41672706604003906,
      "learning_rate": 0.00012273339749759385,
      "loss": 0.7306,
      "step": 2016
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3966820240020752,
      "learning_rate": 0.00012269489894128972,
      "loss": 0.7323,
      "step": 2017
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.35392627120018005,
      "learning_rate": 0.00012265640038498557,
      "loss": 0.6155,
      "step": 2018
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3570041060447693,
      "learning_rate": 0.00012261790182868142,
      "loss": 0.7711,
      "step": 2019
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.43094366788864136,
      "learning_rate": 0.0001225794032723773,
      "loss": 0.6572,
      "step": 2020
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.46118679642677307,
      "learning_rate": 0.00012254090471607316,
      "loss": 0.7388,
      "step": 2021
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4110174775123596,
      "learning_rate": 0.000122502406159769,
      "loss": 0.7633,
      "step": 2022
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.45007872581481934,
      "learning_rate": 0.00012246390760346486,
      "loss": 0.9979,
      "step": 2023
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4811002016067505,
      "learning_rate": 0.00012242540904716073,
      "loss": 0.8884,
      "step": 2024
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4139425456523895,
      "learning_rate": 0.0001223869104908566,
      "loss": 0.8244,
      "step": 2025
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3508036434650421,
      "learning_rate": 0.00012234841193455246,
      "loss": 0.6291,
      "step": 2026
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3564074635505676,
      "learning_rate": 0.00012230991337824833,
      "loss": 0.5993,
      "step": 2027
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.414589524269104,
      "learning_rate": 0.00012227141482194418,
      "loss": 0.852,
      "step": 2028
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3774373233318329,
      "learning_rate": 0.00012223291626564005,
      "loss": 0.7644,
      "step": 2029
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3742597997188568,
      "learning_rate": 0.0001221944177093359,
      "loss": 0.759,
      "step": 2030
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.44344642758369446,
      "learning_rate": 0.00012215591915303177,
      "loss": 0.8021,
      "step": 2031
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3895547389984131,
      "learning_rate": 0.00012211742059672765,
      "loss": 0.6419,
      "step": 2032
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.39308854937553406,
      "learning_rate": 0.00012207892204042347,
      "loss": 0.8102,
      "step": 2033
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3756394386291504,
      "learning_rate": 0.00012204042348411934,
      "loss": 0.8025,
      "step": 2034
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.473209023475647,
      "learning_rate": 0.00012200192492781522,
      "loss": 0.7383,
      "step": 2035
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.369880348443985,
      "learning_rate": 0.00012196342637151108,
      "loss": 0.8364,
      "step": 2036
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5240722894668579,
      "learning_rate": 0.00012192492781520694,
      "loss": 0.7232,
      "step": 2037
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4130686819553375,
      "learning_rate": 0.00012188642925890279,
      "loss": 0.7917,
      "step": 2038
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.43963950872421265,
      "learning_rate": 0.00012184793070259866,
      "loss": 0.6286,
      "step": 2039
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.37483248114585876,
      "learning_rate": 0.00012180943214629452,
      "loss": 0.8085,
      "step": 2040
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.367349237203598,
      "learning_rate": 0.00012177093358999038,
      "loss": 0.7864,
      "step": 2041
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3880409300327301,
      "learning_rate": 0.00012173243503368623,
      "loss": 0.8338,
      "step": 2042
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.38258102536201477,
      "learning_rate": 0.00012169393647738209,
      "loss": 0.7258,
      "step": 2043
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3926050662994385,
      "learning_rate": 0.00012165543792107797,
      "loss": 0.8641,
      "step": 2044
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.37094995379447937,
      "learning_rate": 0.00012161693936477383,
      "loss": 0.6142,
      "step": 2045
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4337383806705475,
      "learning_rate": 0.00012157844080846969,
      "loss": 0.7139,
      "step": 2046
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.47775086760520935,
      "learning_rate": 0.00012153994225216554,
      "loss": 0.7185,
      "step": 2047
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4545615613460541,
      "learning_rate": 0.00012150144369586141,
      "loss": 0.8431,
      "step": 2048
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4105686545372009,
      "learning_rate": 0.00012146294513955727,
      "loss": 0.8707,
      "step": 2049
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.439957857131958,
      "learning_rate": 0.00012142444658325313,
      "loss": 0.7798,
      "step": 2050
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.42720144987106323,
      "learning_rate": 0.00012138594802694901,
      "loss": 0.8267,
      "step": 2051
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4625844359397888,
      "learning_rate": 0.00012134744947064484,
      "loss": 0.7636,
      "step": 2052
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.42650502920150757,
      "learning_rate": 0.00012130895091434072,
      "loss": 0.6839,
      "step": 2053
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3767647445201874,
      "learning_rate": 0.00012127045235803658,
      "loss": 0.6378,
      "step": 2054
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5337833166122437,
      "learning_rate": 0.00012123195380173245,
      "loss": 0.7482,
      "step": 2055
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3877149224281311,
      "learning_rate": 0.00012119345524542831,
      "loss": 0.8567,
      "step": 2056
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4098486304283142,
      "learning_rate": 0.00012115495668912416,
      "loss": 0.8867,
      "step": 2057
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4096219539642334,
      "learning_rate": 0.00012111645813282002,
      "loss": 0.6185,
      "step": 2058
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.41645532846450806,
      "learning_rate": 0.00012107795957651588,
      "loss": 0.7481,
      "step": 2059
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.44036686420440674,
      "learning_rate": 0.00012103946102021176,
      "loss": 0.8522,
      "step": 2060
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3624647557735443,
      "learning_rate": 0.00012100096246390762,
      "loss": 0.9329,
      "step": 2061
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3435777723789215,
      "learning_rate": 0.00012096246390760347,
      "loss": 0.7418,
      "step": 2062
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3517408072948456,
      "learning_rate": 0.00012092396535129933,
      "loss": 0.839,
      "step": 2063
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3461979627609253,
      "learning_rate": 0.0001208854667949952,
      "loss": 0.7873,
      "step": 2064
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.41387102007865906,
      "learning_rate": 0.00012084696823869106,
      "loss": 0.7371,
      "step": 2065
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3783990740776062,
      "learning_rate": 0.00012080846968238692,
      "loss": 0.9437,
      "step": 2066
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3668247163295746,
      "learning_rate": 0.00012076997112608277,
      "loss": 0.7077,
      "step": 2067
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.45170772075653076,
      "learning_rate": 0.00012073147256977863,
      "loss": 0.9455,
      "step": 2068
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3328435719013214,
      "learning_rate": 0.0001206929740134745,
      "loss": 0.7731,
      "step": 2069
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4016663432121277,
      "learning_rate": 0.00012065447545717037,
      "loss": 0.8585,
      "step": 2070
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.349935382604599,
      "learning_rate": 0.00012061597690086624,
      "loss": 0.7813,
      "step": 2071
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4058588743209839,
      "learning_rate": 0.00012057747834456207,
      "loss": 0.8394,
      "step": 2072
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35471197962760925,
      "learning_rate": 0.00012053897978825795,
      "loss": 0.9745,
      "step": 2073
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.40163925290107727,
      "learning_rate": 0.00012050048123195381,
      "loss": 0.9427,
      "step": 2074
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.348477303981781,
      "learning_rate": 0.00012046198267564967,
      "loss": 0.7882,
      "step": 2075
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4035891592502594,
      "learning_rate": 0.00012042348411934552,
      "loss": 0.8257,
      "step": 2076
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.336616188287735,
      "learning_rate": 0.00012038498556304138,
      "loss": 0.8863,
      "step": 2077
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4254840314388275,
      "learning_rate": 0.00012034648700673725,
      "loss": 0.8186,
      "step": 2078
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3925730884075165,
      "learning_rate": 0.00012030798845043312,
      "loss": 0.7048,
      "step": 2079
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4888431429862976,
      "learning_rate": 0.00012026948989412899,
      "loss": 0.792,
      "step": 2080
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36251410841941833,
      "learning_rate": 0.00012023099133782482,
      "loss": 0.6641,
      "step": 2081
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.452556312084198,
      "learning_rate": 0.0001201924927815207,
      "loss": 1.0918,
      "step": 2082
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3192079961299896,
      "learning_rate": 0.00012015399422521656,
      "loss": 0.659,
      "step": 2083
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4449225068092346,
      "learning_rate": 0.00012011549566891242,
      "loss": 0.9653,
      "step": 2084
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4607343375682831,
      "learning_rate": 0.0001200769971126083,
      "loss": 0.6892,
      "step": 2085
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38626304268836975,
      "learning_rate": 0.00012003849855630414,
      "loss": 0.823,
      "step": 2086
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.39865872263908386,
      "learning_rate": 0.00012,
      "loss": 0.6312,
      "step": 2087
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3629981577396393,
      "learning_rate": 0.00011996150144369586,
      "loss": 0.5786,
      "step": 2088
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.33878591656684875,
      "learning_rate": 0.00011992300288739174,
      "loss": 0.6086,
      "step": 2089
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4121987521648407,
      "learning_rate": 0.0001198845043310876,
      "loss": 0.8919,
      "step": 2090
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.42842817306518555,
      "learning_rate": 0.00011984600577478345,
      "loss": 0.8634,
      "step": 2091
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3267122805118561,
      "learning_rate": 0.00011980750721847931,
      "loss": 0.8016,
      "step": 2092
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38008689880371094,
      "learning_rate": 0.00011976900866217517,
      "loss": 0.6774,
      "step": 2093
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.371703565120697,
      "learning_rate": 0.00011973051010587104,
      "loss": 0.6651,
      "step": 2094
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.40235620737075806,
      "learning_rate": 0.0001196920115495669,
      "loss": 0.57,
      "step": 2095
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36884161829948425,
      "learning_rate": 0.00011965351299326275,
      "loss": 0.8883,
      "step": 2096
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38928765058517456,
      "learning_rate": 0.00011961501443695861,
      "loss": 0.5824,
      "step": 2097
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4125731289386749,
      "learning_rate": 0.00011957651588065449,
      "loss": 0.6825,
      "step": 2098
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38826653361320496,
      "learning_rate": 0.00011953801732435035,
      "loss": 0.734,
      "step": 2099
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36381569504737854,
      "learning_rate": 0.00011949951876804621,
      "loss": 0.7878,
      "step": 2100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38993075489997864,
      "learning_rate": 0.00011946102021174206,
      "loss": 0.7783,
      "step": 2101
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35114869475364685,
      "learning_rate": 0.00011942252165543792,
      "loss": 0.8276,
      "step": 2102
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36438387632369995,
      "learning_rate": 0.00011938402309913379,
      "loss": 0.7548,
      "step": 2103
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38075965642929077,
      "learning_rate": 0.00011934552454282965,
      "loss": 0.5093,
      "step": 2104
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5186618566513062,
      "learning_rate": 0.0001193070259865255,
      "loss": 0.7995,
      "step": 2105
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35744789242744446,
      "learning_rate": 0.00011926852743022136,
      "loss": 0.8253,
      "step": 2106
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.46181604266166687,
      "learning_rate": 0.00011923002887391724,
      "loss": 0.7555,
      "step": 2107
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.41561734676361084,
      "learning_rate": 0.0001191915303176131,
      "loss": 0.67,
      "step": 2108
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5243691205978394,
      "learning_rate": 0.00011915303176130896,
      "loss": 0.8616,
      "step": 2109
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3749087154865265,
      "learning_rate": 0.0001191145332050048,
      "loss": 0.7561,
      "step": 2110
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3935352563858032,
      "learning_rate": 0.00011907603464870068,
      "loss": 0.4916,
      "step": 2111
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4450353682041168,
      "learning_rate": 0.00011903753609239654,
      "loss": 0.7837,
      "step": 2112
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.404316246509552,
      "learning_rate": 0.0001189990375360924,
      "loss": 0.7107,
      "step": 2113
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.39937281608581543,
      "learning_rate": 0.00011896053897978828,
      "loss": 0.628,
      "step": 2114
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.33659496903419495,
      "learning_rate": 0.00011892204042348411,
      "loss": 0.7332,
      "step": 2115
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4303329586982727,
      "learning_rate": 0.00011888354186717998,
      "loss": 0.7383,
      "step": 2116
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4730582535266876,
      "learning_rate": 0.00011884504331087585,
      "loss": 0.8185,
      "step": 2117
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.391056627035141,
      "learning_rate": 0.00011880654475457171,
      "loss": 0.788,
      "step": 2118
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4046691060066223,
      "learning_rate": 0.00011876804619826758,
      "loss": 0.6094,
      "step": 2119
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.36625105142593384,
      "learning_rate": 0.00011872954764196343,
      "loss": 0.7257,
      "step": 2120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.34632712602615356,
      "learning_rate": 0.00011869104908565929,
      "loss": 0.7336,
      "step": 2121
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4273027777671814,
      "learning_rate": 0.00011865255052935515,
      "loss": 0.7583,
      "step": 2122
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3731849491596222,
      "learning_rate": 0.00011861405197305103,
      "loss": 0.7226,
      "step": 2123
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4662467837333679,
      "learning_rate": 0.00011857555341674689,
      "loss": 0.7155,
      "step": 2124
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.38742488622665405,
      "learning_rate": 0.00011853705486044273,
      "loss": 0.725,
      "step": 2125
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4040181636810303,
      "learning_rate": 0.0001184985563041386,
      "loss": 0.7673,
      "step": 2126
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.30353009700775146,
      "learning_rate": 0.00011846005774783447,
      "loss": 0.8217,
      "step": 2127
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.36975014209747314,
      "learning_rate": 0.00011842155919153033,
      "loss": 0.7549,
      "step": 2128
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3579721450805664,
      "learning_rate": 0.00011838306063522619,
      "loss": 0.6209,
      "step": 2129
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.41974034905433655,
      "learning_rate": 0.00011834456207892204,
      "loss": 0.7765,
      "step": 2130
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3708135187625885,
      "learning_rate": 0.0001183060635226179,
      "loss": 0.6746,
      "step": 2131
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.40387025475502014,
      "learning_rate": 0.00011826756496631377,
      "loss": 0.8385,
      "step": 2132
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4114353060722351,
      "learning_rate": 0.00011822906641000964,
      "loss": 0.8504,
      "step": 2133
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.39249905943870544,
      "learning_rate": 0.0001181905678537055,
      "loss": 0.6662,
      "step": 2134
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4487074315547943,
      "learning_rate": 0.00011815206929740134,
      "loss": 0.7328,
      "step": 2135
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4329341948032379,
      "learning_rate": 0.00011811357074109722,
      "loss": 0.6605,
      "step": 2136
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.35302406549453735,
      "learning_rate": 0.00011807507218479308,
      "loss": 0.8785,
      "step": 2137
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.41990190744400024,
      "learning_rate": 0.00011803657362848894,
      "loss": 0.6838,
      "step": 2138
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3867860734462738,
      "learning_rate": 0.00011799807507218479,
      "loss": 0.64,
      "step": 2139
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.36581718921661377,
      "learning_rate": 0.00011795957651588065,
      "loss": 0.8618,
      "step": 2140
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.38583192229270935,
      "learning_rate": 0.00011792107795957652,
      "loss": 0.8423,
      "step": 2141
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4324902892112732,
      "learning_rate": 0.00011788257940327238,
      "loss": 0.9207,
      "step": 2142
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.37691575288772583,
      "learning_rate": 0.00011784408084696826,
      "loss": 0.781,
      "step": 2143
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.35415902733802795,
      "learning_rate": 0.00011780558229066409,
      "loss": 0.89,
      "step": 2144
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3834824562072754,
      "learning_rate": 0.00011776708373435997,
      "loss": 0.62,
      "step": 2145
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.35229063034057617,
      "learning_rate": 0.00011772858517805583,
      "loss": 0.8919,
      "step": 2146
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3849932849407196,
      "learning_rate": 0.00011769008662175169,
      "loss": 0.8604,
      "step": 2147
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4088347852230072,
      "learning_rate": 0.00011765158806544756,
      "loss": 0.5953,
      "step": 2148
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3911071717739105,
      "learning_rate": 0.0001176130895091434,
      "loss": 0.7384,
      "step": 2149
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3532554805278778,
      "learning_rate": 0.00011757459095283927,
      "loss": 0.9581,
      "step": 2150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.37079471349716187,
      "learning_rate": 0.00011753609239653513,
      "loss": 0.6157,
      "step": 2151
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3765881359577179,
      "learning_rate": 0.00011749759384023101,
      "loss": 0.7524,
      "step": 2152
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.37913039326667786,
      "learning_rate": 0.00011745909528392687,
      "loss": 0.59,
      "step": 2153
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.45149025321006775,
      "learning_rate": 0.00011742059672762272,
      "loss": 0.9526,
      "step": 2154
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.45502373576164246,
      "learning_rate": 0.00011738209817131858,
      "loss": 0.7003,
      "step": 2155
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.43611082434654236,
      "learning_rate": 0.00011734359961501444,
      "loss": 0.8076,
      "step": 2156
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3466450870037079,
      "learning_rate": 0.00011730510105871031,
      "loss": 0.7995,
      "step": 2157
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.43203219771385193,
      "learning_rate": 0.00011726660250240617,
      "loss": 0.6678,
      "step": 2158
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4337347447872162,
      "learning_rate": 0.00011722810394610202,
      "loss": 0.7053,
      "step": 2159
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3633384108543396,
      "learning_rate": 0.00011718960538979788,
      "loss": 0.8275,
      "step": 2160
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3544694185256958,
      "learning_rate": 0.00011715110683349376,
      "loss": 0.7186,
      "step": 2161
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.34964147210121155,
      "learning_rate": 0.00011711260827718962,
      "loss": 0.7391,
      "step": 2162
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3838012218475342,
      "learning_rate": 0.00011707410972088548,
      "loss": 0.8694,
      "step": 2163
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.37226739525794983,
      "learning_rate": 0.00011703561116458133,
      "loss": 0.706,
      "step": 2164
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.36740508675575256,
      "learning_rate": 0.00011699711260827719,
      "loss": 0.8952,
      "step": 2165
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.45933470129966736,
      "learning_rate": 0.00011695861405197306,
      "loss": 0.7205,
      "step": 2166
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.34722211956977844,
      "learning_rate": 0.00011692011549566892,
      "loss": 0.5792,
      "step": 2167
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39424246549606323,
      "learning_rate": 0.00011688161693936477,
      "loss": 0.7433,
      "step": 2168
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3727954626083374,
      "learning_rate": 0.00011684311838306063,
      "loss": 0.7183,
      "step": 2169
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.43588918447494507,
      "learning_rate": 0.0001168046198267565,
      "loss": 0.7547,
      "step": 2170
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3994671106338501,
      "learning_rate": 0.00011676612127045237,
      "loss": 0.8475,
      "step": 2171
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4374796748161316,
      "learning_rate": 0.00011672762271414823,
      "loss": 0.6487,
      "step": 2172
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3510798215866089,
      "learning_rate": 0.00011668912415784407,
      "loss": 0.8229,
      "step": 2173
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.31816792488098145,
      "learning_rate": 0.00011665062560153995,
      "loss": 0.5512,
      "step": 2174
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39799198508262634,
      "learning_rate": 0.00011661212704523581,
      "loss": 0.7265,
      "step": 2175
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3674633204936981,
      "learning_rate": 0.00011657362848893167,
      "loss": 0.8548,
      "step": 2176
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.41232773661613464,
      "learning_rate": 0.00011653512993262755,
      "loss": 0.7883,
      "step": 2177
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.31514766812324524,
      "learning_rate": 0.00011649663137632338,
      "loss": 0.735,
      "step": 2178
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3474244475364685,
      "learning_rate": 0.00011645813282001925,
      "loss": 0.7009,
      "step": 2179
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5831050276756287,
      "learning_rate": 0.00011641963426371511,
      "loss": 0.8299,
      "step": 2180
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.34989917278289795,
      "learning_rate": 0.00011638113570741098,
      "loss": 0.8585,
      "step": 2181
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39064136147499084,
      "learning_rate": 0.00011634263715110685,
      "loss": 0.6846,
      "step": 2182
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3657332956790924,
      "learning_rate": 0.0001163041385948027,
      "loss": 0.6809,
      "step": 2183
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4927739202976227,
      "learning_rate": 0.00011626564003849856,
      "loss": 0.9036,
      "step": 2184
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3519545793533325,
      "learning_rate": 0.00011622714148219442,
      "loss": 0.9329,
      "step": 2185
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3810443580150604,
      "learning_rate": 0.0001161886429258903,
      "loss": 0.814,
      "step": 2186
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.38749560713768005,
      "learning_rate": 0.00011615014436958616,
      "loss": 0.737,
      "step": 2187
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.38307780027389526,
      "learning_rate": 0.000116111645813282,
      "loss": 0.7107,
      "step": 2188
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.45294371247291565,
      "learning_rate": 0.00011607314725697786,
      "loss": 0.7368,
      "step": 2189
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3494775593280792,
      "learning_rate": 0.00011603464870067374,
      "loss": 0.8482,
      "step": 2190
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3788994252681732,
      "learning_rate": 0.0001159961501443696,
      "loss": 0.6443,
      "step": 2191
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.35197412967681885,
      "learning_rate": 0.00011595765158806546,
      "loss": 0.7006,
      "step": 2192
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3743210434913635,
      "learning_rate": 0.00011591915303176131,
      "loss": 0.6876,
      "step": 2193
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4382580816745758,
      "learning_rate": 0.00011588065447545717,
      "loss": 0.9875,
      "step": 2194
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.43281832337379456,
      "learning_rate": 0.00011584215591915304,
      "loss": 0.7739,
      "step": 2195
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5362384915351868,
      "learning_rate": 0.0001158036573628489,
      "loss": 0.7773,
      "step": 2196
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.33842676877975464,
      "learning_rate": 0.00011576515880654476,
      "loss": 0.6923,
      "step": 2197
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4255611002445221,
      "learning_rate": 0.00011572666025024061,
      "loss": 0.6065,
      "step": 2198
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.42196813225746155,
      "learning_rate": 0.00011568816169393649,
      "loss": 0.8991,
      "step": 2199
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6695072054862976,
      "learning_rate": 0.00011564966313763235,
      "loss": 0.7331,
      "step": 2200
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.37636908888816833,
      "learning_rate": 0.00011561116458132821,
      "loss": 0.7774,
      "step": 2201
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39924994111061096,
      "learning_rate": 0.00011557266602502406,
      "loss": 0.8166,
      "step": 2202
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4560956358909607,
      "learning_rate": 0.00011553416746871992,
      "loss": 0.7657,
      "step": 2203
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.38918790221214294,
      "learning_rate": 0.00011549566891241579,
      "loss": 0.8862,
      "step": 2204
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4045034348964691,
      "learning_rate": 0.00011545717035611165,
      "loss": 0.7936,
      "step": 2205
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3869166672229767,
      "learning_rate": 0.00011541867179980753,
      "loss": 0.7128,
      "step": 2206
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3621947467327118,
      "learning_rate": 0.00011538017324350336,
      "loss": 0.6448,
      "step": 2207
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.451094388961792,
      "learning_rate": 0.00011534167468719924,
      "loss": 0.672,
      "step": 2208
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.40903109312057495,
      "learning_rate": 0.0001153031761308951,
      "loss": 0.6931,
      "step": 2209
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4317462146282196,
      "learning_rate": 0.00011526467757459096,
      "loss": 0.6477,
      "step": 2210
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.45974451303482056,
      "learning_rate": 0.00011522617901828683,
      "loss": 0.7118,
      "step": 2211
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3950754702091217,
      "learning_rate": 0.00011518768046198267,
      "loss": 0.8234,
      "step": 2212
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.43915367126464844,
      "learning_rate": 0.00011514918190567854,
      "loss": 0.8549,
      "step": 2213
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3887704610824585,
      "learning_rate": 0.0001151106833493744,
      "loss": 0.9144,
      "step": 2214
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3834078013896942,
      "learning_rate": 0.00011507218479307028,
      "loss": 0.7304,
      "step": 2215
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.34007346630096436,
      "learning_rate": 0.00011503368623676614,
      "loss": 0.8786,
      "step": 2216
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.34697577357292175,
      "learning_rate": 0.00011499518768046198,
      "loss": 0.818,
      "step": 2217
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3561306893825531,
      "learning_rate": 0.00011495668912415785,
      "loss": 0.6732,
      "step": 2218
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4111763536930084,
      "learning_rate": 0.0001149181905678537,
      "loss": 0.6244,
      "step": 2219
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4119049906730652,
      "learning_rate": 0.00011487969201154958,
      "loss": 0.6451,
      "step": 2220
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5962485074996948,
      "learning_rate": 0.00011484119345524544,
      "loss": 0.6272,
      "step": 2221
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3762066066265106,
      "learning_rate": 0.00011480269489894129,
      "loss": 0.6962,
      "step": 2222
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.40572991967201233,
      "learning_rate": 0.00011476419634263715,
      "loss": 0.6708,
      "step": 2223
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4560997784137726,
      "learning_rate": 0.00011472569778633302,
      "loss": 0.6799,
      "step": 2224
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37530553340911865,
      "learning_rate": 0.00011468719923002889,
      "loss": 0.7117,
      "step": 2225
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5370792746543884,
      "learning_rate": 0.00011464870067372475,
      "loss": 0.8868,
      "step": 2226
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.39349594712257385,
      "learning_rate": 0.0001146102021174206,
      "loss": 0.65,
      "step": 2227
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.47389501333236694,
      "learning_rate": 0.00011457170356111646,
      "loss": 0.7197,
      "step": 2228
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.41830310225486755,
      "learning_rate": 0.00011453320500481233,
      "loss": 0.6879,
      "step": 2229
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4125405550003052,
      "learning_rate": 0.00011449470644850819,
      "loss": 0.5865,
      "step": 2230
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4581775367259979,
      "learning_rate": 0.00011445620789220404,
      "loss": 0.8667,
      "step": 2231
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3450378179550171,
      "learning_rate": 0.0001144177093358999,
      "loss": 0.714,
      "step": 2232
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.36255624890327454,
      "learning_rate": 0.00011437921077959577,
      "loss": 0.7251,
      "step": 2233
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.451427161693573,
      "learning_rate": 0.00011434071222329163,
      "loss": 0.7691,
      "step": 2234
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3887130618095398,
      "learning_rate": 0.0001143022136669875,
      "loss": 0.7635,
      "step": 2235
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4292912781238556,
      "learning_rate": 0.00011426371511068334,
      "loss": 0.7085,
      "step": 2236
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3934601843357086,
      "learning_rate": 0.00011422521655437922,
      "loss": 0.7259,
      "step": 2237
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4225533902645111,
      "learning_rate": 0.00011418671799807508,
      "loss": 0.731,
      "step": 2238
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37969255447387695,
      "learning_rate": 0.00011414821944177094,
      "loss": 0.7642,
      "step": 2239
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3569066524505615,
      "learning_rate": 0.00011410972088546681,
      "loss": 0.6758,
      "step": 2240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3293171525001526,
      "learning_rate": 0.00011407122232916265,
      "loss": 0.6727,
      "step": 2241
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3563540279865265,
      "learning_rate": 0.00011403272377285852,
      "loss": 0.8185,
      "step": 2242
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.38513055443763733,
      "learning_rate": 0.00011399422521655438,
      "loss": 0.7503,
      "step": 2243
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.39274439215660095,
      "learning_rate": 0.00011395572666025024,
      "loss": 0.5435,
      "step": 2244
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4159555435180664,
      "learning_rate": 0.00011391722810394612,
      "loss": 0.9383,
      "step": 2245
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4847348928451538,
      "learning_rate": 0.00011387872954764197,
      "loss": 0.7943,
      "step": 2246
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4440983831882477,
      "learning_rate": 0.00011384023099133783,
      "loss": 0.9087,
      "step": 2247
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.40952223539352417,
      "learning_rate": 0.00011380173243503369,
      "loss": 0.6278,
      "step": 2248
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3898506164550781,
      "learning_rate": 0.00011376323387872956,
      "loss": 0.8054,
      "step": 2249
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.43739867210388184,
      "learning_rate": 0.00011372473532242542,
      "loss": 0.7229,
      "step": 2250
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.29777491092681885,
      "learning_rate": 0.00011368623676612127,
      "loss": 0.8507,
      "step": 2251
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37370622158050537,
      "learning_rate": 0.00011364773820981713,
      "loss": 0.7598,
      "step": 2252
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37024766206741333,
      "learning_rate": 0.00011360923965351299,
      "loss": 0.6984,
      "step": 2253
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4456980228424072,
      "learning_rate": 0.00011357074109720887,
      "loss": 0.6366,
      "step": 2254
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.34074464440345764,
      "learning_rate": 0.00011353224254090473,
      "loss": 0.6394,
      "step": 2255
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3592866361141205,
      "learning_rate": 0.00011349374398460058,
      "loss": 0.6728,
      "step": 2256
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4990155100822449,
      "learning_rate": 0.00011345524542829644,
      "loss": 0.7981,
      "step": 2257
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3971361219882965,
      "learning_rate": 0.00011341674687199231,
      "loss": 0.7578,
      "step": 2258
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4726282060146332,
      "learning_rate": 0.00011337824831568817,
      "loss": 0.7665,
      "step": 2259
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3617214560508728,
      "learning_rate": 0.00011333974975938403,
      "loss": 0.8644,
      "step": 2260
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3469032347202301,
      "learning_rate": 0.00011330125120307988,
      "loss": 0.8264,
      "step": 2261
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3822077512741089,
      "learning_rate": 0.00011326275264677576,
      "loss": 0.7407,
      "step": 2262
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3991341292858124,
      "learning_rate": 0.00011322425409047162,
      "loss": 0.6754,
      "step": 2263
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43235301971435547,
      "learning_rate": 0.00011318575553416748,
      "loss": 0.5176,
      "step": 2264
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3917157053947449,
      "learning_rate": 0.00011314725697786332,
      "loss": 0.686,
      "step": 2265
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3825984299182892,
      "learning_rate": 0.00011310875842155919,
      "loss": 0.7495,
      "step": 2266
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.380463182926178,
      "learning_rate": 0.00011307025986525506,
      "loss": 0.7106,
      "step": 2267
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.42118051648139954,
      "learning_rate": 0.00011303176130895092,
      "loss": 0.6746,
      "step": 2268
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43703749775886536,
      "learning_rate": 0.00011299326275264678,
      "loss": 0.9715,
      "step": 2269
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4579017758369446,
      "learning_rate": 0.00011295476419634263,
      "loss": 0.7184,
      "step": 2270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.40276655554771423,
      "learning_rate": 0.0001129162656400385,
      "loss": 0.9976,
      "step": 2271
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4463086426258087,
      "learning_rate": 0.00011287776708373437,
      "loss": 0.7995,
      "step": 2272
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4307232201099396,
      "learning_rate": 0.00011283926852743023,
      "loss": 0.7266,
      "step": 2273
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3784542381763458,
      "learning_rate": 0.0001128007699711261,
      "loss": 0.8141,
      "step": 2274
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3715219795703888,
      "learning_rate": 0.00011276227141482193,
      "loss": 0.6447,
      "step": 2275
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33160173892974854,
      "learning_rate": 0.00011272377285851781,
      "loss": 0.6825,
      "step": 2276
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43266379833221436,
      "learning_rate": 0.00011268527430221367,
      "loss": 0.7538,
      "step": 2277
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4119640588760376,
      "learning_rate": 0.00011264677574590954,
      "loss": 0.9136,
      "step": 2278
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4355044364929199,
      "learning_rate": 0.0001126082771896054,
      "loss": 0.7242,
      "step": 2279
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4403360188007355,
      "learning_rate": 0.00011256977863330125,
      "loss": 0.8253,
      "step": 2280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.38947322964668274,
      "learning_rate": 0.00011253128007699711,
      "loss": 0.7287,
      "step": 2281
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.458931028842926,
      "learning_rate": 0.00011249278152069298,
      "loss": 0.9275,
      "step": 2282
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.36456066370010376,
      "learning_rate": 0.00011245428296438885,
      "loss": 0.9106,
      "step": 2283
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5292866230010986,
      "learning_rate": 0.00011241578440808471,
      "loss": 0.7169,
      "step": 2284
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.34969237446784973,
      "learning_rate": 0.00011237728585178056,
      "loss": 0.8353,
      "step": 2285
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33650732040405273,
      "learning_rate": 0.00011233878729547642,
      "loss": 0.7964,
      "step": 2286
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.38508012890815735,
      "learning_rate": 0.0001123002887391723,
      "loss": 0.5989,
      "step": 2287
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.39526471495628357,
      "learning_rate": 0.00011226179018286815,
      "loss": 0.6714,
      "step": 2288
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.350534051656723,
      "learning_rate": 0.00011222329162656402,
      "loss": 0.7765,
      "step": 2289
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4445461630821228,
      "learning_rate": 0.00011218479307025986,
      "loss": 0.8326,
      "step": 2290
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4376275837421417,
      "learning_rate": 0.00011214629451395572,
      "loss": 0.7497,
      "step": 2291
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4612148106098175,
      "learning_rate": 0.0001121077959576516,
      "loss": 0.677,
      "step": 2292
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4444798529148102,
      "learning_rate": 0.00011206929740134746,
      "loss": 0.843,
      "step": 2293
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3846166133880615,
      "learning_rate": 0.00011203079884504331,
      "loss": 0.8211,
      "step": 2294
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.426296591758728,
      "learning_rate": 0.00011199230028873917,
      "loss": 0.8342,
      "step": 2295
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3999997675418854,
      "learning_rate": 0.00011195380173243504,
      "loss": 0.7201,
      "step": 2296
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.35047706961631775,
      "learning_rate": 0.0001119153031761309,
      "loss": 0.7547,
      "step": 2297
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33704060316085815,
      "learning_rate": 0.00011187680461982676,
      "loss": 0.6568,
      "step": 2298
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3626995384693146,
      "learning_rate": 0.00011183830606352261,
      "loss": 0.8075,
      "step": 2299
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3678150475025177,
      "learning_rate": 0.00011179980750721847,
      "loss": 0.535,
      "step": 2300
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.44119253754615784,
      "learning_rate": 0.00011176130895091435,
      "loss": 0.6779,
      "step": 2301
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.40295276045799255,
      "learning_rate": 0.00011172281039461021,
      "loss": 0.629,
      "step": 2302
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3215882182121277,
      "learning_rate": 0.00011168431183830608,
      "loss": 0.9204,
      "step": 2303
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.34080109000205994,
      "learning_rate": 0.00011164581328200192,
      "loss": 0.6843,
      "step": 2304
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.38247257471084595,
      "learning_rate": 0.00011160731472569779,
      "loss": 0.7238,
      "step": 2305
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.41464027762413025,
      "learning_rate": 0.00011156881616939365,
      "loss": 0.7843,
      "step": 2306
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3956071734428406,
      "learning_rate": 0.00011153031761308951,
      "loss": 0.7814,
      "step": 2307
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.44631510972976685,
      "learning_rate": 0.00011149181905678539,
      "loss": 0.8242,
      "step": 2308
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3873317241668701,
      "learning_rate": 0.00011145332050048124,
      "loss": 0.713,
      "step": 2309
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3849426209926605,
      "learning_rate": 0.0001114148219441771,
      "loss": 0.5627,
      "step": 2310
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.46417564153671265,
      "learning_rate": 0.00011137632338787296,
      "loss": 0.7249,
      "step": 2311
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4046604037284851,
      "learning_rate": 0.00011133782483156883,
      "loss": 0.849,
      "step": 2312
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.39463022351264954,
      "learning_rate": 0.00011129932627526469,
      "loss": 0.8241,
      "step": 2313
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3883354365825653,
      "learning_rate": 0.00011126082771896054,
      "loss": 0.8225,
      "step": 2314
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.46334436535835266,
      "learning_rate": 0.0001112223291626564,
      "loss": 0.7582,
      "step": 2315
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39377129077911377,
      "learning_rate": 0.00011118383060635226,
      "loss": 0.7537,
      "step": 2316
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.33363932371139526,
      "learning_rate": 0.00011114533205004814,
      "loss": 0.7518,
      "step": 2317
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.38473016023635864,
      "learning_rate": 0.000111106833493744,
      "loss": 0.7644,
      "step": 2318
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.34498131275177,
      "learning_rate": 0.00011106833493743984,
      "loss": 0.7808,
      "step": 2319
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.44471287727355957,
      "learning_rate": 0.0001110298363811357,
      "loss": 0.8422,
      "step": 2320
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4140911102294922,
      "learning_rate": 0.00011099133782483158,
      "loss": 0.6267,
      "step": 2321
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3590106964111328,
      "learning_rate": 0.00011095283926852744,
      "loss": 0.763,
      "step": 2322
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.43496426939964294,
      "learning_rate": 0.0001109143407122233,
      "loss": 0.7054,
      "step": 2323
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5209596157073975,
      "learning_rate": 0.00011087584215591915,
      "loss": 0.6405,
      "step": 2324
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4252814054489136,
      "learning_rate": 0.00011083734359961502,
      "loss": 0.6794,
      "step": 2325
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4579400420188904,
      "learning_rate": 0.00011079884504331089,
      "loss": 0.7631,
      "step": 2326
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3879834711551666,
      "learning_rate": 0.00011076034648700675,
      "loss": 0.7644,
      "step": 2327
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.47464868426322937,
      "learning_rate": 0.0001107218479307026,
      "loss": 0.7741,
      "step": 2328
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4251587986946106,
      "learning_rate": 0.00011068334937439845,
      "loss": 0.6253,
      "step": 2329
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3873426616191864,
      "learning_rate": 0.00011064485081809433,
      "loss": 0.7812,
      "step": 2330
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37440595030784607,
      "learning_rate": 0.00011060635226179019,
      "loss": 0.7137,
      "step": 2331
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3972944915294647,
      "learning_rate": 0.00011056785370548605,
      "loss": 0.5877,
      "step": 2332
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40689557790756226,
      "learning_rate": 0.0001105293551491819,
      "loss": 0.7028,
      "step": 2333
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3650725781917572,
      "learning_rate": 0.00011049085659287777,
      "loss": 0.7862,
      "step": 2334
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41022011637687683,
      "learning_rate": 0.00011045235803657363,
      "loss": 0.7118,
      "step": 2335
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39737942814826965,
      "learning_rate": 0.0001104138594802695,
      "loss": 0.6757,
      "step": 2336
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36400172114372253,
      "learning_rate": 0.00011037536092396537,
      "loss": 0.7087,
      "step": 2337
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3891964256763458,
      "learning_rate": 0.0001103368623676612,
      "loss": 0.6328,
      "step": 2338
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4111221432685852,
      "learning_rate": 0.00011029836381135708,
      "loss": 0.6792,
      "step": 2339
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40574342012405396,
      "learning_rate": 0.00011025986525505294,
      "loss": 0.74,
      "step": 2340
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.35706257820129395,
      "learning_rate": 0.00011022136669874881,
      "loss": 0.7392,
      "step": 2341
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4300258457660675,
      "learning_rate": 0.00011018286814244467,
      "loss": 0.7228,
      "step": 2342
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.33952802419662476,
      "learning_rate": 0.00011014436958614052,
      "loss": 0.7598,
      "step": 2343
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4344272017478943,
      "learning_rate": 0.00011010587102983638,
      "loss": 0.6776,
      "step": 2344
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4763488173484802,
      "learning_rate": 0.00011006737247353224,
      "loss": 0.6444,
      "step": 2345
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37266600131988525,
      "learning_rate": 0.00011002887391722812,
      "loss": 0.6925,
      "step": 2346
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4069986343383789,
      "learning_rate": 0.00010999037536092398,
      "loss": 0.7609,
      "step": 2347
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.38464513421058655,
      "learning_rate": 0.00010995187680461983,
      "loss": 0.722,
      "step": 2348
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3833748400211334,
      "learning_rate": 0.00010991337824831569,
      "loss": 0.8871,
      "step": 2349
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4405025541782379,
      "learning_rate": 0.00010987487969201156,
      "loss": 0.6784,
      "step": 2350
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.33842357993125916,
      "learning_rate": 0.00010983638113570742,
      "loss": 0.7432,
      "step": 2351
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41140973567962646,
      "learning_rate": 0.00010979788257940328,
      "loss": 0.812,
      "step": 2352
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39032095670700073,
      "learning_rate": 0.00010975938402309913,
      "loss": 0.6616,
      "step": 2353
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40140148997306824,
      "learning_rate": 0.00010972088546679499,
      "loss": 0.7673,
      "step": 2354
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39274275302886963,
      "learning_rate": 0.00010968238691049087,
      "loss": 0.5909,
      "step": 2355
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37527140974998474,
      "learning_rate": 0.00010964388835418673,
      "loss": 0.7377,
      "step": 2356
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41771450638771057,
      "learning_rate": 0.00010960538979788258,
      "loss": 0.6753,
      "step": 2357
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.34901154041290283,
      "learning_rate": 0.00010956689124157844,
      "loss": 0.7058,
      "step": 2358
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3821899890899658,
      "learning_rate": 0.00010952839268527431,
      "loss": 0.9096,
      "step": 2359
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4075283408164978,
      "learning_rate": 0.00010948989412897017,
      "loss": 0.721,
      "step": 2360
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3885054886341095,
      "learning_rate": 0.00010945139557266603,
      "loss": 0.9134,
      "step": 2361
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36912694573402405,
      "learning_rate": 0.00010941289701636188,
      "loss": 0.8379,
      "step": 2362
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4590597152709961,
      "learning_rate": 0.00010937439846005774,
      "loss": 0.7429,
      "step": 2363
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3710440397262573,
      "learning_rate": 0.00010933589990375362,
      "loss": 0.5216,
      "step": 2364
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39545395970344543,
      "learning_rate": 0.00010929740134744948,
      "loss": 0.7839,
      "step": 2365
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3728938698768616,
      "learning_rate": 0.00010925890279114535,
      "loss": 0.7069,
      "step": 2366
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4875277578830719,
      "learning_rate": 0.00010922040423484119,
      "loss": 0.638,
      "step": 2367
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.472263365983963,
      "learning_rate": 0.00010918190567853706,
      "loss": 0.7518,
      "step": 2368
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39096471667289734,
      "learning_rate": 0.00010914340712223292,
      "loss": 0.6152,
      "step": 2369
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4162939190864563,
      "learning_rate": 0.00010910490856592878,
      "loss": 0.7758,
      "step": 2370
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7216567397117615,
      "learning_rate": 0.00010906641000962466,
      "loss": 0.7506,
      "step": 2371
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3610159754753113,
      "learning_rate": 0.0001090279114533205,
      "loss": 0.7787,
      "step": 2372
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.44025230407714844,
      "learning_rate": 0.00010898941289701636,
      "loss": 0.6573,
      "step": 2373
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.48516783118247986,
      "learning_rate": 0.00010895091434071223,
      "loss": 0.8196,
      "step": 2374
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.391536682844162,
      "learning_rate": 0.0001089124157844081,
      "loss": 0.7971,
      "step": 2375
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.44229811429977417,
      "learning_rate": 0.00010887391722810396,
      "loss": 0.704,
      "step": 2376
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.42935293912887573,
      "learning_rate": 0.00010883541867179981,
      "loss": 0.6974,
      "step": 2377
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4733726382255554,
      "learning_rate": 0.00010879692011549567,
      "loss": 0.7412,
      "step": 2378
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41009944677352905,
      "learning_rate": 0.00010875842155919153,
      "loss": 0.7394,
      "step": 2379
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5144756436347961,
      "learning_rate": 0.0001087199230028874,
      "loss": 0.9251,
      "step": 2380
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3374182879924774,
      "learning_rate": 0.00010868142444658327,
      "loss": 0.711,
      "step": 2381
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.40043482184410095,
      "learning_rate": 0.00010864292589027911,
      "loss": 0.7363,
      "step": 2382
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.392500102519989,
      "learning_rate": 0.00010860442733397497,
      "loss": 0.8894,
      "step": 2383
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39522337913513184,
      "learning_rate": 0.00010856592877767085,
      "loss": 0.5762,
      "step": 2384
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4278419017791748,
      "learning_rate": 0.00010852743022136671,
      "loss": 0.6512,
      "step": 2385
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5222858786582947,
      "learning_rate": 0.00010848893166506257,
      "loss": 0.7143,
      "step": 2386
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5088847875595093,
      "learning_rate": 0.00010845043310875842,
      "loss": 0.8155,
      "step": 2387
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3474803566932678,
      "learning_rate": 0.00010841193455245429,
      "loss": 0.7527,
      "step": 2388
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.33903735876083374,
      "learning_rate": 0.00010837343599615015,
      "loss": 0.6075,
      "step": 2389
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4357243776321411,
      "learning_rate": 0.00010833493743984601,
      "loss": 0.8038,
      "step": 2390
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4495459198951721,
      "learning_rate": 0.00010829643888354186,
      "loss": 0.6594,
      "step": 2391
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41215696930885315,
      "learning_rate": 0.00010825794032723772,
      "loss": 0.5705,
      "step": 2392
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.43066734075546265,
      "learning_rate": 0.0001082194417709336,
      "loss": 0.7671,
      "step": 2393
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39642664790153503,
      "learning_rate": 0.00010818094321462946,
      "loss": 0.6507,
      "step": 2394
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.43875041604042053,
      "learning_rate": 0.00010814244465832532,
      "loss": 0.8804,
      "step": 2395
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5127138495445251,
      "learning_rate": 0.00010810394610202117,
      "loss": 0.7297,
      "step": 2396
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4480130076408386,
      "learning_rate": 0.00010806544754571704,
      "loss": 0.8083,
      "step": 2397
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4779157042503357,
      "learning_rate": 0.0001080269489894129,
      "loss": 0.7412,
      "step": 2398
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3975629508495331,
      "learning_rate": 0.00010798845043310876,
      "loss": 0.7201,
      "step": 2399
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.48626387119293213,
      "learning_rate": 0.00010794995187680464,
      "loss": 0.6488,
      "step": 2400
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3893550932407379,
      "learning_rate": 0.00010791145332050047,
      "loss": 0.7231,
      "step": 2401
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39619746804237366,
      "learning_rate": 0.00010787295476419635,
      "loss": 0.9375,
      "step": 2402
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.42466121912002563,
      "learning_rate": 0.00010783445620789221,
      "loss": 0.7703,
      "step": 2403
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4260205924510956,
      "learning_rate": 0.00010779595765158807,
      "loss": 0.7913,
      "step": 2404
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41400957107543945,
      "learning_rate": 0.00010775745909528394,
      "loss": 0.6578,
      "step": 2405
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4373241364955902,
      "learning_rate": 0.00010771896053897979,
      "loss": 0.6646,
      "step": 2406
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4760693609714508,
      "learning_rate": 0.00010768046198267565,
      "loss": 0.7379,
      "step": 2407
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.373685747385025,
      "learning_rate": 0.00010764196342637151,
      "loss": 0.6755,
      "step": 2408
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4167444407939911,
      "learning_rate": 0.00010760346487006739,
      "loss": 0.8616,
      "step": 2409
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.33050963282585144,
      "learning_rate": 0.00010756496631376325,
      "loss": 0.7417,
      "step": 2410
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.37958580255508423,
      "learning_rate": 0.0001075264677574591,
      "loss": 0.6462,
      "step": 2411
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3599099814891815,
      "learning_rate": 0.00010748796920115496,
      "loss": 0.7637,
      "step": 2412
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4238422214984894,
      "learning_rate": 0.00010744947064485083,
      "loss": 0.7517,
      "step": 2413
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4933719336986542,
      "learning_rate": 0.00010741097208854669,
      "loss": 0.6979,
      "step": 2414
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.45664355158805847,
      "learning_rate": 0.00010737247353224255,
      "loss": 0.7987,
      "step": 2415
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4060629904270172,
      "learning_rate": 0.0001073339749759384,
      "loss": 0.6155,
      "step": 2416
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4933921992778778,
      "learning_rate": 0.00010729547641963426,
      "loss": 0.8787,
      "step": 2417
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41116487979888916,
      "learning_rate": 0.00010725697786333014,
      "loss": 0.849,
      "step": 2418
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3629951477050781,
      "learning_rate": 0.000107218479307026,
      "loss": 0.8611,
      "step": 2419
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4830476939678192,
      "learning_rate": 0.00010717998075072184,
      "loss": 0.6486,
      "step": 2420
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.41938549280166626,
      "learning_rate": 0.0001071414821944177,
      "loss": 0.6418,
      "step": 2421
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.42721328139305115,
      "learning_rate": 0.00010710298363811358,
      "loss": 0.7287,
      "step": 2422
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4458140730857849,
      "learning_rate": 0.00010706448508180944,
      "loss": 0.89,
      "step": 2423
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.49471187591552734,
      "learning_rate": 0.0001070259865255053,
      "loss": 0.7521,
      "step": 2424
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4991021454334259,
      "learning_rate": 0.00010698748796920115,
      "loss": 1.1311,
      "step": 2425
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3906738758087158,
      "learning_rate": 0.00010694898941289701,
      "loss": 0.7831,
      "step": 2426
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3895919620990753,
      "learning_rate": 0.00010691049085659288,
      "loss": 0.7001,
      "step": 2427
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.49465692043304443,
      "learning_rate": 0.00010687199230028875,
      "loss": 0.8675,
      "step": 2428
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37799057364463806,
      "learning_rate": 0.00010683349374398462,
      "loss": 0.776,
      "step": 2429
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39210665225982666,
      "learning_rate": 0.00010679499518768045,
      "loss": 0.8061,
      "step": 2430
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4115479588508606,
      "learning_rate": 0.00010675649663137633,
      "loss": 0.6569,
      "step": 2431
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4144365191459656,
      "learning_rate": 0.00010671799807507219,
      "loss": 0.7965,
      "step": 2432
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.44552552700042725,
      "learning_rate": 0.00010667949951876805,
      "loss": 0.6653,
      "step": 2433
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.46572089195251465,
      "learning_rate": 0.00010664100096246393,
      "loss": 0.751,
      "step": 2434
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3344278335571289,
      "learning_rate": 0.00010660250240615976,
      "loss": 0.7992,
      "step": 2435
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3466501832008362,
      "learning_rate": 0.00010656400384985563,
      "loss": 0.7365,
      "step": 2436
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.448806494474411,
      "learning_rate": 0.0001065255052935515,
      "loss": 0.7602,
      "step": 2437
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.41926589608192444,
      "learning_rate": 0.00010648700673724737,
      "loss": 0.6445,
      "step": 2438
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.47828710079193115,
      "learning_rate": 0.00010644850818094323,
      "loss": 0.7023,
      "step": 2439
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4155615270137787,
      "learning_rate": 0.00010641000962463908,
      "loss": 0.6808,
      "step": 2440
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37202009558677673,
      "learning_rate": 0.00010637151106833494,
      "loss": 0.6744,
      "step": 2441
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39455941319465637,
      "learning_rate": 0.0001063330125120308,
      "loss": 0.8144,
      "step": 2442
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.28369224071502686,
      "learning_rate": 0.00010629451395572667,
      "loss": 0.6837,
      "step": 2443
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3785744607448578,
      "learning_rate": 0.00010625601539942253,
      "loss": 0.741,
      "step": 2444
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3449590504169464,
      "learning_rate": 0.00010621751684311838,
      "loss": 0.7957,
      "step": 2445
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39042341709136963,
      "learning_rate": 0.00010617901828681424,
      "loss": 0.7669,
      "step": 2446
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37575051188468933,
      "learning_rate": 0.00010614051973051012,
      "loss": 0.6304,
      "step": 2447
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4370383024215698,
      "learning_rate": 0.00010610202117420598,
      "loss": 0.6967,
      "step": 2448
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.41294026374816895,
      "learning_rate": 0.00010606352261790184,
      "loss": 0.666,
      "step": 2449
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.44650569558143616,
      "learning_rate": 0.00010602502406159769,
      "loss": 0.695,
      "step": 2450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4378415644168854,
      "learning_rate": 0.00010598652550529355,
      "loss": 0.7769,
      "step": 2451
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4206666350364685,
      "learning_rate": 0.00010594802694898942,
      "loss": 0.8208,
      "step": 2452
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3981338143348694,
      "learning_rate": 0.00010590952839268528,
      "loss": 0.9173,
      "step": 2453
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3832845389842987,
      "learning_rate": 0.00010587102983638113,
      "loss": 0.7482,
      "step": 2454
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4273471534252167,
      "learning_rate": 0.00010583253128007699,
      "loss": 0.8739,
      "step": 2455
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.35656657814979553,
      "learning_rate": 0.00010579403272377287,
      "loss": 0.7599,
      "step": 2456
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3701593279838562,
      "learning_rate": 0.00010575553416746873,
      "loss": 0.67,
      "step": 2457
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.36156415939331055,
      "learning_rate": 0.00010571703561116459,
      "loss": 0.8042,
      "step": 2458
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7337693572044373,
      "learning_rate": 0.00010567853705486044,
      "loss": 0.7177,
      "step": 2459
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39362555742263794,
      "learning_rate": 0.00010564003849855631,
      "loss": 0.6684,
      "step": 2460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39397212862968445,
      "learning_rate": 0.00010560153994225217,
      "loss": 0.7021,
      "step": 2461
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.38539284467697144,
      "learning_rate": 0.00010556304138594803,
      "loss": 0.6501,
      "step": 2462
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.36503028869628906,
      "learning_rate": 0.00010552454282964391,
      "loss": 0.7818,
      "step": 2463
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39424991607666016,
      "learning_rate": 0.00010548604427333974,
      "loss": 0.6401,
      "step": 2464
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.40232083201408386,
      "learning_rate": 0.00010544754571703562,
      "loss": 0.7927,
      "step": 2465
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37082961201667786,
      "learning_rate": 0.00010540904716073148,
      "loss": 0.6639,
      "step": 2466
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37345248460769653,
      "learning_rate": 0.00010537054860442734,
      "loss": 0.7498,
      "step": 2467
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.38427990674972534,
      "learning_rate": 0.00010533205004812321,
      "loss": 0.8139,
      "step": 2468
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4326833486557007,
      "learning_rate": 0.00010529355149181906,
      "loss": 0.6919,
      "step": 2469
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4030657410621643,
      "learning_rate": 0.00010525505293551492,
      "loss": 0.6273,
      "step": 2470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44224339723587036,
      "learning_rate": 0.00010521655437921078,
      "loss": 0.9079,
      "step": 2471
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.36092349886894226,
      "learning_rate": 0.00010517805582290666,
      "loss": 0.8248,
      "step": 2472
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44922709465026855,
      "learning_rate": 0.00010513955726660252,
      "loss": 0.6616,
      "step": 2473
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3882730007171631,
      "learning_rate": 0.00010510105871029836,
      "loss": 0.7248,
      "step": 2474
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4320143163204193,
      "learning_rate": 0.00010506256015399423,
      "loss": 0.864,
      "step": 2475
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.427635133266449,
      "learning_rate": 0.0001050240615976901,
      "loss": 0.7518,
      "step": 2476
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3647995591163635,
      "learning_rate": 0.00010498556304138596,
      "loss": 0.802,
      "step": 2477
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3850099444389343,
      "learning_rate": 0.00010494706448508182,
      "loss": 0.789,
      "step": 2478
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5306535363197327,
      "learning_rate": 0.00010490856592877767,
      "loss": 0.7186,
      "step": 2479
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4845297038555145,
      "learning_rate": 0.00010487006737247353,
      "loss": 0.8156,
      "step": 2480
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4271756410598755,
      "learning_rate": 0.0001048315688161694,
      "loss": 0.842,
      "step": 2481
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44169744849205017,
      "learning_rate": 0.00010479307025986527,
      "loss": 0.6954,
      "step": 2482
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3591703772544861,
      "learning_rate": 0.00010475457170356111,
      "loss": 0.6429,
      "step": 2483
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.32014140486717224,
      "learning_rate": 0.00010471607314725697,
      "loss": 0.8984,
      "step": 2484
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3563832640647888,
      "learning_rate": 0.00010467757459095285,
      "loss": 0.6218,
      "step": 2485
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.34702759981155396,
      "learning_rate": 0.00010463907603464871,
      "loss": 0.7596,
      "step": 2486
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.475062757730484,
      "learning_rate": 0.00010460057747834457,
      "loss": 0.722,
      "step": 2487
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.37916338443756104,
      "learning_rate": 0.00010456207892204042,
      "loss": 0.6358,
      "step": 2488
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4562825560569763,
      "learning_rate": 0.00010452358036573628,
      "loss": 0.8883,
      "step": 2489
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3856847286224365,
      "learning_rate": 0.00010448508180943215,
      "loss": 0.8971,
      "step": 2490
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3566306531429291,
      "learning_rate": 0.00010444658325312801,
      "loss": 0.6958,
      "step": 2491
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.35179609060287476,
      "learning_rate": 0.00010440808469682389,
      "loss": 0.8015,
      "step": 2492
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.380289763212204,
      "learning_rate": 0.00010436958614051972,
      "loss": 0.9263,
      "step": 2493
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5747924447059631,
      "learning_rate": 0.0001043310875842156,
      "loss": 0.7888,
      "step": 2494
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4178891181945801,
      "learning_rate": 0.00010429258902791146,
      "loss": 0.6376,
      "step": 2495
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4368913471698761,
      "learning_rate": 0.00010425409047160732,
      "loss": 0.6347,
      "step": 2496
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3705434501171112,
      "learning_rate": 0.0001042155919153032,
      "loss": 0.65,
      "step": 2497
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3721732795238495,
      "learning_rate": 0.00010417709335899903,
      "loss": 0.7796,
      "step": 2498
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3988465368747711,
      "learning_rate": 0.0001041385948026949,
      "loss": 0.7929,
      "step": 2499
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3996538519859314,
      "learning_rate": 0.00010410009624639076,
      "loss": 0.7482,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.48071402311325073,
      "learning_rate": 0.00010406159769008664,
      "loss": 0.631,
      "step": 2501
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3899560272693634,
      "learning_rate": 0.0001040230991337825,
      "loss": 0.8135,
      "step": 2502
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4035302400588989,
      "learning_rate": 0.00010398460057747835,
      "loss": 0.6386,
      "step": 2503
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3273959755897522,
      "learning_rate": 0.00010394610202117421,
      "loss": 0.8014,
      "step": 2504
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3374646008014679,
      "learning_rate": 0.00010390760346487007,
      "loss": 0.7513,
      "step": 2505
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3918435871601105,
      "learning_rate": 0.00010386910490856594,
      "loss": 0.7474,
      "step": 2506
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44908449053764343,
      "learning_rate": 0.0001038306063522618,
      "loss": 0.7021,
      "step": 2507
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4093625247478485,
      "learning_rate": 0.00010379210779595765,
      "loss": 0.7108,
      "step": 2508
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5031642317771912,
      "learning_rate": 0.00010375360923965351,
      "loss": 0.824,
      "step": 2509
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.40299123525619507,
      "learning_rate": 0.00010371511068334939,
      "loss": 0.7367,
      "step": 2510
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4251953661441803,
      "learning_rate": 0.00010367661212704525,
      "loss": 0.6676,
      "step": 2511
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.41666170954704285,
      "learning_rate": 0.00010363811357074111,
      "loss": 0.6754,
      "step": 2512
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.38444188237190247,
      "learning_rate": 0.00010359961501443696,
      "loss": 0.6828,
      "step": 2513
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.39448800683021545,
      "learning_rate": 0.00010356111645813282,
      "loss": 0.9123,
      "step": 2514
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3752245306968689,
      "learning_rate": 0.00010352261790182869,
      "loss": 0.8417,
      "step": 2515
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.43051615357398987,
      "learning_rate": 0.00010348411934552455,
      "loss": 0.6572,
      "step": 2516
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.34709376096725464,
      "learning_rate": 0.0001034456207892204,
      "loss": 0.8028,
      "step": 2517
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4100029170513153,
      "learning_rate": 0.00010340712223291626,
      "loss": 0.7308,
      "step": 2518
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4835284352302551,
      "learning_rate": 0.00010336862367661214,
      "loss": 0.6951,
      "step": 2519
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.479619562625885,
      "learning_rate": 0.000103330125120308,
      "loss": 0.9418,
      "step": 2520
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3415648937225342,
      "learning_rate": 0.00010329162656400386,
      "loss": 0.8003,
      "step": 2521
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3873975872993469,
      "learning_rate": 0.0001032531280076997,
      "loss": 0.9137,
      "step": 2522
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3694837987422943,
      "learning_rate": 0.00010321462945139558,
      "loss": 0.6446,
      "step": 2523
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3692682385444641,
      "learning_rate": 0.00010317613089509144,
      "loss": 0.7546,
      "step": 2524
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3238344192504883,
      "learning_rate": 0.0001031376323387873,
      "loss": 0.8592,
      "step": 2525
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41298216581344604,
      "learning_rate": 0.00010309913378248318,
      "loss": 0.6574,
      "step": 2526
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4157401919364929,
      "learning_rate": 0.00010306063522617901,
      "loss": 0.7527,
      "step": 2527
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.35542717576026917,
      "learning_rate": 0.00010302213666987488,
      "loss": 0.7417,
      "step": 2528
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37594878673553467,
      "learning_rate": 0.00010298363811357075,
      "loss": 0.7002,
      "step": 2529
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3743545114994049,
      "learning_rate": 0.0001029451395572666,
      "loss": 0.9866,
      "step": 2530
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.385532945394516,
      "learning_rate": 0.00010290664100096248,
      "loss": 0.6411,
      "step": 2531
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.32439833879470825,
      "learning_rate": 0.00010286814244465833,
      "loss": 0.9702,
      "step": 2532
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41891902685165405,
      "learning_rate": 0.00010282964388835419,
      "loss": 0.686,
      "step": 2533
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37079358100891113,
      "learning_rate": 0.00010279114533205005,
      "loss": 0.7318,
      "step": 2534
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3408580422401428,
      "learning_rate": 0.00010275264677574592,
      "loss": 0.6818,
      "step": 2535
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.415795236825943,
      "learning_rate": 0.00010271414821944179,
      "loss": 0.723,
      "step": 2536
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4153701364994049,
      "learning_rate": 0.00010267564966313763,
      "loss": 0.8586,
      "step": 2537
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40930286049842834,
      "learning_rate": 0.0001026371511068335,
      "loss": 0.7669,
      "step": 2538
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.38056835532188416,
      "learning_rate": 0.00010259865255052935,
      "loss": 0.6408,
      "step": 2539
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.34456145763397217,
      "learning_rate": 0.00010256015399422523,
      "loss": 0.9255,
      "step": 2540
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41792285442352295,
      "learning_rate": 0.00010252165543792109,
      "loss": 0.6779,
      "step": 2541
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3652982711791992,
      "learning_rate": 0.00010248315688161694,
      "loss": 0.8307,
      "step": 2542
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4799535274505615,
      "learning_rate": 0.0001024446583253128,
      "loss": 0.7321,
      "step": 2543
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.344407856464386,
      "learning_rate": 0.00010240615976900867,
      "loss": 0.8218,
      "step": 2544
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4030497670173645,
      "learning_rate": 0.00010236766121270453,
      "loss": 0.8392,
      "step": 2545
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.43066391348838806,
      "learning_rate": 0.00010232916265640038,
      "loss": 0.8087,
      "step": 2546
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.39469844102859497,
      "learning_rate": 0.00010229066410009624,
      "loss": 0.7308,
      "step": 2547
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3960837721824646,
      "learning_rate": 0.00010225216554379212,
      "loss": 0.67,
      "step": 2548
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4415815472602844,
      "learning_rate": 0.00010221366698748798,
      "loss": 0.6718,
      "step": 2549
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4354984760284424,
      "learning_rate": 0.00010217516843118384,
      "loss": 0.6976,
      "step": 2550
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.45369163155555725,
      "learning_rate": 0.00010213666987487969,
      "loss": 0.8301,
      "step": 2551
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37768101692199707,
      "learning_rate": 0.00010209817131857555,
      "loss": 0.6339,
      "step": 2552
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40513351559638977,
      "learning_rate": 0.00010205967276227142,
      "loss": 0.8907,
      "step": 2553
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4639405608177185,
      "learning_rate": 0.00010202117420596728,
      "loss": 0.9293,
      "step": 2554
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37537869811058044,
      "learning_rate": 0.00010198267564966314,
      "loss": 0.7818,
      "step": 2555
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3522058129310608,
      "learning_rate": 0.00010194417709335899,
      "loss": 0.7707,
      "step": 2556
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.36954742670059204,
      "learning_rate": 0.00010190567853705487,
      "loss": 0.7296,
      "step": 2557
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.36441275477409363,
      "learning_rate": 0.00010186717998075073,
      "loss": 0.8048,
      "step": 2558
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4324532449245453,
      "learning_rate": 0.00010182868142444659,
      "loss": 0.6628,
      "step": 2559
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4019789397716522,
      "learning_rate": 0.00010179018286814246,
      "loss": 0.7619,
      "step": 2560
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3735848069190979,
      "learning_rate": 0.0001017516843118383,
      "loss": 0.6615,
      "step": 2561
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3188644051551819,
      "learning_rate": 0.00010171318575553417,
      "loss": 0.5551,
      "step": 2562
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40389353036880493,
      "learning_rate": 0.00010167468719923003,
      "loss": 0.7585,
      "step": 2563
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4187348484992981,
      "learning_rate": 0.0001016361886429259,
      "loss": 0.713,
      "step": 2564
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41641777753829956,
      "learning_rate": 0.00010159769008662177,
      "loss": 0.6782,
      "step": 2565
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40833693742752075,
      "learning_rate": 0.00010155919153031761,
      "loss": 0.701,
      "step": 2566
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3792363405227661,
      "learning_rate": 0.00010152069297401348,
      "loss": 0.5979,
      "step": 2567
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.378476619720459,
      "learning_rate": 0.00010148219441770934,
      "loss": 0.534,
      "step": 2568
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.46916088461875916,
      "learning_rate": 0.00010144369586140521,
      "loss": 0.7965,
      "step": 2569
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4249125123023987,
      "learning_rate": 0.00010140519730510107,
      "loss": 0.6347,
      "step": 2570
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4129938781261444,
      "learning_rate": 0.00010136669874879692,
      "loss": 0.8744,
      "step": 2571
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4037359058856964,
      "learning_rate": 0.00010132820019249278,
      "loss": 0.7367,
      "step": 2572
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.44239550828933716,
      "learning_rate": 0.00010128970163618866,
      "loss": 0.6232,
      "step": 2573
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4591420292854309,
      "learning_rate": 0.00010125120307988452,
      "loss": 0.7176,
      "step": 2574
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.45397794246673584,
      "learning_rate": 0.00010121270452358038,
      "loss": 0.7016,
      "step": 2575
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4130418300628662,
      "learning_rate": 0.00010117420596727622,
      "loss": 0.7513,
      "step": 2576
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3734782040119171,
      "learning_rate": 0.00010113570741097209,
      "loss": 0.9942,
      "step": 2577
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3790094256401062,
      "learning_rate": 0.00010109720885466796,
      "loss": 0.8067,
      "step": 2578
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3580275774002075,
      "learning_rate": 0.00010105871029836382,
      "loss": 0.8046,
      "step": 2579
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.442428320646286,
      "learning_rate": 0.00010102021174205967,
      "loss": 0.7117,
      "step": 2580
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4331128001213074,
      "learning_rate": 0.00010098171318575553,
      "loss": 0.773,
      "step": 2581
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3999486267566681,
      "learning_rate": 0.0001009432146294514,
      "loss": 0.704,
      "step": 2582
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3880247473716736,
      "learning_rate": 0.00010090471607314727,
      "loss": 0.6745,
      "step": 2583
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4232076406478882,
      "learning_rate": 0.00010086621751684313,
      "loss": 0.8143,
      "step": 2584
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3709017038345337,
      "learning_rate": 0.00010082771896053897,
      "loss": 0.979,
      "step": 2585
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.43612533807754517,
      "learning_rate": 0.00010078922040423483,
      "loss": 0.9127,
      "step": 2586
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.41326287388801575,
      "learning_rate": 0.00010075072184793071,
      "loss": 0.7431,
      "step": 2587
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4031268060207367,
      "learning_rate": 0.00010071222329162657,
      "loss": 0.6836,
      "step": 2588
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3634794354438782,
      "learning_rate": 0.00010067372473532244,
      "loss": 0.7565,
      "step": 2589
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3639274537563324,
      "learning_rate": 0.00010063522617901828,
      "loss": 0.6459,
      "step": 2590
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.421529084444046,
      "learning_rate": 0.00010059672762271415,
      "loss": 0.7654,
      "step": 2591
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.44208401441574097,
      "learning_rate": 0.00010055822906641001,
      "loss": 0.7975,
      "step": 2592
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.39977145195007324,
      "learning_rate": 0.00010051973051010587,
      "loss": 0.6649,
      "step": 2593
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3436776101589203,
      "learning_rate": 0.00010048123195380175,
      "loss": 0.7438,
      "step": 2594
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3004840910434723,
      "learning_rate": 0.0001004427333974976,
      "loss": 0.8425,
      "step": 2595
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3488222360610962,
      "learning_rate": 0.00010040423484119346,
      "loss": 0.6474,
      "step": 2596
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.338974267244339,
      "learning_rate": 0.00010036573628488932,
      "loss": 0.8054,
      "step": 2597
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3887273073196411,
      "learning_rate": 0.0001003272377285852,
      "loss": 0.7395,
      "step": 2598
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.34807851910591125,
      "learning_rate": 0.00010028873917228105,
      "loss": 0.6729,
      "step": 2599
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4023602306842804,
      "learning_rate": 0.0001002502406159769,
      "loss": 0.795,
      "step": 2600
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3544400930404663,
      "learning_rate": 0.00010021174205967276,
      "loss": 0.9121,
      "step": 2601
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4559398889541626,
      "learning_rate": 0.00010017324350336862,
      "loss": 0.8116,
      "step": 2602
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3570156395435333,
      "learning_rate": 0.0001001347449470645,
      "loss": 0.8127,
      "step": 2603
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3253714144229889,
      "learning_rate": 0.00010009624639076036,
      "loss": 0.787,
      "step": 2604
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3904109597206116,
      "learning_rate": 0.0001000577478344562,
      "loss": 0.5813,
      "step": 2605
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3942689001560211,
      "learning_rate": 0.00010001924927815207,
      "loss": 0.8463,
      "step": 2606
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3666599690914154,
      "learning_rate": 9.998075072184794e-05,
      "loss": 0.6241,
      "step": 2607
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.46651968359947205,
      "learning_rate": 9.994225216554379e-05,
      "loss": 0.7011,
      "step": 2608
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.35468071699142456,
      "learning_rate": 9.990375360923966e-05,
      "loss": 0.7134,
      "step": 2609
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4088934063911438,
      "learning_rate": 9.986525505293552e-05,
      "loss": 0.8918,
      "step": 2610
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.45155641436576843,
      "learning_rate": 9.982675649663139e-05,
      "loss": 0.7172,
      "step": 2611
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3660615384578705,
      "learning_rate": 9.978825794032725e-05,
      "loss": 0.6103,
      "step": 2612
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.47046220302581787,
      "learning_rate": 9.97497593840231e-05,
      "loss": 0.7398,
      "step": 2613
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.347634881734848,
      "learning_rate": 9.971126082771897e-05,
      "loss": 0.7151,
      "step": 2614
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3740624189376831,
      "learning_rate": 9.967276227141482e-05,
      "loss": 0.6964,
      "step": 2615
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.34971922636032104,
      "learning_rate": 9.963426371511069e-05,
      "loss": 0.6553,
      "step": 2616
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3481005132198334,
      "learning_rate": 9.959576515880655e-05,
      "loss": 0.9362,
      "step": 2617
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.42597150802612305,
      "learning_rate": 9.955726660250241e-05,
      "loss": 0.6124,
      "step": 2618
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.41528186202049255,
      "learning_rate": 9.951876804619827e-05,
      "loss": 0.9229,
      "step": 2619
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4176585078239441,
      "learning_rate": 9.948026948989413e-05,
      "loss": 0.696,
      "step": 2620
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.543842613697052,
      "learning_rate": 9.944177093359e-05,
      "loss": 0.7197,
      "step": 2621
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3558616042137146,
      "learning_rate": 9.940327237728586e-05,
      "loss": 0.7479,
      "step": 2622
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4272859990596771,
      "learning_rate": 9.936477382098172e-05,
      "loss": 0.9726,
      "step": 2623
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.41532647609710693,
      "learning_rate": 9.932627526467758e-05,
      "loss": 0.669,
      "step": 2624
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.36482369899749756,
      "learning_rate": 9.928777670837344e-05,
      "loss": 0.7795,
      "step": 2625
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.44944584369659424,
      "learning_rate": 9.92492781520693e-05,
      "loss": 0.7122,
      "step": 2626
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39764365553855896,
      "learning_rate": 9.921077959576518e-05,
      "loss": 0.8075,
      "step": 2627
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3625902831554413,
      "learning_rate": 9.917228103946102e-05,
      "loss": 0.6834,
      "step": 2628
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.45909276604652405,
      "learning_rate": 9.913378248315688e-05,
      "loss": 0.812,
      "step": 2629
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42261141538619995,
      "learning_rate": 9.909528392685274e-05,
      "loss": 0.6991,
      "step": 2630
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.43785494565963745,
      "learning_rate": 9.90567853705486e-05,
      "loss": 0.7846,
      "step": 2631
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.34957897663116455,
      "learning_rate": 9.901828681424447e-05,
      "loss": 0.9918,
      "step": 2632
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42457422614097595,
      "learning_rate": 9.897978825794033e-05,
      "loss": 0.7425,
      "step": 2633
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4469139277935028,
      "learning_rate": 9.89412897016362e-05,
      "loss": 0.7189,
      "step": 2634
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4049527943134308,
      "learning_rate": 9.890279114533205e-05,
      "loss": 0.5966,
      "step": 2635
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39370107650756836,
      "learning_rate": 9.886429258902792e-05,
      "loss": 0.741,
      "step": 2636
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.38606467843055725,
      "learning_rate": 9.882579403272377e-05,
      "loss": 0.7689,
      "step": 2637
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4060196578502655,
      "learning_rate": 9.878729547641963e-05,
      "loss": 0.7294,
      "step": 2638
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3409809172153473,
      "learning_rate": 9.874879692011551e-05,
      "loss": 0.7197,
      "step": 2639
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3114698827266693,
      "learning_rate": 9.871029836381135e-05,
      "loss": 0.9107,
      "step": 2640
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.30118328332901,
      "learning_rate": 9.867179980750723e-05,
      "loss": 0.6513,
      "step": 2641
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36824777722358704,
      "learning_rate": 9.863330125120308e-05,
      "loss": 0.726,
      "step": 2642
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36830776929855347,
      "learning_rate": 9.859480269489895e-05,
      "loss": 0.6927,
      "step": 2643
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4871748089790344,
      "learning_rate": 9.855630413859481e-05,
      "loss": 0.6131,
      "step": 2644
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.384880930185318,
      "learning_rate": 9.851780558229067e-05,
      "loss": 0.7973,
      "step": 2645
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39566418528556824,
      "learning_rate": 9.847930702598653e-05,
      "loss": 0.5089,
      "step": 2646
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.34621623158454895,
      "learning_rate": 9.84408084696824e-05,
      "loss": 0.6484,
      "step": 2647
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3409580588340759,
      "learning_rate": 9.840230991337826e-05,
      "loss": 0.7648,
      "step": 2648
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.35811856389045715,
      "learning_rate": 9.83638113570741e-05,
      "loss": 0.6353,
      "step": 2649
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5521526336669922,
      "learning_rate": 9.832531280076998e-05,
      "loss": 0.9373,
      "step": 2650
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.46870702505111694,
      "learning_rate": 9.828681424446584e-05,
      "loss": 0.6894,
      "step": 2651
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5914435386657715,
      "learning_rate": 9.82483156881617e-05,
      "loss": 0.6737,
      "step": 2652
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.40676915645599365,
      "learning_rate": 9.820981713185756e-05,
      "loss": 0.8397,
      "step": 2653
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.44660550355911255,
      "learning_rate": 9.817131857555342e-05,
      "loss": 0.8723,
      "step": 2654
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.49965110421180725,
      "learning_rate": 9.813282001924928e-05,
      "loss": 0.7745,
      "step": 2655
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4054611921310425,
      "learning_rate": 9.809432146294514e-05,
      "loss": 0.8466,
      "step": 2656
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.37791886925697327,
      "learning_rate": 9.8055822906641e-05,
      "loss": 0.8434,
      "step": 2657
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4496481418609619,
      "learning_rate": 9.801732435033687e-05,
      "loss": 0.7264,
      "step": 2658
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4039559066295624,
      "learning_rate": 9.797882579403273e-05,
      "loss": 0.8314,
      "step": 2659
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36064550280570984,
      "learning_rate": 9.794032723772859e-05,
      "loss": 0.6574,
      "step": 2660
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.32746902108192444,
      "learning_rate": 9.790182868142446e-05,
      "loss": 0.814,
      "step": 2661
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.45734986662864685,
      "learning_rate": 9.786333012512031e-05,
      "loss": 0.7732,
      "step": 2662
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4584044814109802,
      "learning_rate": 9.782483156881618e-05,
      "loss": 0.7671,
      "step": 2663
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42239952087402344,
      "learning_rate": 9.778633301251203e-05,
      "loss": 0.6406,
      "step": 2664
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39517053961753845,
      "learning_rate": 9.774783445620789e-05,
      "loss": 0.8316,
      "step": 2665
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3856295943260193,
      "learning_rate": 9.770933589990375e-05,
      "loss": 0.7031,
      "step": 2666
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3667305111885071,
      "learning_rate": 9.767083734359961e-05,
      "loss": 0.646,
      "step": 2667
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4343735873699188,
      "learning_rate": 9.763233878729549e-05,
      "loss": 0.7877,
      "step": 2668
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3634078800678253,
      "learning_rate": 9.759384023099134e-05,
      "loss": 0.6541,
      "step": 2669
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4146299958229065,
      "learning_rate": 9.755534167468721e-05,
      "loss": 0.7214,
      "step": 2670
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3450891673564911,
      "learning_rate": 9.751684311838306e-05,
      "loss": 0.7076,
      "step": 2671
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.38791990280151367,
      "learning_rate": 9.747834456207893e-05,
      "loss": 0.68,
      "step": 2672
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.38618192076683044,
      "learning_rate": 9.74398460057748e-05,
      "loss": 0.7117,
      "step": 2673
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.34496501088142395,
      "learning_rate": 9.740134744947065e-05,
      "loss": 0.9315,
      "step": 2674
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4337468147277832,
      "learning_rate": 9.736284889316652e-05,
      "loss": 0.6536,
      "step": 2675
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3299131989479065,
      "learning_rate": 9.732435033686236e-05,
      "loss": 0.695,
      "step": 2676
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.41560354828834534,
      "learning_rate": 9.728585178055824e-05,
      "loss": 0.77,
      "step": 2677
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4055533707141876,
      "learning_rate": 9.724735322425409e-05,
      "loss": 0.8147,
      "step": 2678
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3739679157733917,
      "learning_rate": 9.720885466794996e-05,
      "loss": 0.6544,
      "step": 2679
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38883379101753235,
      "learning_rate": 9.717035611164582e-05,
      "loss": 0.927,
      "step": 2680
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3955147862434387,
      "learning_rate": 9.713185755534168e-05,
      "loss": 0.793,
      "step": 2681
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4074682295322418,
      "learning_rate": 9.709335899903754e-05,
      "loss": 0.7504,
      "step": 2682
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4010629653930664,
      "learning_rate": 9.70548604427334e-05,
      "loss": 0.7805,
      "step": 2683
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5188684463500977,
      "learning_rate": 9.701636188642926e-05,
      "loss": 0.6821,
      "step": 2684
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42911797761917114,
      "learning_rate": 9.697786333012513e-05,
      "loss": 0.7896,
      "step": 2685
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.49286001920700073,
      "learning_rate": 9.693936477382099e-05,
      "loss": 0.7709,
      "step": 2686
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3598155081272125,
      "learning_rate": 9.690086621751685e-05,
      "loss": 0.7135,
      "step": 2687
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3726073205471039,
      "learning_rate": 9.686236766121271e-05,
      "loss": 0.7548,
      "step": 2688
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38944321870803833,
      "learning_rate": 9.682386910490857e-05,
      "loss": 0.8866,
      "step": 2689
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4093657433986664,
      "learning_rate": 9.678537054860443e-05,
      "loss": 0.7013,
      "step": 2690
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.397154301404953,
      "learning_rate": 9.674687199230029e-05,
      "loss": 0.727,
      "step": 2691
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.35011792182922363,
      "learning_rate": 9.670837343599615e-05,
      "loss": 0.8789,
      "step": 2692
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.43300482630729675,
      "learning_rate": 9.666987487969201e-05,
      "loss": 0.7087,
      "step": 2693
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37470895051956177,
      "learning_rate": 9.663137632338787e-05,
      "loss": 0.7031,
      "step": 2694
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.39725247025489807,
      "learning_rate": 9.659287776708374e-05,
      "loss": 0.7727,
      "step": 2695
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3705846667289734,
      "learning_rate": 9.65543792107796e-05,
      "loss": 0.7541,
      "step": 2696
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3693074882030487,
      "learning_rate": 9.651588065447547e-05,
      "loss": 0.5931,
      "step": 2697
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.45383843779563904,
      "learning_rate": 9.647738209817132e-05,
      "loss": 0.63,
      "step": 2698
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4746633768081665,
      "learning_rate": 9.643888354186719e-05,
      "loss": 0.7547,
      "step": 2699
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42711588740348816,
      "learning_rate": 9.640038498556304e-05,
      "loss": 0.9355,
      "step": 2700
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4309035837650299,
      "learning_rate": 9.63618864292589e-05,
      "loss": 0.6263,
      "step": 2701
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3983113169670105,
      "learning_rate": 9.632338787295478e-05,
      "loss": 0.6252,
      "step": 2702
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.40827110409736633,
      "learning_rate": 9.628488931665062e-05,
      "loss": 0.7479,
      "step": 2703
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.35438084602355957,
      "learning_rate": 9.62463907603465e-05,
      "loss": 0.799,
      "step": 2704
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.36741045117378235,
      "learning_rate": 9.620789220404235e-05,
      "loss": 0.7292,
      "step": 2705
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3866897225379944,
      "learning_rate": 9.616939364773822e-05,
      "loss": 0.7394,
      "step": 2706
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4621310830116272,
      "learning_rate": 9.613089509143408e-05,
      "loss": 0.8491,
      "step": 2707
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3753466308116913,
      "learning_rate": 9.609239653512994e-05,
      "loss": 0.7231,
      "step": 2708
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.34718993306159973,
      "learning_rate": 9.60538979788258e-05,
      "loss": 0.8003,
      "step": 2709
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.39184048771858215,
      "learning_rate": 9.601539942252166e-05,
      "loss": 0.8582,
      "step": 2710
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.39735668897628784,
      "learning_rate": 9.597690086621752e-05,
      "loss": 0.6262,
      "step": 2711
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.44474315643310547,
      "learning_rate": 9.593840230991337e-05,
      "loss": 0.8317,
      "step": 2712
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42861032485961914,
      "learning_rate": 9.589990375360925e-05,
      "loss": 0.7156,
      "step": 2713
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3818977177143097,
      "learning_rate": 9.586140519730511e-05,
      "loss": 0.5519,
      "step": 2714
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.46580058336257935,
      "learning_rate": 9.582290664100097e-05,
      "loss": 0.8786,
      "step": 2715
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.35603412985801697,
      "learning_rate": 9.578440808469683e-05,
      "loss": 0.8306,
      "step": 2716
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37628695368766785,
      "learning_rate": 9.574590952839269e-05,
      "loss": 0.6643,
      "step": 2717
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3828714191913605,
      "learning_rate": 9.570741097208855e-05,
      "loss": 1.0173,
      "step": 2718
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37890157103538513,
      "learning_rate": 9.566891241578441e-05,
      "loss": 0.7534,
      "step": 2719
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.41415390372276306,
      "learning_rate": 9.563041385948027e-05,
      "loss": 0.736,
      "step": 2720
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5296254754066467,
      "learning_rate": 9.559191530317613e-05,
      "loss": 0.7179,
      "step": 2721
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3670431971549988,
      "learning_rate": 9.5553416746872e-05,
      "loss": 0.7759,
      "step": 2722
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4312911331653595,
      "learning_rate": 9.551491819056786e-05,
      "loss": 0.6532,
      "step": 2723
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38563641905784607,
      "learning_rate": 9.547641963426373e-05,
      "loss": 0.8344,
      "step": 2724
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3566568195819855,
      "learning_rate": 9.543792107795958e-05,
      "loss": 0.5668,
      "step": 2725
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.427213191986084,
      "learning_rate": 9.539942252165545e-05,
      "loss": 0.7799,
      "step": 2726
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.34794506430625916,
      "learning_rate": 9.53609239653513e-05,
      "loss": 0.8698,
      "step": 2727
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.49164533615112305,
      "learning_rate": 9.532242540904716e-05,
      "loss": 0.9732,
      "step": 2728
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.41152793169021606,
      "learning_rate": 9.528392685274302e-05,
      "loss": 0.8091,
      "step": 2729
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.46910563111305237,
      "learning_rate": 9.524542829643888e-05,
      "loss": 0.8117,
      "step": 2730
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3341697156429291,
      "learning_rate": 9.520692974013476e-05,
      "loss": 0.6104,
      "step": 2731
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5079325437545776,
      "learning_rate": 9.51684311838306e-05,
      "loss": 0.8432,
      "step": 2732
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.42191705107688904,
      "learning_rate": 9.512993262752648e-05,
      "loss": 0.6476,
      "step": 2733
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4585024416446686,
      "learning_rate": 9.509143407122233e-05,
      "loss": 0.7879,
      "step": 2734
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4160514771938324,
      "learning_rate": 9.50529355149182e-05,
      "loss": 0.5466,
      "step": 2735
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41245535016059875,
      "learning_rate": 9.501443695861406e-05,
      "loss": 0.6672,
      "step": 2736
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4548846185207367,
      "learning_rate": 9.497593840230991e-05,
      "loss": 1.051,
      "step": 2737
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41005784273147583,
      "learning_rate": 9.493743984600578e-05,
      "loss": 0.5998,
      "step": 2738
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4560503363609314,
      "learning_rate": 9.489894128970163e-05,
      "loss": 0.7634,
      "step": 2739
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4302331209182739,
      "learning_rate": 9.48604427333975e-05,
      "loss": 0.7022,
      "step": 2740
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.40021786093711853,
      "learning_rate": 9.482194417709335e-05,
      "loss": 0.5809,
      "step": 2741
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4216630458831787,
      "learning_rate": 9.478344562078923e-05,
      "loss": 0.7119,
      "step": 2742
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3351995050907135,
      "learning_rate": 9.474494706448509e-05,
      "loss": 0.8031,
      "step": 2743
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3647398352622986,
      "learning_rate": 9.470644850818095e-05,
      "loss": 0.7588,
      "step": 2744
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.378101646900177,
      "learning_rate": 9.466794995187681e-05,
      "loss": 0.5223,
      "step": 2745
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4245156943798065,
      "learning_rate": 9.462945139557267e-05,
      "loss": 0.6944,
      "step": 2746
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.42838868498802185,
      "learning_rate": 9.459095283926853e-05,
      "loss": 0.727,
      "step": 2747
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3747614324092865,
      "learning_rate": 9.45524542829644e-05,
      "loss": 0.7866,
      "step": 2748
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3732750713825226,
      "learning_rate": 9.451395572666026e-05,
      "loss": 0.6618,
      "step": 2749
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4157002568244934,
      "learning_rate": 9.447545717035612e-05,
      "loss": 0.8388,
      "step": 2750
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4553559720516205,
      "learning_rate": 9.443695861405198e-05,
      "loss": 0.7207,
      "step": 2751
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.37897419929504395,
      "learning_rate": 9.439846005774784e-05,
      "loss": 0.707,
      "step": 2752
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.46221840381622314,
      "learning_rate": 9.43599615014437e-05,
      "loss": 0.8537,
      "step": 2753
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.42768946290016174,
      "learning_rate": 9.432146294513956e-05,
      "loss": 0.9237,
      "step": 2754
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4406779408454895,
      "learning_rate": 9.428296438883542e-05,
      "loss": 0.5678,
      "step": 2755
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41388893127441406,
      "learning_rate": 9.424446583253128e-05,
      "loss": 0.655,
      "step": 2756
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.408597469329834,
      "learning_rate": 9.420596727622714e-05,
      "loss": 0.6185,
      "step": 2757
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45803266763687134,
      "learning_rate": 9.4167468719923e-05,
      "loss": 0.6642,
      "step": 2758
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45868343114852905,
      "learning_rate": 9.412897016361886e-05,
      "loss": 0.913,
      "step": 2759
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4235965311527252,
      "learning_rate": 9.409047160731474e-05,
      "loss": 0.7288,
      "step": 2760
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4753710925579071,
      "learning_rate": 9.405197305101059e-05,
      "loss": 0.7407,
      "step": 2761
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45380404591560364,
      "learning_rate": 9.401347449470646e-05,
      "loss": 0.5757,
      "step": 2762
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4321337938308716,
      "learning_rate": 9.397497593840231e-05,
      "loss": 0.6363,
      "step": 2763
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.46082526445388794,
      "learning_rate": 9.393647738209817e-05,
      "loss": 0.5783,
      "step": 2764
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41777241230010986,
      "learning_rate": 9.389797882579404e-05,
      "loss": 0.7253,
      "step": 2765
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.35176077485084534,
      "learning_rate": 9.385948026948989e-05,
      "loss": 0.7682,
      "step": 2766
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45977091789245605,
      "learning_rate": 9.382098171318577e-05,
      "loss": 0.6427,
      "step": 2767
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41520360112190247,
      "learning_rate": 9.378248315688161e-05,
      "loss": 0.6642,
      "step": 2768
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.37321650981903076,
      "learning_rate": 9.374398460057749e-05,
      "loss": 0.7177,
      "step": 2769
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.36918535828590393,
      "learning_rate": 9.370548604427335e-05,
      "loss": 0.6132,
      "step": 2770
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4034837782382965,
      "learning_rate": 9.366698748796921e-05,
      "loss": 0.8139,
      "step": 2771
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3515503704547882,
      "learning_rate": 9.362848893166507e-05,
      "loss": 0.8852,
      "step": 2772
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4351012110710144,
      "learning_rate": 9.358999037536092e-05,
      "loss": 0.7767,
      "step": 2773
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.470998078584671,
      "learning_rate": 9.355149181905679e-05,
      "loss": 0.6098,
      "step": 2774
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.33775222301483154,
      "learning_rate": 9.351299326275264e-05,
      "loss": 0.6776,
      "step": 2775
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.40457963943481445,
      "learning_rate": 9.347449470644852e-05,
      "loss": 0.6759,
      "step": 2776
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3728804588317871,
      "learning_rate": 9.343599615014438e-05,
      "loss": 0.5816,
      "step": 2777
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3660212457180023,
      "learning_rate": 9.339749759384024e-05,
      "loss": 0.7322,
      "step": 2778
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3984057903289795,
      "learning_rate": 9.33589990375361e-05,
      "loss": 0.913,
      "step": 2779
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3831469714641571,
      "learning_rate": 9.332050048123196e-05,
      "loss": 0.7803,
      "step": 2780
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3171207010746002,
      "learning_rate": 9.328200192492782e-05,
      "loss": 0.7339,
      "step": 2781
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.37906327843666077,
      "learning_rate": 9.324350336862368e-05,
      "loss": 0.7626,
      "step": 2782
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4031168222427368,
      "learning_rate": 9.320500481231954e-05,
      "loss": 0.6172,
      "step": 2783
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.48304930329322815,
      "learning_rate": 9.31665062560154e-05,
      "loss": 0.6892,
      "step": 2784
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5125494599342346,
      "learning_rate": 9.312800769971126e-05,
      "loss": 0.7633,
      "step": 2785
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3571116328239441,
      "learning_rate": 9.308950914340712e-05,
      "loss": 0.8318,
      "step": 2786
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3991086483001709,
      "learning_rate": 9.3051010587103e-05,
      "loss": 0.7324,
      "step": 2787
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.45366477966308594,
      "learning_rate": 9.301251203079885e-05,
      "loss": 0.8019,
      "step": 2788
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4745069444179535,
      "learning_rate": 9.297401347449471e-05,
      "loss": 0.7918,
      "step": 2789
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6458076238632202,
      "learning_rate": 9.293551491819057e-05,
      "loss": 0.6993,
      "step": 2790
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36458152532577515,
      "learning_rate": 9.289701636188643e-05,
      "loss": 0.717,
      "step": 2791
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36609095335006714,
      "learning_rate": 9.285851780558229e-05,
      "loss": 0.7263,
      "step": 2792
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.39812082052230835,
      "learning_rate": 9.282001924927815e-05,
      "loss": 0.8768,
      "step": 2793
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3899972140789032,
      "learning_rate": 9.278152069297403e-05,
      "loss": 0.6938,
      "step": 2794
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.38520726561546326,
      "learning_rate": 9.274302213666987e-05,
      "loss": 0.8575,
      "step": 2795
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3379688262939453,
      "learning_rate": 9.270452358036575e-05,
      "loss": 0.7282,
      "step": 2796
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4168599843978882,
      "learning_rate": 9.26660250240616e-05,
      "loss": 0.7604,
      "step": 2797
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4539785385131836,
      "learning_rate": 9.262752646775747e-05,
      "loss": 0.7912,
      "step": 2798
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.40116366744041443,
      "learning_rate": 9.258902791145333e-05,
      "loss": 0.8382,
      "step": 2799
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4303094744682312,
      "learning_rate": 9.255052935514918e-05,
      "loss": 0.8188,
      "step": 2800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.44493377208709717,
      "learning_rate": 9.251203079884505e-05,
      "loss": 0.7916,
      "step": 2801
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3810407817363739,
      "learning_rate": 9.24735322425409e-05,
      "loss": 0.7109,
      "step": 2802
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.419050395488739,
      "learning_rate": 9.243503368623678e-05,
      "loss": 0.7605,
      "step": 2803
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.38970908522605896,
      "learning_rate": 9.239653512993262e-05,
      "loss": 0.6512,
      "step": 2804
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3724699914455414,
      "learning_rate": 9.23580365736285e-05,
      "loss": 0.699,
      "step": 2805
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4833805561065674,
      "learning_rate": 9.231953801732436e-05,
      "loss": 0.8053,
      "step": 2806
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3950551748275757,
      "learning_rate": 9.228103946102022e-05,
      "loss": 0.7248,
      "step": 2807
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3381422162055969,
      "learning_rate": 9.224254090471608e-05,
      "loss": 0.8029,
      "step": 2808
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4003801643848419,
      "learning_rate": 9.220404234841194e-05,
      "loss": 0.792,
      "step": 2809
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4134269654750824,
      "learning_rate": 9.21655437921078e-05,
      "loss": 0.7153,
      "step": 2810
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3668113052845001,
      "learning_rate": 9.212704523580366e-05,
      "loss": 0.7811,
      "step": 2811
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4028051793575287,
      "learning_rate": 9.208854667949952e-05,
      "loss": 0.9382,
      "step": 2812
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3918861150741577,
      "learning_rate": 9.205004812319538e-05,
      "loss": 0.6874,
      "step": 2813
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3845873475074768,
      "learning_rate": 9.201154956689125e-05,
      "loss": 0.5873,
      "step": 2814
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.388715535402298,
      "learning_rate": 9.197305101058711e-05,
      "loss": 0.6755,
      "step": 2815
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.35740038752555847,
      "learning_rate": 9.193455245428297e-05,
      "loss": 0.8547,
      "step": 2816
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4041628837585449,
      "learning_rate": 9.189605389797883e-05,
      "loss": 0.7188,
      "step": 2817
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.46415743231773376,
      "learning_rate": 9.185755534167469e-05,
      "loss": 0.8829,
      "step": 2818
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.365942120552063,
      "learning_rate": 9.181905678537055e-05,
      "loss": 0.8705,
      "step": 2819
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3230234980583191,
      "learning_rate": 9.178055822906641e-05,
      "loss": 0.5913,
      "step": 2820
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.485588937997818,
      "learning_rate": 9.174205967276227e-05,
      "loss": 0.8193,
      "step": 2821
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3983975946903229,
      "learning_rate": 9.170356111645813e-05,
      "loss": 0.7545,
      "step": 2822
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4771266579627991,
      "learning_rate": 9.166506256015401e-05,
      "loss": 0.6723,
      "step": 2823
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.37741178274154663,
      "learning_rate": 9.162656400384986e-05,
      "loss": 0.7654,
      "step": 2824
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3860509991645813,
      "learning_rate": 9.158806544754572e-05,
      "loss": 0.8365,
      "step": 2825
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3375798165798187,
      "learning_rate": 9.154956689124158e-05,
      "loss": 0.6837,
      "step": 2826
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36191824078559875,
      "learning_rate": 9.151106833493744e-05,
      "loss": 0.684,
      "step": 2827
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.40673625469207764,
      "learning_rate": 9.147256977863331e-05,
      "loss": 0.7576,
      "step": 2828
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4260772168636322,
      "learning_rate": 9.143407122232916e-05,
      "loss": 0.6361,
      "step": 2829
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.38121578097343445,
      "learning_rate": 9.139557266602504e-05,
      "loss": 0.7469,
      "step": 2830
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5164923667907715,
      "learning_rate": 9.135707410972088e-05,
      "loss": 0.6234,
      "step": 2831
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.395438015460968,
      "learning_rate": 9.131857555341676e-05,
      "loss": 0.7412,
      "step": 2832
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3232191801071167,
      "learning_rate": 9.128007699711262e-05,
      "loss": 0.5848,
      "step": 2833
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5802314877510071,
      "learning_rate": 9.124157844080848e-05,
      "loss": 0.6819,
      "step": 2834
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.44517797231674194,
      "learning_rate": 9.120307988450434e-05,
      "loss": 0.6694,
      "step": 2835
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.42143067717552185,
      "learning_rate": 9.116458132820019e-05,
      "loss": 0.6637,
      "step": 2836
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.43481990694999695,
      "learning_rate": 9.112608277189606e-05,
      "loss": 0.722,
      "step": 2837
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3496464192867279,
      "learning_rate": 9.108758421559191e-05,
      "loss": 0.7902,
      "step": 2838
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4002549350261688,
      "learning_rate": 9.104908565928778e-05,
      "loss": 0.8588,
      "step": 2839
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36089980602264404,
      "learning_rate": 9.101058710298364e-05,
      "loss": 0.7507,
      "step": 2840
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4186657965183258,
      "learning_rate": 9.09720885466795e-05,
      "loss": 0.7434,
      "step": 2841
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.35271862149238586,
      "learning_rate": 9.093358999037537e-05,
      "loss": 0.6929,
      "step": 2842
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.44647592306137085,
      "learning_rate": 9.089509143407123e-05,
      "loss": 0.7317,
      "step": 2843
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.37427327036857605,
      "learning_rate": 9.085659287776709e-05,
      "loss": 0.7493,
      "step": 2844
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.41690152883529663,
      "learning_rate": 9.081809432146295e-05,
      "loss": 0.6794,
      "step": 2845
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3804219365119934,
      "learning_rate": 9.077959576515881e-05,
      "loss": 0.7332,
      "step": 2846
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33989498019218445,
      "learning_rate": 9.074109720885467e-05,
      "loss": 0.7037,
      "step": 2847
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4020856022834778,
      "learning_rate": 9.070259865255053e-05,
      "loss": 0.8182,
      "step": 2848
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.35108479857444763,
      "learning_rate": 9.06641000962464e-05,
      "loss": 0.6341,
      "step": 2849
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33928540349006653,
      "learning_rate": 9.062560153994227e-05,
      "loss": 0.6192,
      "step": 2850
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33077698945999146,
      "learning_rate": 9.058710298363812e-05,
      "loss": 0.8419,
      "step": 2851
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.34697359800338745,
      "learning_rate": 9.054860442733398e-05,
      "loss": 0.7431,
      "step": 2852
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4845176041126251,
      "learning_rate": 9.051010587102984e-05,
      "loss": 0.6786,
      "step": 2853
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.41932523250579834,
      "learning_rate": 9.04716073147257e-05,
      "loss": 0.5909,
      "step": 2854
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3865486979484558,
      "learning_rate": 9.043310875842156e-05,
      "loss": 0.801,
      "step": 2855
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3709048628807068,
      "learning_rate": 9.039461020211742e-05,
      "loss": 0.7462,
      "step": 2856
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4040481746196747,
      "learning_rate": 9.03561116458133e-05,
      "loss": 0.7955,
      "step": 2857
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4533383846282959,
      "learning_rate": 9.031761308950914e-05,
      "loss": 0.6527,
      "step": 2858
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.40524983406066895,
      "learning_rate": 9.027911453320502e-05,
      "loss": 0.8632,
      "step": 2859
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4301786422729492,
      "learning_rate": 9.024061597690086e-05,
      "loss": 0.7756,
      "step": 2860
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36955997347831726,
      "learning_rate": 9.020211742059674e-05,
      "loss": 0.5456,
      "step": 2861
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.45608827471733093,
      "learning_rate": 9.01636188642926e-05,
      "loss": 0.7914,
      "step": 2862
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.32765597105026245,
      "learning_rate": 9.012512030798845e-05,
      "loss": 0.6205,
      "step": 2863
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.340890496969223,
      "learning_rate": 9.008662175168432e-05,
      "loss": 0.8615,
      "step": 2864
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.437499463558197,
      "learning_rate": 9.004812319538017e-05,
      "loss": 0.8559,
      "step": 2865
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36097609996795654,
      "learning_rate": 9.000962463907604e-05,
      "loss": 0.7927,
      "step": 2866
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4326573610305786,
      "learning_rate": 8.997112608277189e-05,
      "loss": 0.6842,
      "step": 2867
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4294595420360565,
      "learning_rate": 8.993262752646777e-05,
      "loss": 0.7752,
      "step": 2868
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.31293976306915283,
      "learning_rate": 8.989412897016363e-05,
      "loss": 0.8118,
      "step": 2869
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3660814166069031,
      "learning_rate": 8.985563041385949e-05,
      "loss": 1.0256,
      "step": 2870
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4098501205444336,
      "learning_rate": 8.981713185755535e-05,
      "loss": 0.7164,
      "step": 2871
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4167764186859131,
      "learning_rate": 8.97786333012512e-05,
      "loss": 0.7051,
      "step": 2872
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.42730122804641724,
      "learning_rate": 8.974013474494707e-05,
      "loss": 0.6536,
      "step": 2873
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4070715308189392,
      "learning_rate": 8.970163618864293e-05,
      "loss": 0.6284,
      "step": 2874
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.539680540561676,
      "learning_rate": 8.966313763233879e-05,
      "loss": 0.7446,
      "step": 2875
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3918716013431549,
      "learning_rate": 8.962463907603465e-05,
      "loss": 0.8508,
      "step": 2876
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36316877603530884,
      "learning_rate": 8.958614051973051e-05,
      "loss": 0.7058,
      "step": 2877
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3337201476097107,
      "learning_rate": 8.954764196342638e-05,
      "loss": 0.8747,
      "step": 2878
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4683586061000824,
      "learning_rate": 8.950914340712224e-05,
      "loss": 0.8371,
      "step": 2879
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3896545469760895,
      "learning_rate": 8.94706448508181e-05,
      "loss": 0.8585,
      "step": 2880
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3878212571144104,
      "learning_rate": 8.943214629451396e-05,
      "loss": 0.6601,
      "step": 2881
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.34758320450782776,
      "learning_rate": 8.939364773820982e-05,
      "loss": 0.6657,
      "step": 2882
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4290383458137512,
      "learning_rate": 8.935514918190568e-05,
      "loss": 1.0621,
      "step": 2883
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.40262433886528015,
      "learning_rate": 8.931665062560154e-05,
      "loss": 0.7208,
      "step": 2884
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3899232745170593,
      "learning_rate": 8.92781520692974e-05,
      "loss": 0.6483,
      "step": 2885
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3759238123893738,
      "learning_rate": 8.923965351299328e-05,
      "loss": 0.7801,
      "step": 2886
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.42231032252311707,
      "learning_rate": 8.920115495668912e-05,
      "loss": 0.8101,
      "step": 2887
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3559333086013794,
      "learning_rate": 8.916265640038499e-05,
      "loss": 0.8507,
      "step": 2888
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.46276184916496277,
      "learning_rate": 8.912415784408085e-05,
      "loss": 0.7832,
      "step": 2889
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40699031949043274,
      "learning_rate": 8.908565928777671e-05,
      "loss": 0.6677,
      "step": 2890
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.37261641025543213,
      "learning_rate": 8.904716073147258e-05,
      "loss": 0.7519,
      "step": 2891
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3761143088340759,
      "learning_rate": 8.900866217516843e-05,
      "loss": 0.6834,
      "step": 2892
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.49081575870513916,
      "learning_rate": 8.89701636188643e-05,
      "loss": 0.6296,
      "step": 2893
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.48830530047416687,
      "learning_rate": 8.893166506256015e-05,
      "loss": 0.7815,
      "step": 2894
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40555036067962646,
      "learning_rate": 8.889316650625603e-05,
      "loss": 0.7023,
      "step": 2895
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3409014940261841,
      "learning_rate": 8.885466794995189e-05,
      "loss": 0.679,
      "step": 2896
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.34803691506385803,
      "learning_rate": 8.881616939364775e-05,
      "loss": 0.667,
      "step": 2897
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.34251976013183594,
      "learning_rate": 8.877767083734361e-05,
      "loss": 0.9499,
      "step": 2898
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3937492072582245,
      "learning_rate": 8.873917228103946e-05,
      "loss": 0.847,
      "step": 2899
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3814133405685425,
      "learning_rate": 8.870067372473533e-05,
      "loss": 0.919,
      "step": 2900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3986157476902008,
      "learning_rate": 8.866217516843118e-05,
      "loss": 0.7099,
      "step": 2901
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5054865479469299,
      "learning_rate": 8.862367661212705e-05,
      "loss": 0.6952,
      "step": 2902
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3693200349807739,
      "learning_rate": 8.858517805582291e-05,
      "loss": 0.9969,
      "step": 2903
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4748612940311432,
      "learning_rate": 8.854667949951877e-05,
      "loss": 0.6979,
      "step": 2904
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5188175439834595,
      "learning_rate": 8.850818094321464e-05,
      "loss": 0.7108,
      "step": 2905
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4080547094345093,
      "learning_rate": 8.84696823869105e-05,
      "loss": 0.695,
      "step": 2906
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3473585247993469,
      "learning_rate": 8.843118383060636e-05,
      "loss": 0.8173,
      "step": 2907
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.39433586597442627,
      "learning_rate": 8.839268527430222e-05,
      "loss": 0.7416,
      "step": 2908
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.43010690808296204,
      "learning_rate": 8.835418671799808e-05,
      "loss": 0.8107,
      "step": 2909
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.43029510974884033,
      "learning_rate": 8.831568816169394e-05,
      "loss": 0.6944,
      "step": 2910
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3851475119590759,
      "learning_rate": 8.82771896053898e-05,
      "loss": 0.8442,
      "step": 2911
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.34610864520072937,
      "learning_rate": 8.823869104908566e-05,
      "loss": 0.8208,
      "step": 2912
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.39209821820259094,
      "learning_rate": 8.820019249278154e-05,
      "loss": 0.5828,
      "step": 2913
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5107370615005493,
      "learning_rate": 8.816169393647738e-05,
      "loss": 0.7525,
      "step": 2914
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3296544849872589,
      "learning_rate": 8.812319538017325e-05,
      "loss": 0.7437,
      "step": 2915
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3933621346950531,
      "learning_rate": 8.80846968238691e-05,
      "loss": 0.7657,
      "step": 2916
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.37629860639572144,
      "learning_rate": 8.804619826756497e-05,
      "loss": 0.9121,
      "step": 2917
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.47256308794021606,
      "learning_rate": 8.800769971126083e-05,
      "loss": 0.7634,
      "step": 2918
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3793465495109558,
      "learning_rate": 8.796920115495669e-05,
      "loss": 0.6526,
      "step": 2919
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5061706900596619,
      "learning_rate": 8.793070259865256e-05,
      "loss": 0.6716,
      "step": 2920
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.35709261894226074,
      "learning_rate": 8.789220404234841e-05,
      "loss": 0.8166,
      "step": 2921
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.36971381306648254,
      "learning_rate": 8.785370548604429e-05,
      "loss": 0.7874,
      "step": 2922
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.32395830750465393,
      "learning_rate": 8.781520692974013e-05,
      "loss": 0.7758,
      "step": 2923
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.38003313541412354,
      "learning_rate": 8.7776708373436e-05,
      "loss": 0.6717,
      "step": 2924
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.41731560230255127,
      "learning_rate": 8.773820981713187e-05,
      "loss": 0.6497,
      "step": 2925
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5238102078437805,
      "learning_rate": 8.769971126082772e-05,
      "loss": 0.851,
      "step": 2926
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40814730525016785,
      "learning_rate": 8.766121270452359e-05,
      "loss": 0.7649,
      "step": 2927
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.42083796858787537,
      "learning_rate": 8.762271414821944e-05,
      "loss": 0.577,
      "step": 2928
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.44320690631866455,
      "learning_rate": 8.758421559191531e-05,
      "loss": 0.8005,
      "step": 2929
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4579533040523529,
      "learning_rate": 8.754571703561116e-05,
      "loss": 0.7082,
      "step": 2930
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.35686010122299194,
      "learning_rate": 8.750721847930703e-05,
      "loss": 0.65,
      "step": 2931
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3632524013519287,
      "learning_rate": 8.74687199230029e-05,
      "loss": 0.6835,
      "step": 2932
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4755534827709198,
      "learning_rate": 8.743022136669876e-05,
      "loss": 0.8268,
      "step": 2933
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3900643587112427,
      "learning_rate": 8.739172281039462e-05,
      "loss": 0.7471,
      "step": 2934
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.39191409945487976,
      "learning_rate": 8.735322425409046e-05,
      "loss": 0.8015,
      "step": 2935
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.47083425521850586,
      "learning_rate": 8.731472569778634e-05,
      "loss": 0.6387,
      "step": 2936
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3882507383823395,
      "learning_rate": 8.72762271414822e-05,
      "loss": 0.9305,
      "step": 2937
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3471020460128784,
      "learning_rate": 8.723772858517806e-05,
      "loss": 0.7584,
      "step": 2938
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.464735746383667,
      "learning_rate": 8.719923002887392e-05,
      "loss": 0.8403,
      "step": 2939
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4831490218639374,
      "learning_rate": 8.716073147256978e-05,
      "loss": 0.6777,
      "step": 2940
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.405985563993454,
      "learning_rate": 8.712223291626564e-05,
      "loss": 0.7235,
      "step": 2941
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39689281582832336,
      "learning_rate": 8.70837343599615e-05,
      "loss": 1.0458,
      "step": 2942
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4091799557209015,
      "learning_rate": 8.704523580365737e-05,
      "loss": 0.7484,
      "step": 2943
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3654005825519562,
      "learning_rate": 8.700673724735323e-05,
      "loss": 0.8205,
      "step": 2944
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3939017653465271,
      "learning_rate": 8.696823869104909e-05,
      "loss": 0.5875,
      "step": 2945
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.44400614500045776,
      "learning_rate": 8.692974013474495e-05,
      "loss": 0.8277,
      "step": 2946
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4408559799194336,
      "learning_rate": 8.689124157844081e-05,
      "loss": 0.7862,
      "step": 2947
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.36650896072387695,
      "learning_rate": 8.685274302213667e-05,
      "loss": 0.6283,
      "step": 2948
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4378194808959961,
      "learning_rate": 8.681424446583255e-05,
      "loss": 0.8628,
      "step": 2949
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3790963590145111,
      "learning_rate": 8.677574590952839e-05,
      "loss": 0.6326,
      "step": 2950
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39199042320251465,
      "learning_rate": 8.673724735322425e-05,
      "loss": 0.7979,
      "step": 2951
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3936658799648285,
      "learning_rate": 8.669874879692012e-05,
      "loss": 0.6993,
      "step": 2952
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.36705565452575684,
      "learning_rate": 8.666025024061598e-05,
      "loss": 0.7377,
      "step": 2953
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3873213827610016,
      "learning_rate": 8.662175168431185e-05,
      "loss": 0.772,
      "step": 2954
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4524272680282593,
      "learning_rate": 8.65832531280077e-05,
      "loss": 0.5508,
      "step": 2955
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.44556063413619995,
      "learning_rate": 8.654475457170357e-05,
      "loss": 0.713,
      "step": 2956
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39351359009742737,
      "learning_rate": 8.650625601539942e-05,
      "loss": 0.6233,
      "step": 2957
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3622664511203766,
      "learning_rate": 8.64677574590953e-05,
      "loss": 0.8046,
      "step": 2958
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.42846745252609253,
      "learning_rate": 8.642925890279116e-05,
      "loss": 0.8084,
      "step": 2959
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3746493458747864,
      "learning_rate": 8.639076034648702e-05,
      "loss": 0.8529,
      "step": 2960
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.37741994857788086,
      "learning_rate": 8.635226179018288e-05,
      "loss": 0.858,
      "step": 2961
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3826678991317749,
      "learning_rate": 8.631376323387872e-05,
      "loss": 0.7145,
      "step": 2962
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.45306047797203064,
      "learning_rate": 8.62752646775746e-05,
      "loss": 0.8812,
      "step": 2963
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.415784627199173,
      "learning_rate": 8.623676612127045e-05,
      "loss": 0.7826,
      "step": 2964
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39615491032600403,
      "learning_rate": 8.619826756496632e-05,
      "loss": 0.7365,
      "step": 2965
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.38244518637657166,
      "learning_rate": 8.615976900866218e-05,
      "loss": 0.7028,
      "step": 2966
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6230850219726562,
      "learning_rate": 8.612127045235804e-05,
      "loss": 0.7848,
      "step": 2967
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3664399981498718,
      "learning_rate": 8.60827718960539e-05,
      "loss": 0.8981,
      "step": 2968
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5149267315864563,
      "learning_rate": 8.604427333974977e-05,
      "loss": 0.6785,
      "step": 2969
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3640612065792084,
      "learning_rate": 8.600577478344563e-05,
      "loss": 0.7897,
      "step": 2970
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39035215973854065,
      "learning_rate": 8.596727622714149e-05,
      "loss": 0.7535,
      "step": 2971
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.43723925948143005,
      "learning_rate": 8.592877767083735e-05,
      "loss": 0.7027,
      "step": 2972
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.48142871260643005,
      "learning_rate": 8.589027911453321e-05,
      "loss": 0.7661,
      "step": 2973
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.434040904045105,
      "learning_rate": 8.585178055822907e-05,
      "loss": 0.8681,
      "step": 2974
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.37783241271972656,
      "learning_rate": 8.581328200192493e-05,
      "loss": 0.6025,
      "step": 2975
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.40306907892227173,
      "learning_rate": 8.577478344562079e-05,
      "loss": 0.7614,
      "step": 2976
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.37107524275779724,
      "learning_rate": 8.573628488931665e-05,
      "loss": 0.7245,
      "step": 2977
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4057290554046631,
      "learning_rate": 8.569778633301251e-05,
      "loss": 0.8704,
      "step": 2978
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39799946546554565,
      "learning_rate": 8.565928777670837e-05,
      "loss": 0.5533,
      "step": 2979
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.331628680229187,
      "learning_rate": 8.562078922040424e-05,
      "loss": 0.7831,
      "step": 2980
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3970165252685547,
      "learning_rate": 8.55822906641001e-05,
      "loss": 0.708,
      "step": 2981
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4301331043243408,
      "learning_rate": 8.554379210779596e-05,
      "loss": 0.6718,
      "step": 2982
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.33409005403518677,
      "learning_rate": 8.550529355149183e-05,
      "loss": 0.7458,
      "step": 2983
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3594038188457489,
      "learning_rate": 8.546679499518768e-05,
      "loss": 0.7709,
      "step": 2984
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.38728198409080505,
      "learning_rate": 8.542829643888355e-05,
      "loss": 0.7095,
      "step": 2985
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3721837103366852,
      "learning_rate": 8.53897978825794e-05,
      "loss": 0.7444,
      "step": 2986
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3624342679977417,
      "learning_rate": 8.535129932627526e-05,
      "loss": 0.7857,
      "step": 2987
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3952600359916687,
      "learning_rate": 8.531280076997114e-05,
      "loss": 0.7385,
      "step": 2988
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3612956404685974,
      "learning_rate": 8.527430221366698e-05,
      "loss": 0.865,
      "step": 2989
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.335948646068573,
      "learning_rate": 8.523580365736286e-05,
      "loss": 0.6928,
      "step": 2990
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3487108647823334,
      "learning_rate": 8.51973051010587e-05,
      "loss": 0.8617,
      "step": 2991
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.36239027976989746,
      "learning_rate": 8.515880654475458e-05,
      "loss": 0.6305,
      "step": 2992
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4028669595718384,
      "learning_rate": 8.512030798845043e-05,
      "loss": 0.724,
      "step": 2993
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.37176331877708435,
      "learning_rate": 8.50818094321463e-05,
      "loss": 0.5042,
      "step": 2994
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.34827330708503723,
      "learning_rate": 8.504331087584216e-05,
      "loss": 0.7105,
      "step": 2995
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.41380688548088074,
      "learning_rate": 8.500481231953803e-05,
      "loss": 0.8361,
      "step": 2996
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.30160510540008545,
      "learning_rate": 8.496631376323389e-05,
      "loss": 0.6831,
      "step": 2997
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.40283289551734924,
      "learning_rate": 8.492781520692973e-05,
      "loss": 0.8428,
      "step": 2998
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.38722291588783264,
      "learning_rate": 8.488931665062561e-05,
      "loss": 0.7629,
      "step": 2999
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3990435004234314,
      "learning_rate": 8.485081809432147e-05,
      "loss": 0.9541,
      "step": 3000
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.343185693025589,
      "learning_rate": 8.481231953801733e-05,
      "loss": 0.8077,
      "step": 3001
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.41313594579696655,
      "learning_rate": 8.477382098171319e-05,
      "loss": 0.7197,
      "step": 3002
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3519099950790405,
      "learning_rate": 8.473532242540905e-05,
      "loss": 0.6273,
      "step": 3003
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.40752866864204407,
      "learning_rate": 8.469682386910491e-05,
      "loss": 0.8916,
      "step": 3004
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.483894944190979,
      "learning_rate": 8.465832531280077e-05,
      "loss": 0.9172,
      "step": 3005
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.39526960253715515,
      "learning_rate": 8.461982675649663e-05,
      "loss": 0.6851,
      "step": 3006
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.37634268403053284,
      "learning_rate": 8.45813282001925e-05,
      "loss": 0.7938,
      "step": 3007
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3989843428134918,
      "learning_rate": 8.454282964388836e-05,
      "loss": 0.8392,
      "step": 3008
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3661162257194519,
      "learning_rate": 8.450433108758422e-05,
      "loss": 0.757,
      "step": 3009
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3956104516983032,
      "learning_rate": 8.446583253128008e-05,
      "loss": 0.7629,
      "step": 3010
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4118632376194,
      "learning_rate": 8.442733397497594e-05,
      "loss": 0.8972,
      "step": 3011
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.38057592511177063,
      "learning_rate": 8.438883541867181e-05,
      "loss": 0.6079,
      "step": 3012
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4037204384803772,
      "learning_rate": 8.435033686236766e-05,
      "loss": 0.7345,
      "step": 3013
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3728887736797333,
      "learning_rate": 8.431183830606352e-05,
      "loss": 0.7271,
      "step": 3014
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.49224698543548584,
      "learning_rate": 8.427333974975938e-05,
      "loss": 0.8494,
      "step": 3015
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.49558141827583313,
      "learning_rate": 8.423484119345524e-05,
      "loss": 0.6961,
      "step": 3016
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.37798821926116943,
      "learning_rate": 8.419634263715112e-05,
      "loss": 0.9088,
      "step": 3017
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3998437523841858,
      "learning_rate": 8.415784408084697e-05,
      "loss": 0.7811,
      "step": 3018
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.37347841262817383,
      "learning_rate": 8.411934552454284e-05,
      "loss": 0.7205,
      "step": 3019
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.45343852043151855,
      "learning_rate": 8.408084696823869e-05,
      "loss": 0.908,
      "step": 3020
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.369571328163147,
      "learning_rate": 8.404234841193456e-05,
      "loss": 0.7194,
      "step": 3021
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3666676878929138,
      "learning_rate": 8.400384985563042e-05,
      "loss": 0.9039,
      "step": 3022
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3771924674510956,
      "learning_rate": 8.396535129932627e-05,
      "loss": 0.6152,
      "step": 3023
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3413681089878082,
      "learning_rate": 8.392685274302215e-05,
      "loss": 0.6607,
      "step": 3024
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3930250108242035,
      "learning_rate": 8.3888354186718e-05,
      "loss": 0.7157,
      "step": 3025
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4857483208179474,
      "learning_rate": 8.384985563041387e-05,
      "loss": 0.8596,
      "step": 3026
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.31889808177948,
      "learning_rate": 8.381135707410972e-05,
      "loss": 0.5823,
      "step": 3027
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.36766207218170166,
      "learning_rate": 8.377285851780559e-05,
      "loss": 0.71,
      "step": 3028
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.40570729970932007,
      "learning_rate": 8.373435996150145e-05,
      "loss": 0.8046,
      "step": 3029
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3698839545249939,
      "learning_rate": 8.369586140519731e-05,
      "loss": 0.8602,
      "step": 3030
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4342040419578552,
      "learning_rate": 8.365736284889317e-05,
      "loss": 0.7316,
      "step": 3031
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.40667200088500977,
      "learning_rate": 8.361886429258903e-05,
      "loss": 0.668,
      "step": 3032
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.2995244860649109,
      "learning_rate": 8.35803657362849e-05,
      "loss": 0.654,
      "step": 3033
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4303078055381775,
      "learning_rate": 8.354186717998076e-05,
      "loss": 0.9027,
      "step": 3034
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4165410101413727,
      "learning_rate": 8.350336862367662e-05,
      "loss": 0.7858,
      "step": 3035
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.38310301303863525,
      "learning_rate": 8.346487006737248e-05,
      "loss": 0.6494,
      "step": 3036
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4140000343322754,
      "learning_rate": 8.342637151106834e-05,
      "loss": 0.7581,
      "step": 3037
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3516513705253601,
      "learning_rate": 8.33878729547642e-05,
      "loss": 0.7617,
      "step": 3038
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3769511878490448,
      "learning_rate": 8.334937439846006e-05,
      "loss": 0.6028,
      "step": 3039
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4004611074924469,
      "learning_rate": 8.331087584215592e-05,
      "loss": 0.6487,
      "step": 3040
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3958001136779785,
      "learning_rate": 8.327237728585178e-05,
      "loss": 0.633,
      "step": 3041
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.36831149458885193,
      "learning_rate": 8.323387872954764e-05,
      "loss": 0.66,
      "step": 3042
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3464539349079132,
      "learning_rate": 8.31953801732435e-05,
      "loss": 0.8419,
      "step": 3043
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4404592216014862,
      "learning_rate": 8.315688161693937e-05,
      "loss": 0.6695,
      "step": 3044
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.39150115847587585,
      "learning_rate": 8.311838306063523e-05,
      "loss": 0.6814,
      "step": 3045
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3942280411720276,
      "learning_rate": 8.30798845043311e-05,
      "loss": 0.8425,
      "step": 3046
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5229547023773193,
      "learning_rate": 8.304138594802695e-05,
      "loss": 0.8593,
      "step": 3047
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3789931535720825,
      "learning_rate": 8.300288739172282e-05,
      "loss": 0.6389,
      "step": 3048
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4015362858772278,
      "learning_rate": 8.296438883541867e-05,
      "loss": 0.7989,
      "step": 3049
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3654949963092804,
      "learning_rate": 8.292589027911453e-05,
      "loss": 0.763,
      "step": 3050
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4083048105239868,
      "learning_rate": 8.28873917228104e-05,
      "loss": 0.8268,
      "step": 3051
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.44949519634246826,
      "learning_rate": 8.284889316650625e-05,
      "loss": 0.6988,
      "step": 3052
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3964414596557617,
      "learning_rate": 8.281039461020213e-05,
      "loss": 0.8119,
      "step": 3053
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6300835609436035,
      "learning_rate": 8.277189605389798e-05,
      "loss": 0.8107,
      "step": 3054
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.46497759222984314,
      "learning_rate": 8.273339749759385e-05,
      "loss": 0.7285,
      "step": 3055
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4117645025253296,
      "learning_rate": 8.26948989412897e-05,
      "loss": 0.8119,
      "step": 3056
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4038364589214325,
      "learning_rate": 8.265640038498557e-05,
      "loss": 0.7784,
      "step": 3057
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.40974873304367065,
      "learning_rate": 8.261790182868143e-05,
      "loss": 0.8815,
      "step": 3058
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3488812744617462,
      "learning_rate": 8.257940327237728e-05,
      "loss": 0.9,
      "step": 3059
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4417809545993805,
      "learning_rate": 8.254090471607315e-05,
      "loss": 0.6855,
      "step": 3060
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.35793834924697876,
      "learning_rate": 8.2502406159769e-05,
      "loss": 0.6196,
      "step": 3061
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.35618501901626587,
      "learning_rate": 8.246390760346488e-05,
      "loss": 0.6672,
      "step": 3062
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3310820162296295,
      "learning_rate": 8.242540904716074e-05,
      "loss": 0.6427,
      "step": 3063
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4592832326889038,
      "learning_rate": 8.23869104908566e-05,
      "loss": 0.7394,
      "step": 3064
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3306371569633484,
      "learning_rate": 8.234841193455246e-05,
      "loss": 0.884,
      "step": 3065
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4637131690979004,
      "learning_rate": 8.230991337824832e-05,
      "loss": 0.7896,
      "step": 3066
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.44091445207595825,
      "learning_rate": 8.227141482194418e-05,
      "loss": 0.8554,
      "step": 3067
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.37957683205604553,
      "learning_rate": 8.223291626564004e-05,
      "loss": 0.878,
      "step": 3068
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.39277318120002747,
      "learning_rate": 8.21944177093359e-05,
      "loss": 0.6292,
      "step": 3069
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4286018908023834,
      "learning_rate": 8.215591915303176e-05,
      "loss": 0.6899,
      "step": 3070
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.503832995891571,
      "learning_rate": 8.211742059672763e-05,
      "loss": 0.7726,
      "step": 3071
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.49366265535354614,
      "learning_rate": 8.207892204042349e-05,
      "loss": 0.7831,
      "step": 3072
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3911329507827759,
      "learning_rate": 8.204042348411935e-05,
      "loss": 0.6681,
      "step": 3073
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3906988203525543,
      "learning_rate": 8.200192492781521e-05,
      "loss": 0.8194,
      "step": 3074
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.44513699412345886,
      "learning_rate": 8.196342637151107e-05,
      "loss": 0.7686,
      "step": 3075
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.37963759899139404,
      "learning_rate": 8.192492781520693e-05,
      "loss": 0.555,
      "step": 3076
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.38680025935173035,
      "learning_rate": 8.188642925890279e-05,
      "loss": 1.0524,
      "step": 3077
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3879455327987671,
      "learning_rate": 8.184793070259865e-05,
      "loss": 0.6605,
      "step": 3078
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3889458477497101,
      "learning_rate": 8.180943214629451e-05,
      "loss": 1.1254,
      "step": 3079
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.544352650642395,
      "learning_rate": 8.177093358999039e-05,
      "loss": 0.8977,
      "step": 3080
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4725799858570099,
      "learning_rate": 8.173243503368624e-05,
      "loss": 0.6986,
      "step": 3081
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3567846417427063,
      "learning_rate": 8.169393647738211e-05,
      "loss": 0.7628,
      "step": 3082
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4397065043449402,
      "learning_rate": 8.165543792107796e-05,
      "loss": 0.7046,
      "step": 3083
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3775022327899933,
      "learning_rate": 8.161693936477383e-05,
      "loss": 0.7867,
      "step": 3084
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.36611297726631165,
      "learning_rate": 8.157844080846969e-05,
      "loss": 0.8895,
      "step": 3085
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4588242471218109,
      "learning_rate": 8.153994225216554e-05,
      "loss": 0.6362,
      "step": 3086
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4032593369483948,
      "learning_rate": 8.150144369586141e-05,
      "loss": 0.6103,
      "step": 3087
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3679167926311493,
      "learning_rate": 8.146294513955726e-05,
      "loss": 0.719,
      "step": 3088
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5836543440818787,
      "learning_rate": 8.142444658325314e-05,
      "loss": 0.7752,
      "step": 3089
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5938268303871155,
      "learning_rate": 8.138594802694898e-05,
      "loss": 0.6275,
      "step": 3090
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3482045531272888,
      "learning_rate": 8.134744947064486e-05,
      "loss": 0.6402,
      "step": 3091
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3976655602455139,
      "learning_rate": 8.130895091434072e-05,
      "loss": 0.9335,
      "step": 3092
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.42517152428627014,
      "learning_rate": 8.127045235803658e-05,
      "loss": 0.5832,
      "step": 3093
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3224916160106659,
      "learning_rate": 8.123195380173244e-05,
      "loss": 0.8702,
      "step": 3094
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4476451277732849,
      "learning_rate": 8.11934552454283e-05,
      "loss": 0.7826,
      "step": 3095
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.34871968626976013,
      "learning_rate": 8.115495668912416e-05,
      "loss": 0.6871,
      "step": 3096
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3737809360027313,
      "learning_rate": 8.111645813282002e-05,
      "loss": 0.7857,
      "step": 3097
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.45309221744537354,
      "learning_rate": 8.107795957651589e-05,
      "loss": 0.8117,
      "step": 3098
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4607088267803192,
      "learning_rate": 8.103946102021175e-05,
      "loss": 0.6814,
      "step": 3099
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.40047821402549744,
      "learning_rate": 8.100096246390761e-05,
      "loss": 0.8237,
      "step": 3100
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.43524837493896484,
      "learning_rate": 8.096246390760347e-05,
      "loss": 0.8441,
      "step": 3101
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.32069647312164307,
      "learning_rate": 8.092396535129933e-05,
      "loss": 0.68,
      "step": 3102
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3456234931945801,
      "learning_rate": 8.088546679499519e-05,
      "loss": 0.6746,
      "step": 3103
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6461619734764099,
      "learning_rate": 8.084696823869105e-05,
      "loss": 0.7688,
      "step": 3104
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4109783470630646,
      "learning_rate": 8.080846968238691e-05,
      "loss": 0.7871,
      "step": 3105
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5725099444389343,
      "learning_rate": 8.076997112608277e-05,
      "loss": 0.752,
      "step": 3106
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3494473695755005,
      "learning_rate": 8.073147256977863e-05,
      "loss": 0.7803,
      "step": 3107
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4428911507129669,
      "learning_rate": 8.06929740134745e-05,
      "loss": 0.6895,
      "step": 3108
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.47184818983078003,
      "learning_rate": 8.065447545717037e-05,
      "loss": 0.9077,
      "step": 3109
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3482377231121063,
      "learning_rate": 8.061597690086622e-05,
      "loss": 0.7531,
      "step": 3110
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.44663503766059875,
      "learning_rate": 8.057747834456209e-05,
      "loss": 0.7759,
      "step": 3111
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.41757312417030334,
      "learning_rate": 8.053897978825794e-05,
      "loss": 0.7531,
      "step": 3112
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.44269025325775146,
      "learning_rate": 8.05004812319538e-05,
      "loss": 0.714,
      "step": 3113
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.35777053236961365,
      "learning_rate": 8.046198267564967e-05,
      "loss": 0.9356,
      "step": 3114
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.42061692476272583,
      "learning_rate": 8.042348411934552e-05,
      "loss": 0.5136,
      "step": 3115
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4034384787082672,
      "learning_rate": 8.03849855630414e-05,
      "loss": 0.8703,
      "step": 3116
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3444957137107849,
      "learning_rate": 8.034648700673724e-05,
      "loss": 0.588,
      "step": 3117
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3068435490131378,
      "learning_rate": 8.030798845043312e-05,
      "loss": 0.8489,
      "step": 3118
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3930521011352539,
      "learning_rate": 8.026948989412897e-05,
      "loss": 0.7065,
      "step": 3119
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.38005608320236206,
      "learning_rate": 8.023099133782484e-05,
      "loss": 0.7166,
      "step": 3120
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.39048251509666443,
      "learning_rate": 8.01924927815207e-05,
      "loss": 0.7282,
      "step": 3121
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4858318269252777,
      "learning_rate": 8.015399422521655e-05,
      "loss": 0.7004,
      "step": 3122
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4052146077156067,
      "learning_rate": 8.011549566891242e-05,
      "loss": 0.676,
      "step": 3123
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.48094889521598816,
      "learning_rate": 8.007699711260827e-05,
      "loss": 0.7533,
      "step": 3124
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.44806456565856934,
      "learning_rate": 8.003849855630415e-05,
      "loss": 0.6323,
      "step": 3125
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.464498907327652,
      "learning_rate": 8e-05,
      "loss": 0.8001,
      "step": 3126
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.43299075961112976,
      "learning_rate": 7.996150144369587e-05,
      "loss": 0.8823,
      "step": 3127
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.40703868865966797,
      "learning_rate": 7.992300288739173e-05,
      "loss": 0.8802,
      "step": 3128
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.45466098189353943,
      "learning_rate": 7.988450433108759e-05,
      "loss": 0.8616,
      "step": 3129
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.42560651898384094,
      "learning_rate": 7.984600577478345e-05,
      "loss": 0.7276,
      "step": 3130
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.36456120014190674,
      "learning_rate": 7.980750721847931e-05,
      "loss": 0.5646,
      "step": 3131
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4015639126300812,
      "learning_rate": 7.976900866217517e-05,
      "loss": 0.6842,
      "step": 3132
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9981422424316406,
      "learning_rate": 7.973051010587103e-05,
      "loss": 0.6659,
      "step": 3133
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.35377949476242065,
      "learning_rate": 7.96920115495669e-05,
      "loss": 0.7671,
      "step": 3134
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3638392686843872,
      "learning_rate": 7.965351299326276e-05,
      "loss": 0.8657,
      "step": 3135
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4104955792427063,
      "learning_rate": 7.961501443695862e-05,
      "loss": 0.8376,
      "step": 3136
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.406023770570755,
      "learning_rate": 7.957651588065448e-05,
      "loss": 0.8026,
      "step": 3137
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3785809874534607,
      "learning_rate": 7.953801732435034e-05,
      "loss": 0.6116,
      "step": 3138
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.48360174894332886,
      "learning_rate": 7.94995187680462e-05,
      "loss": 0.6498,
      "step": 3139
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.39570730924606323,
      "learning_rate": 7.946102021174206e-05,
      "loss": 0.7134,
      "step": 3140
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.47326645255088806,
      "learning_rate": 7.942252165543792e-05,
      "loss": 0.7933,
      "step": 3141
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.46987438201904297,
      "learning_rate": 7.938402309913378e-05,
      "loss": 0.6981,
      "step": 3142
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4623181223869324,
      "learning_rate": 7.934552454282966e-05,
      "loss": 0.7865,
      "step": 3143
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4587595760822296,
      "learning_rate": 7.93070259865255e-05,
      "loss": 0.7717,
      "step": 3144
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.35261785984039307,
      "learning_rate": 7.926852743022138e-05,
      "loss": 0.8714,
      "step": 3145
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.349996954202652,
      "learning_rate": 7.923002887391723e-05,
      "loss": 0.6801,
      "step": 3146
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4526873230934143,
      "learning_rate": 7.91915303176131e-05,
      "loss": 0.6802,
      "step": 3147
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.39013296365737915,
      "learning_rate": 7.915303176130896e-05,
      "loss": 0.6909,
      "step": 3148
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4114494025707245,
      "learning_rate": 7.911453320500481e-05,
      "loss": 0.6179,
      "step": 3149
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.41470617055892944,
      "learning_rate": 7.907603464870068e-05,
      "loss": 0.7109,
      "step": 3150
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.363972008228302,
      "learning_rate": 7.903753609239653e-05,
      "loss": 0.7297,
      "step": 3151
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3768376410007477,
      "learning_rate": 7.89990375360924e-05,
      "loss": 0.7251,
      "step": 3152
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3925165832042694,
      "learning_rate": 7.896053897978825e-05,
      "loss": 0.8162,
      "step": 3153
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3908020257949829,
      "learning_rate": 7.892204042348413e-05,
      "loss": 0.7257,
      "step": 3154
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3797414302825928,
      "learning_rate": 7.888354186717999e-05,
      "loss": 0.8074,
      "step": 3155
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4091716408729553,
      "learning_rate": 7.884504331087585e-05,
      "loss": 0.7503,
      "step": 3156
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4790990948677063,
      "learning_rate": 7.880654475457171e-05,
      "loss": 0.6337,
      "step": 3157
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4093915820121765,
      "learning_rate": 7.876804619826756e-05,
      "loss": 0.7358,
      "step": 3158
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3929155468940735,
      "learning_rate": 7.872954764196343e-05,
      "loss": 0.66,
      "step": 3159
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.47067636251449585,
      "learning_rate": 7.86910490856593e-05,
      "loss": 0.7612,
      "step": 3160
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.47761064767837524,
      "learning_rate": 7.865255052935515e-05,
      "loss": 0.8176,
      "step": 3161
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.40368208289146423,
      "learning_rate": 7.861405197305102e-05,
      "loss": 0.7747,
      "step": 3162
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.36156556010246277,
      "learning_rate": 7.857555341674688e-05,
      "loss": 0.5204,
      "step": 3163
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3707115352153778,
      "learning_rate": 7.853705486044274e-05,
      "loss": 0.5396,
      "step": 3164
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.37799814343452454,
      "learning_rate": 7.84985563041386e-05,
      "loss": 0.9414,
      "step": 3165
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4763464331626892,
      "learning_rate": 7.846005774783446e-05,
      "loss": 0.7207,
      "step": 3166
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.41156190633773804,
      "learning_rate": 7.842155919153032e-05,
      "loss": 0.6696,
      "step": 3167
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.404452919960022,
      "learning_rate": 7.838306063522618e-05,
      "loss": 0.7348,
      "step": 3168
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.42094555497169495,
      "learning_rate": 7.834456207892204e-05,
      "loss": 0.7317,
      "step": 3169
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4270249605178833,
      "learning_rate": 7.83060635226179e-05,
      "loss": 0.6527,
      "step": 3170
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4087783694267273,
      "learning_rate": 7.826756496631376e-05,
      "loss": 0.6809,
      "step": 3171
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3577374517917633,
      "learning_rate": 7.822906641000964e-05,
      "loss": 0.8666,
      "step": 3172
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.390450656414032,
      "learning_rate": 7.819056785370549e-05,
      "loss": 0.7736,
      "step": 3173
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4263068437576294,
      "learning_rate": 7.815206929740135e-05,
      "loss": 0.8269,
      "step": 3174
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.39841312170028687,
      "learning_rate": 7.811357074109721e-05,
      "loss": 0.9243,
      "step": 3175
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.38090720772743225,
      "learning_rate": 7.807507218479307e-05,
      "loss": 0.6899,
      "step": 3176
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.39459359645843506,
      "learning_rate": 7.803657362848894e-05,
      "loss": 0.7742,
      "step": 3177
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3677707016468048,
      "learning_rate": 7.799807507218479e-05,
      "loss": 0.749,
      "step": 3178
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.34641510248184204,
      "learning_rate": 7.795957651588067e-05,
      "loss": 0.7835,
      "step": 3179
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.389128178358078,
      "learning_rate": 7.792107795957651e-05,
      "loss": 0.6017,
      "step": 3180
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5747141242027283,
      "learning_rate": 7.788257940327239e-05,
      "loss": 0.962,
      "step": 3181
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3740430772304535,
      "learning_rate": 7.784408084696823e-05,
      "loss": 0.8505,
      "step": 3182
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.455660879611969,
      "learning_rate": 7.780558229066411e-05,
      "loss": 0.5982,
      "step": 3183
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.475314736366272,
      "learning_rate": 7.776708373435997e-05,
      "loss": 0.5914,
      "step": 3184
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4570014774799347,
      "learning_rate": 7.772858517805582e-05,
      "loss": 0.8778,
      "step": 3185
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4258643388748169,
      "learning_rate": 7.769008662175169e-05,
      "loss": 0.7092,
      "step": 3186
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.37572842836380005,
      "learning_rate": 7.765158806544754e-05,
      "loss": 0.828,
      "step": 3187
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.40858152508735657,
      "learning_rate": 7.761308950914341e-05,
      "loss": 0.6793,
      "step": 3188
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.397010862827301,
      "learning_rate": 7.757459095283928e-05,
      "loss": 0.5671,
      "step": 3189
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3911954164505005,
      "learning_rate": 7.753609239653514e-05,
      "loss": 0.7007,
      "step": 3190
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.37619927525520325,
      "learning_rate": 7.7497593840231e-05,
      "loss": 0.7116,
      "step": 3191
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4262179732322693,
      "learning_rate": 7.745909528392686e-05,
      "loss": 0.8499,
      "step": 3192
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3455931842327118,
      "learning_rate": 7.742059672762272e-05,
      "loss": 0.9127,
      "step": 3193
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.40927064418792725,
      "learning_rate": 7.738209817131858e-05,
      "loss": 0.8091,
      "step": 3194
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3495061993598938,
      "learning_rate": 7.734359961501444e-05,
      "loss": 0.7826,
      "step": 3195
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.29086875915527344,
      "learning_rate": 7.73051010587103e-05,
      "loss": 0.8662,
      "step": 3196
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3969514071941376,
      "learning_rate": 7.726660250240616e-05,
      "loss": 0.9891,
      "step": 3197
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3129332959651947,
      "learning_rate": 7.722810394610202e-05,
      "loss": 0.7192,
      "step": 3198
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.39697712659835815,
      "learning_rate": 7.718960538979789e-05,
      "loss": 0.7068,
      "step": 3199
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3984391987323761,
      "learning_rate": 7.715110683349375e-05,
      "loss": 0.6831,
      "step": 3200
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3852039873600006,
      "learning_rate": 7.711260827718961e-05,
      "loss": 0.6691,
      "step": 3201
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.395406574010849,
      "learning_rate": 7.707410972088547e-05,
      "loss": 0.8867,
      "step": 3202
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.39705467224121094,
      "learning_rate": 7.703561116458133e-05,
      "loss": 0.9637,
      "step": 3203
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.37535813450813293,
      "learning_rate": 7.699711260827719e-05,
      "loss": 0.8548,
      "step": 3204
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.34915512800216675,
      "learning_rate": 7.695861405197305e-05,
      "loss": 0.6138,
      "step": 3205
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.32602328062057495,
      "learning_rate": 7.692011549566893e-05,
      "loss": 0.9185,
      "step": 3206
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.45774510502815247,
      "learning_rate": 7.688161693936477e-05,
      "loss": 0.7992,
      "step": 3207
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4055064022541046,
      "learning_rate": 7.684311838306065e-05,
      "loss": 0.7352,
      "step": 3208
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1321452856063843,
      "learning_rate": 7.68046198267565e-05,
      "loss": 0.9314,
      "step": 3209
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.37934714555740356,
      "learning_rate": 7.676612127045236e-05,
      "loss": 0.5602,
      "step": 3210
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3895130455493927,
      "learning_rate": 7.672762271414823e-05,
      "loss": 0.8459,
      "step": 3211
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.42140376567840576,
      "learning_rate": 7.668912415784408e-05,
      "loss": 0.8734,
      "step": 3212
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3731917142868042,
      "learning_rate": 7.665062560153995e-05,
      "loss": 0.7181,
      "step": 3213
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3588618338108063,
      "learning_rate": 7.66121270452358e-05,
      "loss": 0.7039,
      "step": 3214
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4102572798728943,
      "learning_rate": 7.657362848893167e-05,
      "loss": 0.7151,
      "step": 3215
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4511280357837677,
      "learning_rate": 7.653512993262752e-05,
      "loss": 0.776,
      "step": 3216
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3639926016330719,
      "learning_rate": 7.64966313763234e-05,
      "loss": 0.7402,
      "step": 3217
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.43501004576683044,
      "learning_rate": 7.645813282001926e-05,
      "loss": 0.7301,
      "step": 3218
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3976086676120758,
      "learning_rate": 7.641963426371512e-05,
      "loss": 0.6806,
      "step": 3219
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4492357075214386,
      "learning_rate": 7.638113570741098e-05,
      "loss": 0.908,
      "step": 3220
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.42376333475112915,
      "learning_rate": 7.634263715110683e-05,
      "loss": 0.766,
      "step": 3221
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3837694227695465,
      "learning_rate": 7.63041385948027e-05,
      "loss": 0.768,
      "step": 3222
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.42666128277778625,
      "learning_rate": 7.626564003849856e-05,
      "loss": 0.6697,
      "step": 3223
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3362993597984314,
      "learning_rate": 7.622714148219442e-05,
      "loss": 0.5896,
      "step": 3224
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.40074288845062256,
      "learning_rate": 7.618864292589028e-05,
      "loss": 0.7639,
      "step": 3225
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5863466262817383,
      "learning_rate": 7.615014436958615e-05,
      "loss": 0.6006,
      "step": 3226
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4073939621448517,
      "learning_rate": 7.6111645813282e-05,
      "loss": 0.7966,
      "step": 3227
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.40913036465644836,
      "learning_rate": 7.607314725697787e-05,
      "loss": 0.6593,
      "step": 3228
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.449084997177124,
      "learning_rate": 7.603464870067373e-05,
      "loss": 0.7339,
      "step": 3229
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3696070909500122,
      "learning_rate": 7.599615014436959e-05,
      "loss": 0.8193,
      "step": 3230
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4758624732494354,
      "learning_rate": 7.595765158806545e-05,
      "loss": 0.7505,
      "step": 3231
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.38616037368774414,
      "learning_rate": 7.591915303176131e-05,
      "loss": 0.6942,
      "step": 3232
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.43087098002433777,
      "learning_rate": 7.588065447545717e-05,
      "loss": 0.6052,
      "step": 3233
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3590552806854248,
      "learning_rate": 7.584215591915303e-05,
      "loss": 0.905,
      "step": 3234
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.34738972783088684,
      "learning_rate": 7.580365736284891e-05,
      "loss": 0.765,
      "step": 3235
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3689389228820801,
      "learning_rate": 7.576515880654475e-05,
      "loss": 0.715,
      "step": 3236
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.37844347953796387,
      "learning_rate": 7.572666025024062e-05,
      "loss": 0.6684,
      "step": 3237
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.40013569593429565,
      "learning_rate": 7.568816169393648e-05,
      "loss": 0.6324,
      "step": 3238
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.41577571630477905,
      "learning_rate": 7.564966313763234e-05,
      "loss": 0.7724,
      "step": 3239
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3855705261230469,
      "learning_rate": 7.561116458132821e-05,
      "loss": 0.8818,
      "step": 3240
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3791694939136505,
      "learning_rate": 7.557266602502406e-05,
      "loss": 0.7667,
      "step": 3241
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4205933213233948,
      "learning_rate": 7.553416746871993e-05,
      "loss": 0.7697,
      "step": 3242
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.39088374376296997,
      "learning_rate": 7.549566891241578e-05,
      "loss": 0.8914,
      "step": 3243
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.39371171593666077,
      "learning_rate": 7.545717035611166e-05,
      "loss": 0.8485,
      "step": 3244
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.41371622681617737,
      "learning_rate": 7.54186717998075e-05,
      "loss": 0.6375,
      "step": 3245
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3992449939250946,
      "learning_rate": 7.538017324350338e-05,
      "loss": 0.7542,
      "step": 3246
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.41305410861968994,
      "learning_rate": 7.534167468719924e-05,
      "loss": 0.8675,
      "step": 3247
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.40234455466270447,
      "learning_rate": 7.530317613089509e-05,
      "loss": 0.8039,
      "step": 3248
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.48579350113868713,
      "learning_rate": 7.526467757459096e-05,
      "loss": 0.8211,
      "step": 3249
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.41258591413497925,
      "learning_rate": 7.522617901828681e-05,
      "loss": 0.8427,
      "step": 3250
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.37472501397132874,
      "learning_rate": 7.518768046198268e-05,
      "loss": 0.544,
      "step": 3251
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3671351671218872,
      "learning_rate": 7.514918190567854e-05,
      "loss": 0.6793,
      "step": 3252
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39663222432136536,
      "learning_rate": 7.51106833493744e-05,
      "loss": 0.7589,
      "step": 3253
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.34167078137397766,
      "learning_rate": 7.507218479307027e-05,
      "loss": 0.7551,
      "step": 3254
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4556160271167755,
      "learning_rate": 7.503368623676613e-05,
      "loss": 0.6574,
      "step": 3255
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.42365387082099915,
      "learning_rate": 7.499518768046199e-05,
      "loss": 0.6828,
      "step": 3256
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4035448729991913,
      "learning_rate": 7.495668912415785e-05,
      "loss": 0.8026,
      "step": 3257
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39375174045562744,
      "learning_rate": 7.491819056785371e-05,
      "loss": 0.7953,
      "step": 3258
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.44154536724090576,
      "learning_rate": 7.487969201154957e-05,
      "loss": 0.7546,
      "step": 3259
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3352638781070709,
      "learning_rate": 7.484119345524543e-05,
      "loss": 0.8364,
      "step": 3260
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.38383355736732483,
      "learning_rate": 7.480269489894129e-05,
      "loss": 0.6471,
      "step": 3261
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3501184582710266,
      "learning_rate": 7.476419634263715e-05,
      "loss": 0.6224,
      "step": 3262
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39035773277282715,
      "learning_rate": 7.472569778633301e-05,
      "loss": 0.7897,
      "step": 3263
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.37025177478790283,
      "learning_rate": 7.468719923002888e-05,
      "loss": 0.6914,
      "step": 3264
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39949923753738403,
      "learning_rate": 7.464870067372474e-05,
      "loss": 0.6996,
      "step": 3265
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.38985344767570496,
      "learning_rate": 7.46102021174206e-05,
      "loss": 0.7421,
      "step": 3266
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.49324271082878113,
      "learning_rate": 7.457170356111646e-05,
      "loss": 0.9006,
      "step": 3267
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.387617826461792,
      "learning_rate": 7.453320500481232e-05,
      "loss": 0.7414,
      "step": 3268
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3590240776538849,
      "learning_rate": 7.44947064485082e-05,
      "loss": 0.8703,
      "step": 3269
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.356291800737381,
      "learning_rate": 7.445620789220404e-05,
      "loss": 0.737,
      "step": 3270
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4371192753314972,
      "learning_rate": 7.441770933589992e-05,
      "loss": 0.8782,
      "step": 3271
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.41555914282798767,
      "learning_rate": 7.437921077959576e-05,
      "loss": 0.799,
      "step": 3272
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.38088831305503845,
      "learning_rate": 7.434071222329162e-05,
      "loss": 0.8263,
      "step": 3273
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4081113934516907,
      "learning_rate": 7.43022136669875e-05,
      "loss": 0.7334,
      "step": 3274
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4146654009819031,
      "learning_rate": 7.426371511068335e-05,
      "loss": 0.7869,
      "step": 3275
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39854148030281067,
      "learning_rate": 7.422521655437922e-05,
      "loss": 0.7517,
      "step": 3276
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.41253527998924255,
      "learning_rate": 7.418671799807507e-05,
      "loss": 0.8374,
      "step": 3277
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3943275213241577,
      "learning_rate": 7.414821944177094e-05,
      "loss": 0.6871,
      "step": 3278
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.40658751130104065,
      "learning_rate": 7.410972088546679e-05,
      "loss": 0.698,
      "step": 3279
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.37027397751808167,
      "learning_rate": 7.407122232916266e-05,
      "loss": 0.7746,
      "step": 3280
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4697743356227875,
      "learning_rate": 7.403272377285853e-05,
      "loss": 0.7798,
      "step": 3281
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.32670819759368896,
      "learning_rate": 7.399422521655439e-05,
      "loss": 0.7717,
      "step": 3282
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3748084306716919,
      "learning_rate": 7.395572666025025e-05,
      "loss": 0.726,
      "step": 3283
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.35121795535087585,
      "learning_rate": 7.39172281039461e-05,
      "loss": 0.8222,
      "step": 3284
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3771165609359741,
      "learning_rate": 7.387872954764197e-05,
      "loss": 0.8569,
      "step": 3285
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4208945631980896,
      "learning_rate": 7.384023099133783e-05,
      "loss": 0.8599,
      "step": 3286
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3526057302951813,
      "learning_rate": 7.380173243503369e-05,
      "loss": 0.703,
      "step": 3287
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3842795193195343,
      "learning_rate": 7.376323387872955e-05,
      "loss": 0.6865,
      "step": 3288
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.36440572142601013,
      "learning_rate": 7.372473532242541e-05,
      "loss": 0.8026,
      "step": 3289
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3683801591396332,
      "learning_rate": 7.368623676612127e-05,
      "loss": 0.7478,
      "step": 3290
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.379438191652298,
      "learning_rate": 7.364773820981714e-05,
      "loss": 0.6012,
      "step": 3291
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3529978394508362,
      "learning_rate": 7.3609239653513e-05,
      "loss": 0.7854,
      "step": 3292
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4563756585121155,
      "learning_rate": 7.357074109720886e-05,
      "loss": 0.6364,
      "step": 3293
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3871002197265625,
      "learning_rate": 7.353224254090472e-05,
      "loss": 0.6118,
      "step": 3294
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.42504939436912537,
      "learning_rate": 7.349374398460058e-05,
      "loss": 0.7219,
      "step": 3295
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3625773787498474,
      "learning_rate": 7.345524542829644e-05,
      "loss": 0.6907,
      "step": 3296
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39222925901412964,
      "learning_rate": 7.34167468719923e-05,
      "loss": 0.7305,
      "step": 3297
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4335310459136963,
      "learning_rate": 7.337824831568818e-05,
      "loss": 0.7784,
      "step": 3298
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4495027959346771,
      "learning_rate": 7.333974975938402e-05,
      "loss": 0.82,
      "step": 3299
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39108484983444214,
      "learning_rate": 7.330125120307988e-05,
      "loss": 0.6623,
      "step": 3300
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.42277979850769043,
      "learning_rate": 7.326275264677575e-05,
      "loss": 0.7075,
      "step": 3301
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.39078301191329956,
      "learning_rate": 7.32242540904716e-05,
      "loss": 0.6173,
      "step": 3302
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4917117655277252,
      "learning_rate": 7.318575553416748e-05,
      "loss": 0.775,
      "step": 3303
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.42551296949386597,
      "learning_rate": 7.314725697786333e-05,
      "loss": 0.7386,
      "step": 3304
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5113512277603149,
      "learning_rate": 7.31087584215592e-05,
      "loss": 0.8162,
      "step": 3305
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.43924522399902344,
      "learning_rate": 7.307025986525505e-05,
      "loss": 0.7558,
      "step": 3306
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4403342604637146,
      "learning_rate": 7.303176130895092e-05,
      "loss": 0.5298,
      "step": 3307
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5100345611572266,
      "learning_rate": 7.299326275264677e-05,
      "loss": 0.6308,
      "step": 3308
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3900292217731476,
      "learning_rate": 7.295476419634263e-05,
      "loss": 0.6847,
      "step": 3309
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.36985087394714355,
      "learning_rate": 7.291626564003851e-05,
      "loss": 0.7948,
      "step": 3310
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5432722568511963,
      "learning_rate": 7.287776708373436e-05,
      "loss": 0.7021,
      "step": 3311
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3565389811992645,
      "learning_rate": 7.283926852743023e-05,
      "loss": 0.6913,
      "step": 3312
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.37842705845832825,
      "learning_rate": 7.280076997112608e-05,
      "loss": 0.6625,
      "step": 3313
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4043799936771393,
      "learning_rate": 7.276227141482195e-05,
      "loss": 0.5996,
      "step": 3314
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.47097310423851013,
      "learning_rate": 7.272377285851781e-05,
      "loss": 0.7917,
      "step": 3315
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3908584713935852,
      "learning_rate": 7.268527430221367e-05,
      "loss": 0.8245,
      "step": 3316
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5069403052330017,
      "learning_rate": 7.264677574590953e-05,
      "loss": 0.787,
      "step": 3317
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.42003512382507324,
      "learning_rate": 7.26082771896054e-05,
      "loss": 1.0287,
      "step": 3318
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.42766061425209045,
      "learning_rate": 7.256977863330126e-05,
      "loss": 0.7322,
      "step": 3319
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3503445088863373,
      "learning_rate": 7.253128007699712e-05,
      "loss": 0.8151,
      "step": 3320
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4366563558578491,
      "learning_rate": 7.249278152069298e-05,
      "loss": 0.7187,
      "step": 3321
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.400999516248703,
      "learning_rate": 7.245428296438884e-05,
      "loss": 0.7535,
      "step": 3322
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.554760217666626,
      "learning_rate": 7.24157844080847e-05,
      "loss": 0.772,
      "step": 3323
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5169610977172852,
      "learning_rate": 7.237728585178056e-05,
      "loss": 0.8583,
      "step": 3324
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3303092420101166,
      "learning_rate": 7.233878729547642e-05,
      "loss": 0.627,
      "step": 3325
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.41233956813812256,
      "learning_rate": 7.230028873917228e-05,
      "loss": 0.6799,
      "step": 3326
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.35397499799728394,
      "learning_rate": 7.226179018286814e-05,
      "loss": 0.6225,
      "step": 3327
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4127119183540344,
      "learning_rate": 7.2223291626564e-05,
      "loss": 0.8018,
      "step": 3328
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.39122283458709717,
      "learning_rate": 7.218479307025987e-05,
      "loss": 0.6915,
      "step": 3329
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3827598989009857,
      "learning_rate": 7.214629451395573e-05,
      "loss": 0.7834,
      "step": 3330
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4157978892326355,
      "learning_rate": 7.210779595765159e-05,
      "loss": 0.7027,
      "step": 3331
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3844776451587677,
      "learning_rate": 7.206929740134746e-05,
      "loss": 0.7646,
      "step": 3332
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4965607225894928,
      "learning_rate": 7.203079884504331e-05,
      "loss": 0.587,
      "step": 3333
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4785618185997009,
      "learning_rate": 7.199230028873918e-05,
      "loss": 0.7991,
      "step": 3334
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3797776699066162,
      "learning_rate": 7.195380173243503e-05,
      "loss": 0.5892,
      "step": 3335
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3533337712287903,
      "learning_rate": 7.19153031761309e-05,
      "loss": 0.6709,
      "step": 3336
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3681045174598694,
      "learning_rate": 7.187680461982677e-05,
      "loss": 0.7672,
      "step": 3337
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3564254939556122,
      "learning_rate": 7.183830606352262e-05,
      "loss": 0.6781,
      "step": 3338
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4825390875339508,
      "learning_rate": 7.179980750721849e-05,
      "loss": 0.9502,
      "step": 3339
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.33526018261909485,
      "learning_rate": 7.176130895091434e-05,
      "loss": 0.7939,
      "step": 3340
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.38409528136253357,
      "learning_rate": 7.172281039461021e-05,
      "loss": 0.6097,
      "step": 3341
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3565380573272705,
      "learning_rate": 7.168431183830606e-05,
      "loss": 0.8224,
      "step": 3342
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.348354309797287,
      "learning_rate": 7.164581328200193e-05,
      "loss": 0.7933,
      "step": 3343
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3983173072338104,
      "learning_rate": 7.16073147256978e-05,
      "loss": 0.8565,
      "step": 3344
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4797925055027008,
      "learning_rate": 7.156881616939364e-05,
      "loss": 0.6926,
      "step": 3345
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3531579077243805,
      "learning_rate": 7.153031761308952e-05,
      "loss": 0.5413,
      "step": 3346
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3683687150478363,
      "learning_rate": 7.149181905678536e-05,
      "loss": 0.7261,
      "step": 3347
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3621448576450348,
      "learning_rate": 7.145332050048124e-05,
      "loss": 0.6559,
      "step": 3348
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4162232577800751,
      "learning_rate": 7.14148219441771e-05,
      "loss": 0.6373,
      "step": 3349
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.39973050355911255,
      "learning_rate": 7.137632338787296e-05,
      "loss": 0.6768,
      "step": 3350
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.38550254702568054,
      "learning_rate": 7.133782483156882e-05,
      "loss": 0.5683,
      "step": 3351
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5045886635780334,
      "learning_rate": 7.129932627526468e-05,
      "loss": 0.7889,
      "step": 3352
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3666413128376007,
      "learning_rate": 7.126082771896054e-05,
      "loss": 0.8252,
      "step": 3353
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3360437750816345,
      "learning_rate": 7.12223291626564e-05,
      "loss": 0.7585,
      "step": 3354
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.37047481536865234,
      "learning_rate": 7.118383060635227e-05,
      "loss": 0.724,
      "step": 3355
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.34501829743385315,
      "learning_rate": 7.114533205004813e-05,
      "loss": 0.5979,
      "step": 3356
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3466781973838806,
      "learning_rate": 7.110683349374399e-05,
      "loss": 0.8665,
      "step": 3357
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.38571450114250183,
      "learning_rate": 7.106833493743985e-05,
      "loss": 0.7919,
      "step": 3358
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3961047828197479,
      "learning_rate": 7.102983638113571e-05,
      "loss": 0.6786,
      "step": 3359
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.468720942735672,
      "learning_rate": 7.099133782483157e-05,
      "loss": 0.774,
      "step": 3360
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.42682892084121704,
      "learning_rate": 7.095283926852743e-05,
      "loss": 0.6908,
      "step": 3361
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4272337257862091,
      "learning_rate": 7.091434071222329e-05,
      "loss": 0.7014,
      "step": 3362
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4049204885959625,
      "learning_rate": 7.087584215591915e-05,
      "loss": 0.7505,
      "step": 3363
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.36875197291374207,
      "learning_rate": 7.083734359961501e-05,
      "loss": 0.6296,
      "step": 3364
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5028815269470215,
      "learning_rate": 7.079884504331088e-05,
      "loss": 0.6606,
      "step": 3365
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41221046447753906,
      "learning_rate": 7.076034648700675e-05,
      "loss": 0.8702,
      "step": 3366
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.44227367639541626,
      "learning_rate": 7.07218479307026e-05,
      "loss": 0.829,
      "step": 3367
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3848923146724701,
      "learning_rate": 7.068334937439847e-05,
      "loss": 0.778,
      "step": 3368
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.35017576813697815,
      "learning_rate": 7.064485081809432e-05,
      "loss": 0.6625,
      "step": 3369
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4004649519920349,
      "learning_rate": 7.06063522617902e-05,
      "loss": 0.6526,
      "step": 3370
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3677448034286499,
      "learning_rate": 7.056785370548604e-05,
      "loss": 0.8051,
      "step": 3371
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3825700879096985,
      "learning_rate": 7.05293551491819e-05,
      "loss": 0.7995,
      "step": 3372
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5018372535705566,
      "learning_rate": 7.049085659287778e-05,
      "loss": 0.7315,
      "step": 3373
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4009108245372772,
      "learning_rate": 7.045235803657362e-05,
      "loss": 0.9356,
      "step": 3374
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41110414266586304,
      "learning_rate": 7.04138594802695e-05,
      "loss": 0.6636,
      "step": 3375
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3671032786369324,
      "learning_rate": 7.037536092396535e-05,
      "loss": 0.6057,
      "step": 3376
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4551395773887634,
      "learning_rate": 7.033686236766122e-05,
      "loss": 0.776,
      "step": 3377
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41677364706993103,
      "learning_rate": 7.029836381135708e-05,
      "loss": 0.7619,
      "step": 3378
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3978937864303589,
      "learning_rate": 7.025986525505294e-05,
      "loss": 0.8201,
      "step": 3379
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.34791913628578186,
      "learning_rate": 7.02213666987488e-05,
      "loss": 0.8593,
      "step": 3380
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.45833820104599,
      "learning_rate": 7.018286814244466e-05,
      "loss": 1.0348,
      "step": 3381
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.39380285143852234,
      "learning_rate": 7.014436958614053e-05,
      "loss": 0.6628,
      "step": 3382
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4114859402179718,
      "learning_rate": 7.010587102983639e-05,
      "loss": 0.7948,
      "step": 3383
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.382977157831192,
      "learning_rate": 7.006737247353225e-05,
      "loss": 0.6922,
      "step": 3384
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41112762689590454,
      "learning_rate": 7.002887391722811e-05,
      "loss": 0.8675,
      "step": 3385
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.419413298368454,
      "learning_rate": 6.999037536092397e-05,
      "loss": 0.6721,
      "step": 3386
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.37927010655403137,
      "learning_rate": 6.995187680461983e-05,
      "loss": 0.9188,
      "step": 3387
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4613068997859955,
      "learning_rate": 6.991337824831569e-05,
      "loss": 0.8378,
      "step": 3388
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4796544909477234,
      "learning_rate": 6.987487969201155e-05,
      "loss": 0.6923,
      "step": 3389
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41381317377090454,
      "learning_rate": 6.983638113570741e-05,
      "loss": 0.6913,
      "step": 3390
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3831675946712494,
      "learning_rate": 6.979788257940327e-05,
      "loss": 0.7166,
      "step": 3391
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41622352600097656,
      "learning_rate": 6.975938402309914e-05,
      "loss": 0.8595,
      "step": 3392
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.32933634519577026,
      "learning_rate": 6.9720885466795e-05,
      "loss": 0.729,
      "step": 3393
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.37579646706581116,
      "learning_rate": 6.968238691049086e-05,
      "loss": 0.7095,
      "step": 3394
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.46054574847221375,
      "learning_rate": 6.964388835418673e-05,
      "loss": 0.7203,
      "step": 3395
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.46152135729789734,
      "learning_rate": 6.960538979788258e-05,
      "loss": 0.7482,
      "step": 3396
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4499955475330353,
      "learning_rate": 6.956689124157845e-05,
      "loss": 0.7609,
      "step": 3397
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.37730690836906433,
      "learning_rate": 6.95283926852743e-05,
      "loss": 0.8014,
      "step": 3398
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.38492006063461304,
      "learning_rate": 6.948989412897016e-05,
      "loss": 0.6023,
      "step": 3399
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.36029213666915894,
      "learning_rate": 6.945139557266604e-05,
      "loss": 0.7317,
      "step": 3400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.34702420234680176,
      "learning_rate": 6.941289701636188e-05,
      "loss": 0.711,
      "step": 3401
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3363477289676666,
      "learning_rate": 6.937439846005776e-05,
      "loss": 0.8104,
      "step": 3402
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.41896024346351624,
      "learning_rate": 6.93358999037536e-05,
      "loss": 0.6128,
      "step": 3403
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3356614112854004,
      "learning_rate": 6.929740134744948e-05,
      "loss": 0.7632,
      "step": 3404
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.38025516271591187,
      "learning_rate": 6.925890279114533e-05,
      "loss": 0.6584,
      "step": 3405
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.43431466817855835,
      "learning_rate": 6.92204042348412e-05,
      "loss": 0.7269,
      "step": 3406
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.49645760655403137,
      "learning_rate": 6.918190567853706e-05,
      "loss": 0.6031,
      "step": 3407
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3541576862335205,
      "learning_rate": 6.914340712223291e-05,
      "loss": 0.695,
      "step": 3408
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.40942516922950745,
      "learning_rate": 6.910490856592879e-05,
      "loss": 0.8711,
      "step": 3409
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.39827418327331543,
      "learning_rate": 6.906641000962463e-05,
      "loss": 0.7037,
      "step": 3410
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3433794379234314,
      "learning_rate": 6.902791145332051e-05,
      "loss": 0.6767,
      "step": 3411
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.38225075602531433,
      "learning_rate": 6.898941289701637e-05,
      "loss": 0.8208,
      "step": 3412
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3696756958961487,
      "learning_rate": 6.895091434071223e-05,
      "loss": 0.7287,
      "step": 3413
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.42879682779312134,
      "learning_rate": 6.891241578440809e-05,
      "loss": 0.8272,
      "step": 3414
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.37802472710609436,
      "learning_rate": 6.887391722810395e-05,
      "loss": 0.7861,
      "step": 3415
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3931120038032532,
      "learning_rate": 6.883541867179981e-05,
      "loss": 0.7741,
      "step": 3416
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3684830367565155,
      "learning_rate": 6.879692011549567e-05,
      "loss": 0.8171,
      "step": 3417
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.40605291724205017,
      "learning_rate": 6.875842155919153e-05,
      "loss": 0.9141,
      "step": 3418
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.44610610604286194,
      "learning_rate": 6.87199230028874e-05,
      "loss": 0.7487,
      "step": 3419
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3632945716381073,
      "learning_rate": 6.868142444658326e-05,
      "loss": 0.6203,
      "step": 3420
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3921709656715393,
      "learning_rate": 6.864292589027912e-05,
      "loss": 0.7692,
      "step": 3421
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.403216153383255,
      "learning_rate": 6.860442733397498e-05,
      "loss": 0.7647,
      "step": 3422
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4253503382205963,
      "learning_rate": 6.856592877767084e-05,
      "loss": 0.8003,
      "step": 3423
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.39694803953170776,
      "learning_rate": 6.85274302213667e-05,
      "loss": 0.7803,
      "step": 3424
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5408936738967896,
      "learning_rate": 6.848893166506256e-05,
      "loss": 0.7469,
      "step": 3425
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.37199777364730835,
      "learning_rate": 6.845043310875842e-05,
      "loss": 0.8497,
      "step": 3426
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4004601538181305,
      "learning_rate": 6.841193455245428e-05,
      "loss": 0.8273,
      "step": 3427
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4162793755531311,
      "learning_rate": 6.837343599615014e-05,
      "loss": 0.7508,
      "step": 3428
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3465268313884735,
      "learning_rate": 6.833493743984602e-05,
      "loss": 0.7222,
      "step": 3429
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.36008864641189575,
      "learning_rate": 6.829643888354187e-05,
      "loss": 0.655,
      "step": 3430
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.382182240486145,
      "learning_rate": 6.825794032723774e-05,
      "loss": 0.6506,
      "step": 3431
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3505030870437622,
      "learning_rate": 6.821944177093359e-05,
      "loss": 0.7502,
      "step": 3432
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3937976658344269,
      "learning_rate": 6.818094321462946e-05,
      "loss": 0.7479,
      "step": 3433
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4777602255344391,
      "learning_rate": 6.814244465832531e-05,
      "loss": 0.8919,
      "step": 3434
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.37164103984832764,
      "learning_rate": 6.810394610202117e-05,
      "loss": 0.7829,
      "step": 3435
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3731735050678253,
      "learning_rate": 6.806544754571705e-05,
      "loss": 0.8198,
      "step": 3436
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3825392723083496,
      "learning_rate": 6.802694898941289e-05,
      "loss": 0.8309,
      "step": 3437
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3839637041091919,
      "learning_rate": 6.798845043310877e-05,
      "loss": 0.6931,
      "step": 3438
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.38674601912498474,
      "learning_rate": 6.794995187680461e-05,
      "loss": 0.8445,
      "step": 3439
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4026190936565399,
      "learning_rate": 6.791145332050049e-05,
      "loss": 1.0745,
      "step": 3440
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4627680778503418,
      "learning_rate": 6.787295476419635e-05,
      "loss": 0.6179,
      "step": 3441
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3938022255897522,
      "learning_rate": 6.783445620789221e-05,
      "loss": 0.8096,
      "step": 3442
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3711390495300293,
      "learning_rate": 6.779595765158807e-05,
      "loss": 0.7513,
      "step": 3443
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.37128394842147827,
      "learning_rate": 6.775745909528392e-05,
      "loss": 0.8643,
      "step": 3444
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.32767918705940247,
      "learning_rate": 6.77189605389798e-05,
      "loss": 0.7053,
      "step": 3445
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.39120998978614807,
      "learning_rate": 6.768046198267566e-05,
      "loss": 0.7221,
      "step": 3446
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.41150352358818054,
      "learning_rate": 6.764196342637152e-05,
      "loss": 0.6835,
      "step": 3447
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3763048052787781,
      "learning_rate": 6.760346487006738e-05,
      "loss": 0.6573,
      "step": 3448
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.39862653613090515,
      "learning_rate": 6.756496631376324e-05,
      "loss": 0.8677,
      "step": 3449
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.374430775642395,
      "learning_rate": 6.75264677574591e-05,
      "loss": 0.8804,
      "step": 3450
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.48696258664131165,
      "learning_rate": 6.748796920115496e-05,
      "loss": 0.7183,
      "step": 3451
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4117962419986725,
      "learning_rate": 6.744947064485082e-05,
      "loss": 0.918,
      "step": 3452
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4022523760795593,
      "learning_rate": 6.741097208854668e-05,
      "loss": 0.6802,
      "step": 3453
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.37843120098114014,
      "learning_rate": 6.737247353224254e-05,
      "loss": 0.7552,
      "step": 3454
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3528500497341156,
      "learning_rate": 6.73339749759384e-05,
      "loss": 0.7284,
      "step": 3455
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3815831243991852,
      "learning_rate": 6.729547641963426e-05,
      "loss": 0.5929,
      "step": 3456
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3379887044429779,
      "learning_rate": 6.725697786333013e-05,
      "loss": 0.6558,
      "step": 3457
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.39260369539260864,
      "learning_rate": 6.7218479307026e-05,
      "loss": 0.8474,
      "step": 3458
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.36286866664886475,
      "learning_rate": 6.717998075072185e-05,
      "loss": 0.7499,
      "step": 3459
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3970807194709778,
      "learning_rate": 6.714148219441771e-05,
      "loss": 0.627,
      "step": 3460
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3503612279891968,
      "learning_rate": 6.710298363811357e-05,
      "loss": 0.707,
      "step": 3461
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3674583435058594,
      "learning_rate": 6.706448508180943e-05,
      "loss": 0.652,
      "step": 3462
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.43821924924850464,
      "learning_rate": 6.70259865255053e-05,
      "loss": 0.8431,
      "step": 3463
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.42236557602882385,
      "learning_rate": 6.698748796920115e-05,
      "loss": 0.6752,
      "step": 3464
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.38741472363471985,
      "learning_rate": 6.694898941289703e-05,
      "loss": 0.67,
      "step": 3465
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3548882305622101,
      "learning_rate": 6.691049085659287e-05,
      "loss": 0.7338,
      "step": 3466
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.39201992750167847,
      "learning_rate": 6.687199230028875e-05,
      "loss": 0.7602,
      "step": 3467
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.42753463983535767,
      "learning_rate": 6.68334937439846e-05,
      "loss": 0.7798,
      "step": 3468
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.36294013261795044,
      "learning_rate": 6.679499518768047e-05,
      "loss": 0.8825,
      "step": 3469
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3624018132686615,
      "learning_rate": 6.675649663137633e-05,
      "loss": 0.8034,
      "step": 3470
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4168190658092499,
      "learning_rate": 6.671799807507218e-05,
      "loss": 1.0153,
      "step": 3471
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.43345147371292114,
      "learning_rate": 6.667949951876805e-05,
      "loss": 0.6326,
      "step": 3472
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5610184073448181,
      "learning_rate": 6.66410009624639e-05,
      "loss": 0.722,
      "step": 3473
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.38929346203804016,
      "learning_rate": 6.660250240615978e-05,
      "loss": 0.6511,
      "step": 3474
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3725239038467407,
      "learning_rate": 6.656400384985564e-05,
      "loss": 0.7743,
      "step": 3475
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4258432686328888,
      "learning_rate": 6.65255052935515e-05,
      "loss": 0.8436,
      "step": 3476
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.49042099714279175,
      "learning_rate": 6.648700673724736e-05,
      "loss": 0.6961,
      "step": 3477
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.41443076729774475,
      "learning_rate": 6.644850818094322e-05,
      "loss": 0.7617,
      "step": 3478
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.37425726652145386,
      "learning_rate": 6.641000962463908e-05,
      "loss": 0.7507,
      "step": 3479
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4419185221195221,
      "learning_rate": 6.637151106833494e-05,
      "loss": 0.6819,
      "step": 3480
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.349856436252594,
      "learning_rate": 6.63330125120308e-05,
      "loss": 0.8427,
      "step": 3481
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.380891889333725,
      "learning_rate": 6.629451395572666e-05,
      "loss": 0.7035,
      "step": 3482
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4692193567752838,
      "learning_rate": 6.625601539942252e-05,
      "loss": 0.5756,
      "step": 3483
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.31580668687820435,
      "learning_rate": 6.621751684311839e-05,
      "loss": 0.6898,
      "step": 3484
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3893718719482422,
      "learning_rate": 6.617901828681425e-05,
      "loss": 0.5487,
      "step": 3485
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.38932836055755615,
      "learning_rate": 6.614051973051011e-05,
      "loss": 0.7047,
      "step": 3486
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5449430346488953,
      "learning_rate": 6.610202117420597e-05,
      "loss": 0.6754,
      "step": 3487
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3990038335323334,
      "learning_rate": 6.606352261790183e-05,
      "loss": 0.784,
      "step": 3488
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3963499665260315,
      "learning_rate": 6.602502406159769e-05,
      "loss": 0.6835,
      "step": 3489
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.40556564927101135,
      "learning_rate": 6.598652550529355e-05,
      "loss": 0.7295,
      "step": 3490
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.44704392552375793,
      "learning_rate": 6.594802694898941e-05,
      "loss": 0.7016,
      "step": 3491
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5011113882064819,
      "learning_rate": 6.590952839268529e-05,
      "loss": 0.7851,
      "step": 3492
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.44068536162376404,
      "learning_rate": 6.587102983638113e-05,
      "loss": 0.6993,
      "step": 3493
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.37495413422584534,
      "learning_rate": 6.583253128007701e-05,
      "loss": 0.6377,
      "step": 3494
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4144160747528076,
      "learning_rate": 6.579403272377286e-05,
      "loss": 0.6954,
      "step": 3495
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.44547316431999207,
      "learning_rate": 6.575553416746872e-05,
      "loss": 0.7003,
      "step": 3496
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.38827958703041077,
      "learning_rate": 6.571703561116458e-05,
      "loss": 0.8499,
      "step": 3497
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.42406749725341797,
      "learning_rate": 6.567853705486044e-05,
      "loss": 0.748,
      "step": 3498
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.40195804834365845,
      "learning_rate": 6.564003849855631e-05,
      "loss": 0.7873,
      "step": 3499
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3114844262599945,
      "learning_rate": 6.560153994225216e-05,
      "loss": 0.7477,
      "step": 3500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.37832850217819214,
      "learning_rate": 6.556304138594804e-05,
      "loss": 0.9168,
      "step": 3501
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.37208977341651917,
      "learning_rate": 6.552454282964388e-05,
      "loss": 0.7999,
      "step": 3502
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.44475167989730835,
      "learning_rate": 6.548604427333976e-05,
      "loss": 0.7191,
      "step": 3503
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3757939040660858,
      "learning_rate": 6.544754571703562e-05,
      "loss": 0.6437,
      "step": 3504
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4786373972892761,
      "learning_rate": 6.540904716073148e-05,
      "loss": 0.7045,
      "step": 3505
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.35399383306503296,
      "learning_rate": 6.537054860442734e-05,
      "loss": 0.5953,
      "step": 3506
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3807116150856018,
      "learning_rate": 6.533205004812319e-05,
      "loss": 0.82,
      "step": 3507
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4588809013366699,
      "learning_rate": 6.529355149181906e-05,
      "loss": 0.8337,
      "step": 3508
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4238176643848419,
      "learning_rate": 6.525505293551492e-05,
      "loss": 0.7276,
      "step": 3509
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.35791000723838806,
      "learning_rate": 6.521655437921078e-05,
      "loss": 0.7215,
      "step": 3510
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3918018937110901,
      "learning_rate": 6.517805582290665e-05,
      "loss": 0.7673,
      "step": 3511
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3965000510215759,
      "learning_rate": 6.51395572666025e-05,
      "loss": 0.6969,
      "step": 3512
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.39626917243003845,
      "learning_rate": 6.510105871029837e-05,
      "loss": 0.6576,
      "step": 3513
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3633406162261963,
      "learning_rate": 6.506256015399423e-05,
      "loss": 0.6956,
      "step": 3514
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.36424916982650757,
      "learning_rate": 6.502406159769009e-05,
      "loss": 0.7257,
      "step": 3515
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3442474603652954,
      "learning_rate": 6.498556304138595e-05,
      "loss": 0.7701,
      "step": 3516
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.31938430666923523,
      "learning_rate": 6.494706448508181e-05,
      "loss": 0.5543,
      "step": 3517
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.40805062651634216,
      "learning_rate": 6.490856592877767e-05,
      "loss": 0.834,
      "step": 3518
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.40583285689353943,
      "learning_rate": 6.487006737247353e-05,
      "loss": 0.7417,
      "step": 3519
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.439747154712677,
      "learning_rate": 6.48315688161694e-05,
      "loss": 0.7289,
      "step": 3520
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4115344285964966,
      "learning_rate": 6.479307025986527e-05,
      "loss": 0.7552,
      "step": 3521
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3371873199939728,
      "learning_rate": 6.475457170356112e-05,
      "loss": 0.7762,
      "step": 3522
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4586044251918793,
      "learning_rate": 6.471607314725698e-05,
      "loss": 0.5971,
      "step": 3523
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4299379587173462,
      "learning_rate": 6.467757459095284e-05,
      "loss": 0.7263,
      "step": 3524
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.38964593410491943,
      "learning_rate": 6.46390760346487e-05,
      "loss": 0.7791,
      "step": 3525
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.36074620485305786,
      "learning_rate": 6.460057747834457e-05,
      "loss": 0.7405,
      "step": 3526
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.40001198649406433,
      "learning_rate": 6.456207892204042e-05,
      "loss": 1.1195,
      "step": 3527
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4556836485862732,
      "learning_rate": 6.45235803657363e-05,
      "loss": 0.9382,
      "step": 3528
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4675569534301758,
      "learning_rate": 6.448508180943214e-05,
      "loss": 0.7951,
      "step": 3529
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.44014450907707214,
      "learning_rate": 6.444658325312802e-05,
      "loss": 0.8585,
      "step": 3530
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.38741031289100647,
      "learning_rate": 6.440808469682387e-05,
      "loss": 0.7175,
      "step": 3531
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.34930166602134705,
      "learning_rate": 6.436958614051974e-05,
      "loss": 0.8354,
      "step": 3532
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.37687361240386963,
      "learning_rate": 6.43310875842156e-05,
      "loss": 0.5104,
      "step": 3533
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.351857453584671,
      "learning_rate": 6.429258902791145e-05,
      "loss": 0.9055,
      "step": 3534
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3931235074996948,
      "learning_rate": 6.425409047160732e-05,
      "loss": 0.7078,
      "step": 3535
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.37288233637809753,
      "learning_rate": 6.421559191530317e-05,
      "loss": 0.6811,
      "step": 3536
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4539032578468323,
      "learning_rate": 6.417709335899904e-05,
      "loss": 0.6015,
      "step": 3537
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.357338011264801,
      "learning_rate": 6.41385948026949e-05,
      "loss": 0.815,
      "step": 3538
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.44671744108200073,
      "learning_rate": 6.410009624639077e-05,
      "loss": 0.5449,
      "step": 3539
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.43331438302993774,
      "learning_rate": 6.406159769008663e-05,
      "loss": 0.6655,
      "step": 3540
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.39883461594581604,
      "learning_rate": 6.402309913378249e-05,
      "loss": 0.6585,
      "step": 3541
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.43640556931495667,
      "learning_rate": 6.398460057747835e-05,
      "loss": 0.6906,
      "step": 3542
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3616686761379242,
      "learning_rate": 6.394610202117421e-05,
      "loss": 0.8565,
      "step": 3543
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3726018965244293,
      "learning_rate": 6.390760346487007e-05,
      "loss": 0.738,
      "step": 3544
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.43627986311912537,
      "learning_rate": 6.386910490856593e-05,
      "loss": 0.7203,
      "step": 3545
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3889928162097931,
      "learning_rate": 6.38306063522618e-05,
      "loss": 0.8011,
      "step": 3546
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.35306641459465027,
      "learning_rate": 6.379210779595765e-05,
      "loss": 0.7774,
      "step": 3547
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4747759699821472,
      "learning_rate": 6.375360923965352e-05,
      "loss": 0.8531,
      "step": 3548
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3774948716163635,
      "learning_rate": 6.371511068334938e-05,
      "loss": 0.6567,
      "step": 3549
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5283979773521423,
      "learning_rate": 6.367661212704524e-05,
      "loss": 0.5965,
      "step": 3550
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4367813467979431,
      "learning_rate": 6.36381135707411e-05,
      "loss": 0.7426,
      "step": 3551
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.39956793189048767,
      "learning_rate": 6.359961501443696e-05,
      "loss": 0.793,
      "step": 3552
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.46892431378364563,
      "learning_rate": 6.356111645813282e-05,
      "loss": 0.6366,
      "step": 3553
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.40279266238212585,
      "learning_rate": 6.352261790182868e-05,
      "loss": 0.8194,
      "step": 3554
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3731989562511444,
      "learning_rate": 6.348411934552456e-05,
      "loss": 0.7138,
      "step": 3555
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.37677085399627686,
      "learning_rate": 6.34456207892204e-05,
      "loss": 0.7146,
      "step": 3556
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4141462743282318,
      "learning_rate": 6.340712223291628e-05,
      "loss": 0.6512,
      "step": 3557
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4711913764476776,
      "learning_rate": 6.336862367661213e-05,
      "loss": 1.0674,
      "step": 3558
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.469160795211792,
      "learning_rate": 6.333012512030799e-05,
      "loss": 0.7773,
      "step": 3559
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.46975913643836975,
      "learning_rate": 6.329162656400385e-05,
      "loss": 0.699,
      "step": 3560
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.37831413745880127,
      "learning_rate": 6.325312800769971e-05,
      "loss": 0.7613,
      "step": 3561
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3447943329811096,
      "learning_rate": 6.321462945139558e-05,
      "loss": 0.7918,
      "step": 3562
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.51407390832901,
      "learning_rate": 6.317613089509143e-05,
      "loss": 0.6208,
      "step": 3563
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.33515697717666626,
      "learning_rate": 6.31376323387873e-05,
      "loss": 0.928,
      "step": 3564
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4535205662250519,
      "learning_rate": 6.309913378248315e-05,
      "loss": 0.7546,
      "step": 3565
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3089164197444916,
      "learning_rate": 6.306063522617903e-05,
      "loss": 0.7811,
      "step": 3566
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.44937047362327576,
      "learning_rate": 6.302213666987489e-05,
      "loss": 0.5774,
      "step": 3567
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.42424270510673523,
      "learning_rate": 6.298363811357075e-05,
      "loss": 0.784,
      "step": 3568
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3691752851009369,
      "learning_rate": 6.294513955726661e-05,
      "loss": 0.8407,
      "step": 3569
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.399730384349823,
      "learning_rate": 6.290664100096246e-05,
      "loss": 0.7115,
      "step": 3570
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4117414057254791,
      "learning_rate": 6.286814244465833e-05,
      "loss": 0.7314,
      "step": 3571
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.31563177704811096,
      "learning_rate": 6.282964388835419e-05,
      "loss": 0.4937,
      "step": 3572
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3755025267601013,
      "learning_rate": 6.279114533205005e-05,
      "loss": 0.7161,
      "step": 3573
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3753986954689026,
      "learning_rate": 6.275264677574591e-05,
      "loss": 0.6146,
      "step": 3574
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.45217660069465637,
      "learning_rate": 6.271414821944178e-05,
      "loss": 0.6295,
      "step": 3575
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4982239902019501,
      "learning_rate": 6.267564966313764e-05,
      "loss": 0.8908,
      "step": 3576
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.49544933438301086,
      "learning_rate": 6.26371511068335e-05,
      "loss": 0.8149,
      "step": 3577
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.39750903844833374,
      "learning_rate": 6.259865255052936e-05,
      "loss": 0.5346,
      "step": 3578
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.39386147260665894,
      "learning_rate": 6.256015399422522e-05,
      "loss": 0.8131,
      "step": 3579
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.42425674200057983,
      "learning_rate": 6.252165543792108e-05,
      "loss": 0.7223,
      "step": 3580
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4159180819988251,
      "learning_rate": 6.248315688161694e-05,
      "loss": 0.7662,
      "step": 3581
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3593176007270813,
      "learning_rate": 6.24446583253128e-05,
      "loss": 1.0018,
      "step": 3582
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.471890389919281,
      "learning_rate": 6.240615976900866e-05,
      "loss": 0.7353,
      "step": 3583
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.42270633578300476,
      "learning_rate": 6.236766121270454e-05,
      "loss": 0.6727,
      "step": 3584
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4233015477657318,
      "learning_rate": 6.232916265640039e-05,
      "loss": 0.7561,
      "step": 3585
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.42029455304145813,
      "learning_rate": 6.229066410009625e-05,
      "loss": 0.7074,
      "step": 3586
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.382842481136322,
      "learning_rate": 6.225216554379211e-05,
      "loss": 0.5679,
      "step": 3587
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5629754662513733,
      "learning_rate": 6.221366698748797e-05,
      "loss": 0.7545,
      "step": 3588
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.39565619826316833,
      "learning_rate": 6.217516843118384e-05,
      "loss": 0.6883,
      "step": 3589
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.43653205037117004,
      "learning_rate": 6.213666987487969e-05,
      "loss": 0.6587,
      "step": 3590
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3551172614097595,
      "learning_rate": 6.209817131857556e-05,
      "loss": 0.8901,
      "step": 3591
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5918748378753662,
      "learning_rate": 6.205967276227141e-05,
      "loss": 0.7946,
      "step": 3592
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.385891854763031,
      "learning_rate": 6.202117420596729e-05,
      "loss": 0.5919,
      "step": 3593
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.403076171875,
      "learning_rate": 6.198267564966313e-05,
      "loss": 0.7991,
      "step": 3594
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.37538862228393555,
      "learning_rate": 6.1944177093359e-05,
      "loss": 0.572,
      "step": 3595
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.39217111468315125,
      "learning_rate": 6.190567853705487e-05,
      "loss": 0.6947,
      "step": 3596
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4334763288497925,
      "learning_rate": 6.186717998075072e-05,
      "loss": 0.7037,
      "step": 3597
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.38498592376708984,
      "learning_rate": 6.182868142444659e-05,
      "loss": 0.7205,
      "step": 3598
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.36080706119537354,
      "learning_rate": 6.179018286814244e-05,
      "loss": 0.7913,
      "step": 3599
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5596926808357239,
      "learning_rate": 6.175168431183831e-05,
      "loss": 0.7654,
      "step": 3600
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4017460346221924,
      "learning_rate": 6.171318575553417e-05,
      "loss": 0.8515,
      "step": 3601
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.39176011085510254,
      "learning_rate": 6.167468719923004e-05,
      "loss": 0.7838,
      "step": 3602
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5041418075561523,
      "learning_rate": 6.16361886429259e-05,
      "loss": 0.5746,
      "step": 3603
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5107149481773376,
      "learning_rate": 6.159769008662176e-05,
      "loss": 0.5809,
      "step": 3604
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3948657512664795,
      "learning_rate": 6.155919153031762e-05,
      "loss": 0.7637,
      "step": 3605
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.41544628143310547,
      "learning_rate": 6.152069297401348e-05,
      "loss": 0.9097,
      "step": 3606
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.407242089509964,
      "learning_rate": 6.148219441770934e-05,
      "loss": 0.8704,
      "step": 3607
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.44839414954185486,
      "learning_rate": 6.14436958614052e-05,
      "loss": 0.855,
      "step": 3608
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.37184613943099976,
      "learning_rate": 6.140519730510106e-05,
      "loss": 0.7881,
      "step": 3609
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4342650771141052,
      "learning_rate": 6.136669874879692e-05,
      "loss": 0.8484,
      "step": 3610
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.41314631700515747,
      "learning_rate": 6.132820019249278e-05,
      "loss": 0.6474,
      "step": 3611
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3979705572128296,
      "learning_rate": 6.128970163618865e-05,
      "loss": 0.8251,
      "step": 3612
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.36148542165756226,
      "learning_rate": 6.12512030798845e-05,
      "loss": 0.6801,
      "step": 3613
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.33605021238327026,
      "learning_rate": 6.121270452358037e-05,
      "loss": 0.8013,
      "step": 3614
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3763159513473511,
      "learning_rate": 6.117420596727623e-05,
      "loss": 0.7743,
      "step": 3615
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4841482639312744,
      "learning_rate": 6.113570741097209e-05,
      "loss": 0.5173,
      "step": 3616
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.34227222204208374,
      "learning_rate": 6.109720885466795e-05,
      "loss": 0.8879,
      "step": 3617
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3694329857826233,
      "learning_rate": 6.105871029836382e-05,
      "loss": 0.6666,
      "step": 3618
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.32149723172187805,
      "learning_rate": 6.102021174205967e-05,
      "loss": 0.6609,
      "step": 3619
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.40625542402267456,
      "learning_rate": 6.098171318575554e-05,
      "loss": 0.7562,
      "step": 3620
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3794865012168884,
      "learning_rate": 6.0943214629451394e-05,
      "loss": 0.7474,
      "step": 3621
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4270125925540924,
      "learning_rate": 6.090471607314726e-05,
      "loss": 0.7543,
      "step": 3622
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.43172311782836914,
      "learning_rate": 6.0866217516843116e-05,
      "loss": 0.6183,
      "step": 3623
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4120250344276428,
      "learning_rate": 6.0827718960538984e-05,
      "loss": 0.8415,
      "step": 3624
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4194958209991455,
      "learning_rate": 6.0789220404234845e-05,
      "loss": 0.6387,
      "step": 3625
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.34260323643684387,
      "learning_rate": 6.0750721847930706e-05,
      "loss": 0.5646,
      "step": 3626
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3996686041355133,
      "learning_rate": 6.071222329162657e-05,
      "loss": 0.7526,
      "step": 3627
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3911837041378021,
      "learning_rate": 6.067372473532242e-05,
      "loss": 0.6854,
      "step": 3628
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5182331800460815,
      "learning_rate": 6.063522617901829e-05,
      "loss": 0.7398,
      "step": 3629
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4294702112674713,
      "learning_rate": 6.0596727622714156e-05,
      "loss": 0.7736,
      "step": 3630
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.31969815492630005,
      "learning_rate": 6.055822906641001e-05,
      "loss": 0.7401,
      "step": 3631
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3577045798301697,
      "learning_rate": 6.051973051010588e-05,
      "loss": 0.663,
      "step": 3632
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.387631356716156,
      "learning_rate": 6.048123195380173e-05,
      "loss": 0.743,
      "step": 3633
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3641479015350342,
      "learning_rate": 6.04427333974976e-05,
      "loss": 0.7348,
      "step": 3634
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.47744378447532654,
      "learning_rate": 6.040423484119346e-05,
      "loss": 0.6834,
      "step": 3635
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.36191144585609436,
      "learning_rate": 6.0365736284889315e-05,
      "loss": 0.5622,
      "step": 3636
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.38838398456573486,
      "learning_rate": 6.032723772858518e-05,
      "loss": 0.6546,
      "step": 3637
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.36299318075180054,
      "learning_rate": 6.028873917228104e-05,
      "loss": 0.826,
      "step": 3638
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4136318564414978,
      "learning_rate": 6.0250240615976905e-05,
      "loss": 0.7869,
      "step": 3639
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.44790908694267273,
      "learning_rate": 6.021174205967276e-05,
      "loss": 0.5578,
      "step": 3640
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.438914954662323,
      "learning_rate": 6.017324350336863e-05,
      "loss": 0.6729,
      "step": 3641
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.38394132256507874,
      "learning_rate": 6.0134744947064495e-05,
      "loss": 0.7973,
      "step": 3642
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3227789103984833,
      "learning_rate": 6.009624639076035e-05,
      "loss": 0.7784,
      "step": 3643
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4182104766368866,
      "learning_rate": 6.005774783445621e-05,
      "loss": 0.4974,
      "step": 3644
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3733832836151123,
      "learning_rate": 6.001924927815207e-05,
      "loss": 0.6881,
      "step": 3645
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.40882477164268494,
      "learning_rate": 5.998075072184793e-05,
      "loss": 0.6659,
      "step": 3646
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4043313264846802,
      "learning_rate": 5.99422521655438e-05,
      "loss": 0.713,
      "step": 3647
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.46230214834213257,
      "learning_rate": 5.9903753609239654e-05,
      "loss": 0.7485,
      "step": 3648
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4678025543689728,
      "learning_rate": 5.986525505293552e-05,
      "loss": 0.5673,
      "step": 3649
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.38857418298721313,
      "learning_rate": 5.9826756496631376e-05,
      "loss": 0.6307,
      "step": 3650
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3734992444515228,
      "learning_rate": 5.9788257940327244e-05,
      "loss": 0.6881,
      "step": 3651
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.39011237025260925,
      "learning_rate": 5.9749759384023105e-05,
      "loss": 0.8157,
      "step": 3652
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3256891071796417,
      "learning_rate": 5.971126082771896e-05,
      "loss": 0.6067,
      "step": 3653
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4604370892047882,
      "learning_rate": 5.9672762271414827e-05,
      "loss": 0.5867,
      "step": 3654
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3777705729007721,
      "learning_rate": 5.963426371511068e-05,
      "loss": 0.7692,
      "step": 3655
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.46086350083351135,
      "learning_rate": 5.959576515880655e-05,
      "loss": 0.8046,
      "step": 3656
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4421885013580322,
      "learning_rate": 5.95572666025024e-05,
      "loss": 0.5896,
      "step": 3657
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.376817911863327,
      "learning_rate": 5.951876804619827e-05,
      "loss": 0.7615,
      "step": 3658
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3955226242542267,
      "learning_rate": 5.948026948989414e-05,
      "loss": 0.7617,
      "step": 3659
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.43577641248703003,
      "learning_rate": 5.944177093358999e-05,
      "loss": 0.7952,
      "step": 3660
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4518800675868988,
      "learning_rate": 5.9403272377285853e-05,
      "loss": 0.7346,
      "step": 3661
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.40718287229537964,
      "learning_rate": 5.9364773820981714e-05,
      "loss": 0.7631,
      "step": 3662
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.38282498717308044,
      "learning_rate": 5.9326275264677575e-05,
      "loss": 0.8844,
      "step": 3663
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.44236135482788086,
      "learning_rate": 5.928777670837344e-05,
      "loss": 0.7,
      "step": 3664
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4158862233161926,
      "learning_rate": 5.92492781520693e-05,
      "loss": 0.9289,
      "step": 3665
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.40179532766342163,
      "learning_rate": 5.9210779595765165e-05,
      "loss": 0.6345,
      "step": 3666
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.40335813164711,
      "learning_rate": 5.917228103946102e-05,
      "loss": 0.6554,
      "step": 3667
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.42935237288475037,
      "learning_rate": 5.913378248315689e-05,
      "loss": 0.7226,
      "step": 3668
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4101460874080658,
      "learning_rate": 5.909528392685275e-05,
      "loss": 0.8538,
      "step": 3669
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4259083867073059,
      "learning_rate": 5.905678537054861e-05,
      "loss": 0.824,
      "step": 3670
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3791274428367615,
      "learning_rate": 5.901828681424447e-05,
      "loss": 0.8859,
      "step": 3671
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.39984211325645447,
      "learning_rate": 5.8979788257940324e-05,
      "loss": 0.891,
      "step": 3672
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3351602554321289,
      "learning_rate": 5.894128970163619e-05,
      "loss": 0.6861,
      "step": 3673
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3968632221221924,
      "learning_rate": 5.8902791145332046e-05,
      "loss": 0.7733,
      "step": 3674
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3330048620700836,
      "learning_rate": 5.8864292589027914e-05,
      "loss": 0.6265,
      "step": 3675
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.40365371108055115,
      "learning_rate": 5.882579403272378e-05,
      "loss": 0.7745,
      "step": 3676
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5526448488235474,
      "learning_rate": 5.8787295476419636e-05,
      "loss": 0.6662,
      "step": 3677
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3854166567325592,
      "learning_rate": 5.8748796920115504e-05,
      "loss": 0.6688,
      "step": 3678
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4248911440372467,
      "learning_rate": 5.871029836381136e-05,
      "loss": 0.8652,
      "step": 3679
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3680831491947174,
      "learning_rate": 5.867179980750722e-05,
      "loss": 0.7014,
      "step": 3680
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4427933990955353,
      "learning_rate": 5.8633301251203087e-05,
      "loss": 0.7568,
      "step": 3681
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.37174224853515625,
      "learning_rate": 5.859480269489894e-05,
      "loss": 0.6928,
      "step": 3682
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.35025033354759216,
      "learning_rate": 5.855630413859481e-05,
      "loss": 0.728,
      "step": 3683
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3962099850177765,
      "learning_rate": 5.851780558229066e-05,
      "loss": 0.768,
      "step": 3684
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3726063072681427,
      "learning_rate": 5.847930702598653e-05,
      "loss": 0.9331,
      "step": 3685
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4199422001838684,
      "learning_rate": 5.8440808469682385e-05,
      "loss": 0.5434,
      "step": 3686
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.44104617834091187,
      "learning_rate": 5.840230991337825e-05,
      "loss": 0.8428,
      "step": 3687
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.45584920048713684,
      "learning_rate": 5.8363811357074113e-05,
      "loss": 0.6309,
      "step": 3688
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.46253883838653564,
      "learning_rate": 5.8325312800769974e-05,
      "loss": 0.5984,
      "step": 3689
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.42667731642723083,
      "learning_rate": 5.8286814244465835e-05,
      "loss": 0.858,
      "step": 3690
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.39068201184272766,
      "learning_rate": 5.824831568816169e-05,
      "loss": 0.6344,
      "step": 3691
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4694775938987732,
      "learning_rate": 5.820981713185756e-05,
      "loss": 0.7945,
      "step": 3692
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4482311010360718,
      "learning_rate": 5.8171318575553425e-05,
      "loss": 0.7044,
      "step": 3693
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3968292474746704,
      "learning_rate": 5.813282001924928e-05,
      "loss": 0.8133,
      "step": 3694
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3561042249202728,
      "learning_rate": 5.809432146294515e-05,
      "loss": 0.7466,
      "step": 3695
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3930964469909668,
      "learning_rate": 5.8055822906641e-05,
      "loss": 0.7328,
      "step": 3696
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.398637592792511,
      "learning_rate": 5.801732435033687e-05,
      "loss": 0.599,
      "step": 3697
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5709096789360046,
      "learning_rate": 5.797882579403273e-05,
      "loss": 0.8322,
      "step": 3698
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.36822083592414856,
      "learning_rate": 5.7940327237728584e-05,
      "loss": 0.6271,
      "step": 3699
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3531615138053894,
      "learning_rate": 5.790182868142445e-05,
      "loss": 0.8474,
      "step": 3700
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4811212122440338,
      "learning_rate": 5.7863330125120306e-05,
      "loss": 0.7195,
      "step": 3701
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.46930113434791565,
      "learning_rate": 5.7824831568816174e-05,
      "loss": 0.773,
      "step": 3702
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.33725598454475403,
      "learning_rate": 5.778633301251203e-05,
      "loss": 0.6619,
      "step": 3703
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.34847694635391235,
      "learning_rate": 5.7747834456207896e-05,
      "loss": 0.6736,
      "step": 3704
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4246642291545868,
      "learning_rate": 5.7709335899903764e-05,
      "loss": 0.754,
      "step": 3705
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4066924750804901,
      "learning_rate": 5.767083734359962e-05,
      "loss": 0.8542,
      "step": 3706
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3880156874656677,
      "learning_rate": 5.763233878729548e-05,
      "loss": 0.722,
      "step": 3707
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.416402131319046,
      "learning_rate": 5.759384023099133e-05,
      "loss": 0.8445,
      "step": 3708
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3716920018196106,
      "learning_rate": 5.75553416746872e-05,
      "loss": 0.7263,
      "step": 3709
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.41357338428497314,
      "learning_rate": 5.751684311838307e-05,
      "loss": 0.7584,
      "step": 3710
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.399544358253479,
      "learning_rate": 5.747834456207892e-05,
      "loss": 0.6987,
      "step": 3711
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3467795252799988,
      "learning_rate": 5.743984600577479e-05,
      "loss": 0.8746,
      "step": 3712
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3479870557785034,
      "learning_rate": 5.7401347449470645e-05,
      "loss": 0.7722,
      "step": 3713
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3486725986003876,
      "learning_rate": 5.736284889316651e-05,
      "loss": 0.8163,
      "step": 3714
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.4366104304790497,
      "learning_rate": 5.732435033686237e-05,
      "loss": 0.8665,
      "step": 3715
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3950473964214325,
      "learning_rate": 5.728585178055823e-05,
      "loss": 0.779,
      "step": 3716
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5106235146522522,
      "learning_rate": 5.7247353224254095e-05,
      "loss": 0.973,
      "step": 3717
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.412270188331604,
      "learning_rate": 5.720885466794995e-05,
      "loss": 0.7578,
      "step": 3718
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4312940239906311,
      "learning_rate": 5.717035611164582e-05,
      "loss": 0.5492,
      "step": 3719
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.45574951171875,
      "learning_rate": 5.713185755534167e-05,
      "loss": 0.7095,
      "step": 3720
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4302949905395508,
      "learning_rate": 5.709335899903754e-05,
      "loss": 0.7324,
      "step": 3721
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3691803812980652,
      "learning_rate": 5.705486044273341e-05,
      "loss": 0.9094,
      "step": 3722
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.40040022134780884,
      "learning_rate": 5.701636188642926e-05,
      "loss": 0.6385,
      "step": 3723
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.43812453746795654,
      "learning_rate": 5.697786333012512e-05,
      "loss": 0.873,
      "step": 3724
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.37119513750076294,
      "learning_rate": 5.693936477382098e-05,
      "loss": 0.6124,
      "step": 3725
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4201560616493225,
      "learning_rate": 5.6900866217516844e-05,
      "loss": 0.7594,
      "step": 3726
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5128626823425293,
      "learning_rate": 5.686236766121271e-05,
      "loss": 0.7835,
      "step": 3727
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4030008316040039,
      "learning_rate": 5.6823869104908566e-05,
      "loss": 0.8801,
      "step": 3728
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.35246536135673523,
      "learning_rate": 5.6785370548604434e-05,
      "loss": 0.8248,
      "step": 3729
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3965977728366852,
      "learning_rate": 5.674687199230029e-05,
      "loss": 0.6508,
      "step": 3730
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.37920424342155457,
      "learning_rate": 5.6708373435996156e-05,
      "loss": 0.6833,
      "step": 3731
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5146105289459229,
      "learning_rate": 5.666987487969202e-05,
      "loss": 0.9187,
      "step": 3732
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6653259992599487,
      "learning_rate": 5.663137632338788e-05,
      "loss": 0.7369,
      "step": 3733
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.44713830947875977,
      "learning_rate": 5.659287776708374e-05,
      "loss": 0.9032,
      "step": 3734
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.41780832409858704,
      "learning_rate": 5.655437921077959e-05,
      "loss": 0.7808,
      "step": 3735
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.35999733209609985,
      "learning_rate": 5.651588065447546e-05,
      "loss": 0.6768,
      "step": 3736
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.35587507486343384,
      "learning_rate": 5.6477382098171315e-05,
      "loss": 0.8015,
      "step": 3737
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4075436592102051,
      "learning_rate": 5.643888354186718e-05,
      "loss": 0.873,
      "step": 3738
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3882867693901062,
      "learning_rate": 5.640038498556305e-05,
      "loss": 0.6357,
      "step": 3739
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.34632807970046997,
      "learning_rate": 5.6361886429258905e-05,
      "loss": 0.5563,
      "step": 3740
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4053833484649658,
      "learning_rate": 5.632338787295477e-05,
      "loss": 0.7273,
      "step": 3741
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3809470534324646,
      "learning_rate": 5.6284889316650627e-05,
      "loss": 0.936,
      "step": 3742
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4247629642486572,
      "learning_rate": 5.624639076034649e-05,
      "loss": 0.5575,
      "step": 3743
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.32068026065826416,
      "learning_rate": 5.6207892204042355e-05,
      "loss": 0.7279,
      "step": 3744
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4713924527168274,
      "learning_rate": 5.616939364773821e-05,
      "loss": 0.7448,
      "step": 3745
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.465250700712204,
      "learning_rate": 5.613089509143408e-05,
      "loss": 0.8416,
      "step": 3746
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.39655953645706177,
      "learning_rate": 5.609239653512993e-05,
      "loss": 0.714,
      "step": 3747
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3338613510131836,
      "learning_rate": 5.60538979788258e-05,
      "loss": 0.7556,
      "step": 3748
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.47523587942123413,
      "learning_rate": 5.6015399422521653e-05,
      "loss": 0.9409,
      "step": 3749
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.41861099004745483,
      "learning_rate": 5.597690086621752e-05,
      "loss": 0.7961,
      "step": 3750
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3958723545074463,
      "learning_rate": 5.593840230991338e-05,
      "loss": 0.8489,
      "step": 3751
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.394583135843277,
      "learning_rate": 5.5899903753609236e-05,
      "loss": 0.6951,
      "step": 3752
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.40219536423683167,
      "learning_rate": 5.5861405197305104e-05,
      "loss": 0.7775,
      "step": 3753
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.43686726689338684,
      "learning_rate": 5.582290664100096e-05,
      "loss": 0.9465,
      "step": 3754
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3710174560546875,
      "learning_rate": 5.5784408084696826e-05,
      "loss": 0.8333,
      "step": 3755
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.47770974040031433,
      "learning_rate": 5.5745909528392694e-05,
      "loss": 0.743,
      "step": 3756
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.374896764755249,
      "learning_rate": 5.570741097208855e-05,
      "loss": 0.5304,
      "step": 3757
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.38766101002693176,
      "learning_rate": 5.5668912415784416e-05,
      "loss": 0.7974,
      "step": 3758
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3901181221008301,
      "learning_rate": 5.563041385948027e-05,
      "loss": 0.7686,
      "step": 3759
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.38283416628837585,
      "learning_rate": 5.559191530317613e-05,
      "loss": 0.6398,
      "step": 3760
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4075724184513092,
      "learning_rate": 5.5553416746872e-05,
      "loss": 0.6406,
      "step": 3761
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3504959046840668,
      "learning_rate": 5.551491819056785e-05,
      "loss": 0.7322,
      "step": 3762
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4910171926021576,
      "learning_rate": 5.547641963426372e-05,
      "loss": 0.8718,
      "step": 3763
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4601994454860687,
      "learning_rate": 5.5437921077959575e-05,
      "loss": 0.6583,
      "step": 3764
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.44386953115463257,
      "learning_rate": 5.539942252165544e-05,
      "loss": 0.7549,
      "step": 3765
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.38392552733421326,
      "learning_rate": 5.53609239653513e-05,
      "loss": 0.7318,
      "step": 3766
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.38322752714157104,
      "learning_rate": 5.5322425409047165e-05,
      "loss": 0.7312,
      "step": 3767
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.33826324343681335,
      "learning_rate": 5.5283926852743026e-05,
      "loss": 0.7363,
      "step": 3768
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.36971837282180786,
      "learning_rate": 5.5245428296438887e-05,
      "loss": 0.6578,
      "step": 3769
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.38461020588874817,
      "learning_rate": 5.520692974013475e-05,
      "loss": 0.7203,
      "step": 3770
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.42068564891815186,
      "learning_rate": 5.51684311838306e-05,
      "loss": 0.7118,
      "step": 3771
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.438556432723999,
      "learning_rate": 5.512993262752647e-05,
      "loss": 0.7335,
      "step": 3772
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.40845900774002075,
      "learning_rate": 5.509143407122234e-05,
      "loss": 0.6255,
      "step": 3773
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.37250345945358276,
      "learning_rate": 5.505293551491819e-05,
      "loss": 0.5997,
      "step": 3774
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.34678182005882263,
      "learning_rate": 5.501443695861406e-05,
      "loss": 0.8858,
      "step": 3775
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.45218175649642944,
      "learning_rate": 5.497593840230991e-05,
      "loss": 0.6278,
      "step": 3776
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.48590192198753357,
      "learning_rate": 5.493743984600578e-05,
      "loss": 0.6704,
      "step": 3777
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3690586984157562,
      "learning_rate": 5.489894128970164e-05,
      "loss": 0.8048,
      "step": 3778
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4429152309894562,
      "learning_rate": 5.4860442733397496e-05,
      "loss": 0.6758,
      "step": 3779
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.388174444437027,
      "learning_rate": 5.4821944177093364e-05,
      "loss": 0.8465,
      "step": 3780
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.2994019687175751,
      "learning_rate": 5.478344562078922e-05,
      "loss": 0.8863,
      "step": 3781
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3885720670223236,
      "learning_rate": 5.4744947064485086e-05,
      "loss": 0.6953,
      "step": 3782
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.45301732420921326,
      "learning_rate": 5.470644850818094e-05,
      "loss": 0.7726,
      "step": 3783
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.387052059173584,
      "learning_rate": 5.466794995187681e-05,
      "loss": 0.787,
      "step": 3784
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4151194989681244,
      "learning_rate": 5.4629451395572676e-05,
      "loss": 0.6529,
      "step": 3785
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.37400269508361816,
      "learning_rate": 5.459095283926853e-05,
      "loss": 0.5978,
      "step": 3786
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.42435580492019653,
      "learning_rate": 5.455245428296439e-05,
      "loss": 0.6053,
      "step": 3787
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3577536344528198,
      "learning_rate": 5.451395572666025e-05,
      "loss": 0.6964,
      "step": 3788
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.38286492228507996,
      "learning_rate": 5.447545717035611e-05,
      "loss": 0.6675,
      "step": 3789
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.34839528799057007,
      "learning_rate": 5.443695861405198e-05,
      "loss": 0.6892,
      "step": 3790
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.41482099890708923,
      "learning_rate": 5.4398460057747835e-05,
      "loss": 0.8671,
      "step": 3791
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5817440748214722,
      "learning_rate": 5.43599615014437e-05,
      "loss": 0.7672,
      "step": 3792
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.43292370438575745,
      "learning_rate": 5.432146294513956e-05,
      "loss": 0.6973,
      "step": 3793
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3916992247104645,
      "learning_rate": 5.4282964388835425e-05,
      "loss": 0.8197,
      "step": 3794
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.40335050225257874,
      "learning_rate": 5.4244465832531286e-05,
      "loss": 0.8012,
      "step": 3795
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3920685946941376,
      "learning_rate": 5.4205967276227146e-05,
      "loss": 0.7473,
      "step": 3796
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.38917019963264465,
      "learning_rate": 5.416746871992301e-05,
      "loss": 0.6063,
      "step": 3797
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3373540937900543,
      "learning_rate": 5.412897016361886e-05,
      "loss": 0.8698,
      "step": 3798
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4301537573337555,
      "learning_rate": 5.409047160731473e-05,
      "loss": 0.7742,
      "step": 3799
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4730338156223297,
      "learning_rate": 5.4051973051010584e-05,
      "loss": 0.6781,
      "step": 3800
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.43444186449050903,
      "learning_rate": 5.401347449470645e-05,
      "loss": 0.8855,
      "step": 3801
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5065397620201111,
      "learning_rate": 5.397497593840232e-05,
      "loss": 0.7568,
      "step": 3802
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.44098222255706787,
      "learning_rate": 5.393647738209817e-05,
      "loss": 0.7024,
      "step": 3803
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.43243008852005005,
      "learning_rate": 5.3897978825794034e-05,
      "loss": 1.0099,
      "step": 3804
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.42063066363334656,
      "learning_rate": 5.3859480269489895e-05,
      "loss": 0.9715,
      "step": 3805
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.37045758962631226,
      "learning_rate": 5.3820981713185756e-05,
      "loss": 0.6562,
      "step": 3806
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4258107542991638,
      "learning_rate": 5.3782483156881624e-05,
      "loss": 0.7114,
      "step": 3807
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4506259560585022,
      "learning_rate": 5.374398460057748e-05,
      "loss": 0.7489,
      "step": 3808
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3385767936706543,
      "learning_rate": 5.3705486044273346e-05,
      "loss": 0.729,
      "step": 3809
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.4253707528114319,
      "learning_rate": 5.36669874879692e-05,
      "loss": 0.9121,
      "step": 3810
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.38890931010246277,
      "learning_rate": 5.362848893166507e-05,
      "loss": 0.7439,
      "step": 3811
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3211326003074646,
      "learning_rate": 5.358999037536092e-05,
      "loss": 0.7765,
      "step": 3812
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3999495804309845,
      "learning_rate": 5.355149181905679e-05,
      "loss": 0.9395,
      "step": 3813
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.33503755927085876,
      "learning_rate": 5.351299326275265e-05,
      "loss": 0.8519,
      "step": 3814
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.36528387665748596,
      "learning_rate": 5.3474494706448505e-05,
      "loss": 0.7419,
      "step": 3815
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3548148572444916,
      "learning_rate": 5.343599615014437e-05,
      "loss": 0.7721,
      "step": 3816
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5692758560180664,
      "learning_rate": 5.339749759384023e-05,
      "loss": 0.8037,
      "step": 3817
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.35835886001586914,
      "learning_rate": 5.3358999037536095e-05,
      "loss": 0.9861,
      "step": 3818
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.39795008301734924,
      "learning_rate": 5.332050048123196e-05,
      "loss": 0.7762,
      "step": 3819
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.45852744579315186,
      "learning_rate": 5.328200192492782e-05,
      "loss": 0.8158,
      "step": 3820
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.463274210691452,
      "learning_rate": 5.3243503368623684e-05,
      "loss": 0.6633,
      "step": 3821
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3755810260772705,
      "learning_rate": 5.320500481231954e-05,
      "loss": 0.7054,
      "step": 3822
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4277154803276062,
      "learning_rate": 5.31665062560154e-05,
      "loss": 0.6835,
      "step": 3823
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.33547794818878174,
      "learning_rate": 5.312800769971127e-05,
      "loss": 0.7756,
      "step": 3824
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4167879521846771,
      "learning_rate": 5.308950914340712e-05,
      "loss": 0.8944,
      "step": 3825
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4162890613079071,
      "learning_rate": 5.305101058710299e-05,
      "loss": 0.8837,
      "step": 3826
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3872286379337311,
      "learning_rate": 5.3012512030798844e-05,
      "loss": 0.6146,
      "step": 3827
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3960224986076355,
      "learning_rate": 5.297401347449471e-05,
      "loss": 0.6489,
      "step": 3828
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.42553699016571045,
      "learning_rate": 5.2935514918190566e-05,
      "loss": 0.7446,
      "step": 3829
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.44597360491752625,
      "learning_rate": 5.289701636188643e-05,
      "loss": 0.72,
      "step": 3830
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3493512272834778,
      "learning_rate": 5.2858517805582294e-05,
      "loss": 0.8885,
      "step": 3831
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.36227479577064514,
      "learning_rate": 5.2820019249278155e-05,
      "loss": 0.7286,
      "step": 3832
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3750463128089905,
      "learning_rate": 5.2781520692974016e-05,
      "loss": 0.8252,
      "step": 3833
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.40169158577919006,
      "learning_rate": 5.274302213666987e-05,
      "loss": 0.5889,
      "step": 3834
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3480648398399353,
      "learning_rate": 5.270452358036574e-05,
      "loss": 0.8669,
      "step": 3835
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.43466049432754517,
      "learning_rate": 5.2666025024061606e-05,
      "loss": 0.9853,
      "step": 3836
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3506540060043335,
      "learning_rate": 5.262752646775746e-05,
      "loss": 0.763,
      "step": 3837
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.33941906690597534,
      "learning_rate": 5.258902791145333e-05,
      "loss": 0.8623,
      "step": 3838
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3787666857242584,
      "learning_rate": 5.255052935514918e-05,
      "loss": 0.6358,
      "step": 3839
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3575912117958069,
      "learning_rate": 5.251203079884505e-05,
      "loss": 0.9079,
      "step": 3840
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4641791582107544,
      "learning_rate": 5.247353224254091e-05,
      "loss": 0.7888,
      "step": 3841
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.35689154267311096,
      "learning_rate": 5.2435033686236765e-05,
      "loss": 0.8431,
      "step": 3842
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4360233247280121,
      "learning_rate": 5.239653512993263e-05,
      "loss": 0.6498,
      "step": 3843
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3721139430999756,
      "learning_rate": 5.235803657362849e-05,
      "loss": 0.6766,
      "step": 3844
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.38227951526641846,
      "learning_rate": 5.2319538017324355e-05,
      "loss": 0.8783,
      "step": 3845
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4405427873134613,
      "learning_rate": 5.228103946102021e-05,
      "loss": 0.6891,
      "step": 3846
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4635028541088104,
      "learning_rate": 5.224254090471608e-05,
      "loss": 0.6673,
      "step": 3847
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.46735680103302,
      "learning_rate": 5.2204042348411944e-05,
      "loss": 0.7535,
      "step": 3848
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.33231863379478455,
      "learning_rate": 5.21655437921078e-05,
      "loss": 0.8858,
      "step": 3849
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4084357023239136,
      "learning_rate": 5.212704523580366e-05,
      "loss": 0.6817,
      "step": 3850
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3839572072029114,
      "learning_rate": 5.2088546679499514e-05,
      "loss": 0.6286,
      "step": 3851
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.45361125469207764,
      "learning_rate": 5.205004812319538e-05,
      "loss": 0.5437,
      "step": 3852
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.49717947840690613,
      "learning_rate": 5.201154956689125e-05,
      "loss": 1.0004,
      "step": 3853
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3785237669944763,
      "learning_rate": 5.1973051010587104e-05,
      "loss": 0.6417,
      "step": 3854
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.38520926237106323,
      "learning_rate": 5.193455245428297e-05,
      "loss": 0.7209,
      "step": 3855
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.40163010358810425,
      "learning_rate": 5.1896053897978826e-05,
      "loss": 0.7469,
      "step": 3856
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4089224636554718,
      "learning_rate": 5.185755534167469e-05,
      "loss": 0.6568,
      "step": 3857
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.34596332907676697,
      "learning_rate": 5.1819056785370554e-05,
      "loss": 0.8753,
      "step": 3858
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3727802336215973,
      "learning_rate": 5.178055822906641e-05,
      "loss": 0.7491,
      "step": 3859
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.37358734011650085,
      "learning_rate": 5.1742059672762276e-05,
      "loss": 0.7295,
      "step": 3860
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4000478982925415,
      "learning_rate": 5.170356111645813e-05,
      "loss": 0.7298,
      "step": 3861
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.40190601348876953,
      "learning_rate": 5.1665062560154e-05,
      "loss": 0.6673,
      "step": 3862
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.32522591948509216,
      "learning_rate": 5.162656400384985e-05,
      "loss": 0.6836,
      "step": 3863
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.40347716212272644,
      "learning_rate": 5.158806544754572e-05,
      "loss": 0.8811,
      "step": 3864
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.33275747299194336,
      "learning_rate": 5.154956689124159e-05,
      "loss": 0.8449,
      "step": 3865
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3967568278312683,
      "learning_rate": 5.151106833493744e-05,
      "loss": 0.6754,
      "step": 3866
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.37105900049209595,
      "learning_rate": 5.14725697786333e-05,
      "loss": 0.8172,
      "step": 3867
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4268190562725067,
      "learning_rate": 5.1434071222329164e-05,
      "loss": 0.7733,
      "step": 3868
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3348953127861023,
      "learning_rate": 5.1395572666025025e-05,
      "loss": 0.7263,
      "step": 3869
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3597233295440674,
      "learning_rate": 5.135707410972089e-05,
      "loss": 0.7906,
      "step": 3870
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3743017911911011,
      "learning_rate": 5.131857555341675e-05,
      "loss": 0.5757,
      "step": 3871
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3033504784107208,
      "learning_rate": 5.1280076997112615e-05,
      "loss": 0.8202,
      "step": 3872
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4399469792842865,
      "learning_rate": 5.124157844080847e-05,
      "loss": 0.7954,
      "step": 3873
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.37195059657096863,
      "learning_rate": 5.120307988450434e-05,
      "loss": 0.7852,
      "step": 3874
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3971180021762848,
      "learning_rate": 5.116458132820019e-05,
      "loss": 0.7563,
      "step": 3875
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4384136199951172,
      "learning_rate": 5.112608277189606e-05,
      "loss": 1.0849,
      "step": 3876
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3733925223350525,
      "learning_rate": 5.108758421559192e-05,
      "loss": 0.8753,
      "step": 3877
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.49590709805488586,
      "learning_rate": 5.1049085659287774e-05,
      "loss": 0.8479,
      "step": 3878
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3129790127277374,
      "learning_rate": 5.101058710298364e-05,
      "loss": 0.7972,
      "step": 3879
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3719448447227478,
      "learning_rate": 5.0972088546679496e-05,
      "loss": 0.7654,
      "step": 3880
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4728415012359619,
      "learning_rate": 5.0933589990375364e-05,
      "loss": 0.8113,
      "step": 3881
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.39372262358665466,
      "learning_rate": 5.089509143407123e-05,
      "loss": 0.8994,
      "step": 3882
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3817494511604309,
      "learning_rate": 5.0856592877767085e-05,
      "loss": 0.7187,
      "step": 3883
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.40600571036338806,
      "learning_rate": 5.081809432146295e-05,
      "loss": 0.7645,
      "step": 3884
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.47542455792427063,
      "learning_rate": 5.077959576515881e-05,
      "loss": 0.7404,
      "step": 3885
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.45335376262664795,
      "learning_rate": 5.074109720885467e-05,
      "loss": 0.7409,
      "step": 3886
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3872758448123932,
      "learning_rate": 5.0702598652550536e-05,
      "loss": 0.6564,
      "step": 3887
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.40557244420051575,
      "learning_rate": 5.066410009624639e-05,
      "loss": 0.692,
      "step": 3888
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3975888788700104,
      "learning_rate": 5.062560153994226e-05,
      "loss": 0.6937,
      "step": 3889
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4274806082248688,
      "learning_rate": 5.058710298363811e-05,
      "loss": 0.6408,
      "step": 3890
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.42763960361480713,
      "learning_rate": 5.054860442733398e-05,
      "loss": 0.9159,
      "step": 3891
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.37838318943977356,
      "learning_rate": 5.0510105871029834e-05,
      "loss": 0.7791,
      "step": 3892
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3891552686691284,
      "learning_rate": 5.04716073147257e-05,
      "loss": 0.6925,
      "step": 3893
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.35511907935142517,
      "learning_rate": 5.043310875842156e-05,
      "loss": 0.782,
      "step": 3894
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.719667911529541,
      "learning_rate": 5.039461020211742e-05,
      "loss": 0.6918,
      "step": 3895
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.42965471744537354,
      "learning_rate": 5.0356111645813285e-05,
      "loss": 0.6223,
      "step": 3896
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4154968857765198,
      "learning_rate": 5.031761308950914e-05,
      "loss": 0.7169,
      "step": 3897
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.39789721369743347,
      "learning_rate": 5.027911453320501e-05,
      "loss": 0.7222,
      "step": 3898
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.42072704434394836,
      "learning_rate": 5.0240615976900875e-05,
      "loss": 0.6213,
      "step": 3899
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.515986442565918,
      "learning_rate": 5.020211742059673e-05,
      "loss": 0.7637,
      "step": 3900
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.38145938515663147,
      "learning_rate": 5.01636188642926e-05,
      "loss": 0.7647,
      "step": 3901
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4633360803127289,
      "learning_rate": 5.012512030798845e-05,
      "loss": 0.6977,
      "step": 3902
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3654901087284088,
      "learning_rate": 5.008662175168431e-05,
      "loss": 0.709,
      "step": 3903
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.33284255862236023,
      "learning_rate": 5.004812319538018e-05,
      "loss": 0.6966,
      "step": 3904
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3967297077178955,
      "learning_rate": 5.0009624639076034e-05,
      "loss": 1.0353,
      "step": 3905
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.41219964623451233,
      "learning_rate": 4.9971126082771895e-05,
      "loss": 0.6896,
      "step": 3906
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4449569284915924,
      "learning_rate": 4.993262752646776e-05,
      "loss": 0.7878,
      "step": 3907
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3527185916900635,
      "learning_rate": 4.9894128970163623e-05,
      "loss": 0.7663,
      "step": 3908
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3970593810081482,
      "learning_rate": 4.9855630413859484e-05,
      "loss": 0.774,
      "step": 3909
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4697403311729431,
      "learning_rate": 4.9817131857555345e-05,
      "loss": 0.9017,
      "step": 3910
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.346177339553833,
      "learning_rate": 4.9778633301251206e-05,
      "loss": 0.6471,
      "step": 3911
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.34898626804351807,
      "learning_rate": 4.974013474494707e-05,
      "loss": 0.8955,
      "step": 3912
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.40716883540153503,
      "learning_rate": 4.970163618864293e-05,
      "loss": 0.8012,
      "step": 3913
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.35069823265075684,
      "learning_rate": 4.966313763233879e-05,
      "loss": 0.7046,
      "step": 3914
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4812348783016205,
      "learning_rate": 4.962463907603465e-05,
      "loss": 0.6667,
      "step": 3915
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.37536755204200745,
      "learning_rate": 4.958614051973051e-05,
      "loss": 0.6091,
      "step": 3916
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5201338529586792,
      "learning_rate": 4.954764196342637e-05,
      "loss": 0.7293,
      "step": 3917
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.45286014676094055,
      "learning_rate": 4.950914340712223e-05,
      "loss": 0.6935,
      "step": 3918
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3278251588344574,
      "learning_rate": 4.94706448508181e-05,
      "loss": 0.9955,
      "step": 3919
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4781845211982727,
      "learning_rate": 4.943214629451396e-05,
      "loss": 0.7266,
      "step": 3920
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.42019888758659363,
      "learning_rate": 4.9393647738209816e-05,
      "loss": 0.7318,
      "step": 3921
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3796842098236084,
      "learning_rate": 4.935514918190568e-05,
      "loss": 0.7588,
      "step": 3922
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.32410430908203125,
      "learning_rate": 4.931665062560154e-05,
      "loss": 0.7528,
      "step": 3923
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.34484606981277466,
      "learning_rate": 4.9278152069297406e-05,
      "loss": 0.6293,
      "step": 3924
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4573054611682892,
      "learning_rate": 4.923965351299327e-05,
      "loss": 0.8057,
      "step": 3925
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3718336224555969,
      "learning_rate": 4.920115495668913e-05,
      "loss": 0.5627,
      "step": 3926
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3647492527961731,
      "learning_rate": 4.916265640038499e-05,
      "loss": 0.7243,
      "step": 3927
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4459307789802551,
      "learning_rate": 4.912415784408085e-05,
      "loss": 0.7522,
      "step": 3928
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.32904890179634094,
      "learning_rate": 4.908565928777671e-05,
      "loss": 0.7245,
      "step": 3929
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.43478986620903015,
      "learning_rate": 4.904716073147257e-05,
      "loss": 0.7639,
      "step": 3930
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.33302319049835205,
      "learning_rate": 4.900866217516843e-05,
      "loss": 0.8672,
      "step": 3931
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4209674596786499,
      "learning_rate": 4.8970163618864294e-05,
      "loss": 0.6304,
      "step": 3932
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3612850308418274,
      "learning_rate": 4.8931665062560155e-05,
      "loss": 0.7817,
      "step": 3933
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4088508188724518,
      "learning_rate": 4.8893166506256016e-05,
      "loss": 0.6473,
      "step": 3934
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4361610412597656,
      "learning_rate": 4.885466794995188e-05,
      "loss": 0.5422,
      "step": 3935
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3954405188560486,
      "learning_rate": 4.8816169393647744e-05,
      "loss": 0.7905,
      "step": 3936
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.40728291869163513,
      "learning_rate": 4.8777670837343605e-05,
      "loss": 0.7337,
      "step": 3937
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.38086992502212524,
      "learning_rate": 4.8739172281039466e-05,
      "loss": 0.7639,
      "step": 3938
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4041711091995239,
      "learning_rate": 4.870067372473533e-05,
      "loss": 0.6834,
      "step": 3939
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.31438738107681274,
      "learning_rate": 4.866217516843118e-05,
      "loss": 0.6847,
      "step": 3940
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.37431037425994873,
      "learning_rate": 4.862367661212704e-05,
      "loss": 0.761,
      "step": 3941
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3736584186553955,
      "learning_rate": 4.858517805582291e-05,
      "loss": 0.7315,
      "step": 3942
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4389069676399231,
      "learning_rate": 4.854667949951877e-05,
      "loss": 0.5223,
      "step": 3943
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.39805662631988525,
      "learning_rate": 4.850818094321463e-05,
      "loss": 0.6917,
      "step": 3944
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3589307963848114,
      "learning_rate": 4.846968238691049e-05,
      "loss": 0.6354,
      "step": 3945
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.38092297315597534,
      "learning_rate": 4.8431183830606354e-05,
      "loss": 0.6371,
      "step": 3946
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3665209114551544,
      "learning_rate": 4.8392685274302215e-05,
      "loss": 0.6672,
      "step": 3947
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.39192190766334534,
      "learning_rate": 4.8354186717998076e-05,
      "loss": 0.7475,
      "step": 3948
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.481959730386734,
      "learning_rate": 4.831568816169394e-05,
      "loss": 0.7039,
      "step": 3949
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3952530324459076,
      "learning_rate": 4.82771896053898e-05,
      "loss": 0.9314,
      "step": 3950
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4128325283527374,
      "learning_rate": 4.823869104908566e-05,
      "loss": 0.6532,
      "step": 3951
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4395389258861542,
      "learning_rate": 4.820019249278152e-05,
      "loss": 0.7075,
      "step": 3952
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5030907988548279,
      "learning_rate": 4.816169393647739e-05,
      "loss": 0.8956,
      "step": 3953
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.34798577427864075,
      "learning_rate": 4.812319538017325e-05,
      "loss": 0.536,
      "step": 3954
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3133717477321625,
      "learning_rate": 4.808469682386911e-05,
      "loss": 0.5591,
      "step": 3955
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4060627520084381,
      "learning_rate": 4.804619826756497e-05,
      "loss": 0.8655,
      "step": 3956
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4152657985687256,
      "learning_rate": 4.800769971126083e-05,
      "loss": 0.8023,
      "step": 3957
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3353104591369629,
      "learning_rate": 4.7969201154956686e-05,
      "loss": 0.7677,
      "step": 3958
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.38185784220695496,
      "learning_rate": 4.7930702598652554e-05,
      "loss": 0.8227,
      "step": 3959
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4023623764514923,
      "learning_rate": 4.7892204042348415e-05,
      "loss": 0.7836,
      "step": 3960
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3826655149459839,
      "learning_rate": 4.7853705486044276e-05,
      "loss": 0.6657,
      "step": 3961
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4329468905925751,
      "learning_rate": 4.781520692974014e-05,
      "loss": 0.7128,
      "step": 3962
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.35682523250579834,
      "learning_rate": 4.7776708373436e-05,
      "loss": 0.8615,
      "step": 3963
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.39820948243141174,
      "learning_rate": 4.7738209817131865e-05,
      "loss": 0.5874,
      "step": 3964
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.415760338306427,
      "learning_rate": 4.7699711260827726e-05,
      "loss": 0.7824,
      "step": 3965
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.391759991645813,
      "learning_rate": 4.766121270452358e-05,
      "loss": 0.7632,
      "step": 3966
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3897961974143982,
      "learning_rate": 4.762271414821944e-05,
      "loss": 0.7504,
      "step": 3967
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.44187796115875244,
      "learning_rate": 4.75842155919153e-05,
      "loss": 0.7263,
      "step": 3968
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4519312381744385,
      "learning_rate": 4.7545717035611163e-05,
      "loss": 0.8662,
      "step": 3969
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4007473587989807,
      "learning_rate": 4.750721847930703e-05,
      "loss": 0.7348,
      "step": 3970
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3821762800216675,
      "learning_rate": 4.746871992300289e-05,
      "loss": 0.7422,
      "step": 3971
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3540780544281006,
      "learning_rate": 4.743022136669875e-05,
      "loss": 0.8529,
      "step": 3972
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.41334906220436096,
      "learning_rate": 4.7391722810394614e-05,
      "loss": 0.7343,
      "step": 3973
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4030512869358063,
      "learning_rate": 4.7353224254090475e-05,
      "loss": 0.8637,
      "step": 3974
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.41394612193107605,
      "learning_rate": 4.7314725697786336e-05,
      "loss": 0.6548,
      "step": 3975
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4198540151119232,
      "learning_rate": 4.72762271414822e-05,
      "loss": 0.6711,
      "step": 3976
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.36285200715065,
      "learning_rate": 4.723772858517806e-05,
      "loss": 0.8683,
      "step": 3977
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.44113361835479736,
      "learning_rate": 4.719923002887392e-05,
      "loss": 0.7605,
      "step": 3978
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.40789374709129333,
      "learning_rate": 4.716073147256978e-05,
      "loss": 0.8931,
      "step": 3979
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.43639445304870605,
      "learning_rate": 4.712223291626564e-05,
      "loss": 0.6748,
      "step": 3980
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3716842234134674,
      "learning_rate": 4.70837343599615e-05,
      "loss": 0.6845,
      "step": 3981
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3813808560371399,
      "learning_rate": 4.704523580365737e-05,
      "loss": 0.7054,
      "step": 3982
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.582696795463562,
      "learning_rate": 4.700673724735323e-05,
      "loss": 0.6604,
      "step": 3983
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4158656895160675,
      "learning_rate": 4.6968238691049085e-05,
      "loss": 0.6556,
      "step": 3984
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4453727602958679,
      "learning_rate": 4.6929740134744946e-05,
      "loss": 0.7852,
      "step": 3985
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4198744297027588,
      "learning_rate": 4.689124157844081e-05,
      "loss": 0.8317,
      "step": 3986
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3381423056125641,
      "learning_rate": 4.6852743022136675e-05,
      "loss": 0.8771,
      "step": 3987
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3955591320991516,
      "learning_rate": 4.6814244465832536e-05,
      "loss": 0.8265,
      "step": 3988
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.36785271763801575,
      "learning_rate": 4.6775745909528397e-05,
      "loss": 0.7296,
      "step": 3989
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4168741703033447,
      "learning_rate": 4.673724735322426e-05,
      "loss": 0.7414,
      "step": 3990
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4088538885116577,
      "learning_rate": 4.669874879692012e-05,
      "loss": 0.7711,
      "step": 3991
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3469531834125519,
      "learning_rate": 4.666025024061598e-05,
      "loss": 0.9096,
      "step": 3992
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3838264048099518,
      "learning_rate": 4.662175168431184e-05,
      "loss": 0.7084,
      "step": 3993
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4506266415119171,
      "learning_rate": 4.65832531280077e-05,
      "loss": 0.6438,
      "step": 3994
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4503701329231262,
      "learning_rate": 4.654475457170356e-05,
      "loss": 0.7604,
      "step": 3995
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.34327879548072815,
      "learning_rate": 4.6506256015399423e-05,
      "loss": 0.7828,
      "step": 3996
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4293116331100464,
      "learning_rate": 4.6467757459095284e-05,
      "loss": 0.758,
      "step": 3997
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3839147090911865,
      "learning_rate": 4.6429258902791145e-05,
      "loss": 0.9662,
      "step": 3998
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3913445472717285,
      "learning_rate": 4.639076034648701e-05,
      "loss": 0.643,
      "step": 3999
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.44219937920570374,
      "learning_rate": 4.6352261790182874e-05,
      "loss": 0.9003,
      "step": 4000
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3997859060764313,
      "learning_rate": 4.6313763233878735e-05,
      "loss": 0.7232,
      "step": 4001
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.43605348467826843,
      "learning_rate": 4.627526467757459e-05,
      "loss": 0.8061,
      "step": 4002
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4250580072402954,
      "learning_rate": 4.623676612127045e-05,
      "loss": 0.7091,
      "step": 4003
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.380997896194458,
      "learning_rate": 4.619826756496631e-05,
      "loss": 0.7349,
      "step": 4004
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.45522794127464294,
      "learning_rate": 4.615976900866218e-05,
      "loss": 0.6184,
      "step": 4005
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.38472455739974976,
      "learning_rate": 4.612127045235804e-05,
      "loss": 0.7787,
      "step": 4006
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.37412047386169434,
      "learning_rate": 4.60827718960539e-05,
      "loss": 0.6307,
      "step": 4007
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4412579834461212,
      "learning_rate": 4.604427333974976e-05,
      "loss": 0.8174,
      "step": 4008
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3796052932739258,
      "learning_rate": 4.600577478344562e-05,
      "loss": 0.7452,
      "step": 4009
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3925088346004486,
      "learning_rate": 4.5967276227141484e-05,
      "loss": 0.6891,
      "step": 4010
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3966805338859558,
      "learning_rate": 4.5928777670837345e-05,
      "loss": 0.6811,
      "step": 4011
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.40873321890830994,
      "learning_rate": 4.5890279114533206e-05,
      "loss": 0.6968,
      "step": 4012
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.39418327808380127,
      "learning_rate": 4.585178055822907e-05,
      "loss": 0.7459,
      "step": 4013
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.42193353176116943,
      "learning_rate": 4.581328200192493e-05,
      "loss": 0.6705,
      "step": 4014
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.38888514041900635,
      "learning_rate": 4.577478344562079e-05,
      "loss": 0.5768,
      "step": 4015
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3432210683822632,
      "learning_rate": 4.5736284889316657e-05,
      "loss": 0.8105,
      "step": 4016
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3922610878944397,
      "learning_rate": 4.569778633301252e-05,
      "loss": 0.714,
      "step": 4017
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3980928063392639,
      "learning_rate": 4.565928777670838e-05,
      "loss": 0.8427,
      "step": 4018
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.452888160943985,
      "learning_rate": 4.562078922040424e-05,
      "loss": 0.8183,
      "step": 4019
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5716364979743958,
      "learning_rate": 4.5582290664100094e-05,
      "loss": 0.7152,
      "step": 4020
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.41255640983581543,
      "learning_rate": 4.5543792107795955e-05,
      "loss": 0.7855,
      "step": 4021
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3797330856323242,
      "learning_rate": 4.550529355149182e-05,
      "loss": 0.706,
      "step": 4022
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.456696093082428,
      "learning_rate": 4.5466794995187683e-05,
      "loss": 0.8579,
      "step": 4023
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.46888861060142517,
      "learning_rate": 4.5428296438883544e-05,
      "loss": 0.7731,
      "step": 4024
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3780898451805115,
      "learning_rate": 4.5389797882579405e-05,
      "loss": 0.8053,
      "step": 4025
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4200544059276581,
      "learning_rate": 4.5351299326275266e-05,
      "loss": 0.6716,
      "step": 4026
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.40138980746269226,
      "learning_rate": 4.5312800769971134e-05,
      "loss": 0.8407,
      "step": 4027
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.42660465836524963,
      "learning_rate": 4.527430221366699e-05,
      "loss": 0.9887,
      "step": 4028
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4221378266811371,
      "learning_rate": 4.523580365736285e-05,
      "loss": 0.6453,
      "step": 4029
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.44818150997161865,
      "learning_rate": 4.519730510105871e-05,
      "loss": 0.8341,
      "step": 4030
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5069273114204407,
      "learning_rate": 4.515880654475457e-05,
      "loss": 0.6496,
      "step": 4031
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4701189696788788,
      "learning_rate": 4.512030798845043e-05,
      "loss": 0.674,
      "step": 4032
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5130579471588135,
      "learning_rate": 4.50818094321463e-05,
      "loss": 0.8001,
      "step": 4033
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4180683493614197,
      "learning_rate": 4.504331087584216e-05,
      "loss": 0.737,
      "step": 4034
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6313657164573669,
      "learning_rate": 4.500481231953802e-05,
      "loss": 0.6948,
      "step": 4035
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4243100881576538,
      "learning_rate": 4.496631376323388e-05,
      "loss": 0.6123,
      "step": 4036
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.37810876965522766,
      "learning_rate": 4.4927815206929744e-05,
      "loss": 0.7888,
      "step": 4037
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3697306215763092,
      "learning_rate": 4.48893166506256e-05,
      "loss": 0.8599,
      "step": 4038
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3702017664909363,
      "learning_rate": 4.4850818094321466e-05,
      "loss": 0.6477,
      "step": 4039
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4409281611442566,
      "learning_rate": 4.481231953801733e-05,
      "loss": 0.6186,
      "step": 4040
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.428661972284317,
      "learning_rate": 4.477382098171319e-05,
      "loss": 0.8078,
      "step": 4041
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4260847568511963,
      "learning_rate": 4.473532242540905e-05,
      "loss": 0.658,
      "step": 4042
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.47948652505874634,
      "learning_rate": 4.469682386910491e-05,
      "loss": 0.7291,
      "step": 4043
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.32554465532302856,
      "learning_rate": 4.465832531280077e-05,
      "loss": 0.7357,
      "step": 4044
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.32498690485954285,
      "learning_rate": 4.461982675649664e-05,
      "loss": 0.6824,
      "step": 4045
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3562188446521759,
      "learning_rate": 4.458132820019249e-05,
      "loss": 0.7334,
      "step": 4046
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.38181138038635254,
      "learning_rate": 4.4542829643888354e-05,
      "loss": 0.7828,
      "step": 4047
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4645785987377167,
      "learning_rate": 4.4504331087584215e-05,
      "loss": 0.7751,
      "step": 4048
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4139486253261566,
      "learning_rate": 4.4465832531280076e-05,
      "loss": 0.6718,
      "step": 4049
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.43046075105667114,
      "learning_rate": 4.442733397497594e-05,
      "loss": 0.7888,
      "step": 4050
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4130885601043701,
      "learning_rate": 4.4388835418671804e-05,
      "loss": 0.8118,
      "step": 4051
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.43680325150489807,
      "learning_rate": 4.4350336862367665e-05,
      "loss": 0.756,
      "step": 4052
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3825511634349823,
      "learning_rate": 4.4311838306063526e-05,
      "loss": 0.584,
      "step": 4053
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3823602795600891,
      "learning_rate": 4.427333974975939e-05,
      "loss": 0.6731,
      "step": 4054
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.358705073595047,
      "learning_rate": 4.423484119345525e-05,
      "loss": 0.7389,
      "step": 4055
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3784716725349426,
      "learning_rate": 4.419634263715111e-05,
      "loss": 0.7114,
      "step": 4056
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3927147090435028,
      "learning_rate": 4.415784408084697e-05,
      "loss": 0.6615,
      "step": 4057
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3819684386253357,
      "learning_rate": 4.411934552454283e-05,
      "loss": 0.7914,
      "step": 4058
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5218636393547058,
      "learning_rate": 4.408084696823869e-05,
      "loss": 0.7199,
      "step": 4059
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3958226442337036,
      "learning_rate": 4.404234841193455e-05,
      "loss": 0.7694,
      "step": 4060
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5899584293365479,
      "learning_rate": 4.4003849855630414e-05,
      "loss": 0.7206,
      "step": 4061
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.32218053936958313,
      "learning_rate": 4.396535129932628e-05,
      "loss": 0.8291,
      "step": 4062
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.39509621262550354,
      "learning_rate": 4.392685274302214e-05,
      "loss": 0.6737,
      "step": 4063
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3362116813659668,
      "learning_rate": 4.3888354186718e-05,
      "loss": 0.8266,
      "step": 4064
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3743574321269989,
      "learning_rate": 4.384985563041386e-05,
      "loss": 0.6652,
      "step": 4065
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3909912407398224,
      "learning_rate": 4.381135707410972e-05,
      "loss": 0.6749,
      "step": 4066
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3751114308834076,
      "learning_rate": 4.377285851780558e-05,
      "loss": 0.6735,
      "step": 4067
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3708484172821045,
      "learning_rate": 4.373435996150145e-05,
      "loss": 0.8085,
      "step": 4068
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4076661169528961,
      "learning_rate": 4.369586140519731e-05,
      "loss": 0.5513,
      "step": 4069
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3502558767795563,
      "learning_rate": 4.365736284889317e-05,
      "loss": 0.6989,
      "step": 4070
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.38922539353370667,
      "learning_rate": 4.361886429258903e-05,
      "loss": 0.8562,
      "step": 4071
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.37474602460861206,
      "learning_rate": 4.358036573628489e-05,
      "loss": 0.7655,
      "step": 4072
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.34060144424438477,
      "learning_rate": 4.354186717998075e-05,
      "loss": 0.5771,
      "step": 4073
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3719419836997986,
      "learning_rate": 4.3503368623676614e-05,
      "loss": 0.7123,
      "step": 4074
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.43661582469940186,
      "learning_rate": 4.3464870067372475e-05,
      "loss": 0.7185,
      "step": 4075
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4179156720638275,
      "learning_rate": 4.3426371511068336e-05,
      "loss": 0.5526,
      "step": 4076
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.38912156224250793,
      "learning_rate": 4.3387872954764197e-05,
      "loss": 0.5984,
      "step": 4077
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3487336039543152,
      "learning_rate": 4.334937439846006e-05,
      "loss": 0.8396,
      "step": 4078
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.47077372670173645,
      "learning_rate": 4.3310875842155925e-05,
      "loss": 0.7636,
      "step": 4079
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3334641456604004,
      "learning_rate": 4.3272377285851786e-05,
      "loss": 0.7554,
      "step": 4080
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3992865979671478,
      "learning_rate": 4.323387872954765e-05,
      "loss": 0.8292,
      "step": 4081
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.37920254468917847,
      "learning_rate": 4.319538017324351e-05,
      "loss": 0.8651,
      "step": 4082
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.353772908449173,
      "learning_rate": 4.315688161693936e-05,
      "loss": 0.8668,
      "step": 4083
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.39120936393737793,
      "learning_rate": 4.311838306063522e-05,
      "loss": 0.6555,
      "step": 4084
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.32220518589019775,
      "learning_rate": 4.307988450433109e-05,
      "loss": 0.775,
      "step": 4085
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4276832342147827,
      "learning_rate": 4.304138594802695e-05,
      "loss": 0.6463,
      "step": 4086
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3740547001361847,
      "learning_rate": 4.300288739172281e-05,
      "loss": 0.6058,
      "step": 4087
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4079868197441101,
      "learning_rate": 4.2964388835418674e-05,
      "loss": 0.8759,
      "step": 4088
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.44288069009780884,
      "learning_rate": 4.2925890279114535e-05,
      "loss": 0.5147,
      "step": 4089
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.38376882672309875,
      "learning_rate": 4.2887391722810396e-05,
      "loss": 0.6472,
      "step": 4090
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.39837342500686646,
      "learning_rate": 4.284889316650626e-05,
      "loss": 0.698,
      "step": 4091
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3832220733165741,
      "learning_rate": 4.281039461020212e-05,
      "loss": 0.8487,
      "step": 4092
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3287261724472046,
      "learning_rate": 4.277189605389798e-05,
      "loss": 0.783,
      "step": 4093
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.36804676055908203,
      "learning_rate": 4.273339749759384e-05,
      "loss": 0.7023,
      "step": 4094
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.42542606592178345,
      "learning_rate": 4.26948989412897e-05,
      "loss": 0.5471,
      "step": 4095
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4125661551952362,
      "learning_rate": 4.265640038498557e-05,
      "loss": 0.7281,
      "step": 4096
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3906543254852295,
      "learning_rate": 4.261790182868143e-05,
      "loss": 0.5605,
      "step": 4097
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3772527873516083,
      "learning_rate": 4.257940327237729e-05,
      "loss": 0.7577,
      "step": 4098
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.33549976348876953,
      "learning_rate": 4.254090471607315e-05,
      "loss": 0.6784,
      "step": 4099
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4169055223464966,
      "learning_rate": 4.250240615976901e-05,
      "loss": 0.6588,
      "step": 4100
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.371955543756485,
      "learning_rate": 4.246390760346487e-05,
      "loss": 0.8312,
      "step": 4101
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3484863042831421,
      "learning_rate": 4.2425409047160735e-05,
      "loss": 0.7102,
      "step": 4102
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4469628930091858,
      "learning_rate": 4.2386910490856596e-05,
      "loss": 0.9079,
      "step": 4103
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.39175766706466675,
      "learning_rate": 4.2348411934552457e-05,
      "loss": 0.6483,
      "step": 4104
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.34952470660209656,
      "learning_rate": 4.230991337824832e-05,
      "loss": 0.7036,
      "step": 4105
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.42410337924957275,
      "learning_rate": 4.227141482194418e-05,
      "loss": 0.7444,
      "step": 4106
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4014997184276581,
      "learning_rate": 4.223291626564004e-05,
      "loss": 0.7679,
      "step": 4107
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4089341163635254,
      "learning_rate": 4.219441770933591e-05,
      "loss": 0.738,
      "step": 4108
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5129190683364868,
      "learning_rate": 4.215591915303176e-05,
      "loss": 0.714,
      "step": 4109
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.44000479578971863,
      "learning_rate": 4.211742059672762e-05,
      "loss": 0.8133,
      "step": 4110
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.34404557943344116,
      "learning_rate": 4.207892204042348e-05,
      "loss": 0.6852,
      "step": 4111
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3545055091381073,
      "learning_rate": 4.2040423484119344e-05,
      "loss": 0.7523,
      "step": 4112
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3481563627719879,
      "learning_rate": 4.200192492781521e-05,
      "loss": 0.7908,
      "step": 4113
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4428861141204834,
      "learning_rate": 4.196342637151107e-05,
      "loss": 0.5849,
      "step": 4114
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4258998930454254,
      "learning_rate": 4.1924927815206934e-05,
      "loss": 0.7696,
      "step": 4115
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.45052221417427063,
      "learning_rate": 4.1886429258902795e-05,
      "loss": 0.7919,
      "step": 4116
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.39134204387664795,
      "learning_rate": 4.1847930702598656e-05,
      "loss": 0.8733,
      "step": 4117
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5511379241943359,
      "learning_rate": 4.180943214629452e-05,
      "loss": 0.7281,
      "step": 4118
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.37309151887893677,
      "learning_rate": 4.177093358999038e-05,
      "loss": 0.8496,
      "step": 4119
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.43989214301109314,
      "learning_rate": 4.173243503368624e-05,
      "loss": 0.8865,
      "step": 4120
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.335954874753952,
      "learning_rate": 4.16939364773821e-05,
      "loss": 0.7012,
      "step": 4121
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.37973007559776306,
      "learning_rate": 4.165543792107796e-05,
      "loss": 0.8125,
      "step": 4122
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4425943195819855,
      "learning_rate": 4.161693936477382e-05,
      "loss": 1.0226,
      "step": 4123
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.340195894241333,
      "learning_rate": 4.157844080846968e-05,
      "loss": 0.7617,
      "step": 4124
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.43404966592788696,
      "learning_rate": 4.153994225216555e-05,
      "loss": 0.7963,
      "step": 4125
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.39287787675857544,
      "learning_rate": 4.150144369586141e-05,
      "loss": 0.6959,
      "step": 4126
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.44821280241012573,
      "learning_rate": 4.1462945139557266e-05,
      "loss": 0.5993,
      "step": 4127
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4605455994606018,
      "learning_rate": 4.142444658325313e-05,
      "loss": 0.7761,
      "step": 4128
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3441494107246399,
      "learning_rate": 4.138594802694899e-05,
      "loss": 0.8156,
      "step": 4129
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.501794159412384,
      "learning_rate": 4.134744947064485e-05,
      "loss": 0.7819,
      "step": 4130
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.37994760274887085,
      "learning_rate": 4.1308950914340716e-05,
      "loss": 0.661,
      "step": 4131
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4087165892124176,
      "learning_rate": 4.127045235803658e-05,
      "loss": 0.8495,
      "step": 4132
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.48018336296081543,
      "learning_rate": 4.123195380173244e-05,
      "loss": 0.6744,
      "step": 4133
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4105237126350403,
      "learning_rate": 4.11934552454283e-05,
      "loss": 0.6199,
      "step": 4134
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4237009286880493,
      "learning_rate": 4.115495668912416e-05,
      "loss": 0.7429,
      "step": 4135
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3887230157852173,
      "learning_rate": 4.111645813282002e-05,
      "loss": 0.5753,
      "step": 4136
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3719349503517151,
      "learning_rate": 4.107795957651588e-05,
      "loss": 0.7514,
      "step": 4137
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3578813374042511,
      "learning_rate": 4.103946102021174e-05,
      "loss": 0.8042,
      "step": 4138
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3323054909706116,
      "learning_rate": 4.1000962463907604e-05,
      "loss": 0.8238,
      "step": 4139
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3503592908382416,
      "learning_rate": 4.0962463907603465e-05,
      "loss": 0.6627,
      "step": 4140
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3856998383998871,
      "learning_rate": 4.0923965351299326e-05,
      "loss": 0.7322,
      "step": 4141
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.45086029171943665,
      "learning_rate": 4.0885466794995194e-05,
      "loss": 0.7228,
      "step": 4142
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4491860270500183,
      "learning_rate": 4.0846968238691055e-05,
      "loss": 0.6483,
      "step": 4143
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.39233675599098206,
      "learning_rate": 4.0808469682386916e-05,
      "loss": 0.6901,
      "step": 4144
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4104529023170471,
      "learning_rate": 4.076997112608277e-05,
      "loss": 0.7728,
      "step": 4145
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5160381197929382,
      "learning_rate": 4.073147256977863e-05,
      "loss": 0.7603,
      "step": 4146
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5003092885017395,
      "learning_rate": 4.069297401347449e-05,
      "loss": 0.628,
      "step": 4147
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3617534339427948,
      "learning_rate": 4.065447545717036e-05,
      "loss": 0.667,
      "step": 4148
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5032967329025269,
      "learning_rate": 4.061597690086622e-05,
      "loss": 0.6784,
      "step": 4149
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.38228359818458557,
      "learning_rate": 4.057747834456208e-05,
      "loss": 0.7138,
      "step": 4150
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3940478265285492,
      "learning_rate": 4.053897978825794e-05,
      "loss": 0.7589,
      "step": 4151
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.38480186462402344,
      "learning_rate": 4.0500481231953804e-05,
      "loss": 0.9486,
      "step": 4152
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.39953547716140747,
      "learning_rate": 4.0461982675649665e-05,
      "loss": 0.8488,
      "step": 4153
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.422955185174942,
      "learning_rate": 4.0423484119345526e-05,
      "loss": 0.8419,
      "step": 4154
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.43508434295654297,
      "learning_rate": 4.038498556304139e-05,
      "loss": 0.7332,
      "step": 4155
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.35335028171539307,
      "learning_rate": 4.034648700673725e-05,
      "loss": 0.7708,
      "step": 4156
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.452644020318985,
      "learning_rate": 4.030798845043311e-05,
      "loss": 0.7146,
      "step": 4157
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.37145355343818665,
      "learning_rate": 4.026948989412897e-05,
      "loss": 0.9169,
      "step": 4158
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4193548858165741,
      "learning_rate": 4.023099133782484e-05,
      "loss": 0.6308,
      "step": 4159
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.39441385865211487,
      "learning_rate": 4.01924927815207e-05,
      "loss": 0.9002,
      "step": 4160
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4235726296901703,
      "learning_rate": 4.015399422521656e-05,
      "loss": 0.7136,
      "step": 4161
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.422235369682312,
      "learning_rate": 4.011549566891242e-05,
      "loss": 0.6177,
      "step": 4162
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.39234021306037903,
      "learning_rate": 4.0076997112608275e-05,
      "loss": 0.6109,
      "step": 4163
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3869033455848694,
      "learning_rate": 4.0038498556304136e-05,
      "loss": 0.6929,
      "step": 4164
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4570625424385071,
      "learning_rate": 4e-05,
      "loss": 0.8716,
      "step": 4165
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4365617334842682,
      "learning_rate": 3.9961501443695864e-05,
      "loss": 0.7733,
      "step": 4166
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.40357452630996704,
      "learning_rate": 3.9923002887391725e-05,
      "loss": 0.869,
      "step": 4167
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.41415631771087646,
      "learning_rate": 3.9884504331087586e-05,
      "loss": 0.7052,
      "step": 4168
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3779353201389313,
      "learning_rate": 3.984600577478345e-05,
      "loss": 0.6906,
      "step": 4169
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.38791918754577637,
      "learning_rate": 3.980750721847931e-05,
      "loss": 0.7597,
      "step": 4170
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.35525578260421753,
      "learning_rate": 3.976900866217517e-05,
      "loss": 0.7661,
      "step": 4171
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.38570645451545715,
      "learning_rate": 3.973051010587103e-05,
      "loss": 0.7064,
      "step": 4172
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.46425560116767883,
      "learning_rate": 3.969201154956689e-05,
      "loss": 0.8423,
      "step": 4173
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3702983856201172,
      "learning_rate": 3.965351299326275e-05,
      "loss": 0.7403,
      "step": 4174
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3391299545764923,
      "learning_rate": 3.961501443695861e-05,
      "loss": 0.7054,
      "step": 4175
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.41424039006233215,
      "learning_rate": 3.957651588065448e-05,
      "loss": 0.6997,
      "step": 4176
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4477778375148773,
      "learning_rate": 3.953801732435034e-05,
      "loss": 0.8651,
      "step": 4177
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.40070220828056335,
      "learning_rate": 3.94995187680462e-05,
      "loss": 0.8312,
      "step": 4178
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.35623931884765625,
      "learning_rate": 3.9461020211742064e-05,
      "loss": 0.9679,
      "step": 4179
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.35840603709220886,
      "learning_rate": 3.9422521655437925e-05,
      "loss": 0.7594,
      "step": 4180
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.40443679690361023,
      "learning_rate": 3.938402309913378e-05,
      "loss": 0.6128,
      "step": 4181
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.36293184757232666,
      "learning_rate": 3.934552454282965e-05,
      "loss": 0.733,
      "step": 4182
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4083493649959564,
      "learning_rate": 3.930702598652551e-05,
      "loss": 0.7436,
      "step": 4183
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4239918887615204,
      "learning_rate": 3.926852743022137e-05,
      "loss": 0.5491,
      "step": 4184
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.41056832671165466,
      "learning_rate": 3.923002887391723e-05,
      "loss": 0.7725,
      "step": 4185
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4332568645477295,
      "learning_rate": 3.919153031761309e-05,
      "loss": 0.6902,
      "step": 4186
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3725118637084961,
      "learning_rate": 3.915303176130895e-05,
      "loss": 0.8281,
      "step": 4187
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.34088850021362305,
      "learning_rate": 3.911453320500482e-05,
      "loss": 0.6781,
      "step": 4188
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.37356263399124146,
      "learning_rate": 3.9076034648700674e-05,
      "loss": 0.6943,
      "step": 4189
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.36827635765075684,
      "learning_rate": 3.9037536092396535e-05,
      "loss": 0.893,
      "step": 4190
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.37812164425849915,
      "learning_rate": 3.8999037536092395e-05,
      "loss": 0.7043,
      "step": 4191
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3897439241409302,
      "learning_rate": 3.8960538979788256e-05,
      "loss": 0.8023,
      "step": 4192
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4284997880458832,
      "learning_rate": 3.892204042348412e-05,
      "loss": 0.8246,
      "step": 4193
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.37952515482902527,
      "learning_rate": 3.8883541867179985e-05,
      "loss": 0.7921,
      "step": 4194
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.418804794549942,
      "learning_rate": 3.8845043310875846e-05,
      "loss": 0.9073,
      "step": 4195
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4202890694141388,
      "learning_rate": 3.880654475457171e-05,
      "loss": 0.7448,
      "step": 4196
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.428768515586853,
      "learning_rate": 3.876804619826757e-05,
      "loss": 0.7785,
      "step": 4197
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3724942207336426,
      "learning_rate": 3.872954764196343e-05,
      "loss": 0.6834,
      "step": 4198
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3887561559677124,
      "learning_rate": 3.869104908565929e-05,
      "loss": 0.7346,
      "step": 4199
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3787332773208618,
      "learning_rate": 3.865255052935515e-05,
      "loss": 0.7098,
      "step": 4200
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3412218689918518,
      "learning_rate": 3.861405197305101e-05,
      "loss": 0.8827,
      "step": 4201
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3708592355251312,
      "learning_rate": 3.857555341674687e-05,
      "loss": 0.8511,
      "step": 4202
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4120221436023712,
      "learning_rate": 3.8537054860442734e-05,
      "loss": 0.8697,
      "step": 4203
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.38629546761512756,
      "learning_rate": 3.8498556304138595e-05,
      "loss": 0.696,
      "step": 4204
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.37450486421585083,
      "learning_rate": 3.846005774783446e-05,
      "loss": 0.6899,
      "step": 4205
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3675825297832489,
      "learning_rate": 3.8421559191530324e-05,
      "loss": 0.7951,
      "step": 4206
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6268443465232849,
      "learning_rate": 3.838306063522618e-05,
      "loss": 0.6422,
      "step": 4207
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4740142822265625,
      "learning_rate": 3.834456207892204e-05,
      "loss": 0.7321,
      "step": 4208
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.32814744114875793,
      "learning_rate": 3.83060635226179e-05,
      "loss": 0.7469,
      "step": 4209
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.432426393032074,
      "learning_rate": 3.826756496631376e-05,
      "loss": 0.7705,
      "step": 4210
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3886635899543762,
      "learning_rate": 3.822906641000963e-05,
      "loss": 0.7386,
      "step": 4211
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.43547067046165466,
      "learning_rate": 3.819056785370549e-05,
      "loss": 0.7177,
      "step": 4212
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4667619466781616,
      "learning_rate": 3.815206929740135e-05,
      "loss": 0.7228,
      "step": 4213
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4577571749687195,
      "learning_rate": 3.811357074109721e-05,
      "loss": 0.623,
      "step": 4214
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3869636654853821,
      "learning_rate": 3.807507218479307e-05,
      "loss": 0.8392,
      "step": 4215
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3692336082458496,
      "learning_rate": 3.8036573628488933e-05,
      "loss": 0.6506,
      "step": 4216
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3741837739944458,
      "learning_rate": 3.7998075072184794e-05,
      "loss": 0.7555,
      "step": 4217
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.40131714940071106,
      "learning_rate": 3.7959576515880655e-05,
      "loss": 0.6745,
      "step": 4218
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4926687180995941,
      "learning_rate": 3.7921077959576516e-05,
      "loss": 0.7171,
      "step": 4219
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3794936537742615,
      "learning_rate": 3.788257940327238e-05,
      "loss": 0.616,
      "step": 4220
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.48849156498908997,
      "learning_rate": 3.784408084696824e-05,
      "loss": 0.7347,
      "step": 4221
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.440708190202713,
      "learning_rate": 3.7805582290664106e-05,
      "loss": 0.7828,
      "step": 4222
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.36522823572158813,
      "learning_rate": 3.776708373435997e-05,
      "loss": 0.7467,
      "step": 4223
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3997153341770172,
      "learning_rate": 3.772858517805583e-05,
      "loss": 0.7257,
      "step": 4224
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4484284520149231,
      "learning_rate": 3.769008662175169e-05,
      "loss": 0.5815,
      "step": 4225
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.346810519695282,
      "learning_rate": 3.765158806544754e-05,
      "loss": 0.683,
      "step": 4226
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.36032959818840027,
      "learning_rate": 3.7613089509143404e-05,
      "loss": 0.6968,
      "step": 4227
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4003048837184906,
      "learning_rate": 3.757459095283927e-05,
      "loss": 0.7413,
      "step": 4228
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3517003357410431,
      "learning_rate": 3.753609239653513e-05,
      "loss": 0.7753,
      "step": 4229
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3442208468914032,
      "learning_rate": 3.7497593840230994e-05,
      "loss": 0.7229,
      "step": 4230
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.39766791462898254,
      "learning_rate": 3.7459095283926855e-05,
      "loss": 0.6585,
      "step": 4231
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.45413464307785034,
      "learning_rate": 3.7420596727622716e-05,
      "loss": 0.6561,
      "step": 4232
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.36558252573013306,
      "learning_rate": 3.738209817131858e-05,
      "loss": 0.8747,
      "step": 4233
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.37678638100624084,
      "learning_rate": 3.734359961501444e-05,
      "loss": 0.7305,
      "step": 4234
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.40159833431243896,
      "learning_rate": 3.73051010587103e-05,
      "loss": 0.6339,
      "step": 4235
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.38176265358924866,
      "learning_rate": 3.726660250240616e-05,
      "loss": 0.8476,
      "step": 4236
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.484382688999176,
      "learning_rate": 3.722810394610202e-05,
      "loss": 0.5736,
      "step": 4237
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4119843542575836,
      "learning_rate": 3.718960538979788e-05,
      "loss": 0.6015,
      "step": 4238
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3990386426448822,
      "learning_rate": 3.715110683349375e-05,
      "loss": 0.6434,
      "step": 4239
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.42091426253318787,
      "learning_rate": 3.711260827718961e-05,
      "loss": 0.7307,
      "step": 4240
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4108964800834656,
      "learning_rate": 3.707410972088547e-05,
      "loss": 0.7012,
      "step": 4241
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3729628324508667,
      "learning_rate": 3.703561116458133e-05,
      "loss": 0.8388,
      "step": 4242
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.32995936274528503,
      "learning_rate": 3.6997112608277193e-05,
      "loss": 0.879,
      "step": 4243
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.35292497277259827,
      "learning_rate": 3.695861405197305e-05,
      "loss": 0.9118,
      "step": 4244
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4288041889667511,
      "learning_rate": 3.6920115495668915e-05,
      "loss": 0.8174,
      "step": 4245
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3891065716743469,
      "learning_rate": 3.6881616939364776e-05,
      "loss": 0.6749,
      "step": 4246
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.42064860463142395,
      "learning_rate": 3.684311838306064e-05,
      "loss": 0.8765,
      "step": 4247
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.38718175888061523,
      "learning_rate": 3.68046198267565e-05,
      "loss": 0.6824,
      "step": 4248
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3891717195510864,
      "learning_rate": 3.676612127045236e-05,
      "loss": 0.5665,
      "step": 4249
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.34983646869659424,
      "learning_rate": 3.672762271414822e-05,
      "loss": 0.8462,
      "step": 4250
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4031772315502167,
      "learning_rate": 3.668912415784409e-05,
      "loss": 0.648,
      "step": 4251
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.345520555973053,
      "learning_rate": 3.665062560153994e-05,
      "loss": 0.6384,
      "step": 4252
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3569733202457428,
      "learning_rate": 3.66121270452358e-05,
      "loss": 0.5916,
      "step": 4253
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.40299537777900696,
      "learning_rate": 3.6573628488931664e-05,
      "loss": 0.6754,
      "step": 4254
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4221087396144867,
      "learning_rate": 3.6535129932627525e-05,
      "loss": 0.798,
      "step": 4255
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3857780694961548,
      "learning_rate": 3.6496631376323386e-05,
      "loss": 0.582,
      "step": 4256
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3326629400253296,
      "learning_rate": 3.6458132820019254e-05,
      "loss": 0.7711,
      "step": 4257
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.41075870394706726,
      "learning_rate": 3.6419634263715115e-05,
      "loss": 0.7208,
      "step": 4258
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.324069082736969,
      "learning_rate": 3.6381135707410976e-05,
      "loss": 0.8267,
      "step": 4259
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.34635046124458313,
      "learning_rate": 3.634263715110684e-05,
      "loss": 0.7757,
      "step": 4260
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.539143443107605,
      "learning_rate": 3.63041385948027e-05,
      "loss": 0.7031,
      "step": 4261
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.44884082674980164,
      "learning_rate": 3.626564003849856e-05,
      "loss": 0.9102,
      "step": 4262
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3519161343574524,
      "learning_rate": 3.622714148219442e-05,
      "loss": 0.7983,
      "step": 4263
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3802604377269745,
      "learning_rate": 3.618864292589028e-05,
      "loss": 0.7195,
      "step": 4264
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4399941861629486,
      "learning_rate": 3.615014436958614e-05,
      "loss": 0.593,
      "step": 4265
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3547452390193939,
      "learning_rate": 3.6111645813282e-05,
      "loss": 0.9024,
      "step": 4266
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.38822516798973083,
      "learning_rate": 3.6073147256977864e-05,
      "loss": 0.7673,
      "step": 4267
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.34775689244270325,
      "learning_rate": 3.603464870067373e-05,
      "loss": 0.7987,
      "step": 4268
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.37968382239341736,
      "learning_rate": 3.599615014436959e-05,
      "loss": 0.6947,
      "step": 4269
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4037248194217682,
      "learning_rate": 3.595765158806545e-05,
      "loss": 0.741,
      "step": 4270
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3877098262310028,
      "learning_rate": 3.591915303176131e-05,
      "loss": 0.8087,
      "step": 4271
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.46681779623031616,
      "learning_rate": 3.588065447545717e-05,
      "loss": 0.6847,
      "step": 4272
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.43334731459617615,
      "learning_rate": 3.584215591915303e-05,
      "loss": 0.7284,
      "step": 4273
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.37847378849983215,
      "learning_rate": 3.58036573628489e-05,
      "loss": 0.7176,
      "step": 4274
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3861939311027527,
      "learning_rate": 3.576515880654476e-05,
      "loss": 0.6166,
      "step": 4275
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4520871639251709,
      "learning_rate": 3.572666025024062e-05,
      "loss": 0.7542,
      "step": 4276
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4573029577732086,
      "learning_rate": 3.568816169393648e-05,
      "loss": 0.7587,
      "step": 4277
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4316968619823456,
      "learning_rate": 3.564966313763234e-05,
      "loss": 0.7546,
      "step": 4278
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4177800416946411,
      "learning_rate": 3.56111645813282e-05,
      "loss": 0.7122,
      "step": 4279
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.36616769433021545,
      "learning_rate": 3.557266602502406e-05,
      "loss": 0.7983,
      "step": 4280
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3467947840690613,
      "learning_rate": 3.5534167468719924e-05,
      "loss": 0.8879,
      "step": 4281
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.377095103263855,
      "learning_rate": 3.5495668912415785e-05,
      "loss": 0.6644,
      "step": 4282
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4478949308395386,
      "learning_rate": 3.5457170356111646e-05,
      "loss": 0.9348,
      "step": 4283
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.397701233625412,
      "learning_rate": 3.541867179980751e-05,
      "loss": 0.6444,
      "step": 4284
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4223368167877197,
      "learning_rate": 3.5380173243503375e-05,
      "loss": 0.6933,
      "step": 4285
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.33110401034355164,
      "learning_rate": 3.5341674687199236e-05,
      "loss": 0.718,
      "step": 4286
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4838038980960846,
      "learning_rate": 3.53031761308951e-05,
      "loss": 0.7798,
      "step": 4287
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.38341787457466125,
      "learning_rate": 3.526467757459095e-05,
      "loss": 0.6632,
      "step": 4288
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.425876259803772,
      "learning_rate": 3.522617901828681e-05,
      "loss": 0.7013,
      "step": 4289
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4526689052581787,
      "learning_rate": 3.518768046198267e-05,
      "loss": 0.7866,
      "step": 4290
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.37860608100891113,
      "learning_rate": 3.514918190567854e-05,
      "loss": 0.7624,
      "step": 4291
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4510956108570099,
      "learning_rate": 3.51106833493744e-05,
      "loss": 0.6505,
      "step": 4292
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3639904260635376,
      "learning_rate": 3.507218479307026e-05,
      "loss": 0.7301,
      "step": 4293
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.395521342754364,
      "learning_rate": 3.5033686236766124e-05,
      "loss": 0.6756,
      "step": 4294
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3826228082180023,
      "learning_rate": 3.4995187680461985e-05,
      "loss": 0.7936,
      "step": 4295
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3750913739204407,
      "learning_rate": 3.4956689124157846e-05,
      "loss": 0.6222,
      "step": 4296
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.47517308592796326,
      "learning_rate": 3.4918190567853707e-05,
      "loss": 0.7915,
      "step": 4297
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.42867740988731384,
      "learning_rate": 3.487969201154957e-05,
      "loss": 0.5364,
      "step": 4298
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3339618742465973,
      "learning_rate": 3.484119345524543e-05,
      "loss": 0.8349,
      "step": 4299
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3879911005496979,
      "learning_rate": 3.480269489894129e-05,
      "loss": 0.9054,
      "step": 4300
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6933049559593201,
      "learning_rate": 3.476419634263715e-05,
      "loss": 0.7038,
      "step": 4301
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.44034409523010254,
      "learning_rate": 3.472569778633302e-05,
      "loss": 0.8739,
      "step": 4302
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.41476383805274963,
      "learning_rate": 3.468719923002888e-05,
      "loss": 0.7559,
      "step": 4303
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3653128147125244,
      "learning_rate": 3.464870067372474e-05,
      "loss": 0.8003,
      "step": 4304
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.36464208364486694,
      "learning_rate": 3.46102021174206e-05,
      "loss": 0.8305,
      "step": 4305
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3892463743686676,
      "learning_rate": 3.4571703561116455e-05,
      "loss": 0.7714,
      "step": 4306
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.35725441575050354,
      "learning_rate": 3.4533205004812316e-05,
      "loss": 0.6397,
      "step": 4307
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.42595988512039185,
      "learning_rate": 3.4494706448508184e-05,
      "loss": 0.7075,
      "step": 4308
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4475646913051605,
      "learning_rate": 3.4456207892204045e-05,
      "loss": 0.7594,
      "step": 4309
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.34551212191581726,
      "learning_rate": 3.4417709335899906e-05,
      "loss": 0.7206,
      "step": 4310
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.39403846859931946,
      "learning_rate": 3.437921077959577e-05,
      "loss": 0.8787,
      "step": 4311
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4750715494155884,
      "learning_rate": 3.434071222329163e-05,
      "loss": 0.6203,
      "step": 4312
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3724660575389862,
      "learning_rate": 3.430221366698749e-05,
      "loss": 0.6525,
      "step": 4313
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.38427916169166565,
      "learning_rate": 3.426371511068335e-05,
      "loss": 0.8637,
      "step": 4314
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.47818654775619507,
      "learning_rate": 3.422521655437921e-05,
      "loss": 0.655,
      "step": 4315
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3606782555580139,
      "learning_rate": 3.418671799807507e-05,
      "loss": 0.6518,
      "step": 4316
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.40802958607673645,
      "learning_rate": 3.414821944177093e-05,
      "loss": 0.6309,
      "step": 4317
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.392425000667572,
      "learning_rate": 3.4109720885466794e-05,
      "loss": 0.8225,
      "step": 4318
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4352900981903076,
      "learning_rate": 3.4071222329162655e-05,
      "loss": 0.7822,
      "step": 4319
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.42819005250930786,
      "learning_rate": 3.403272377285852e-05,
      "loss": 0.6166,
      "step": 4320
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3597090542316437,
      "learning_rate": 3.3994225216554384e-05,
      "loss": 0.8057,
      "step": 4321
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.38418906927108765,
      "learning_rate": 3.3955726660250245e-05,
      "loss": 0.788,
      "step": 4322
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.34640735387802124,
      "learning_rate": 3.3917228103946106e-05,
      "loss": 0.8214,
      "step": 4323
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3540816307067871,
      "learning_rate": 3.387872954764196e-05,
      "loss": 0.7098,
      "step": 4324
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.42523500323295593,
      "learning_rate": 3.384023099133783e-05,
      "loss": 0.7146,
      "step": 4325
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3988916873931885,
      "learning_rate": 3.380173243503369e-05,
      "loss": 0.6958,
      "step": 4326
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3408418893814087,
      "learning_rate": 3.376323387872955e-05,
      "loss": 0.7028,
      "step": 4327
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3886742889881134,
      "learning_rate": 3.372473532242541e-05,
      "loss": 0.741,
      "step": 4328
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4663085341453552,
      "learning_rate": 3.368623676612127e-05,
      "loss": 1.0499,
      "step": 4329
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.41710519790649414,
      "learning_rate": 3.364773820981713e-05,
      "loss": 0.9503,
      "step": 4330
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3613785207271576,
      "learning_rate": 3.3609239653513e-05,
      "loss": 0.6063,
      "step": 4331
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.41418561339378357,
      "learning_rate": 3.3570741097208854e-05,
      "loss": 0.686,
      "step": 4332
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.47606542706489563,
      "learning_rate": 3.3532242540904715e-05,
      "loss": 0.5801,
      "step": 4333
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4472268223762512,
      "learning_rate": 3.3493743984600576e-05,
      "loss": 0.6863,
      "step": 4334
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.47683465480804443,
      "learning_rate": 3.345524542829644e-05,
      "loss": 0.757,
      "step": 4335
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.45172974467277527,
      "learning_rate": 3.34167468719923e-05,
      "loss": 0.8401,
      "step": 4336
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4335455894470215,
      "learning_rate": 3.3378248315688166e-05,
      "loss": 0.7438,
      "step": 4337
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2613335847854614,
      "learning_rate": 3.333974975938403e-05,
      "loss": 0.6546,
      "step": 4338
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.46799659729003906,
      "learning_rate": 3.330125120307989e-05,
      "loss": 0.7192,
      "step": 4339
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.34049391746520996,
      "learning_rate": 3.326275264677575e-05,
      "loss": 0.6633,
      "step": 4340
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.37027502059936523,
      "learning_rate": 3.322425409047161e-05,
      "loss": 0.7824,
      "step": 4341
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3982940912246704,
      "learning_rate": 3.318575553416747e-05,
      "loss": 0.8467,
      "step": 4342
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.39066803455352783,
      "learning_rate": 3.314725697786333e-05,
      "loss": 0.8617,
      "step": 4343
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.44570502638816833,
      "learning_rate": 3.310875842155919e-05,
      "loss": 0.8706,
      "step": 4344
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.40820714831352234,
      "learning_rate": 3.3070259865255054e-05,
      "loss": 0.7745,
      "step": 4345
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3930854797363281,
      "learning_rate": 3.3031761308950915e-05,
      "loss": 0.6787,
      "step": 4346
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.38856562972068787,
      "learning_rate": 3.2993262752646776e-05,
      "loss": 0.6876,
      "step": 4347
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.48582369089126587,
      "learning_rate": 3.2954764196342644e-05,
      "loss": 0.7625,
      "step": 4348
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.31834542751312256,
      "learning_rate": 3.2916265640038505e-05,
      "loss": 0.7089,
      "step": 4349
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3988223075866699,
      "learning_rate": 3.287776708373436e-05,
      "loss": 0.8279,
      "step": 4350
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4464663863182068,
      "learning_rate": 3.283926852743022e-05,
      "loss": 0.7566,
      "step": 4351
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4195549190044403,
      "learning_rate": 3.280076997112608e-05,
      "loss": 0.9172,
      "step": 4352
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.37872427701950073,
      "learning_rate": 3.276227141482194e-05,
      "loss": 0.7435,
      "step": 4353
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.37014827132225037,
      "learning_rate": 3.272377285851781e-05,
      "loss": 0.81,
      "step": 4354
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.33768999576568604,
      "learning_rate": 3.268527430221367e-05,
      "loss": 0.7141,
      "step": 4355
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4023051857948303,
      "learning_rate": 3.264677574590953e-05,
      "loss": 0.631,
      "step": 4356
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.38252508640289307,
      "learning_rate": 3.260827718960539e-05,
      "loss": 0.7991,
      "step": 4357
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.36403313279151917,
      "learning_rate": 3.256977863330125e-05,
      "loss": 0.6709,
      "step": 4358
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.43343284726142883,
      "learning_rate": 3.2531280076997114e-05,
      "loss": 0.7371,
      "step": 4359
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4181382954120636,
      "learning_rate": 3.2492781520692975e-05,
      "loss": 0.759,
      "step": 4360
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.34351569414138794,
      "learning_rate": 3.2454282964388836e-05,
      "loss": 0.66,
      "step": 4361
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.41066834330558777,
      "learning_rate": 3.24157844080847e-05,
      "loss": 0.7547,
      "step": 4362
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3330984115600586,
      "learning_rate": 3.237728585178056e-05,
      "loss": 0.7413,
      "step": 4363
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3366800546646118,
      "learning_rate": 3.233878729547642e-05,
      "loss": 0.5273,
      "step": 4364
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3776836097240448,
      "learning_rate": 3.230028873917229e-05,
      "loss": 0.6914,
      "step": 4365
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.33534303307533264,
      "learning_rate": 3.226179018286815e-05,
      "loss": 0.7685,
      "step": 4366
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.477313756942749,
      "learning_rate": 3.222329162656401e-05,
      "loss": 0.722,
      "step": 4367
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4132130444049835,
      "learning_rate": 3.218479307025987e-05,
      "loss": 0.9648,
      "step": 4368
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.47918441891670227,
      "learning_rate": 3.2146294513955724e-05,
      "loss": 0.6297,
      "step": 4369
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.46850016713142395,
      "learning_rate": 3.2107795957651585e-05,
      "loss": 0.8535,
      "step": 4370
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.36488279700279236,
      "learning_rate": 3.206929740134745e-05,
      "loss": 0.6386,
      "step": 4371
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.38798144459724426,
      "learning_rate": 3.2030798845043314e-05,
      "loss": 0.9475,
      "step": 4372
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3897880017757416,
      "learning_rate": 3.1992300288739175e-05,
      "loss": 0.6917,
      "step": 4373
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3785240948200226,
      "learning_rate": 3.1953801732435036e-05,
      "loss": 0.6946,
      "step": 4374
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.40090811252593994,
      "learning_rate": 3.19153031761309e-05,
      "loss": 0.7845,
      "step": 4375
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.39170923829078674,
      "learning_rate": 3.187680461982676e-05,
      "loss": 0.9648,
      "step": 4376
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3978740870952606,
      "learning_rate": 3.183830606352262e-05,
      "loss": 0.7861,
      "step": 4377
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.37943342328071594,
      "learning_rate": 3.179980750721848e-05,
      "loss": 0.8631,
      "step": 4378
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.41931435465812683,
      "learning_rate": 3.176130895091434e-05,
      "loss": 0.6346,
      "step": 4379
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.31259164214134216,
      "learning_rate": 3.17228103946102e-05,
      "loss": 0.7335,
      "step": 4380
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4093726575374603,
      "learning_rate": 3.168431183830606e-05,
      "loss": 0.7826,
      "step": 4381
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4540308713912964,
      "learning_rate": 3.1645813282001924e-05,
      "loss": 0.668,
      "step": 4382
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5056313276290894,
      "learning_rate": 3.160731472569779e-05,
      "loss": 0.8273,
      "step": 4383
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3304143249988556,
      "learning_rate": 3.156881616939365e-05,
      "loss": 0.6516,
      "step": 4384
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.40889203548431396,
      "learning_rate": 3.153031761308951e-05,
      "loss": 0.8063,
      "step": 4385
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.42223843932151794,
      "learning_rate": 3.1491819056785374e-05,
      "loss": 0.7887,
      "step": 4386
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.352431982755661,
      "learning_rate": 3.145332050048123e-05,
      "loss": 0.7524,
      "step": 4387
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3070000410079956,
      "learning_rate": 3.1414821944177096e-05,
      "loss": 0.6607,
      "step": 4388
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3693821132183075,
      "learning_rate": 3.137632338787296e-05,
      "loss": 0.5991,
      "step": 4389
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.39660170674324036,
      "learning_rate": 3.133782483156882e-05,
      "loss": 0.9715,
      "step": 4390
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.41007107496261597,
      "learning_rate": 3.129932627526468e-05,
      "loss": 0.6577,
      "step": 4391
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3535182476043701,
      "learning_rate": 3.126082771896054e-05,
      "loss": 1.0028,
      "step": 4392
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3611140847206116,
      "learning_rate": 3.12223291626564e-05,
      "loss": 0.7013,
      "step": 4393
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4285748600959778,
      "learning_rate": 3.118383060635227e-05,
      "loss": 0.7022,
      "step": 4394
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.40736082196235657,
      "learning_rate": 3.114533205004812e-05,
      "loss": 0.8018,
      "step": 4395
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3737507462501526,
      "learning_rate": 3.1106833493743984e-05,
      "loss": 0.8845,
      "step": 4396
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3965425491333008,
      "learning_rate": 3.1068334937439845e-05,
      "loss": 0.7255,
      "step": 4397
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4702063500881195,
      "learning_rate": 3.1029836381135706e-05,
      "loss": 0.5579,
      "step": 4398
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.35651880502700806,
      "learning_rate": 3.099133782483157e-05,
      "loss": 0.7315,
      "step": 4399
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4375079572200775,
      "learning_rate": 3.0952839268527435e-05,
      "loss": 0.6404,
      "step": 4400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5284414291381836,
      "learning_rate": 3.0914340712223296e-05,
      "loss": 0.6607,
      "step": 4401
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3939874768257141,
      "learning_rate": 3.087584215591916e-05,
      "loss": 0.9254,
      "step": 4402
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3460075259208679,
      "learning_rate": 3.083734359961502e-05,
      "loss": 0.5822,
      "step": 4403
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.349092036485672,
      "learning_rate": 3.079884504331088e-05,
      "loss": 0.742,
      "step": 4404
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4086030125617981,
      "learning_rate": 3.076034648700674e-05,
      "loss": 0.7035,
      "step": 4405
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4075028598308563,
      "learning_rate": 3.07218479307026e-05,
      "loss": 0.745,
      "step": 4406
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5447514653205872,
      "learning_rate": 3.068334937439846e-05,
      "loss": 0.6845,
      "step": 4407
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.36573174595832825,
      "learning_rate": 3.064485081809432e-05,
      "loss": 0.8008,
      "step": 4408
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4016311764717102,
      "learning_rate": 3.0606352261790184e-05,
      "loss": 0.6682,
      "step": 4409
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3531227707862854,
      "learning_rate": 3.0567853705486045e-05,
      "loss": 0.67,
      "step": 4410
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4578607678413391,
      "learning_rate": 3.052935514918191e-05,
      "loss": 0.8104,
      "step": 4411
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.43055281043052673,
      "learning_rate": 3.049085659287777e-05,
      "loss": 0.8685,
      "step": 4412
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4596390724182129,
      "learning_rate": 3.045235803657363e-05,
      "loss": 0.7235,
      "step": 4413
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.38748255372047424,
      "learning_rate": 3.0413859480269492e-05,
      "loss": 0.7834,
      "step": 4414
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.34893864393234253,
      "learning_rate": 3.0375360923965353e-05,
      "loss": 0.8006,
      "step": 4415
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.39833223819732666,
      "learning_rate": 3.033686236766121e-05,
      "loss": 0.6788,
      "step": 4416
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.40659990906715393,
      "learning_rate": 3.0298363811357078e-05,
      "loss": 0.8887,
      "step": 4417
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5013880133628845,
      "learning_rate": 3.025986525505294e-05,
      "loss": 0.8008,
      "step": 4418
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3787001669406891,
      "learning_rate": 3.02213666987488e-05,
      "loss": 0.839,
      "step": 4419
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4034917652606964,
      "learning_rate": 3.0182868142444658e-05,
      "loss": 0.8737,
      "step": 4420
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4180939793586731,
      "learning_rate": 3.014436958614052e-05,
      "loss": 1.1821,
      "step": 4421
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5090099573135376,
      "learning_rate": 3.010587102983638e-05,
      "loss": 0.7666,
      "step": 4422
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4067525267601013,
      "learning_rate": 3.0067372473532247e-05,
      "loss": 0.4843,
      "step": 4423
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5165822505950928,
      "learning_rate": 3.0028873917228105e-05,
      "loss": 0.8484,
      "step": 4424
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.33791521191596985,
      "learning_rate": 2.9990375360923966e-05,
      "loss": 0.8006,
      "step": 4425
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.37676963210105896,
      "learning_rate": 2.9951876804619827e-05,
      "loss": 0.7134,
      "step": 4426
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.47596558928489685,
      "learning_rate": 2.9913378248315688e-05,
      "loss": 0.8057,
      "step": 4427
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4262210726737976,
      "learning_rate": 2.9874879692011552e-05,
      "loss": 0.8336,
      "step": 4428
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.37869712710380554,
      "learning_rate": 2.9836381135707413e-05,
      "loss": 0.6881,
      "step": 4429
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.40188854932785034,
      "learning_rate": 2.9797882579403274e-05,
      "loss": 0.7886,
      "step": 4430
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4235725402832031,
      "learning_rate": 2.9759384023099135e-05,
      "loss": 0.7013,
      "step": 4431
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.34929436445236206,
      "learning_rate": 2.9720885466794996e-05,
      "loss": 0.7987,
      "step": 4432
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.36249688267707825,
      "learning_rate": 2.9682386910490857e-05,
      "loss": 0.7288,
      "step": 4433
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.50688636302948,
      "learning_rate": 2.964388835418672e-05,
      "loss": 0.8549,
      "step": 4434
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.41970476508140564,
      "learning_rate": 2.9605389797882583e-05,
      "loss": 0.617,
      "step": 4435
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.37447109818458557,
      "learning_rate": 2.9566891241578444e-05,
      "loss": 0.5979,
      "step": 4436
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.39947912096977234,
      "learning_rate": 2.9528392685274305e-05,
      "loss": 0.7397,
      "step": 4437
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.376158207654953,
      "learning_rate": 2.9489894128970162e-05,
      "loss": 0.8383,
      "step": 4438
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.42799147963523865,
      "learning_rate": 2.9451395572666023e-05,
      "loss": 0.6287,
      "step": 4439
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8264315128326416,
      "learning_rate": 2.941289701636189e-05,
      "loss": 0.6024,
      "step": 4440
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3490159511566162,
      "learning_rate": 2.9374398460057752e-05,
      "loss": 0.8172,
      "step": 4441
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3642365038394928,
      "learning_rate": 2.933589990375361e-05,
      "loss": 0.8485,
      "step": 4442
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.39969098567962646,
      "learning_rate": 2.929740134744947e-05,
      "loss": 0.6874,
      "step": 4443
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.43194565176963806,
      "learning_rate": 2.925890279114533e-05,
      "loss": 0.8014,
      "step": 4444
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3425713777542114,
      "learning_rate": 2.9220404234841192e-05,
      "loss": 0.8164,
      "step": 4445
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.49992635846138,
      "learning_rate": 2.9181905678537057e-05,
      "loss": 0.8396,
      "step": 4446
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4587908089160919,
      "learning_rate": 2.9143407122232918e-05,
      "loss": 1.0161,
      "step": 4447
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.43665292859077454,
      "learning_rate": 2.910490856592878e-05,
      "loss": 0.7837,
      "step": 4448
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.37257859110832214,
      "learning_rate": 2.906641000962464e-05,
      "loss": 0.7994,
      "step": 4449
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3505553901195526,
      "learning_rate": 2.90279114533205e-05,
      "loss": 0.7169,
      "step": 4450
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4434795677661896,
      "learning_rate": 2.8989412897016365e-05,
      "loss": 0.9084,
      "step": 4451
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.42225760221481323,
      "learning_rate": 2.8950914340712226e-05,
      "loss": 0.6908,
      "step": 4452
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3856879472732544,
      "learning_rate": 2.8912415784408087e-05,
      "loss": 0.7264,
      "step": 4453
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.37197017669677734,
      "learning_rate": 2.8873917228103948e-05,
      "loss": 0.7251,
      "step": 4454
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.44588398933410645,
      "learning_rate": 2.883541867179981e-05,
      "loss": 0.53,
      "step": 4455
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4818533658981323,
      "learning_rate": 2.8796920115495666e-05,
      "loss": 0.8113,
      "step": 4456
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.33460038900375366,
      "learning_rate": 2.8758421559191534e-05,
      "loss": 0.813,
      "step": 4457
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3698921799659729,
      "learning_rate": 2.8719923002887395e-05,
      "loss": 0.6127,
      "step": 4458
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4155881702899933,
      "learning_rate": 2.8681424446583256e-05,
      "loss": 0.7491,
      "step": 4459
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3977646231651306,
      "learning_rate": 2.8642925890279114e-05,
      "loss": 0.7643,
      "step": 4460
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.42345041036605835,
      "learning_rate": 2.8604427333974975e-05,
      "loss": 0.7114,
      "step": 4461
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.45216140151023865,
      "learning_rate": 2.8565928777670836e-05,
      "loss": 0.7324,
      "step": 4462
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.41855698823928833,
      "learning_rate": 2.8527430221366704e-05,
      "loss": 0.7735,
      "step": 4463
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.44158634543418884,
      "learning_rate": 2.848893166506256e-05,
      "loss": 0.6142,
      "step": 4464
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4463462233543396,
      "learning_rate": 2.8450433108758422e-05,
      "loss": 0.7031,
      "step": 4465
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4026172459125519,
      "learning_rate": 2.8411934552454283e-05,
      "loss": 0.7496,
      "step": 4466
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.44938308000564575,
      "learning_rate": 2.8373435996150144e-05,
      "loss": 0.9409,
      "step": 4467
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.39682963490486145,
      "learning_rate": 2.833493743984601e-05,
      "loss": 0.7219,
      "step": 4468
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.34671252965927124,
      "learning_rate": 2.829643888354187e-05,
      "loss": 0.7379,
      "step": 4469
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4242604374885559,
      "learning_rate": 2.825794032723773e-05,
      "loss": 0.9625,
      "step": 4470
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6398616433143616,
      "learning_rate": 2.821944177093359e-05,
      "loss": 0.862,
      "step": 4471
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.43224629759788513,
      "learning_rate": 2.8180943214629452e-05,
      "loss": 0.668,
      "step": 4472
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.40312203764915466,
      "learning_rate": 2.8142444658325313e-05,
      "loss": 0.6014,
      "step": 4473
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4511520564556122,
      "learning_rate": 2.8103946102021178e-05,
      "loss": 0.6387,
      "step": 4474
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4066890776157379,
      "learning_rate": 2.806544754571704e-05,
      "loss": 0.7901,
      "step": 4475
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.42336082458496094,
      "learning_rate": 2.80269489894129e-05,
      "loss": 0.7525,
      "step": 4476
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.32458028197288513,
      "learning_rate": 2.798845043310876e-05,
      "loss": 0.7826,
      "step": 4477
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3869103193283081,
      "learning_rate": 2.7949951876804618e-05,
      "loss": 0.6268,
      "step": 4478
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4944154918193817,
      "learning_rate": 2.791145332050048e-05,
      "loss": 0.7763,
      "step": 4479
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4007856845855713,
      "learning_rate": 2.7872954764196347e-05,
      "loss": 0.6428,
      "step": 4480
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.39612168073654175,
      "learning_rate": 2.7834456207892208e-05,
      "loss": 0.8742,
      "step": 4481
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4071977138519287,
      "learning_rate": 2.7795957651588065e-05,
      "loss": 0.778,
      "step": 4482
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3717201054096222,
      "learning_rate": 2.7757459095283926e-05,
      "loss": 0.7017,
      "step": 4483
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3440164029598236,
      "learning_rate": 2.7718960538979787e-05,
      "loss": 0.8394,
      "step": 4484
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.49817562103271484,
      "learning_rate": 2.768046198267565e-05,
      "loss": 0.606,
      "step": 4485
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.47978678345680237,
      "learning_rate": 2.7641963426371513e-05,
      "loss": 0.8228,
      "step": 4486
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.33545953035354614,
      "learning_rate": 2.7603464870067374e-05,
      "loss": 0.7703,
      "step": 4487
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3678129315376282,
      "learning_rate": 2.7564966313763235e-05,
      "loss": 0.8363,
      "step": 4488
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3602239191532135,
      "learning_rate": 2.7526467757459096e-05,
      "loss": 0.7355,
      "step": 4489
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.35929015278816223,
      "learning_rate": 2.7487969201154957e-05,
      "loss": 0.5973,
      "step": 4490
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3887944221496582,
      "learning_rate": 2.744947064485082e-05,
      "loss": 0.5807,
      "step": 4491
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.38688650727272034,
      "learning_rate": 2.7410972088546682e-05,
      "loss": 0.6534,
      "step": 4492
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.31881219148635864,
      "learning_rate": 2.7372473532242543e-05,
      "loss": 0.6845,
      "step": 4493
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4341009855270386,
      "learning_rate": 2.7333974975938404e-05,
      "loss": 0.7721,
      "step": 4494
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.42939651012420654,
      "learning_rate": 2.7295476419634265e-05,
      "loss": 0.7828,
      "step": 4495
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.38981232047080994,
      "learning_rate": 2.7256977863330126e-05,
      "loss": 0.6738,
      "step": 4496
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3473384976387024,
      "learning_rate": 2.721847930702599e-05,
      "loss": 0.8849,
      "step": 4497
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.45186567306518555,
      "learning_rate": 2.717998075072185e-05,
      "loss": 0.7591,
      "step": 4498
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4072391390800476,
      "learning_rate": 2.7141482194417712e-05,
      "loss": 0.8248,
      "step": 4499
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3899729549884796,
      "learning_rate": 2.7102983638113573e-05,
      "loss": 0.7608,
      "step": 4500
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3993314504623413,
      "learning_rate": 2.706448508180943e-05,
      "loss": 0.7671,
      "step": 4501
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4165567457675934,
      "learning_rate": 2.7025986525505292e-05,
      "loss": 0.9167,
      "step": 4502
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4046432375907898,
      "learning_rate": 2.698748796920116e-05,
      "loss": 0.6236,
      "step": 4503
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.34548649191856384,
      "learning_rate": 2.6948989412897017e-05,
      "loss": 0.657,
      "step": 4504
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.34847477078437805,
      "learning_rate": 2.6910490856592878e-05,
      "loss": 0.7091,
      "step": 4505
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3865428864955902,
      "learning_rate": 2.687199230028874e-05,
      "loss": 0.6545,
      "step": 4506
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3967805802822113,
      "learning_rate": 2.68334937439846e-05,
      "loss": 0.8558,
      "step": 4507
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3663289248943329,
      "learning_rate": 2.679499518768046e-05,
      "loss": 0.5077,
      "step": 4508
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5825642943382263,
      "learning_rate": 2.6756496631376325e-05,
      "loss": 0.7308,
      "step": 4509
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3228422999382019,
      "learning_rate": 2.6717998075072186e-05,
      "loss": 0.7625,
      "step": 4510
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3644343316555023,
      "learning_rate": 2.6679499518768047e-05,
      "loss": 0.6502,
      "step": 4511
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.43478924036026,
      "learning_rate": 2.664100096246391e-05,
      "loss": 0.6566,
      "step": 4512
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.42583903670310974,
      "learning_rate": 2.660250240615977e-05,
      "loss": 0.7866,
      "step": 4513
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5618898272514343,
      "learning_rate": 2.6564003849855634e-05,
      "loss": 0.9337,
      "step": 4514
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3614979684352875,
      "learning_rate": 2.6525505293551495e-05,
      "loss": 0.9733,
      "step": 4515
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3363741934299469,
      "learning_rate": 2.6487006737247356e-05,
      "loss": 0.7553,
      "step": 4516
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4726579785346985,
      "learning_rate": 2.6448508180943217e-05,
      "loss": 0.71,
      "step": 4517
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.41118964552879333,
      "learning_rate": 2.6410009624639078e-05,
      "loss": 0.6034,
      "step": 4518
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.43593141436576843,
      "learning_rate": 2.6371511068334935e-05,
      "loss": 0.8224,
      "step": 4519
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3967478275299072,
      "learning_rate": 2.6333012512030803e-05,
      "loss": 0.843,
      "step": 4520
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4034009873867035,
      "learning_rate": 2.6294513955726664e-05,
      "loss": 0.6941,
      "step": 4521
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4629184305667877,
      "learning_rate": 2.6256015399422525e-05,
      "loss": 0.7776,
      "step": 4522
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.29872578382492065,
      "learning_rate": 2.6217516843118383e-05,
      "loss": 0.5473,
      "step": 4523
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.471941202878952,
      "learning_rate": 2.6179018286814243e-05,
      "loss": 0.7964,
      "step": 4524
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.44209831953048706,
      "learning_rate": 2.6140519730510104e-05,
      "loss": 0.8628,
      "step": 4525
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.35635724663734436,
      "learning_rate": 2.6102021174205972e-05,
      "loss": 0.9624,
      "step": 4526
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4213945269584656,
      "learning_rate": 2.606352261790183e-05,
      "loss": 0.8858,
      "step": 4527
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.41391119360923767,
      "learning_rate": 2.602502406159769e-05,
      "loss": 0.7695,
      "step": 4528
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4269479513168335,
      "learning_rate": 2.5986525505293552e-05,
      "loss": 0.8137,
      "step": 4529
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.46362507343292236,
      "learning_rate": 2.5948026948989413e-05,
      "loss": 0.7047,
      "step": 4530
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.39068806171417236,
      "learning_rate": 2.5909528392685277e-05,
      "loss": 0.6887,
      "step": 4531
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.37862303853034973,
      "learning_rate": 2.5871029836381138e-05,
      "loss": 0.6154,
      "step": 4532
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.38168856501579285,
      "learning_rate": 2.5832531280077e-05,
      "loss": 0.6926,
      "step": 4533
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3288107216358185,
      "learning_rate": 2.579403272377286e-05,
      "loss": 0.8352,
      "step": 4534
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4723307490348816,
      "learning_rate": 2.575553416746872e-05,
      "loss": 0.8202,
      "step": 4535
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4378991723060608,
      "learning_rate": 2.5717035611164582e-05,
      "loss": 0.7351,
      "step": 4536
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.37581804394721985,
      "learning_rate": 2.5678537054860446e-05,
      "loss": 0.7964,
      "step": 4537
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3589823544025421,
      "learning_rate": 2.5640038498556307e-05,
      "loss": 0.8984,
      "step": 4538
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4092434346675873,
      "learning_rate": 2.560153994225217e-05,
      "loss": 0.6315,
      "step": 4539
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3875660002231598,
      "learning_rate": 2.556304138594803e-05,
      "loss": 0.7493,
      "step": 4540
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4326784908771515,
      "learning_rate": 2.5524542829643887e-05,
      "loss": 0.7432,
      "step": 4541
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.329995334148407,
      "learning_rate": 2.5486044273339748e-05,
      "loss": 0.706,
      "step": 4542
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3958669602870941,
      "learning_rate": 2.5447545717035616e-05,
      "loss": 0.856,
      "step": 4543
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.46495428681373596,
      "learning_rate": 2.5409047160731477e-05,
      "loss": 0.6644,
      "step": 4544
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.40004146099090576,
      "learning_rate": 2.5370548604427334e-05,
      "loss": 0.7437,
      "step": 4545
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3374931514263153,
      "learning_rate": 2.5332050048123195e-05,
      "loss": 0.5943,
      "step": 4546
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3216870427131653,
      "learning_rate": 2.5293551491819056e-05,
      "loss": 0.8124,
      "step": 4547
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.4249073266983032,
      "learning_rate": 2.5255052935514917e-05,
      "loss": 0.7648,
      "step": 4548
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3972756266593933,
      "learning_rate": 2.521655437921078e-05,
      "loss": 0.769,
      "step": 4549
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3687664866447449,
      "learning_rate": 2.5178055822906642e-05,
      "loss": 0.7931,
      "step": 4550
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4199613928794861,
      "learning_rate": 2.5139557266602503e-05,
      "loss": 0.5893,
      "step": 4551
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4015595614910126,
      "learning_rate": 2.5101058710298364e-05,
      "loss": 0.6546,
      "step": 4552
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.33919548988342285,
      "learning_rate": 2.5062560153994225e-05,
      "loss": 0.7635,
      "step": 4553
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3769714832305908,
      "learning_rate": 2.502406159769009e-05,
      "loss": 0.7517,
      "step": 4554
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3907036781311035,
      "learning_rate": 2.4985563041385947e-05,
      "loss": 0.8872,
      "step": 4555
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.46413466334342957,
      "learning_rate": 2.4947064485081812e-05,
      "loss": 0.9275,
      "step": 4556
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.44310954213142395,
      "learning_rate": 2.4908565928777673e-05,
      "loss": 0.7222,
      "step": 4557
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.43512487411499023,
      "learning_rate": 2.4870067372473534e-05,
      "loss": 0.7108,
      "step": 4558
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.37263602018356323,
      "learning_rate": 2.4831568816169395e-05,
      "loss": 0.7147,
      "step": 4559
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.41025230288505554,
      "learning_rate": 2.4793070259865256e-05,
      "loss": 0.4996,
      "step": 4560
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3738504648208618,
      "learning_rate": 2.4754571703561117e-05,
      "loss": 0.7957,
      "step": 4561
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4652411937713623,
      "learning_rate": 2.471607314725698e-05,
      "loss": 0.9388,
      "step": 4562
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4076503813266754,
      "learning_rate": 2.467757459095284e-05,
      "loss": 0.7635,
      "step": 4563
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3402031362056732,
      "learning_rate": 2.4639076034648703e-05,
      "loss": 0.9791,
      "step": 4564
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4253070652484894,
      "learning_rate": 2.4600577478344564e-05,
      "loss": 0.5547,
      "step": 4565
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.45999354124069214,
      "learning_rate": 2.4562078922040425e-05,
      "loss": 0.7319,
      "step": 4566
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4363681972026825,
      "learning_rate": 2.4523580365736286e-05,
      "loss": 0.793,
      "step": 4567
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4301658272743225,
      "learning_rate": 2.4485081809432147e-05,
      "loss": 0.7772,
      "step": 4568
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.463096022605896,
      "learning_rate": 2.4446583253128008e-05,
      "loss": 0.6163,
      "step": 4569
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4473837614059448,
      "learning_rate": 2.4408084696823872e-05,
      "loss": 0.822,
      "step": 4570
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.38250142335891724,
      "learning_rate": 2.4369586140519733e-05,
      "loss": 0.6869,
      "step": 4571
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.34986403584480286,
      "learning_rate": 2.433108758421559e-05,
      "loss": 0.7701,
      "step": 4572
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.39287981390953064,
      "learning_rate": 2.4292589027911455e-05,
      "loss": 0.735,
      "step": 4573
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3876112401485443,
      "learning_rate": 2.4254090471607316e-05,
      "loss": 0.7383,
      "step": 4574
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.36468076705932617,
      "learning_rate": 2.4215591915303177e-05,
      "loss": 0.6492,
      "step": 4575
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.35891634225845337,
      "learning_rate": 2.4177093358999038e-05,
      "loss": 0.6076,
      "step": 4576
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5048202872276306,
      "learning_rate": 2.41385948026949e-05,
      "loss": 0.8905,
      "step": 4577
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5671741366386414,
      "learning_rate": 2.410009624639076e-05,
      "loss": 0.6881,
      "step": 4578
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3923991918563843,
      "learning_rate": 2.4061597690086624e-05,
      "loss": 0.6574,
      "step": 4579
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.46566054224967957,
      "learning_rate": 2.4023099133782485e-05,
      "loss": 0.709,
      "step": 4580
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.41982483863830566,
      "learning_rate": 2.3984600577478343e-05,
      "loss": 0.6943,
      "step": 4581
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3615782558917999,
      "learning_rate": 2.3946102021174207e-05,
      "loss": 0.6548,
      "step": 4582
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4062059819698334,
      "learning_rate": 2.390760346487007e-05,
      "loss": 0.7061,
      "step": 4583
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.42427605390548706,
      "learning_rate": 2.3869104908565933e-05,
      "loss": 0.714,
      "step": 4584
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.45374637842178345,
      "learning_rate": 2.383060635226179e-05,
      "loss": 0.6226,
      "step": 4585
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4682553708553314,
      "learning_rate": 2.379210779595765e-05,
      "loss": 0.6335,
      "step": 4586
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.37678655982017517,
      "learning_rate": 2.3753609239653516e-05,
      "loss": 0.6432,
      "step": 4587
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.42607396841049194,
      "learning_rate": 2.3715110683349377e-05,
      "loss": 0.8568,
      "step": 4588
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.39348652958869934,
      "learning_rate": 2.3676612127045238e-05,
      "loss": 0.9534,
      "step": 4589
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.35480308532714844,
      "learning_rate": 2.36381135707411e-05,
      "loss": 0.7069,
      "step": 4590
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4505188465118408,
      "learning_rate": 2.359961501443696e-05,
      "loss": 0.8033,
      "step": 4591
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3913924992084503,
      "learning_rate": 2.356111645813282e-05,
      "loss": 0.7026,
      "step": 4592
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3534488379955292,
      "learning_rate": 2.3522617901828685e-05,
      "loss": 0.8396,
      "step": 4593
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.37255167961120605,
      "learning_rate": 2.3484119345524542e-05,
      "loss": 0.7437,
      "step": 4594
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.44767138361930847,
      "learning_rate": 2.3445620789220403e-05,
      "loss": 0.5612,
      "step": 4595
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4162227511405945,
      "learning_rate": 2.3407122232916268e-05,
      "loss": 0.645,
      "step": 4596
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.47622138261795044,
      "learning_rate": 2.336862367661213e-05,
      "loss": 0.9647,
      "step": 4597
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4126087725162506,
      "learning_rate": 2.333012512030799e-05,
      "loss": 0.8559,
      "step": 4598
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.49190595746040344,
      "learning_rate": 2.329162656400385e-05,
      "loss": 0.865,
      "step": 4599
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.45045992732048035,
      "learning_rate": 2.3253128007699712e-05,
      "loss": 0.8149,
      "step": 4600
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4558618366718292,
      "learning_rate": 2.3214629451395573e-05,
      "loss": 0.8695,
      "step": 4601
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3610227108001709,
      "learning_rate": 2.3176130895091437e-05,
      "loss": 0.7502,
      "step": 4602
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4448997676372528,
      "learning_rate": 2.3137632338787295e-05,
      "loss": 0.8357,
      "step": 4603
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5431069135665894,
      "learning_rate": 2.3099133782483156e-05,
      "loss": 0.5943,
      "step": 4604
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.45881393551826477,
      "learning_rate": 2.306063522617902e-05,
      "loss": 0.5762,
      "step": 4605
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4115658700466156,
      "learning_rate": 2.302213666987488e-05,
      "loss": 0.7554,
      "step": 4606
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.358535498380661,
      "learning_rate": 2.2983638113570742e-05,
      "loss": 0.7777,
      "step": 4607
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3683096468448639,
      "learning_rate": 2.2945139557266603e-05,
      "loss": 0.6066,
      "step": 4608
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3830336034297943,
      "learning_rate": 2.2906641000962464e-05,
      "loss": 0.7209,
      "step": 4609
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5130090117454529,
      "learning_rate": 2.2868142444658328e-05,
      "loss": 0.7292,
      "step": 4610
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.31992238759994507,
      "learning_rate": 2.282964388835419e-05,
      "loss": 0.7438,
      "step": 4611
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.37993761897087097,
      "learning_rate": 2.2791145332050047e-05,
      "loss": 0.6342,
      "step": 4612
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3947363793849945,
      "learning_rate": 2.275264677574591e-05,
      "loss": 0.671,
      "step": 4613
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4118621051311493,
      "learning_rate": 2.2714148219441772e-05,
      "loss": 0.6916,
      "step": 4614
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3927440643310547,
      "learning_rate": 2.2675649663137633e-05,
      "loss": 0.8082,
      "step": 4615
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4317072629928589,
      "learning_rate": 2.2637151106833494e-05,
      "loss": 0.5259,
      "step": 4616
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3206232488155365,
      "learning_rate": 2.2598652550529355e-05,
      "loss": 0.875,
      "step": 4617
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4038061797618866,
      "learning_rate": 2.2560153994225216e-05,
      "loss": 0.8328,
      "step": 4618
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3562275767326355,
      "learning_rate": 2.252165543792108e-05,
      "loss": 0.6377,
      "step": 4619
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.48592397570610046,
      "learning_rate": 2.248315688161694e-05,
      "loss": 0.6693,
      "step": 4620
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.34704142808914185,
      "learning_rate": 2.24446583253128e-05,
      "loss": 0.7142,
      "step": 4621
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3625067472457886,
      "learning_rate": 2.2406159769008663e-05,
      "loss": 0.6547,
      "step": 4622
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4093915820121765,
      "learning_rate": 2.2367661212704524e-05,
      "loss": 0.6893,
      "step": 4623
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.32507479190826416,
      "learning_rate": 2.2329162656400385e-05,
      "loss": 0.6487,
      "step": 4624
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.42015722393989563,
      "learning_rate": 2.2290664100096246e-05,
      "loss": 0.9862,
      "step": 4625
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.40460118651390076,
      "learning_rate": 2.2252165543792107e-05,
      "loss": 0.6451,
      "step": 4626
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3980945646762848,
      "learning_rate": 2.221366698748797e-05,
      "loss": 0.738,
      "step": 4627
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4001472294330597,
      "learning_rate": 2.2175168431183833e-05,
      "loss": 0.7626,
      "step": 4628
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.44798749685287476,
      "learning_rate": 2.2136669874879694e-05,
      "loss": 0.609,
      "step": 4629
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.38614150881767273,
      "learning_rate": 2.2098171318575555e-05,
      "loss": 0.9031,
      "step": 4630
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4834328889846802,
      "learning_rate": 2.2059672762271416e-05,
      "loss": 0.8293,
      "step": 4631
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3842102587223053,
      "learning_rate": 2.2021174205967277e-05,
      "loss": 0.8065,
      "step": 4632
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.43181726336479187,
      "learning_rate": 2.198267564966314e-05,
      "loss": 0.5818,
      "step": 4633
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3580641746520996,
      "learning_rate": 2.1944177093359e-05,
      "loss": 0.8149,
      "step": 4634
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4091504216194153,
      "learning_rate": 2.190567853705486e-05,
      "loss": 0.6923,
      "step": 4635
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.40792953968048096,
      "learning_rate": 2.1867179980750724e-05,
      "loss": 0.6716,
      "step": 4636
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.435322105884552,
      "learning_rate": 2.1828681424446585e-05,
      "loss": 0.8015,
      "step": 4637
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3980792164802551,
      "learning_rate": 2.1790182868142446e-05,
      "loss": 0.7006,
      "step": 4638
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3727678060531616,
      "learning_rate": 2.1751684311838307e-05,
      "loss": 0.6606,
      "step": 4639
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.49037379026412964,
      "learning_rate": 2.1713185755534168e-05,
      "loss": 0.7241,
      "step": 4640
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.43204832077026367,
      "learning_rate": 2.167468719923003e-05,
      "loss": 0.7423,
      "step": 4641
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.29546797275543213,
      "learning_rate": 2.1636188642925893e-05,
      "loss": 0.6837,
      "step": 4642
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.34798216819763184,
      "learning_rate": 2.1597690086621754e-05,
      "loss": 0.7811,
      "step": 4643
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.417633056640625,
      "learning_rate": 2.155919153031761e-05,
      "loss": 0.6945,
      "step": 4644
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4246350824832916,
      "learning_rate": 2.1520692974013476e-05,
      "loss": 0.9925,
      "step": 4645
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4072588086128235,
      "learning_rate": 2.1482194417709337e-05,
      "loss": 0.6211,
      "step": 4646
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4991638958454132,
      "learning_rate": 2.1443695861405198e-05,
      "loss": 0.9398,
      "step": 4647
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3693326413631439,
      "learning_rate": 2.140519730510106e-05,
      "loss": 0.5524,
      "step": 4648
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3687535524368286,
      "learning_rate": 2.136669874879692e-05,
      "loss": 0.6915,
      "step": 4649
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4140118956565857,
      "learning_rate": 2.1328200192492784e-05,
      "loss": 0.814,
      "step": 4650
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.46060433983802795,
      "learning_rate": 2.1289701636188645e-05,
      "loss": 0.6497,
      "step": 4651
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4733843505382538,
      "learning_rate": 2.1251203079884506e-05,
      "loss": 0.8085,
      "step": 4652
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3667627274990082,
      "learning_rate": 2.1212704523580367e-05,
      "loss": 0.7339,
      "step": 4653
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3967283368110657,
      "learning_rate": 2.1174205967276228e-05,
      "loss": 0.8575,
      "step": 4654
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3744949996471405,
      "learning_rate": 2.113570741097209e-05,
      "loss": 0.6608,
      "step": 4655
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4652971625328064,
      "learning_rate": 2.1097208854667954e-05,
      "loss": 0.7164,
      "step": 4656
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3911813497543335,
      "learning_rate": 2.105871029836381e-05,
      "loss": 0.8088,
      "step": 4657
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.364105224609375,
      "learning_rate": 2.1020211742059672e-05,
      "loss": 0.7444,
      "step": 4658
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5943008661270142,
      "learning_rate": 2.0981713185755537e-05,
      "loss": 0.8351,
      "step": 4659
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3872072696685791,
      "learning_rate": 2.0943214629451398e-05,
      "loss": 0.7497,
      "step": 4660
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3729498088359833,
      "learning_rate": 2.090471607314726e-05,
      "loss": 0.7173,
      "step": 4661
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.40561413764953613,
      "learning_rate": 2.086621751684312e-05,
      "loss": 0.8169,
      "step": 4662
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3757370710372925,
      "learning_rate": 2.082771896053898e-05,
      "loss": 0.7856,
      "step": 4663
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.41591450572013855,
      "learning_rate": 2.078922040423484e-05,
      "loss": 0.816,
      "step": 4664
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.40508630871772766,
      "learning_rate": 2.0750721847930706e-05,
      "loss": 0.7645,
      "step": 4665
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5079099535942078,
      "learning_rate": 2.0712223291626563e-05,
      "loss": 0.7544,
      "step": 4666
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.47392114996910095,
      "learning_rate": 2.0673724735322424e-05,
      "loss": 0.7376,
      "step": 4667
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4777410924434662,
      "learning_rate": 2.063522617901829e-05,
      "loss": 0.6451,
      "step": 4668
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.44768276810646057,
      "learning_rate": 2.059672762271415e-05,
      "loss": 0.6768,
      "step": 4669
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3422253727912903,
      "learning_rate": 2.055822906641001e-05,
      "loss": 0.8411,
      "step": 4670
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.400947242975235,
      "learning_rate": 2.051973051010587e-05,
      "loss": 0.9482,
      "step": 4671
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.48895367980003357,
      "learning_rate": 2.0481231953801733e-05,
      "loss": 0.7761,
      "step": 4672
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5222439169883728,
      "learning_rate": 2.0442733397497597e-05,
      "loss": 0.6616,
      "step": 4673
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4018748998641968,
      "learning_rate": 2.0404234841193458e-05,
      "loss": 0.5857,
      "step": 4674
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.49521785974502563,
      "learning_rate": 2.0365736284889316e-05,
      "loss": 0.8285,
      "step": 4675
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.41942188143730164,
      "learning_rate": 2.032723772858518e-05,
      "loss": 0.6618,
      "step": 4676
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.503883957862854,
      "learning_rate": 2.028873917228104e-05,
      "loss": 0.756,
      "step": 4677
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.36475494503974915,
      "learning_rate": 2.0250240615976902e-05,
      "loss": 0.7646,
      "step": 4678
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3633994460105896,
      "learning_rate": 2.0211742059672763e-05,
      "loss": 0.7332,
      "step": 4679
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3632993698120117,
      "learning_rate": 2.0173243503368624e-05,
      "loss": 0.6298,
      "step": 4680
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3765518367290497,
      "learning_rate": 2.0134744947064485e-05,
      "loss": 0.5657,
      "step": 4681
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.48816463351249695,
      "learning_rate": 2.009624639076035e-05,
      "loss": 0.7137,
      "step": 4682
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.38069406151771545,
      "learning_rate": 2.005774783445621e-05,
      "loss": 0.7847,
      "step": 4683
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4003632366657257,
      "learning_rate": 2.0019249278152068e-05,
      "loss": 0.7102,
      "step": 4684
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3521052300930023,
      "learning_rate": 1.9980750721847932e-05,
      "loss": 0.6689,
      "step": 4685
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.42072805762290955,
      "learning_rate": 1.9942252165543793e-05,
      "loss": 0.7954,
      "step": 4686
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.46151411533355713,
      "learning_rate": 1.9903753609239654e-05,
      "loss": 0.8801,
      "step": 4687
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4017057716846466,
      "learning_rate": 1.9865255052935515e-05,
      "loss": 0.6294,
      "step": 4688
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.33577626943588257,
      "learning_rate": 1.9826756496631376e-05,
      "loss": 0.6421,
      "step": 4689
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3234737515449524,
      "learning_rate": 1.978825794032724e-05,
      "loss": 0.5951,
      "step": 4690
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.39554959535598755,
      "learning_rate": 1.97497593840231e-05,
      "loss": 0.6757,
      "step": 4691
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.33448415994644165,
      "learning_rate": 1.9711260827718962e-05,
      "loss": 0.5794,
      "step": 4692
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.37622493505477905,
      "learning_rate": 1.9672762271414823e-05,
      "loss": 0.9157,
      "step": 4693
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.34352776408195496,
      "learning_rate": 1.9634263715110684e-05,
      "loss": 0.8357,
      "step": 4694
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3990563452243805,
      "learning_rate": 1.9595765158806545e-05,
      "loss": 0.7718,
      "step": 4695
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3772962987422943,
      "learning_rate": 1.955726660250241e-05,
      "loss": 0.5717,
      "step": 4696
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.41319534182548523,
      "learning_rate": 1.9518768046198267e-05,
      "loss": 0.7007,
      "step": 4697
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.43234336376190186,
      "learning_rate": 1.9480269489894128e-05,
      "loss": 0.7372,
      "step": 4698
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3950328528881073,
      "learning_rate": 1.9441770933589993e-05,
      "loss": 0.7825,
      "step": 4699
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5245819091796875,
      "learning_rate": 1.9403272377285854e-05,
      "loss": 0.7905,
      "step": 4700
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.41316044330596924,
      "learning_rate": 1.9364773820981715e-05,
      "loss": 0.6162,
      "step": 4701
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.44494640827178955,
      "learning_rate": 1.9326275264677576e-05,
      "loss": 0.6405,
      "step": 4702
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.38035765290260315,
      "learning_rate": 1.9287776708373437e-05,
      "loss": 0.6714,
      "step": 4703
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3836250603199005,
      "learning_rate": 1.9249278152069297e-05,
      "loss": 0.6649,
      "step": 4704
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4095531702041626,
      "learning_rate": 1.9210779595765162e-05,
      "loss": 0.8031,
      "step": 4705
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.37986239790916443,
      "learning_rate": 1.917228103946102e-05,
      "loss": 0.7867,
      "step": 4706
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.33218660950660706,
      "learning_rate": 1.913378248315688e-05,
      "loss": 0.6392,
      "step": 4707
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.40162762999534607,
      "learning_rate": 1.9095283926852745e-05,
      "loss": 0.8212,
      "step": 4708
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.44451215863227844,
      "learning_rate": 1.9056785370548606e-05,
      "loss": 0.8619,
      "step": 4709
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3270946741104126,
      "learning_rate": 1.9018286814244467e-05,
      "loss": 0.6259,
      "step": 4710
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3760981857776642,
      "learning_rate": 1.8979788257940328e-05,
      "loss": 0.7167,
      "step": 4711
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6327688694000244,
      "learning_rate": 1.894128970163619e-05,
      "loss": 0.819,
      "step": 4712
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.36599069833755493,
      "learning_rate": 1.8902791145332053e-05,
      "loss": 0.7789,
      "step": 4713
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.37747713923454285,
      "learning_rate": 1.8864292589027914e-05,
      "loss": 0.7495,
      "step": 4714
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5177754759788513,
      "learning_rate": 1.882579403272377e-05,
      "loss": 0.7081,
      "step": 4715
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3862462043762207,
      "learning_rate": 1.8787295476419636e-05,
      "loss": 0.6664,
      "step": 4716
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3960544466972351,
      "learning_rate": 1.8748796920115497e-05,
      "loss": 0.679,
      "step": 4717
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.39958447217941284,
      "learning_rate": 1.8710298363811358e-05,
      "loss": 0.8187,
      "step": 4718
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4209757447242737,
      "learning_rate": 1.867179980750722e-05,
      "loss": 0.6273,
      "step": 4719
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4504436254501343,
      "learning_rate": 1.863330125120308e-05,
      "loss": 0.7236,
      "step": 4720
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5316367149353027,
      "learning_rate": 1.859480269489894e-05,
      "loss": 0.6504,
      "step": 4721
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.40188276767730713,
      "learning_rate": 1.8556304138594805e-05,
      "loss": 0.7182,
      "step": 4722
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3863377869129181,
      "learning_rate": 1.8517805582290666e-05,
      "loss": 0.7738,
      "step": 4723
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4659525454044342,
      "learning_rate": 1.8479307025986524e-05,
      "loss": 0.7752,
      "step": 4724
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.416679322719574,
      "learning_rate": 1.8440808469682388e-05,
      "loss": 0.7856,
      "step": 4725
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.37272393703460693,
      "learning_rate": 1.840230991337825e-05,
      "loss": 0.9031,
      "step": 4726
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4548604488372803,
      "learning_rate": 1.836381135707411e-05,
      "loss": 0.8001,
      "step": 4727
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.42872434854507446,
      "learning_rate": 1.832531280076997e-05,
      "loss": 0.6369,
      "step": 4728
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4299187660217285,
      "learning_rate": 1.8286814244465832e-05,
      "loss": 0.7623,
      "step": 4729
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.36496707797050476,
      "learning_rate": 1.8248315688161693e-05,
      "loss": 0.8867,
      "step": 4730
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.38502398133277893,
      "learning_rate": 1.8209817131857557e-05,
      "loss": 0.7807,
      "step": 4731
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3997988998889923,
      "learning_rate": 1.817131857555342e-05,
      "loss": 0.7556,
      "step": 4732
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5055596828460693,
      "learning_rate": 1.813282001924928e-05,
      "loss": 0.645,
      "step": 4733
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3401446044445038,
      "learning_rate": 1.809432146294514e-05,
      "loss": 0.8692,
      "step": 4734
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4425467252731323,
      "learning_rate": 1.8055822906641e-05,
      "loss": 0.652,
      "step": 4735
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.35031676292419434,
      "learning_rate": 1.8017324350336866e-05,
      "loss": 0.6464,
      "step": 4736
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3911381959915161,
      "learning_rate": 1.7978825794032723e-05,
      "loss": 0.708,
      "step": 4737
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.37676095962524414,
      "learning_rate": 1.7940327237728584e-05,
      "loss": 0.6688,
      "step": 4738
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.47409531474113464,
      "learning_rate": 1.790182868142445e-05,
      "loss": 0.7482,
      "step": 4739
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.48856016993522644,
      "learning_rate": 1.786333012512031e-05,
      "loss": 0.9237,
      "step": 4740
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3634648323059082,
      "learning_rate": 1.782483156881617e-05,
      "loss": 0.7471,
      "step": 4741
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.45285987854003906,
      "learning_rate": 1.778633301251203e-05,
      "loss": 0.8633,
      "step": 4742
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3957396149635315,
      "learning_rate": 1.7747834456207893e-05,
      "loss": 0.5014,
      "step": 4743
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3508111536502838,
      "learning_rate": 1.7709335899903754e-05,
      "loss": 0.7545,
      "step": 4744
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4243893325328827,
      "learning_rate": 1.7670837343599618e-05,
      "loss": 0.7715,
      "step": 4745
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3907124698162079,
      "learning_rate": 1.7632338787295476e-05,
      "loss": 0.6603,
      "step": 4746
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.37227627635002136,
      "learning_rate": 1.7593840230991336e-05,
      "loss": 0.7343,
      "step": 4747
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.36832407116889954,
      "learning_rate": 1.75553416746872e-05,
      "loss": 0.7703,
      "step": 4748
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.41682538390159607,
      "learning_rate": 1.7516843118383062e-05,
      "loss": 0.7418,
      "step": 4749
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4559094309806824,
      "learning_rate": 1.7478344562078923e-05,
      "loss": 0.8335,
      "step": 4750
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3718406856060028,
      "learning_rate": 1.7439846005774784e-05,
      "loss": 0.7813,
      "step": 4751
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4387413263320923,
      "learning_rate": 1.7401347449470645e-05,
      "loss": 0.7976,
      "step": 4752
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.341033399105072,
      "learning_rate": 1.736284889316651e-05,
      "loss": 0.6637,
      "step": 4753
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.32954007387161255,
      "learning_rate": 1.732435033686237e-05,
      "loss": 0.7096,
      "step": 4754
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4328264892101288,
      "learning_rate": 1.7285851780558228e-05,
      "loss": 0.8784,
      "step": 4755
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.4162055253982544,
      "learning_rate": 1.7247353224254092e-05,
      "loss": 0.8544,
      "step": 4756
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.336577832698822,
      "learning_rate": 1.7208854667949953e-05,
      "loss": 0.8765,
      "step": 4757
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.41680073738098145,
      "learning_rate": 1.7170356111645814e-05,
      "loss": 0.7816,
      "step": 4758
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3770880699157715,
      "learning_rate": 1.7131857555341675e-05,
      "loss": 0.7096,
      "step": 4759
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.35157349705696106,
      "learning_rate": 1.7093358999037536e-05,
      "loss": 0.6933,
      "step": 4760
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3233989179134369,
      "learning_rate": 1.7054860442733397e-05,
      "loss": 0.7874,
      "step": 4761
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.39539146423339844,
      "learning_rate": 1.701636188642926e-05,
      "loss": 0.7257,
      "step": 4762
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4421650171279907,
      "learning_rate": 1.6977863330125122e-05,
      "loss": 0.5936,
      "step": 4763
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.40726083517074585,
      "learning_rate": 1.693936477382098e-05,
      "loss": 0.755,
      "step": 4764
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.32743650674819946,
      "learning_rate": 1.6900866217516844e-05,
      "loss": 0.6387,
      "step": 4765
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4329821467399597,
      "learning_rate": 1.6862367661212705e-05,
      "loss": 0.841,
      "step": 4766
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3308912515640259,
      "learning_rate": 1.6823869104908566e-05,
      "loss": 0.6843,
      "step": 4767
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.46806600689888,
      "learning_rate": 1.6785370548604427e-05,
      "loss": 0.9079,
      "step": 4768
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3954065144062042,
      "learning_rate": 1.6746871992300288e-05,
      "loss": 0.87,
      "step": 4769
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3740359842777252,
      "learning_rate": 1.670837343599615e-05,
      "loss": 0.8039,
      "step": 4770
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.46314090490341187,
      "learning_rate": 1.6669874879692014e-05,
      "loss": 0.6656,
      "step": 4771
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.402692049741745,
      "learning_rate": 1.6631376323387874e-05,
      "loss": 0.7223,
      "step": 4772
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4109562933444977,
      "learning_rate": 1.6592877767083735e-05,
      "loss": 0.7326,
      "step": 4773
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.39187106490135193,
      "learning_rate": 1.6554379210779596e-05,
      "loss": 0.689,
      "step": 4774
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4452153444290161,
      "learning_rate": 1.6515880654475457e-05,
      "loss": 0.8551,
      "step": 4775
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.36729875206947327,
      "learning_rate": 1.6477382098171322e-05,
      "loss": 0.7125,
      "step": 4776
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4703284204006195,
      "learning_rate": 1.643888354186718e-05,
      "loss": 0.6338,
      "step": 4777
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.39173242449760437,
      "learning_rate": 1.640038498556304e-05,
      "loss": 0.7722,
      "step": 4778
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4749774932861328,
      "learning_rate": 1.6361886429258905e-05,
      "loss": 0.6108,
      "step": 4779
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4406033754348755,
      "learning_rate": 1.6323387872954766e-05,
      "loss": 0.5832,
      "step": 4780
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.35199037194252014,
      "learning_rate": 1.6284889316650627e-05,
      "loss": 0.7882,
      "step": 4781
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.359723836183548,
      "learning_rate": 1.6246390760346488e-05,
      "loss": 0.8054,
      "step": 4782
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.41284969449043274,
      "learning_rate": 1.620789220404235e-05,
      "loss": 0.92,
      "step": 4783
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.40980297327041626,
      "learning_rate": 1.616939364773821e-05,
      "loss": 0.6631,
      "step": 4784
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.35131415724754333,
      "learning_rate": 1.6130895091434074e-05,
      "loss": 0.7217,
      "step": 4785
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.442623496055603,
      "learning_rate": 1.6092396535129935e-05,
      "loss": 0.5581,
      "step": 4786
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.39804545044898987,
      "learning_rate": 1.6053897978825793e-05,
      "loss": 0.809,
      "step": 4787
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.40561816096305847,
      "learning_rate": 1.6015399422521657e-05,
      "loss": 0.66,
      "step": 4788
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.44356346130371094,
      "learning_rate": 1.5976900866217518e-05,
      "loss": 0.9821,
      "step": 4789
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3352155387401581,
      "learning_rate": 1.593840230991338e-05,
      "loss": 0.4918,
      "step": 4790
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3922698199748993,
      "learning_rate": 1.589990375360924e-05,
      "loss": 0.727,
      "step": 4791
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.41076505184173584,
      "learning_rate": 1.58614051973051e-05,
      "loss": 0.7509,
      "step": 4792
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3727363049983978,
      "learning_rate": 1.5822906641000962e-05,
      "loss": 0.81,
      "step": 4793
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.37883833050727844,
      "learning_rate": 1.5784408084696826e-05,
      "loss": 0.6524,
      "step": 4794
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4770474433898926,
      "learning_rate": 1.5745909528392687e-05,
      "loss": 0.5942,
      "step": 4795
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.38233715295791626,
      "learning_rate": 1.5707410972088548e-05,
      "loss": 0.7314,
      "step": 4796
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.37879428267478943,
      "learning_rate": 1.566891241578441e-05,
      "loss": 0.7953,
      "step": 4797
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4275537133216858,
      "learning_rate": 1.563041385948027e-05,
      "loss": 0.6512,
      "step": 4798
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.48233404755592346,
      "learning_rate": 1.5591915303176134e-05,
      "loss": 0.7254,
      "step": 4799
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4629160165786743,
      "learning_rate": 1.5553416746871992e-05,
      "loss": 0.7702,
      "step": 4800
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4823490083217621,
      "learning_rate": 1.5514918190567853e-05,
      "loss": 0.6575,
      "step": 4801
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3717389702796936,
      "learning_rate": 1.5476419634263717e-05,
      "loss": 0.6491,
      "step": 4802
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4689091444015503,
      "learning_rate": 1.543792107795958e-05,
      "loss": 0.844,
      "step": 4803
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3850773572921753,
      "learning_rate": 1.539942252165544e-05,
      "loss": 0.5844,
      "step": 4804
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3895963430404663,
      "learning_rate": 1.53609239653513e-05,
      "loss": 0.7718,
      "step": 4805
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.38129618763923645,
      "learning_rate": 1.532242540904716e-05,
      "loss": 0.8085,
      "step": 4806
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.36260420083999634,
      "learning_rate": 1.5283926852743022e-05,
      "loss": 0.6576,
      "step": 4807
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.381186842918396,
      "learning_rate": 1.5245428296438885e-05,
      "loss": 0.5137,
      "step": 4808
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.36487480998039246,
      "learning_rate": 1.5206929740134746e-05,
      "loss": 0.7249,
      "step": 4809
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.34770479798316956,
      "learning_rate": 1.5168431183830605e-05,
      "loss": 0.673,
      "step": 4810
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4318280816078186,
      "learning_rate": 1.512993262752647e-05,
      "loss": 0.7555,
      "step": 4811
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.46135279536247253,
      "learning_rate": 1.5091434071222329e-05,
      "loss": 0.7877,
      "step": 4812
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.34984028339385986,
      "learning_rate": 1.505293551491819e-05,
      "loss": 0.7305,
      "step": 4813
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.35096949338912964,
      "learning_rate": 1.5014436958614053e-05,
      "loss": 0.9434,
      "step": 4814
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.42540428042411804,
      "learning_rate": 1.4975938402309913e-05,
      "loss": 0.7595,
      "step": 4815
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.40411892533302307,
      "learning_rate": 1.4937439846005776e-05,
      "loss": 0.7395,
      "step": 4816
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.36652275919914246,
      "learning_rate": 1.4898941289701637e-05,
      "loss": 0.6801,
      "step": 4817
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4008857011795044,
      "learning_rate": 1.4860442733397498e-05,
      "loss": 0.7095,
      "step": 4818
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3261651396751404,
      "learning_rate": 1.482194417709336e-05,
      "loss": 0.7393,
      "step": 4819
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3780515193939209,
      "learning_rate": 1.4783445620789222e-05,
      "loss": 0.9071,
      "step": 4820
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4593936502933502,
      "learning_rate": 1.4744947064485081e-05,
      "loss": 0.6474,
      "step": 4821
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.38236290216445923,
      "learning_rate": 1.4706448508180945e-05,
      "loss": 0.8185,
      "step": 4822
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.40797555446624756,
      "learning_rate": 1.4667949951876805e-05,
      "loss": 0.6875,
      "step": 4823
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.334121972322464,
      "learning_rate": 1.4629451395572666e-05,
      "loss": 0.4801,
      "step": 4824
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3947117030620575,
      "learning_rate": 1.4590952839268528e-05,
      "loss": 0.5662,
      "step": 4825
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4394242465496063,
      "learning_rate": 1.455245428296439e-05,
      "loss": 0.6279,
      "step": 4826
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.45133453607559204,
      "learning_rate": 1.451395572666025e-05,
      "loss": 0.6625,
      "step": 4827
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.366681307554245,
      "learning_rate": 1.4475457170356113e-05,
      "loss": 0.8549,
      "step": 4828
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.35003018379211426,
      "learning_rate": 1.4436958614051974e-05,
      "loss": 0.6734,
      "step": 4829
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3965376317501068,
      "learning_rate": 1.4398460057747833e-05,
      "loss": 0.7415,
      "step": 4830
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3791976571083069,
      "learning_rate": 1.4359961501443698e-05,
      "loss": 0.8416,
      "step": 4831
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.383137047290802,
      "learning_rate": 1.4321462945139557e-05,
      "loss": 0.6876,
      "step": 4832
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.36655786633491516,
      "learning_rate": 1.4282964388835418e-05,
      "loss": 0.7551,
      "step": 4833
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5615614056587219,
      "learning_rate": 1.424446583253128e-05,
      "loss": 0.8556,
      "step": 4834
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3307715654373169,
      "learning_rate": 1.4205967276227142e-05,
      "loss": 0.7717,
      "step": 4835
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.49414727091789246,
      "learning_rate": 1.4167468719923004e-05,
      "loss": 0.6564,
      "step": 4836
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3631685972213745,
      "learning_rate": 1.4128970163618865e-05,
      "loss": 0.6402,
      "step": 4837
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3889450132846832,
      "learning_rate": 1.4090471607314726e-05,
      "loss": 0.742,
      "step": 4838
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4049321711063385,
      "learning_rate": 1.4051973051010589e-05,
      "loss": 0.6909,
      "step": 4839
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5811771750450134,
      "learning_rate": 1.401347449470645e-05,
      "loss": 0.8015,
      "step": 4840
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4126823842525482,
      "learning_rate": 1.3974975938402309e-05,
      "loss": 0.8754,
      "step": 4841
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.42150458693504333,
      "learning_rate": 1.3936477382098173e-05,
      "loss": 0.7024,
      "step": 4842
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5712681412696838,
      "learning_rate": 1.3897978825794033e-05,
      "loss": 0.778,
      "step": 4843
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.38878220319747925,
      "learning_rate": 1.3859480269489894e-05,
      "loss": 0.7551,
      "step": 4844
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3943275213241577,
      "learning_rate": 1.3820981713185756e-05,
      "loss": 0.9169,
      "step": 4845
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4207901656627655,
      "learning_rate": 1.3782483156881617e-05,
      "loss": 0.7085,
      "step": 4846
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.426900178194046,
      "learning_rate": 1.3743984600577478e-05,
      "loss": 0.7347,
      "step": 4847
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4233456552028656,
      "learning_rate": 1.3705486044273341e-05,
      "loss": 0.7249,
      "step": 4848
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3989236652851105,
      "learning_rate": 1.3666987487969202e-05,
      "loss": 0.777,
      "step": 4849
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.36024102568626404,
      "learning_rate": 1.3628488931665063e-05,
      "loss": 0.6956,
      "step": 4850
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.38077670335769653,
      "learning_rate": 1.3589990375360926e-05,
      "loss": 0.6436,
      "step": 4851
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.40577447414398193,
      "learning_rate": 1.3551491819056787e-05,
      "loss": 0.7024,
      "step": 4852
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4701373875141144,
      "learning_rate": 1.3512993262752646e-05,
      "loss": 0.7219,
      "step": 4853
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4928658604621887,
      "learning_rate": 1.3474494706448509e-05,
      "loss": 0.6999,
      "step": 4854
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3380255401134491,
      "learning_rate": 1.343599615014437e-05,
      "loss": 0.567,
      "step": 4855
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3838682472705841,
      "learning_rate": 1.339749759384023e-05,
      "loss": 0.6967,
      "step": 4856
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.36164093017578125,
      "learning_rate": 1.3358999037536093e-05,
      "loss": 0.6401,
      "step": 4857
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.39852264523506165,
      "learning_rate": 1.3320500481231954e-05,
      "loss": 0.7043,
      "step": 4858
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3846278190612793,
      "learning_rate": 1.3282001924927817e-05,
      "loss": 0.6002,
      "step": 4859
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3594198226928711,
      "learning_rate": 1.3243503368623678e-05,
      "loss": 0.7266,
      "step": 4860
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4577818214893341,
      "learning_rate": 1.3205004812319539e-05,
      "loss": 0.689,
      "step": 4861
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.4152141511440277,
      "learning_rate": 1.3166506256015401e-05,
      "loss": 0.9772,
      "step": 4862
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.369331955909729,
      "learning_rate": 1.3128007699711262e-05,
      "loss": 0.8461,
      "step": 4863
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.44159045815467834,
      "learning_rate": 1.3089509143407122e-05,
      "loss": 0.5559,
      "step": 4864
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3956087529659271,
      "learning_rate": 1.3051010587102986e-05,
      "loss": 0.6212,
      "step": 4865
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3366447389125824,
      "learning_rate": 1.3012512030798845e-05,
      "loss": 1.0105,
      "step": 4866
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4496460258960724,
      "learning_rate": 1.2974013474494706e-05,
      "loss": 0.74,
      "step": 4867
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.42220717668533325,
      "learning_rate": 1.2935514918190569e-05,
      "loss": 0.6938,
      "step": 4868
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3937692940235138,
      "learning_rate": 1.289701636188643e-05,
      "loss": 0.5723,
      "step": 4869
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.36962419748306274,
      "learning_rate": 1.2858517805582291e-05,
      "loss": 0.6309,
      "step": 4870
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.45922237634658813,
      "learning_rate": 1.2820019249278154e-05,
      "loss": 0.9707,
      "step": 4871
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.36993297934532166,
      "learning_rate": 1.2781520692974015e-05,
      "loss": 0.7389,
      "step": 4872
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4178360402584076,
      "learning_rate": 1.2743022136669874e-05,
      "loss": 0.7764,
      "step": 4873
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3524470329284668,
      "learning_rate": 1.2704523580365738e-05,
      "loss": 0.7161,
      "step": 4874
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3845261335372925,
      "learning_rate": 1.2666025024061598e-05,
      "loss": 0.6848,
      "step": 4875
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4214598536491394,
      "learning_rate": 1.2627526467757459e-05,
      "loss": 0.7314,
      "step": 4876
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3889397382736206,
      "learning_rate": 1.2589027911453321e-05,
      "loss": 0.7207,
      "step": 4877
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.406972736120224,
      "learning_rate": 1.2550529355149182e-05,
      "loss": 0.6402,
      "step": 4878
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.37286868691444397,
      "learning_rate": 1.2512030798845045e-05,
      "loss": 0.761,
      "step": 4879
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.44158312678337097,
      "learning_rate": 1.2473532242540906e-05,
      "loss": 0.4782,
      "step": 4880
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3631298542022705,
      "learning_rate": 1.2435033686236767e-05,
      "loss": 0.8027,
      "step": 4881
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3773038685321808,
      "learning_rate": 1.2396535129932628e-05,
      "loss": 0.5267,
      "step": 4882
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.378713995218277,
      "learning_rate": 1.235803657362849e-05,
      "loss": 0.5962,
      "step": 4883
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4215373992919922,
      "learning_rate": 1.2319538017324351e-05,
      "loss": 0.6499,
      "step": 4884
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3671601414680481,
      "learning_rate": 1.2281039461020212e-05,
      "loss": 0.8092,
      "step": 4885
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4186635911464691,
      "learning_rate": 1.2242540904716073e-05,
      "loss": 0.7169,
      "step": 4886
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.41835635900497437,
      "learning_rate": 1.2204042348411936e-05,
      "loss": 0.6482,
      "step": 4887
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4890979826450348,
      "learning_rate": 1.2165543792107795e-05,
      "loss": 0.5491,
      "step": 4888
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3908502459526062,
      "learning_rate": 1.2127045235803658e-05,
      "loss": 0.6758,
      "step": 4889
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3903668522834778,
      "learning_rate": 1.2088546679499519e-05,
      "loss": 0.6244,
      "step": 4890
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.43425285816192627,
      "learning_rate": 1.205004812319538e-05,
      "loss": 0.7251,
      "step": 4891
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.47908470034599304,
      "learning_rate": 1.2011549566891243e-05,
      "loss": 0.7584,
      "step": 4892
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3528203070163727,
      "learning_rate": 1.1973051010587104e-05,
      "loss": 0.7043,
      "step": 4893
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.37634310126304626,
      "learning_rate": 1.1934552454282966e-05,
      "loss": 0.8374,
      "step": 4894
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3955559730529785,
      "learning_rate": 1.1896053897978826e-05,
      "loss": 0.7138,
      "step": 4895
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.39052584767341614,
      "learning_rate": 1.1857555341674688e-05,
      "loss": 0.8467,
      "step": 4896
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4378266930580139,
      "learning_rate": 1.181905678537055e-05,
      "loss": 0.7773,
      "step": 4897
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4222889244556427,
      "learning_rate": 1.178055822906641e-05,
      "loss": 0.944,
      "step": 4898
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.380164235830307,
      "learning_rate": 1.1742059672762271e-05,
      "loss": 0.6974,
      "step": 4899
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3883765935897827,
      "learning_rate": 1.1703561116458134e-05,
      "loss": 0.786,
      "step": 4900
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.38740307092666626,
      "learning_rate": 1.1665062560153995e-05,
      "loss": 0.752,
      "step": 4901
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4425535500049591,
      "learning_rate": 1.1626564003849856e-05,
      "loss": 0.5573,
      "step": 4902
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5297874808311462,
      "learning_rate": 1.1588065447545719e-05,
      "loss": 0.684,
      "step": 4903
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3965699374675751,
      "learning_rate": 1.1549566891241578e-05,
      "loss": 0.6943,
      "step": 4904
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4224337339401245,
      "learning_rate": 1.151106833493744e-05,
      "loss": 0.8147,
      "step": 4905
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.45876654982566833,
      "learning_rate": 1.1472569778633301e-05,
      "loss": 0.7262,
      "step": 4906
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3539496064186096,
      "learning_rate": 1.1434071222329164e-05,
      "loss": 0.7403,
      "step": 4907
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.40826210379600525,
      "learning_rate": 1.1395572666025023e-05,
      "loss": 0.6293,
      "step": 4908
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3711756765842438,
      "learning_rate": 1.1357074109720886e-05,
      "loss": 0.815,
      "step": 4909
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3665441870689392,
      "learning_rate": 1.1318575553416747e-05,
      "loss": 0.7293,
      "step": 4910
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4487614035606384,
      "learning_rate": 1.1280076997112608e-05,
      "loss": 0.8429,
      "step": 4911
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.37054604291915894,
      "learning_rate": 1.124157844080847e-05,
      "loss": 0.8026,
      "step": 4912
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.39459988474845886,
      "learning_rate": 1.1203079884504332e-05,
      "loss": 0.8927,
      "step": 4913
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.46870747208595276,
      "learning_rate": 1.1164581328200193e-05,
      "loss": 0.7341,
      "step": 4914
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.34847384691238403,
      "learning_rate": 1.1126082771896054e-05,
      "loss": 0.7621,
      "step": 4915
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.45251867175102234,
      "learning_rate": 1.1087584215591916e-05,
      "loss": 0.8651,
      "step": 4916
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3383598029613495,
      "learning_rate": 1.1049085659287777e-05,
      "loss": 0.6546,
      "step": 4917
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.44582653045654297,
      "learning_rate": 1.1010587102983638e-05,
      "loss": 0.8226,
      "step": 4918
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.40303000807762146,
      "learning_rate": 1.09720885466795e-05,
      "loss": 0.6986,
      "step": 4919
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3847719728946686,
      "learning_rate": 1.0933589990375362e-05,
      "loss": 0.6081,
      "step": 4920
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3914826810359955,
      "learning_rate": 1.0895091434071223e-05,
      "loss": 0.7019,
      "step": 4921
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3819993734359741,
      "learning_rate": 1.0856592877767084e-05,
      "loss": 0.6137,
      "step": 4922
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3935889005661011,
      "learning_rate": 1.0818094321462947e-05,
      "loss": 0.7625,
      "step": 4923
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4105745255947113,
      "learning_rate": 1.0779595765158806e-05,
      "loss": 0.6342,
      "step": 4924
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.43691927194595337,
      "learning_rate": 1.0741097208854669e-05,
      "loss": 0.6943,
      "step": 4925
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3750264048576355,
      "learning_rate": 1.070259865255053e-05,
      "loss": 0.6756,
      "step": 4926
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.35095635056495667,
      "learning_rate": 1.0664100096246392e-05,
      "loss": 0.7387,
      "step": 4927
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3570326566696167,
      "learning_rate": 1.0625601539942253e-05,
      "loss": 0.7921,
      "step": 4928
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.34524235129356384,
      "learning_rate": 1.0587102983638114e-05,
      "loss": 0.6019,
      "step": 4929
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4283045828342438,
      "learning_rate": 1.0548604427333977e-05,
      "loss": 0.7008,
      "step": 4930
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3619423806667328,
      "learning_rate": 1.0510105871029836e-05,
      "loss": 0.7042,
      "step": 4931
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4333154261112213,
      "learning_rate": 1.0471607314725699e-05,
      "loss": 0.7811,
      "step": 4932
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4750695526599884,
      "learning_rate": 1.043310875842156e-05,
      "loss": 0.7043,
      "step": 4933
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3502335250377655,
      "learning_rate": 1.039461020211742e-05,
      "loss": 0.6158,
      "step": 4934
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.41439613699913025,
      "learning_rate": 1.0356111645813282e-05,
      "loss": 0.8375,
      "step": 4935
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3698047995567322,
      "learning_rate": 1.0317613089509144e-05,
      "loss": 0.8737,
      "step": 4936
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.37329617142677307,
      "learning_rate": 1.0279114533205005e-05,
      "loss": 0.7839,
      "step": 4937
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.29775702953338623,
      "learning_rate": 1.0240615976900866e-05,
      "loss": 0.9607,
      "step": 4938
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.35325726866722107,
      "learning_rate": 1.0202117420596729e-05,
      "loss": 0.6799,
      "step": 4939
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5122230052947998,
      "learning_rate": 1.016361886429259e-05,
      "loss": 0.7597,
      "step": 4940
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4520857036113739,
      "learning_rate": 1.0125120307988451e-05,
      "loss": 0.7541,
      "step": 4941
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.424003005027771,
      "learning_rate": 1.0086621751684312e-05,
      "loss": 0.7094,
      "step": 4942
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4272322654724121,
      "learning_rate": 1.0048123195380175e-05,
      "loss": 0.8961,
      "step": 4943
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3669152855873108,
      "learning_rate": 1.0009624639076034e-05,
      "loss": 0.5314,
      "step": 4944
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4345974326133728,
      "learning_rate": 9.971126082771897e-06,
      "loss": 0.6964,
      "step": 4945
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.39115509390830994,
      "learning_rate": 9.932627526467758e-06,
      "loss": 0.7953,
      "step": 4946
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.38402917981147766,
      "learning_rate": 9.89412897016362e-06,
      "loss": 0.5872,
      "step": 4947
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.480379581451416,
      "learning_rate": 9.855630413859481e-06,
      "loss": 0.5721,
      "step": 4948
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.37209567427635193,
      "learning_rate": 9.817131857555342e-06,
      "loss": 0.6886,
      "step": 4949
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.39511993527412415,
      "learning_rate": 9.778633301251205e-06,
      "loss": 0.933,
      "step": 4950
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3863537609577179,
      "learning_rate": 9.740134744947064e-06,
      "loss": 0.97,
      "step": 4951
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4078271985054016,
      "learning_rate": 9.701636188642927e-06,
      "loss": 0.8325,
      "step": 4952
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5628710985183716,
      "learning_rate": 9.663137632338788e-06,
      "loss": 0.7257,
      "step": 4953
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.38928166031837463,
      "learning_rate": 9.624639076034649e-06,
      "loss": 0.7536,
      "step": 4954
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.44313207268714905,
      "learning_rate": 9.58614051973051e-06,
      "loss": 0.8267,
      "step": 4955
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3801598846912384,
      "learning_rate": 9.547641963426372e-06,
      "loss": 0.8369,
      "step": 4956
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.42454224824905396,
      "learning_rate": 9.509143407122233e-06,
      "loss": 0.7802,
      "step": 4957
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.41235587000846863,
      "learning_rate": 9.470644850818094e-06,
      "loss": 0.7708,
      "step": 4958
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.36794477701187134,
      "learning_rate": 9.432146294513957e-06,
      "loss": 0.7547,
      "step": 4959
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4099171757698059,
      "learning_rate": 9.393647738209818e-06,
      "loss": 0.8636,
      "step": 4960
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.44632619619369507,
      "learning_rate": 9.355149181905679e-06,
      "loss": 0.5009,
      "step": 4961
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5291094779968262,
      "learning_rate": 9.31665062560154e-06,
      "loss": 0.6197,
      "step": 4962
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.34701108932495117,
      "learning_rate": 9.278152069297403e-06,
      "loss": 0.7628,
      "step": 4963
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.40816420316696167,
      "learning_rate": 9.239653512993262e-06,
      "loss": 0.671,
      "step": 4964
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3455183207988739,
      "learning_rate": 9.201154956689125e-06,
      "loss": 0.7334,
      "step": 4965
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.38871604204177856,
      "learning_rate": 9.162656400384986e-06,
      "loss": 0.7369,
      "step": 4966
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.465644896030426,
      "learning_rate": 9.124157844080847e-06,
      "loss": 0.7031,
      "step": 4967
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.393780380487442,
      "learning_rate": 9.08565928777671e-06,
      "loss": 0.861,
      "step": 4968
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3619910776615143,
      "learning_rate": 9.04716073147257e-06,
      "loss": 0.5607,
      "step": 4969
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4166955053806305,
      "learning_rate": 9.008662175168433e-06,
      "loss": 0.6425,
      "step": 4970
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4216725826263428,
      "learning_rate": 8.970163618864292e-06,
      "loss": 0.7112,
      "step": 4971
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.36384183168411255,
      "learning_rate": 8.931665062560155e-06,
      "loss": 0.786,
      "step": 4972
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5007371306419373,
      "learning_rate": 8.893166506256016e-06,
      "loss": 0.783,
      "step": 4973
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.38586461544036865,
      "learning_rate": 8.854667949951877e-06,
      "loss": 0.5777,
      "step": 4974
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3291773200035095,
      "learning_rate": 8.816169393647738e-06,
      "loss": 0.8307,
      "step": 4975
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.49813908338546753,
      "learning_rate": 8.7776708373436e-06,
      "loss": 0.7571,
      "step": 4976
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3944081664085388,
      "learning_rate": 8.739172281039461e-06,
      "loss": 0.7448,
      "step": 4977
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.37834250926971436,
      "learning_rate": 8.700673724735322e-06,
      "loss": 0.6161,
      "step": 4978
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3792310357093811,
      "learning_rate": 8.662175168431185e-06,
      "loss": 0.7334,
      "step": 4979
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.42321979999542236,
      "learning_rate": 8.623676612127046e-06,
      "loss": 0.7845,
      "step": 4980
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.34495022892951965,
      "learning_rate": 8.585178055822907e-06,
      "loss": 0.7621,
      "step": 4981
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.41793137788772583,
      "learning_rate": 8.546679499518768e-06,
      "loss": 0.8399,
      "step": 4982
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3591456413269043,
      "learning_rate": 8.50818094321463e-06,
      "loss": 0.9338,
      "step": 4983
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.48824751377105713,
      "learning_rate": 8.46968238691049e-06,
      "loss": 0.7835,
      "step": 4984
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.39927583932876587,
      "learning_rate": 8.431183830606353e-06,
      "loss": 0.6097,
      "step": 4985
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3872133195400238,
      "learning_rate": 8.392685274302214e-06,
      "loss": 0.7869,
      "step": 4986
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.46709775924682617,
      "learning_rate": 8.354186717998075e-06,
      "loss": 0.7353,
      "step": 4987
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3309883773326874,
      "learning_rate": 8.315688161693937e-06,
      "loss": 0.8634,
      "step": 4988
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.34697431325912476,
      "learning_rate": 8.277189605389798e-06,
      "loss": 0.6167,
      "step": 4989
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.33383044600486755,
      "learning_rate": 8.238691049085661e-06,
      "loss": 0.7721,
      "step": 4990
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.39182767271995544,
      "learning_rate": 8.20019249278152e-06,
      "loss": 0.7648,
      "step": 4991
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.45513302087783813,
      "learning_rate": 8.161693936477383e-06,
      "loss": 0.7441,
      "step": 4992
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3940509557723999,
      "learning_rate": 8.123195380173244e-06,
      "loss": 0.7165,
      "step": 4993
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3739987015724182,
      "learning_rate": 8.084696823869105e-06,
      "loss": 0.7573,
      "step": 4994
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.442339688539505,
      "learning_rate": 8.046198267564967e-06,
      "loss": 0.8295,
      "step": 4995
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4145590364933014,
      "learning_rate": 8.007699711260828e-06,
      "loss": 0.7043,
      "step": 4996
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4404003322124481,
      "learning_rate": 7.96920115495669e-06,
      "loss": 0.8064,
      "step": 4997
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.44201764464378357,
      "learning_rate": 7.93070259865255e-06,
      "loss": 0.5642,
      "step": 4998
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2982177436351776,
      "learning_rate": 7.892204042348413e-06,
      "loss": 0.7353,
      "step": 4999
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.40861618518829346,
      "learning_rate": 7.853705486044274e-06,
      "loss": 0.7183,
      "step": 5000
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 2.7117296828104704e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

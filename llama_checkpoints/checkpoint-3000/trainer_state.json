{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5768953415701168,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0,
      "loss": 2.098,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.457374572753906,
      "learning_rate": 4e-05,
      "loss": 2.1917,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7966217994689941,
      "learning_rate": 8e-05,
      "loss": 2.0472,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 8e-05,
      "loss": 2.1569,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.239715099334717,
      "learning_rate": 0.00012,
      "loss": 2.1789,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.806528091430664,
      "learning_rate": 0.00016,
      "loss": 1.9093,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7827303409576416,
      "learning_rate": 0.0002,
      "loss": 1.9295,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7811224460601807,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.9561,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.6722819805145264,
      "learning_rate": 0.00019992300288739173,
      "loss": 2.0285,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1149275302886963,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.6257,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7799516916275024,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.8609,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.874711513519287,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.586,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.246931314468384,
      "learning_rate": 0.00019976900866217518,
      "loss": 1.5202,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0075149536132812,
      "learning_rate": 0.00019973051010587105,
      "loss": 1.2222,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4524502754211426,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.2517,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.251847743988037,
      "learning_rate": 0.00019965351299326277,
      "loss": 1.2791,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.737441062927246,
      "learning_rate": 0.00019961501443695862,
      "loss": 1.2863,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.00286865234375,
      "learning_rate": 0.0001995765158806545,
      "loss": 1.103,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9747,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.114648818969727,
      "learning_rate": 0.00019953801732435037,
      "loss": 1.0495,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.003035545349121,
      "learning_rate": 0.0001994995187680462,
      "loss": 1.1688,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.8911,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.781760215759277,
      "learning_rate": 0.00019946102021174206,
      "loss": 1.0611,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.519819736480713,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.9427,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.247189998626709,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9676,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0819637775421143,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.8659,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0306124687194824,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.9604,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1556403636932373,
      "learning_rate": 0.00019926852743022138,
      "loss": 1.0219,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9903797507286072,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.9448,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8551985025405884,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8887,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9833319783210754,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.9098,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8927335143089294,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.8427,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3464423418045044,
      "learning_rate": 0.00019907603464870067,
      "loss": 0.9411,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1088123321533203,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.8362,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.443970799446106,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7319,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0620180368423462,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.8502,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8205506801605225,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.8464,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.026169776916504,
      "learning_rate": 0.00019888354186718,
      "loss": 0.858,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7239542603492737,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.8742,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8644108772277832,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7656,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6905569434165955,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.8372,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8827759623527527,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.7281,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5555065870285034,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.8572,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42273494601249695,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.8768,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5444644689559937,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.7526,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6326220035552979,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.6473,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6100513935089111,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.7474,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8508883714675903,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.8062,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.555642306804657,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7822,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6031041741371155,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.9466,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.612458348274231,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.8309,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6748793721199036,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.8421,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4463978111743927,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.6661,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6735567450523376,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7187,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5610448122024536,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7486,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.468348890542984,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.9174,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49667859077453613,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.8015,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49677103757858276,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.8764,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5423592329025269,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.8467,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46261122822761536,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.7561,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6421524286270142,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.8461,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.44534018635749817,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.9544,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4680206775665283,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.898,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.48604387044906616,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8691,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5105553269386292,
      "learning_rate": 0.00019784408084696825,
      "loss": 0.7244,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.41934075951576233,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.9266,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4944055676460266,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.7894,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4694783389568329,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.9173,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4923385977745056,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.8264,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.584971010684967,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7067,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.460625022649765,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.7259,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5579990744590759,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.6285,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43484073877334595,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.7982,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.451922208070755,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.8647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5411314964294434,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.7489,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.485877126455307,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.6726,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43625229597091675,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.7847,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4604784846305847,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.6761,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.38421735167503357,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.8093,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47359615564346313,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7767,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48932552337646484,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.6937,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4678775668144226,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.929,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49805936217308044,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.6369,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5964849591255188,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.6874,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5139459371566772,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.9437,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5100282430648804,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.7723,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.606708288192749,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.86,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41680747270584106,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.8129,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4841563403606415,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.923,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6219584345817566,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.7727,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4298764765262604,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.8104,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49360743165016174,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.6325,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4630686640739441,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.898,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5353219509124756,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.8399,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4980505704879761,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7985,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5311594009399414,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.7455,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44213631749153137,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.7094,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5181998014450073,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7528,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5781349539756775,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.8595,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40299394726753235,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9345,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5603666305541992,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.9935,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4508861005306244,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7322,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.453523725271225,
      "learning_rate": 0.000196381135707411,
      "loss": 0.7256,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.698917806148529,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8367,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.526947021484375,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.6431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5315524339675903,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7462,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.528644323348999,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.6622,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4947921633720398,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.7692,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40959012508392334,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.8525,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3968225419521332,
      "learning_rate": 0.000196111645813282,
      "loss": 0.9691,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.461165189743042,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.8075,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43429329991340637,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.7966,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45655712485313416,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.6649,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41561511158943176,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.9817,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5914500951766968,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.6949,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4335707128047943,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.8687,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.517529308795929,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8118,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5489369034767151,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.9189,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5018031001091003,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.7887,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5235357880592346,
      "learning_rate": 0.00019572666025024062,
      "loss": 1.0346,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.373628705739975,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.5875,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.444135844707489,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.7871,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45136335492134094,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.6282,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5306428074836731,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.7564,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4356388747692108,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.6983,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4693934917449951,
      "learning_rate": 0.00019549566891241578,
      "loss": 0.7454,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6450073719024658,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.6905,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4784305989742279,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.6944,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39485329389572144,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.9025,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45148515701293945,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.6443,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4086743891239166,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.8381,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6853803992271423,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.6857,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5018186569213867,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.9565,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38910984992980957,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7023,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47104546427726746,
      "learning_rate": 0.00019514918190567855,
      "loss": 0.7211,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.595535159111023,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.8905,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42830514907836914,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.7955,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4417261779308319,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.692,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42573025822639465,
      "learning_rate": 0.000194995187680462,
      "loss": 0.608,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6163130402565002,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.9331,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47019925713539124,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.7338,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4294617176055908,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.7916,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5744539499282837,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.8113,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4397624135017395,
      "learning_rate": 0.0001948026948989413,
      "loss": 0.8047,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4419170916080475,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.7949,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.408357173204422,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.8878,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3972795903682709,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5689,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.402809202671051,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7868,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46714845299720764,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.904,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4382963180541992,
      "learning_rate": 0.00019457170356111648,
      "loss": 0.7987,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49720799922943115,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.6905,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38201817870140076,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.6079,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3585057854652405,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.8645,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5370497703552246,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.7726,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40534526109695435,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.6871,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40718555450439453,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.8994,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6352331638336182,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.8999,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4231524169445038,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.674,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.51837158203125,
      "learning_rate": 0.0001942252165543792,
      "loss": 0.6869,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43487808108329773,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.8495,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.478048175573349,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6706,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4871412217617035,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.8534,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48025259375572205,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.8734,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.376050740480423,
      "learning_rate": 0.00019403272377285853,
      "loss": 1.0056,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4277438819408417,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.6711,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4798095226287842,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.8112,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4388551712036133,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8392,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.633101224899292,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.7927,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3662850558757782,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7108,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43001875281333923,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.6524,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43889835476875305,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.8804,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.449369341135025,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.9322,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5520343780517578,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.7627,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42789730429649353,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.7097,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5099896788597107,
      "learning_rate": 0.000193609239653513,
      "loss": 0.766,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3890852630138397,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8727,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4030917286872864,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.7714,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5613992810249329,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.9946,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48699212074279785,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.6841,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43229538202285767,
      "learning_rate": 0.0001934167468719923,
      "loss": 0.6469,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46411290764808655,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.7614,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49609866738319397,
      "learning_rate": 0.00019333974975938403,
      "loss": 0.6847,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.33297157287597656,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8576,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5082602500915527,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6907,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.48121577501296997,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.8542,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3946192264556885,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6726,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41997063159942627,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.6866,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4409182369709015,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.7627,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3896368145942688,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.7587,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42079252004623413,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.6828,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4358564019203186,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.7743,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47438254952430725,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7295,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3782908022403717,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7665,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3703530728816986,
      "learning_rate": 0.00019287776708373439,
      "loss": 1.006,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3743325173854828,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.8885,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4332818388938904,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.788,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3522750735282898,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6771,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5323351621627808,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7769,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3655940294265747,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.6001,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4050886034965515,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.9004,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44313961267471313,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.9076,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4808651804924011,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.7876,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4099526107311249,
      "learning_rate": 0.00019253128007699712,
      "loss": 0.7545,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42295604944229126,
      "learning_rate": 0.000192492781520693,
      "loss": 0.6868,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.38039496541023254,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.6882,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.392062246799469,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.8275,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.49568668007850647,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.6282,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3389342129230499,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7987,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.43684521317481995,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.8579,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46228134632110596,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.8268,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.36543259024620056,
      "learning_rate": 0.000192223291626564,
      "loss": 0.8892,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3820000886917114,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7667,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47314170002937317,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.7424,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4986186921596527,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.6653,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40106379985809326,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.6973,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5317052006721497,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.7483,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4519927203655243,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.872,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44930392503738403,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.7127,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5897475481033325,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.9663,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4732646346092224,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7192,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40370991826057434,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.945,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5189063549041748,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.9023,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4453914761543274,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.8568,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4872682988643646,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.6934,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4745577573776245,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.785,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.452533096075058,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.7228,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42025381326675415,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.8885,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.45724043250083923,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.7404,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41045424342155457,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.8384,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4606262743473053,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.6972,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47874921560287476,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.9777,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41982775926589966,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.9483,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46619105339050293,
      "learning_rate": 0.00019137632338787298,
      "loss": 0.7675,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.31501007080078125,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.7628,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45184069871902466,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.686,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3631167411804199,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.8303,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3997798562049866,
      "learning_rate": 0.00019122232916265642,
      "loss": 0.8186,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3641427457332611,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.7384,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3745492696762085,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.9408,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4126112461090088,
      "learning_rate": 0.000191106833493744,
      "loss": 0.7691,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.38452523946762085,
      "learning_rate": 0.00019106833493743986,
      "loss": 0.8933,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4313470423221588,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.717,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4877426326274872,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.9048,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.354559063911438,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.8285,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35648438334465027,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.673,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3589836657047272,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.7923,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3994254469871521,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7671,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4231529235839844,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.6565,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4621272385120392,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.6907,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3945978581905365,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.7,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39729538559913635,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.5096,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42322924733161926,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.78,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.44383230805397034,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.8083,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6045325398445129,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.8649,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4234389662742615,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.7185,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.381877601146698,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8355,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3730185031890869,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.675,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4495980739593506,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.6618,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36406174302101135,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.8693,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5642045736312866,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.661,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3980395197868347,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7259,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.47727033495903015,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.6606,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37292900681495667,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.781,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.33142971992492676,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.621,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4019940197467804,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.8589,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4046827554702759,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.7907,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.40318140387535095,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7672,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.41678452491760254,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7602,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3626757264137268,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.6203,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36802080273628235,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.7684,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35103940963745117,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.828,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4074096381664276,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.7727,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39446142315864563,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.7743,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42152348160743713,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.6711,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37022072076797485,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.8369,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45802485942840576,
      "learning_rate": 0.000189720885466795,
      "loss": 0.6817,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3840475082397461,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.6692,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.397205114364624,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.6124,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46793362498283386,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7995,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3204089105129242,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.8052,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5611957907676697,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.7167,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.530852735042572,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5691,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46891504526138306,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9886,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4694139361381531,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.6444,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39388447999954224,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.7208,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4057823717594147,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.6421,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.446094274520874,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.9129,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4163888394832611,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.9019,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.341553658246994,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.7768,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4768024981021881,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.6762,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.401567280292511,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.8641,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44063693284988403,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.5896,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3412891626358032,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.8354,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3813810348510742,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.708,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39346498250961304,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.799,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4597877264022827,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.7395,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3625764548778534,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.8548,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.47845423221588135,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.7139,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4290001094341278,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8762,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.374828964471817,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.7665,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3916478455066681,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8444,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4357036352157593,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.6959,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41867315769195557,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.854,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4803310036659241,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.6415,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4232359230518341,
      "learning_rate": 0.000188604427333975,
      "loss": 0.8127,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3427557647228241,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.8764,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4120095670223236,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.7613,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44978073239326477,
      "learning_rate": 0.00018848893166506256,
      "loss": 0.6352,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3201029598712921,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.7237,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44953957200050354,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.6487,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4061507284641266,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.6154,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4792279005050659,
      "learning_rate": 0.000188334937439846,
      "loss": 0.8293,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3731112480163574,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6101,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4615262448787689,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.7616,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36472374200820923,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.6681,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4000975489616394,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.6767,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4342329800128937,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.8626,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.43993252515792847,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.7314,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36972469091415405,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.7895,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4726084768772125,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.6262,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5106558203697205,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.7688,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3342224955558777,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.8441,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.42816826701164246,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6327,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.34864041209220886,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.7377,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3308842182159424,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.6719,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4306331276893616,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.6301,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39399442076683044,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.7529,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4262602925300598,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.8004,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5589942336082458,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.8591,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.45510587096214294,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.8667,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41702696681022644,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.837,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49357858300209045,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.6308,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49088579416275024,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.8118,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4575938582420349,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7499,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5084648132324219,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.9495,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4152742922306061,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.6591,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.410138875246048,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.6558,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3992723822593689,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.8139,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4198096990585327,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8063,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4146757423877716,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.5979,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3692832291126251,
      "learning_rate": 0.000187218479307026,
      "loss": 0.8527,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37799060344696045,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8657,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3419437110424042,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7457,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4123936593532562,
      "learning_rate": 0.00018710298363811359,
      "loss": 0.6015,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3556390404701233,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.952,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.43549832701683044,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.7719,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44564804434776306,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7465,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4578996002674103,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.7318,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5829522609710693,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6746,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.618412435054779,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6612,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.45777198672294617,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.744,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47281530499458313,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.7054,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933841288089752,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8044,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4211621582508087,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.7529,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.504000186920166,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.6154,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.40663763880729675,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7715,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3982800543308258,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.8856,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39105480909347534,
      "learning_rate": 0.00018656400384985564,
      "loss": 0.5879,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4311503469944,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.7208,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.46843230724334717,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.8434,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37112879753112793,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.7895,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3782634139060974,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.71,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.411615788936615,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.692,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4585183262825012,
      "learning_rate": 0.0001863330125120308,
      "loss": 0.699,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3210856020450592,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.8301,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47548168897628784,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6627,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42618703842163086,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.8115,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4956449270248413,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.7461,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.373945415019989,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.7387,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5128307342529297,
      "learning_rate": 0.000186102021174206,
      "loss": 0.8675,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39190107583999634,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.7088,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4019525647163391,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.7208,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6033728122711182,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.6698,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933517634868622,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.8102,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4288349747657776,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.8585,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42410892248153687,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.7242,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4902440309524536,
      "learning_rate": 0.000185832531280077,
      "loss": 0.5965,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.36604270339012146,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.6267,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4615339934825897,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.9455,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4348839223384857,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.8513,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4273621737957001,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.617,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41383039951324463,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.8803,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5040608048439026,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7583,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.33960476517677307,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.7595,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44689905643463135,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.7853,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41154545545578003,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.7136,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.27520662546157837,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.7979,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5478206276893616,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.8095,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4509338438510895,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7044,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4331468939781189,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.7175,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3315088450908661,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8649,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38282105326652527,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7978,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4138413071632385,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7269,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37460705637931824,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.6528,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34590426087379456,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.9164,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.32010602951049805,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.8575,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37327438592910767,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.8753,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.316778302192688,
      "learning_rate": 0.0001850240615976901,
      "loss": 0.6793,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.403444766998291,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7541,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.491682767868042,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6667,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3501006066799164,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.6655,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41489213705062866,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.8568,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4158405065536499,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.6591,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38367748260498047,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.7529,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4363219141960144,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.7413,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4521339237689972,
      "learning_rate": 0.000184716073147257,
      "loss": 0.5389,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.43186765909194946,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7304,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.40286019444465637,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.865,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3767046630382538,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.8971,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3247160017490387,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.7793,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39206525683403015,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.6463,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3634454011917114,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.7576,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34959307312965393,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8257,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5340710282325745,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.9475,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5003661513328552,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.6891,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39330339431762695,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.6483,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.35932329297065735,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6431,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4380384385585785,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.8178,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37227070331573486,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.8105,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41952013969421387,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.7825,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3422773778438568,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.9381,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3683087229728699,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6737,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3993309736251831,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7685,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39145129919052124,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.6952,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41825953125953674,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.7473,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4179387092590332,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.8116,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.45485833287239075,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5701,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4862624704837799,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.8575,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4824470281600952,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.884,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4922899305820465,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.6477,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4879881739616394,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.7551,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5233360528945923,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.7343,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5586115717887878,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6556,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4199840724468231,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.7226,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.397352397441864,
      "learning_rate": 0.00018359961501443698,
      "loss": 1.0078,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4226352274417877,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.8804,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4273151159286499,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.7279,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4946306347846985,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7425,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38384705781936646,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.8422,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3904738426208496,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7058,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3637390732765198,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.8168,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41314783692359924,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.8248,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.30208462476730347,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.7856,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3953840136528015,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.7159,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37532252073287964,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.668,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3895621597766876,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.7619,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4008345305919647,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.9235,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37399378418922424,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.8747,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44646504521369934,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7659,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40955376625061035,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.7648,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3704189360141754,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.7595,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4268467426300049,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.732,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3477902412414551,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.7803,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3642955720424652,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.8426,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3884435296058655,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.7273,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37005576491355896,
      "learning_rate": 0.00018279114533205007,
      "loss": 0.8231,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4093822240829468,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8097,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4333754777908325,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5244,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38456860184669495,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.9002,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40615877509117126,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.8228,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3670360743999481,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.5899,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38076573610305786,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.7756,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4119761884212494,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.6556,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4783891439437866,
      "learning_rate": 0.00018248315688161696,
      "loss": 1.0189,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40097832679748535,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7869,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3726452887058258,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7804,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3413650393486023,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8006,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4379594027996063,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.7684,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37378251552581787,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.7102,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37973713874816895,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.8109,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.33865559101104736,
      "learning_rate": 0.000182213666987488,
      "loss": 0.7206,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.49138644337654114,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.8076,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5017513632774353,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.9111,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4073384702205658,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8147,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.47447335720062256,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.6633,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.406205952167511,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.684,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.613382875919342,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7979,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4507606625556946,
      "learning_rate": 0.000181944177093359,
      "loss": 0.8019,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4662131667137146,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8455,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3832371234893799,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.6721,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4184776246547699,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.8355,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.31751248240470886,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.8333,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4122768044471741,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.8156,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.365533709526062,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7284,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5359499454498291,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8517,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3743586540222168,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.8607,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40984785556793213,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.8798,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.41061532497406006,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.7626,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5130647420883179,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.6745,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3531906008720398,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.7948,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4617935121059418,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7451,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4042561650276184,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.85,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44275152683258057,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.7308,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4530651569366455,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.7625,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.519067645072937,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.7081,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39324527978897095,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.7552,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3819272518157959,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.9068,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4451203942298889,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.8031,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39822861552238464,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8524,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4579085409641266,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6518,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.35329708456993103,
      "learning_rate": 0.0001810587102983638,
      "loss": 0.6251,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4679481089115143,
      "learning_rate": 0.00018102021174205968,
      "loss": 0.8123,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4190986156463623,
      "learning_rate": 0.00018098171318575555,
      "loss": 0.8069,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4447309374809265,
      "learning_rate": 0.0001809432146294514,
      "loss": 0.7957,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3945259749889374,
      "learning_rate": 0.00018090471607314727,
      "loss": 0.8608,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4472101926803589,
      "learning_rate": 0.00018086621751684312,
      "loss": 0.6545,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.399156391620636,
      "learning_rate": 0.000180827718960539,
      "loss": 0.8384,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.45613279938697815,
      "learning_rate": 0.00018078922040423484,
      "loss": 0.7321,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40805959701538086,
      "learning_rate": 0.00018075072184793072,
      "loss": 0.7444,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.42769765853881836,
      "learning_rate": 0.0001807122232916266,
      "loss": 0.8028,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33644768595695496,
      "learning_rate": 0.00018067372473532244,
      "loss": 0.8101,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.44442418217658997,
      "learning_rate": 0.00018063522617901828,
      "loss": 0.7858,
      "step": 512
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3666957914829254,
      "learning_rate": 0.00018059672762271416,
      "loss": 0.8682,
      "step": 513
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40631023049354553,
      "learning_rate": 0.00018055822906641003,
      "loss": 0.8666,
      "step": 514
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3566116392612457,
      "learning_rate": 0.00018051973051010588,
      "loss": 0.8075,
      "step": 515
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40891098976135254,
      "learning_rate": 0.00018048123195380173,
      "loss": 0.7326,
      "step": 516
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4189295470714569,
      "learning_rate": 0.0001804427333974976,
      "loss": 0.7031,
      "step": 517
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37940719723701477,
      "learning_rate": 0.00018040423484119348,
      "loss": 0.8974,
      "step": 518
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.47053778171539307,
      "learning_rate": 0.00018036573628488933,
      "loss": 0.6617,
      "step": 519
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4119088053703308,
      "learning_rate": 0.0001803272377285852,
      "loss": 0.8485,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4901687502861023,
      "learning_rate": 0.00018028873917228105,
      "loss": 0.7554,
      "step": 521
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3938004970550537,
      "learning_rate": 0.0001802502406159769,
      "loss": 0.7201,
      "step": 522
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4453965425491333,
      "learning_rate": 0.00018021174205967277,
      "loss": 0.9134,
      "step": 523
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4919692575931549,
      "learning_rate": 0.00018017324350336864,
      "loss": 0.6673,
      "step": 524
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4813697040081024,
      "learning_rate": 0.0001801347449470645,
      "loss": 0.7451,
      "step": 525
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4028126895427704,
      "learning_rate": 0.00018009624639076034,
      "loss": 0.7807,
      "step": 526
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4498790502548218,
      "learning_rate": 0.0001800577478344562,
      "loss": 0.8194,
      "step": 527
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4789945185184479,
      "learning_rate": 0.0001800192492781521,
      "loss": 0.6132,
      "step": 528
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5399003624916077,
      "learning_rate": 0.00017998075072184794,
      "loss": 0.8553,
      "step": 529
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4275045394897461,
      "learning_rate": 0.00017994225216554378,
      "loss": 0.7398,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.40307727456092834,
      "learning_rate": 0.00017990375360923966,
      "loss": 0.8353,
      "step": 531
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37099727988243103,
      "learning_rate": 0.00017986525505293553,
      "loss": 0.8753,
      "step": 532
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3537798821926117,
      "learning_rate": 0.00017982675649663138,
      "loss": 0.7497,
      "step": 533
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41050562262535095,
      "learning_rate": 0.00017978825794032725,
      "loss": 0.6499,
      "step": 534
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.38062337040901184,
      "learning_rate": 0.0001797497593840231,
      "loss": 0.8393,
      "step": 535
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.48728129267692566,
      "learning_rate": 0.00017971126082771898,
      "loss": 0.7913,
      "step": 536
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41124552488327026,
      "learning_rate": 0.00017967276227141482,
      "loss": 0.8473,
      "step": 537
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4975420832633972,
      "learning_rate": 0.0001796342637151107,
      "loss": 0.6603,
      "step": 538
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39639201760292053,
      "learning_rate": 0.00017959576515880657,
      "loss": 0.8181,
      "step": 539
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33978918194770813,
      "learning_rate": 0.0001795572666025024,
      "loss": 0.5651,
      "step": 540
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39304712414741516,
      "learning_rate": 0.00017951876804619827,
      "loss": 0.7266,
      "step": 541
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41755804419517517,
      "learning_rate": 0.00017948026948989414,
      "loss": 0.8439,
      "step": 542
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4548015296459198,
      "learning_rate": 0.00017944177093359002,
      "loss": 0.6774,
      "step": 543
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3938901722431183,
      "learning_rate": 0.00017940327237728586,
      "loss": 0.8082,
      "step": 544
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3671741485595703,
      "learning_rate": 0.0001793647738209817,
      "loss": 0.7709,
      "step": 545
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39431828260421753,
      "learning_rate": 0.00017932627526467759,
      "loss": 0.7623,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3910527229309082,
      "learning_rate": 0.00017928777670837343,
      "loss": 0.6227,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5204810500144958,
      "learning_rate": 0.0001792492781520693,
      "loss": 0.7134,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4552685022354126,
      "learning_rate": 0.00017921077959576518,
      "loss": 0.7792,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42712152004241943,
      "learning_rate": 0.00017917228103946103,
      "loss": 1.0187,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.40982896089553833,
      "learning_rate": 0.00017913378248315688,
      "loss": 0.8407,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.38555216789245605,
      "learning_rate": 0.00017909528392685275,
      "loss": 0.8532,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3626030683517456,
      "learning_rate": 0.00017905678537054863,
      "loss": 0.7091,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.44306764006614685,
      "learning_rate": 0.00017901828681424447,
      "loss": 0.8067,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4466676712036133,
      "learning_rate": 0.00017897978825794032,
      "loss": 0.6057,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.403406023979187,
      "learning_rate": 0.0001789412897016362,
      "loss": 0.6674,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4458920955657959,
      "learning_rate": 0.00017890279114533207,
      "loss": 0.6795,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3888542056083679,
      "learning_rate": 0.00017886429258902792,
      "loss": 0.7303,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4329482614994049,
      "learning_rate": 0.0001788257940327238,
      "loss": 0.6602,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4150072932243347,
      "learning_rate": 0.00017878729547641964,
      "loss": 0.7572,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.46370017528533936,
      "learning_rate": 0.0001787487969201155,
      "loss": 0.7198,
      "step": 561
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.40281912684440613,
      "learning_rate": 0.00017871029836381136,
      "loss": 0.8659,
      "step": 562
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42040666937828064,
      "learning_rate": 0.00017867179980750724,
      "loss": 0.6713,
      "step": 563
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3968161344528198,
      "learning_rate": 0.00017863330125120308,
      "loss": 0.723,
      "step": 564
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3881441056728363,
      "learning_rate": 0.00017859480269489896,
      "loss": 0.7526,
      "step": 565
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3257398307323456,
      "learning_rate": 0.0001785563041385948,
      "loss": 0.9035,
      "step": 566
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3617190718650818,
      "learning_rate": 0.00017851780558229068,
      "loss": 0.6702,
      "step": 567
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3779655992984772,
      "learning_rate": 0.00017847930702598655,
      "loss": 0.6569,
      "step": 568
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.41719603538513184,
      "learning_rate": 0.00017844080846968237,
      "loss": 0.8573,
      "step": 569
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3839716911315918,
      "learning_rate": 0.00017840230991337825,
      "loss": 0.7409,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3557591140270233,
      "learning_rate": 0.00017836381135707412,
      "loss": 0.8895,
      "step": 571
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4740881621837616,
      "learning_rate": 0.00017832531280076997,
      "loss": 0.6805,
      "step": 572
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4512026309967041,
      "learning_rate": 0.00017828681424446585,
      "loss": 0.786,
      "step": 573
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.45799720287323,
      "learning_rate": 0.0001782483156881617,
      "loss": 0.8067,
      "step": 574
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.42661893367767334,
      "learning_rate": 0.00017820981713185757,
      "loss": 0.7418,
      "step": 575
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4891342222690582,
      "learning_rate": 0.00017817131857555341,
      "loss": 0.8071,
      "step": 576
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4712083637714386,
      "learning_rate": 0.0001781328200192493,
      "loss": 0.7291,
      "step": 577
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.44885143637657166,
      "learning_rate": 0.00017809432146294516,
      "loss": 0.8356,
      "step": 578
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36697036027908325,
      "learning_rate": 0.000178055822906641,
      "loss": 0.6563,
      "step": 579
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5198047757148743,
      "learning_rate": 0.00017801732435033686,
      "loss": 0.7868,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3903001844882965,
      "learning_rate": 0.00017797882579403273,
      "loss": 0.7775,
      "step": 581
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3861727714538574,
      "learning_rate": 0.0001779403272377286,
      "loss": 0.7176,
      "step": 582
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3334764242172241,
      "learning_rate": 0.00017790182868142445,
      "loss": 0.9657,
      "step": 583
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4170445203781128,
      "learning_rate": 0.0001778633301251203,
      "loss": 0.765,
      "step": 584
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3677545189857483,
      "learning_rate": 0.00017782483156881618,
      "loss": 0.8061,
      "step": 585
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5148152709007263,
      "learning_rate": 0.00017778633301251205,
      "loss": 0.8903,
      "step": 586
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3851109743118286,
      "learning_rate": 0.0001777478344562079,
      "loss": 0.5751,
      "step": 587
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3523044288158417,
      "learning_rate": 0.00017770933589990377,
      "loss": 0.7858,
      "step": 588
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.427933007478714,
      "learning_rate": 0.00017767083734359962,
      "loss": 0.9746,
      "step": 589
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36992552876472473,
      "learning_rate": 0.0001776323387872955,
      "loss": 0.8219,
      "step": 590
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3327391743659973,
      "learning_rate": 0.00017759384023099134,
      "loss": 0.8739,
      "step": 591
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4296494722366333,
      "learning_rate": 0.00017755534167468722,
      "loss": 0.7948,
      "step": 592
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.37695109844207764,
      "learning_rate": 0.00017751684311838306,
      "loss": 0.8366,
      "step": 593
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4121188521385193,
      "learning_rate": 0.0001774783445620789,
      "loss": 0.9157,
      "step": 594
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.4559638500213623,
      "learning_rate": 0.0001774398460057748,
      "loss": 0.6274,
      "step": 595
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.48433220386505127,
      "learning_rate": 0.00017740134744947066,
      "loss": 0.729,
      "step": 596
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3838486671447754,
      "learning_rate": 0.0001773628488931665,
      "loss": 0.7394,
      "step": 597
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.448947012424469,
      "learning_rate": 0.00017732435033686236,
      "loss": 0.8636,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.34840279817581177,
      "learning_rate": 0.00017728585178055823,
      "loss": 0.8343,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.44666817784309387,
      "learning_rate": 0.0001772473532242541,
      "loss": 0.8453,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41129618883132935,
      "learning_rate": 0.00017720885466794995,
      "loss": 0.6779,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4049602448940277,
      "learning_rate": 0.00017717035611164583,
      "loss": 0.954,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38343897461891174,
      "learning_rate": 0.00017713185755534167,
      "loss": 0.7214,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4270513951778412,
      "learning_rate": 0.00017709335899903755,
      "loss": 0.7222,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3907594382762909,
      "learning_rate": 0.0001770548604427334,
      "loss": 0.8616,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3287070393562317,
      "learning_rate": 0.00017701636188642927,
      "loss": 0.8017,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4289465546607971,
      "learning_rate": 0.00017697786333012515,
      "loss": 0.6481,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.40701785683631897,
      "learning_rate": 0.000176939364773821,
      "loss": 0.8361,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4191131591796875,
      "learning_rate": 0.00017690086621751684,
      "loss": 0.7557,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4570298194885254,
      "learning_rate": 0.00017686236766121271,
      "loss": 0.8935,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4185386002063751,
      "learning_rate": 0.0001768238691049086,
      "loss": 0.6673,
      "step": 611
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4229338467121124,
      "learning_rate": 0.00017678537054860444,
      "loss": 0.8806,
      "step": 612
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.39359912276268005,
      "learning_rate": 0.00017674687199230028,
      "loss": 0.664,
      "step": 613
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3372077941894531,
      "learning_rate": 0.00017670837343599616,
      "loss": 0.8618,
      "step": 614
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3153285086154938,
      "learning_rate": 0.00017666987487969203,
      "loss": 0.768,
      "step": 615
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37482786178588867,
      "learning_rate": 0.00017663137632338788,
      "loss": 0.7711,
      "step": 616
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.35621148347854614,
      "learning_rate": 0.00017659287776708376,
      "loss": 0.6685,
      "step": 617
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.43296071887016296,
      "learning_rate": 0.0001765543792107796,
      "loss": 0.7611,
      "step": 618
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.45684507489204407,
      "learning_rate": 0.00017651588065447545,
      "loss": 0.5118,
      "step": 619
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3735063076019287,
      "learning_rate": 0.00017647738209817132,
      "loss": 0.7152,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.42290157079696655,
      "learning_rate": 0.0001764388835418672,
      "loss": 0.6485,
      "step": 621
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46688735485076904,
      "learning_rate": 0.00017640038498556307,
      "loss": 0.6683,
      "step": 622
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38138657808303833,
      "learning_rate": 0.0001763618864292589,
      "loss": 0.7274,
      "step": 623
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.39618390798568726,
      "learning_rate": 0.00017632338787295477,
      "loss": 0.8839,
      "step": 624
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.444378137588501,
      "learning_rate": 0.00017628488931665064,
      "loss": 0.7364,
      "step": 625
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.36690178513526917,
      "learning_rate": 0.0001762463907603465,
      "loss": 0.8898,
      "step": 626
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.40035420656204224,
      "learning_rate": 0.00017620789220404234,
      "loss": 0.7846,
      "step": 627
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3317468762397766,
      "learning_rate": 0.0001761693936477382,
      "loss": 0.8477,
      "step": 628
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4218446910381317,
      "learning_rate": 0.0001761308950914341,
      "loss": 0.7423,
      "step": 629
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38181713223457336,
      "learning_rate": 0.00017609239653512993,
      "loss": 0.8511,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5051924586296082,
      "learning_rate": 0.0001760538979788258,
      "loss": 0.7208,
      "step": 631
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3627151548862457,
      "learning_rate": 0.00017601539942252166,
      "loss": 0.8558,
      "step": 632
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5386068224906921,
      "learning_rate": 0.00017597690086621753,
      "loss": 0.7498,
      "step": 633
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4204239547252655,
      "learning_rate": 0.00017593840230991338,
      "loss": 0.7845,
      "step": 634
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3822893798351288,
      "learning_rate": 0.00017589990375360925,
      "loss": 0.816,
      "step": 635
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.48055341839790344,
      "learning_rate": 0.00017586140519730513,
      "loss": 0.8331,
      "step": 636
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46601784229278564,
      "learning_rate": 0.00017582290664100097,
      "loss": 0.7306,
      "step": 637
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5342617034912109,
      "learning_rate": 0.00017578440808469682,
      "loss": 0.6888,
      "step": 638
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4277246296405792,
      "learning_rate": 0.0001757459095283927,
      "loss": 0.7462,
      "step": 639
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41329824924468994,
      "learning_rate": 0.00017570741097208857,
      "loss": 0.7003,
      "step": 640
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.43545401096343994,
      "learning_rate": 0.00017566891241578442,
      "loss": 1.059,
      "step": 641
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.37881138920783997,
      "learning_rate": 0.00017563041385948027,
      "loss": 0.732,
      "step": 642
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.34206023812294006,
      "learning_rate": 0.00017559191530317614,
      "loss": 1.0778,
      "step": 643
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.35784947872161865,
      "learning_rate": 0.000175553416746872,
      "loss": 0.6666,
      "step": 644
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3838137984275818,
      "learning_rate": 0.00017551491819056786,
      "loss": 0.7739,
      "step": 645
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5151283144950867,
      "learning_rate": 0.00017547641963426374,
      "loss": 0.772,
      "step": 646
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.46383512020111084,
      "learning_rate": 0.00017543792107795958,
      "loss": 0.8412,
      "step": 647
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5041674971580505,
      "learning_rate": 0.00017539942252165543,
      "loss": 0.7372,
      "step": 648
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4784582853317261,
      "learning_rate": 0.0001753609239653513,
      "loss": 0.8203,
      "step": 649
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.38770371675491333,
      "learning_rate": 0.00017532242540904718,
      "loss": 0.7772,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4724113643169403,
      "learning_rate": 0.00017528392685274303,
      "loss": 0.8073,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35377320647239685,
      "learning_rate": 0.00017524542829643888,
      "loss": 0.7301,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.47636106610298157,
      "learning_rate": 0.00017520692974013475,
      "loss": 0.6617,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.42795759439468384,
      "learning_rate": 0.00017516843118383063,
      "loss": 0.7154,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4345453679561615,
      "learning_rate": 0.00017512993262752647,
      "loss": 0.733,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39994534850120544,
      "learning_rate": 0.00017509143407122232,
      "loss": 0.5779,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4123230576515198,
      "learning_rate": 0.0001750529355149182,
      "loss": 0.6915,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3561868369579315,
      "learning_rate": 0.00017501443695861407,
      "loss": 0.7782,
      "step": 658
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4212721884250641,
      "learning_rate": 0.00017497593840230992,
      "loss": 0.7503,
      "step": 659
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.332350492477417,
      "learning_rate": 0.0001749374398460058,
      "loss": 0.9183,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.53046715259552,
      "learning_rate": 0.00017489894128970164,
      "loss": 0.9709,
      "step": 661
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.43777701258659363,
      "learning_rate": 0.0001748604427333975,
      "loss": 1.0169,
      "step": 662
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4565688967704773,
      "learning_rate": 0.00017482194417709336,
      "loss": 0.7592,
      "step": 663
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.38864171504974365,
      "learning_rate": 0.00017478344562078923,
      "loss": 0.8752,
      "step": 664
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3984103202819824,
      "learning_rate": 0.0001747449470644851,
      "loss": 0.7577,
      "step": 665
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5659173727035522,
      "learning_rate": 0.00017470644850818093,
      "loss": 0.8482,
      "step": 666
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3943690359592438,
      "learning_rate": 0.0001746679499518768,
      "loss": 0.859,
      "step": 667
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4091321527957916,
      "learning_rate": 0.00017462945139557268,
      "loss": 0.7477,
      "step": 668
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.37893542647361755,
      "learning_rate": 0.00017459095283926855,
      "loss": 0.7329,
      "step": 669
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3407520055770874,
      "learning_rate": 0.0001745524542829644,
      "loss": 0.7824,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.40860164165496826,
      "learning_rate": 0.00017451395572666025,
      "loss": 0.8027,
      "step": 671
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3064686954021454,
      "learning_rate": 0.00017447545717035612,
      "loss": 0.9002,
      "step": 672
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3411509692668915,
      "learning_rate": 0.00017443695861405197,
      "loss": 0.8394,
      "step": 673
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3462003171443939,
      "learning_rate": 0.00017439846005774784,
      "loss": 0.8784,
      "step": 674
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3487083613872528,
      "learning_rate": 0.00017435996150144372,
      "loss": 0.8504,
      "step": 675
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3693464398384094,
      "learning_rate": 0.00017432146294513957,
      "loss": 0.6981,
      "step": 676
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35222914814949036,
      "learning_rate": 0.00017428296438883541,
      "loss": 0.8873,
      "step": 677
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4253406226634979,
      "learning_rate": 0.0001742444658325313,
      "loss": 0.7945,
      "step": 678
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.34643346071243286,
      "learning_rate": 0.00017420596727622716,
      "loss": 0.7229,
      "step": 679
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.43851718306541443,
      "learning_rate": 0.000174167468719923,
      "loss": 0.7922,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3920727074146271,
      "learning_rate": 0.00017412897016361886,
      "loss": 0.7859,
      "step": 681
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3976938724517822,
      "learning_rate": 0.00017409047160731473,
      "loss": 0.6974,
      "step": 682
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4204944372177124,
      "learning_rate": 0.0001740519730510106,
      "loss": 0.8564,
      "step": 683
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35586726665496826,
      "learning_rate": 0.00017401347449470645,
      "loss": 0.8635,
      "step": 684
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4737916588783264,
      "learning_rate": 0.00017397497593840233,
      "loss": 0.7866,
      "step": 685
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3748070299625397,
      "learning_rate": 0.00017393647738209818,
      "loss": 0.695,
      "step": 686
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36548924446105957,
      "learning_rate": 0.00017389797882579405,
      "loss": 0.716,
      "step": 687
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39750754833221436,
      "learning_rate": 0.0001738594802694899,
      "loss": 0.7952,
      "step": 688
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4891696274280548,
      "learning_rate": 0.00017382098171318577,
      "loss": 0.8809,
      "step": 689
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3966465890407562,
      "learning_rate": 0.00017378248315688162,
      "loss": 1.0013,
      "step": 690
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.47586390376091003,
      "learning_rate": 0.00017374398460057747,
      "loss": 0.7774,
      "step": 691
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4218079149723053,
      "learning_rate": 0.00017370548604427334,
      "loss": 0.9365,
      "step": 692
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4154198467731476,
      "learning_rate": 0.00017366698748796922,
      "loss": 0.8346,
      "step": 693
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4187276363372803,
      "learning_rate": 0.0001736284889316651,
      "loss": 0.676,
      "step": 694
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3848455548286438,
      "learning_rate": 0.0001735899903753609,
      "loss": 0.794,
      "step": 695
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3735641837120056,
      "learning_rate": 0.00017355149181905679,
      "loss": 0.9179,
      "step": 696
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4032048285007477,
      "learning_rate": 0.00017351299326275266,
      "loss": 0.8329,
      "step": 697
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35270655155181885,
      "learning_rate": 0.0001734744947064485,
      "loss": 0.7328,
      "step": 698
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3051532804965973,
      "learning_rate": 0.00017343599615014438,
      "loss": 0.6793,
      "step": 699
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.40052488446235657,
      "learning_rate": 0.00017339749759384023,
      "loss": 0.7087,
      "step": 700
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45748668909072876,
      "learning_rate": 0.0001733589990375361,
      "loss": 0.9148,
      "step": 701
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.36851558089256287,
      "learning_rate": 0.00017332050048123195,
      "loss": 0.6898,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34142744541168213,
      "learning_rate": 0.00017328200192492783,
      "loss": 0.8012,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38720953464508057,
      "learning_rate": 0.0001732435033686237,
      "loss": 0.8193,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3785306215286255,
      "learning_rate": 0.00017320500481231955,
      "loss": 0.8876,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.342033326625824,
      "learning_rate": 0.0001731665062560154,
      "loss": 0.9271,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.41306832432746887,
      "learning_rate": 0.00017312800769971127,
      "loss": 0.7448,
      "step": 707
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4203263819217682,
      "learning_rate": 0.00017308950914340715,
      "loss": 0.7572,
      "step": 708
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4670791029930115,
      "learning_rate": 0.000173051010587103,
      "loss": 0.617,
      "step": 709
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5887750387191772,
      "learning_rate": 0.00017301251203079884,
      "loss": 0.8054,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37040165066719055,
      "learning_rate": 0.00017297401347449471,
      "loss": 0.821,
      "step": 711
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3870273530483246,
      "learning_rate": 0.0001729355149181906,
      "loss": 0.8355,
      "step": 712
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.387721985578537,
      "learning_rate": 0.00017289701636188644,
      "loss": 0.5159,
      "step": 713
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3844657838344574,
      "learning_rate": 0.0001728585178055823,
      "loss": 0.7561,
      "step": 714
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3874747157096863,
      "learning_rate": 0.00017282001924927816,
      "loss": 0.6783,
      "step": 715
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34984755516052246,
      "learning_rate": 0.00017278152069297403,
      "loss": 0.785,
      "step": 716
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5564412474632263,
      "learning_rate": 0.00017274302213666988,
      "loss": 0.6845,
      "step": 717
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3845653533935547,
      "learning_rate": 0.00017270452358036575,
      "loss": 0.8413,
      "step": 718
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.34572526812553406,
      "learning_rate": 0.0001726660250240616,
      "loss": 0.7811,
      "step": 719
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4227907359600067,
      "learning_rate": 0.00017262752646775745,
      "loss": 0.581,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40575093030929565,
      "learning_rate": 0.00017258902791145332,
      "loss": 0.7286,
      "step": 721
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3517785668373108,
      "learning_rate": 0.0001725505293551492,
      "loss": 0.7326,
      "step": 722
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40482303500175476,
      "learning_rate": 0.00017251203079884505,
      "loss": 0.9867,
      "step": 723
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3650476634502411,
      "learning_rate": 0.0001724735322425409,
      "loss": 0.6963,
      "step": 724
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33829617500305176,
      "learning_rate": 0.00017243503368623677,
      "loss": 0.9104,
      "step": 725
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.35361653566360474,
      "learning_rate": 0.00017239653512993264,
      "loss": 0.5383,
      "step": 726
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.45061513781547546,
      "learning_rate": 0.0001723580365736285,
      "loss": 0.7023,
      "step": 727
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4981588125228882,
      "learning_rate": 0.00017231953801732436,
      "loss": 0.8044,
      "step": 728
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.387322336435318,
      "learning_rate": 0.0001722810394610202,
      "loss": 0.992,
      "step": 729
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5148512721061707,
      "learning_rate": 0.0001722425409047161,
      "loss": 0.7358,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4733924865722656,
      "learning_rate": 0.00017220404234841193,
      "loss": 0.7849,
      "step": 731
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.36829113960266113,
      "learning_rate": 0.0001721655437921078,
      "loss": 0.8421,
      "step": 732
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39594176411628723,
      "learning_rate": 0.00017212704523580368,
      "loss": 0.677,
      "step": 733
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4709170162677765,
      "learning_rate": 0.00017208854667949953,
      "loss": 0.7163,
      "step": 734
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39583051204681396,
      "learning_rate": 0.00017205004812319538,
      "loss": 0.6279,
      "step": 735
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3525935411453247,
      "learning_rate": 0.00017201154956689125,
      "loss": 0.5868,
      "step": 736
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37443339824676514,
      "learning_rate": 0.00017197305101058713,
      "loss": 0.8093,
      "step": 737
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3746035695075989,
      "learning_rate": 0.00017193455245428297,
      "loss": 0.7446,
      "step": 738
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.49442774057388306,
      "learning_rate": 0.00017189605389797882,
      "loss": 0.6681,
      "step": 739
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.40556401014328003,
      "learning_rate": 0.0001718575553416747,
      "loss": 0.7086,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38675662875175476,
      "learning_rate": 0.00017181905678537057,
      "loss": 0.8154,
      "step": 741
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6102035641670227,
      "learning_rate": 0.00017178055822906642,
      "loss": 0.6516,
      "step": 742
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.42935019731521606,
      "learning_rate": 0.0001717420596727623,
      "loss": 0.6763,
      "step": 743
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3748353123664856,
      "learning_rate": 0.00017170356111645814,
      "loss": 0.8223,
      "step": 744
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39062535762786865,
      "learning_rate": 0.000171665062560154,
      "loss": 0.6919,
      "step": 745
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38968580961227417,
      "learning_rate": 0.00017162656400384986,
      "loss": 0.7257,
      "step": 746
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.366832971572876,
      "learning_rate": 0.00017158806544754574,
      "loss": 0.8199,
      "step": 747
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4036370515823364,
      "learning_rate": 0.00017154956689124158,
      "loss": 0.9641,
      "step": 748
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.39626967906951904,
      "learning_rate": 0.00017151106833493743,
      "loss": 0.8073,
      "step": 749
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4744478464126587,
      "learning_rate": 0.0001714725697786333,
      "loss": 0.7205,
      "step": 750
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3473556935787201,
      "learning_rate": 0.00017143407122232918,
      "loss": 0.893,
      "step": 751
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5023140907287598,
      "learning_rate": 0.00017139557266602503,
      "loss": 0.6788,
      "step": 752
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4513726532459259,
      "learning_rate": 0.00017135707410972088,
      "loss": 0.7294,
      "step": 753
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.38579440116882324,
      "learning_rate": 0.00017131857555341675,
      "loss": 0.6912,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.35996872186660767,
      "learning_rate": 0.00017128007699711262,
      "loss": 0.8075,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48586297035217285,
      "learning_rate": 0.00017124157844080847,
      "loss": 0.8389,
      "step": 756
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.335565447807312,
      "learning_rate": 0.00017120307988450435,
      "loss": 0.8229,
      "step": 757
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.42499786615371704,
      "learning_rate": 0.0001711645813282002,
      "loss": 0.8287,
      "step": 758
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47522956132888794,
      "learning_rate": 0.00017112608277189607,
      "loss": 0.7809,
      "step": 759
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47940245270729065,
      "learning_rate": 0.00017108758421559192,
      "loss": 0.5907,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.36606478691101074,
      "learning_rate": 0.0001710490856592878,
      "loss": 0.7638,
      "step": 761
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4483763575553894,
      "learning_rate": 0.00017101058710298366,
      "loss": 0.7139,
      "step": 762
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37084662914276123,
      "learning_rate": 0.00017097208854667949,
      "loss": 0.8148,
      "step": 763
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38737088441848755,
      "learning_rate": 0.00017093358999037536,
      "loss": 0.767,
      "step": 764
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3940127193927765,
      "learning_rate": 0.00017089509143407123,
      "loss": 0.7881,
      "step": 765
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43775805830955505,
      "learning_rate": 0.0001708565928777671,
      "loss": 0.716,
      "step": 766
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4488811194896698,
      "learning_rate": 0.00017081809432146296,
      "loss": 0.6087,
      "step": 767
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43547001481056213,
      "learning_rate": 0.0001707795957651588,
      "loss": 0.7073,
      "step": 768
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43893900513648987,
      "learning_rate": 0.00017074109720885468,
      "loss": 0.8044,
      "step": 769
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.372728556394577,
      "learning_rate": 0.00017070259865255053,
      "loss": 0.6557,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38425034284591675,
      "learning_rate": 0.0001706641000962464,
      "loss": 0.6982,
      "step": 771
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5710627436637878,
      "learning_rate": 0.00017062560153994227,
      "loss": 0.5981,
      "step": 772
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4812089800834656,
      "learning_rate": 0.00017058710298363812,
      "loss": 0.7884,
      "step": 773
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3855699300765991,
      "learning_rate": 0.00017054860442733397,
      "loss": 0.6755,
      "step": 774
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4562559425830841,
      "learning_rate": 0.00017051010587102984,
      "loss": 0.8575,
      "step": 775
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4128674864768982,
      "learning_rate": 0.00017047160731472572,
      "loss": 0.8621,
      "step": 776
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.42607802152633667,
      "learning_rate": 0.00017043310875842157,
      "loss": 0.7904,
      "step": 777
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39994102716445923,
      "learning_rate": 0.0001703946102021174,
      "loss": 0.7393,
      "step": 778
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.47832953929901123,
      "learning_rate": 0.0001703561116458133,
      "loss": 0.8006,
      "step": 779
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4949307143688202,
      "learning_rate": 0.00017031761308950916,
      "loss": 0.7873,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3823389410972595,
      "learning_rate": 0.000170279114533205,
      "loss": 0.5423,
      "step": 781
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3938881456851959,
      "learning_rate": 0.00017024061597690086,
      "loss": 0.9979,
      "step": 782
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.36748114228248596,
      "learning_rate": 0.00017020211742059673,
      "loss": 0.7439,
      "step": 783
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3931972086429596,
      "learning_rate": 0.0001701636188642926,
      "loss": 0.8697,
      "step": 784
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.40968993306159973,
      "learning_rate": 0.00017012512030798845,
      "loss": 0.6604,
      "step": 785
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4315906763076782,
      "learning_rate": 0.00017008662175168433,
      "loss": 0.8288,
      "step": 786
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.48962411284446716,
      "learning_rate": 0.00017004812319538018,
      "loss": 0.656,
      "step": 787
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3448035418987274,
      "learning_rate": 0.00017000962463907605,
      "loss": 0.9156,
      "step": 788
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32758450508117676,
      "learning_rate": 0.0001699711260827719,
      "loss": 0.6861,
      "step": 789
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32477089762687683,
      "learning_rate": 0.00016993262752646777,
      "loss": 0.9073,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3972192406654358,
      "learning_rate": 0.00016989412897016365,
      "loss": 0.8017,
      "step": 791
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3958989977836609,
      "learning_rate": 0.00016985563041385947,
      "loss": 0.7159,
      "step": 792
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37689006328582764,
      "learning_rate": 0.00016981713185755534,
      "loss": 0.6752,
      "step": 793
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.46549999713897705,
      "learning_rate": 0.00016977863330125122,
      "loss": 0.8251,
      "step": 794
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.45690783858299255,
      "learning_rate": 0.00016974013474494706,
      "loss": 0.7659,
      "step": 795
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3844454884529114,
      "learning_rate": 0.00016970163618864294,
      "loss": 0.8525,
      "step": 796
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37870171666145325,
      "learning_rate": 0.00016966313763233879,
      "loss": 0.6468,
      "step": 797
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4335814416408539,
      "learning_rate": 0.00016962463907603466,
      "loss": 0.7656,
      "step": 798
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.468999445438385,
      "learning_rate": 0.0001695861405197305,
      "loss": 0.8356,
      "step": 799
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3232964277267456,
      "learning_rate": 0.00016954764196342638,
      "loss": 0.8176,
      "step": 800
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4696967303752899,
      "learning_rate": 0.00016950914340712226,
      "loss": 0.7953,
      "step": 801
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3871324062347412,
      "learning_rate": 0.0001694706448508181,
      "loss": 0.6848,
      "step": 802
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4112791121006012,
      "learning_rate": 0.00016943214629451395,
      "loss": 0.708,
      "step": 803
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39461207389831543,
      "learning_rate": 0.00016939364773820983,
      "loss": 0.692,
      "step": 804
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4254642426967621,
      "learning_rate": 0.0001693551491819057,
      "loss": 0.7218,
      "step": 805
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4372923672199249,
      "learning_rate": 0.00016931665062560155,
      "loss": 0.8679,
      "step": 806
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3410716950893402,
      "learning_rate": 0.0001692781520692974,
      "loss": 0.6845,
      "step": 807
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39188075065612793,
      "learning_rate": 0.00016923965351299327,
      "loss": 0.9276,
      "step": 808
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3984350264072418,
      "learning_rate": 0.00016920115495668914,
      "loss": 0.9317,
      "step": 809
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4146293103694916,
      "learning_rate": 0.000169162656400385,
      "loss": 0.7863,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5660368800163269,
      "learning_rate": 0.00016912415784408087,
      "loss": 0.8132,
      "step": 811
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4297594428062439,
      "learning_rate": 0.00016908565928777671,
      "loss": 0.6906,
      "step": 812
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43333521485328674,
      "learning_rate": 0.0001690471607314726,
      "loss": 0.8655,
      "step": 813
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5511271953582764,
      "learning_rate": 0.00016900866217516844,
      "loss": 0.7373,
      "step": 814
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3771804869174957,
      "learning_rate": 0.0001689701636188643,
      "loss": 0.6566,
      "step": 815
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4080510139465332,
      "learning_rate": 0.00016893166506256016,
      "loss": 1.1367,
      "step": 816
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4585743844509125,
      "learning_rate": 0.000168893166506256,
      "loss": 0.6489,
      "step": 817
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3603699207305908,
      "learning_rate": 0.00016885466794995188,
      "loss": 0.804,
      "step": 818
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3835907578468323,
      "learning_rate": 0.00016881616939364775,
      "loss": 0.6746,
      "step": 819
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42422178387641907,
      "learning_rate": 0.00016877767083734363,
      "loss": 0.8467,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39354193210601807,
      "learning_rate": 0.00016873917228103945,
      "loss": 0.7838,
      "step": 821
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3793525695800781,
      "learning_rate": 0.00016870067372473532,
      "loss": 0.7369,
      "step": 822
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3221934735774994,
      "learning_rate": 0.0001686621751684312,
      "loss": 0.8031,
      "step": 823
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3444366455078125,
      "learning_rate": 0.00016862367661212705,
      "loss": 0.7385,
      "step": 824
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44286707043647766,
      "learning_rate": 0.00016858517805582292,
      "loss": 0.8558,
      "step": 825
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3785991370677948,
      "learning_rate": 0.00016854667949951877,
      "loss": 0.6804,
      "step": 826
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35703325271606445,
      "learning_rate": 0.00016850818094321464,
      "loss": 0.8319,
      "step": 827
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3548316955566406,
      "learning_rate": 0.0001684696823869105,
      "loss": 0.9741,
      "step": 828
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4017500579357147,
      "learning_rate": 0.00016843118383060636,
      "loss": 0.8069,
      "step": 829
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42583325505256653,
      "learning_rate": 0.00016839268527430224,
      "loss": 0.811,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43312227725982666,
      "learning_rate": 0.00016835418671799809,
      "loss": 0.8757,
      "step": 831
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40539172291755676,
      "learning_rate": 0.00016831568816169393,
      "loss": 0.981,
      "step": 832
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41632556915283203,
      "learning_rate": 0.0001682771896053898,
      "loss": 0.7313,
      "step": 833
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.532879114151001,
      "learning_rate": 0.00016823869104908568,
      "loss": 0.6457,
      "step": 834
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40394964814186096,
      "learning_rate": 0.00016820019249278153,
      "loss": 0.6489,
      "step": 835
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4110960364341736,
      "learning_rate": 0.00016816169393647738,
      "loss": 1.0254,
      "step": 836
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4686180353164673,
      "learning_rate": 0.00016812319538017325,
      "loss": 0.6832,
      "step": 837
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31215232610702515,
      "learning_rate": 0.00016808469682386913,
      "loss": 0.7572,
      "step": 838
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44114914536476135,
      "learning_rate": 0.00016804619826756497,
      "loss": 0.7516,
      "step": 839
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4628466069698334,
      "learning_rate": 0.00016800769971126085,
      "loss": 0.8312,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.402778685092926,
      "learning_rate": 0.0001679692011549567,
      "loss": 0.6082,
      "step": 841
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4084111750125885,
      "learning_rate": 0.00016793070259865254,
      "loss": 0.857,
      "step": 842
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43011507391929626,
      "learning_rate": 0.00016789220404234842,
      "loss": 0.5912,
      "step": 843
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3666722774505615,
      "learning_rate": 0.0001678537054860443,
      "loss": 0.8075,
      "step": 844
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4387371838092804,
      "learning_rate": 0.00016781520692974014,
      "loss": 0.7016,
      "step": 845
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4301617443561554,
      "learning_rate": 0.000167776708373436,
      "loss": 0.8587,
      "step": 846
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.45435237884521484,
      "learning_rate": 0.00016773820981713186,
      "loss": 0.9283,
      "step": 847
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42567750811576843,
      "learning_rate": 0.00016769971126082774,
      "loss": 0.8345,
      "step": 848
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5085536241531372,
      "learning_rate": 0.00016766121270452358,
      "loss": 0.6658,
      "step": 849
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.41667377948760986,
      "learning_rate": 0.00016762271414821943,
      "loss": 0.8367,
      "step": 850
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43233269453048706,
      "learning_rate": 0.0001675842155919153,
      "loss": 0.8026,
      "step": 851
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32341477274894714,
      "learning_rate": 0.00016754571703561118,
      "loss": 0.8264,
      "step": 852
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4784422218799591,
      "learning_rate": 0.00016750721847930703,
      "loss": 0.7404,
      "step": 853
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40146604180336,
      "learning_rate": 0.0001674687199230029,
      "loss": 0.608,
      "step": 854
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3967956602573395,
      "learning_rate": 0.00016743022136669875,
      "loss": 0.7052,
      "step": 855
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.43092501163482666,
      "learning_rate": 0.00016739172281039462,
      "loss": 0.8695,
      "step": 856
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3058846592903137,
      "learning_rate": 0.00016735322425409047,
      "loss": 0.9303,
      "step": 857
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3126014173030853,
      "learning_rate": 0.00016731472569778635,
      "loss": 0.7962,
      "step": 858
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4519258141517639,
      "learning_rate": 0.00016727622714148222,
      "loss": 0.9278,
      "step": 859
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3694867193698883,
      "learning_rate": 0.00016723772858517807,
      "loss": 0.8799,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36224937438964844,
      "learning_rate": 0.00016719923002887392,
      "loss": 0.7982,
      "step": 861
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3871414065361023,
      "learning_rate": 0.0001671607314725698,
      "loss": 0.8308,
      "step": 862
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35750070214271545,
      "learning_rate": 0.00016712223291626566,
      "loss": 0.9408,
      "step": 863
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.36376670002937317,
      "learning_rate": 0.0001670837343599615,
      "loss": 0.5507,
      "step": 864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.44785165786743164,
      "learning_rate": 0.00016704523580365736,
      "loss": 0.7235,
      "step": 865
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3633347451686859,
      "learning_rate": 0.00016700673724735323,
      "loss": 0.8807,
      "step": 866
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3864636719226837,
      "learning_rate": 0.0001669682386910491,
      "loss": 0.7263,
      "step": 867
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.411888062953949,
      "learning_rate": 0.00016692974013474496,
      "loss": 0.9225,
      "step": 868
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3231404423713684,
      "learning_rate": 0.00016689124157844083,
      "loss": 0.9061,
      "step": 869
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4525030553340912,
      "learning_rate": 0.00016685274302213668,
      "loss": 0.6509,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40726369619369507,
      "learning_rate": 0.00016681424446583253,
      "loss": 0.7813,
      "step": 871
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4267323613166809,
      "learning_rate": 0.0001667757459095284,
      "loss": 0.7504,
      "step": 872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.41709521412849426,
      "learning_rate": 0.00016673724735322427,
      "loss": 0.6476,
      "step": 873
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37306755781173706,
      "learning_rate": 0.00016669874879692012,
      "loss": 0.7741,
      "step": 874
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39880815148353577,
      "learning_rate": 0.00016666025024061597,
      "loss": 0.5553,
      "step": 875
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3532627522945404,
      "learning_rate": 0.00016662175168431184,
      "loss": 0.7507,
      "step": 876
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4160521626472473,
      "learning_rate": 0.00016658325312800772,
      "loss": 0.9009,
      "step": 877
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4004802405834198,
      "learning_rate": 0.00016654475457170357,
      "loss": 0.8608,
      "step": 878
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3720623254776001,
      "learning_rate": 0.0001665062560153994,
      "loss": 0.7846,
      "step": 879
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43344712257385254,
      "learning_rate": 0.0001664677574590953,
      "loss": 0.7161,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35037553310394287,
      "learning_rate": 0.00016642925890279116,
      "loss": 0.7835,
      "step": 881
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4126090407371521,
      "learning_rate": 0.000166390760346487,
      "loss": 0.7939,
      "step": 882
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3827371299266815,
      "learning_rate": 0.00016635226179018288,
      "loss": 0.7974,
      "step": 883
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4822234511375427,
      "learning_rate": 0.00016631376323387873,
      "loss": 0.6339,
      "step": 884
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3417407274246216,
      "learning_rate": 0.0001662752646775746,
      "loss": 0.8654,
      "step": 885
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35460445284843445,
      "learning_rate": 0.00016623676612127045,
      "loss": 0.5415,
      "step": 886
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3304254114627838,
      "learning_rate": 0.00016619826756496633,
      "loss": 0.694,
      "step": 887
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3509129285812378,
      "learning_rate": 0.0001661597690086622,
      "loss": 0.7794,
      "step": 888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3687591254711151,
      "learning_rate": 0.00016612127045235802,
      "loss": 0.9093,
      "step": 889
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3833083510398865,
      "learning_rate": 0.0001660827718960539,
      "loss": 0.7691,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3668593168258667,
      "learning_rate": 0.00016604427333974977,
      "loss": 0.7972,
      "step": 891
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38549745082855225,
      "learning_rate": 0.00016600577478344565,
      "loss": 0.7949,
      "step": 892
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4266708195209503,
      "learning_rate": 0.0001659672762271415,
      "loss": 0.8721,
      "step": 893
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39876678586006165,
      "learning_rate": 0.00016592877767083734,
      "loss": 0.763,
      "step": 894
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.445230096578598,
      "learning_rate": 0.00016589027911453322,
      "loss": 0.7947,
      "step": 895
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4430351257324219,
      "learning_rate": 0.00016585178055822906,
      "loss": 0.7779,
      "step": 896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4220488965511322,
      "learning_rate": 0.00016581328200192494,
      "loss": 0.7641,
      "step": 897
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.45670175552368164,
      "learning_rate": 0.0001657747834456208,
      "loss": 0.5795,
      "step": 898
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.34386640787124634,
      "learning_rate": 0.00016573628488931666,
      "loss": 0.9229,
      "step": 899
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4725986123085022,
      "learning_rate": 0.0001656977863330125,
      "loss": 0.7,
      "step": 900
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39845186471939087,
      "learning_rate": 0.00016565928777670838,
      "loss": 0.8275,
      "step": 901
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3908142149448395,
      "learning_rate": 0.00016562078922040426,
      "loss": 0.7597,
      "step": 902
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38814297318458557,
      "learning_rate": 0.0001655822906641001,
      "loss": 0.8163,
      "step": 903
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5420342087745667,
      "learning_rate": 0.00016554379210779595,
      "loss": 0.7512,
      "step": 904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43442463874816895,
      "learning_rate": 0.00016550529355149183,
      "loss": 0.6853,
      "step": 905
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3723842203617096,
      "learning_rate": 0.0001654667949951877,
      "loss": 0.7244,
      "step": 906
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39102187752723694,
      "learning_rate": 0.00016542829643888355,
      "loss": 0.6404,
      "step": 907
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4673289954662323,
      "learning_rate": 0.0001653897978825794,
      "loss": 0.7157,
      "step": 908
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3619476854801178,
      "learning_rate": 0.00016535129932627527,
      "loss": 0.6714,
      "step": 909
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35128358006477356,
      "learning_rate": 0.00016531280076997114,
      "loss": 0.7696,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4009929597377777,
      "learning_rate": 0.000165274302213667,
      "loss": 0.6706,
      "step": 911
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4207339882850647,
      "learning_rate": 0.00016523580365736287,
      "loss": 0.7959,
      "step": 912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3549601137638092,
      "learning_rate": 0.0001651973051010587,
      "loss": 0.8371,
      "step": 913
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3207203447818756,
      "learning_rate": 0.00016515880654475456,
      "loss": 0.8151,
      "step": 914
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3994414806365967,
      "learning_rate": 0.00016512030798845044,
      "loss": 0.65,
      "step": 915
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3931208550930023,
      "learning_rate": 0.0001650818094321463,
      "loss": 0.704,
      "step": 916
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3657586872577667,
      "learning_rate": 0.00016504331087584218,
      "loss": 0.7944,
      "step": 917
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.49718624353408813,
      "learning_rate": 0.000165004812319538,
      "loss": 0.8918,
      "step": 918
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4042849838733673,
      "learning_rate": 0.00016496631376323388,
      "loss": 0.7726,
      "step": 919
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43885496258735657,
      "learning_rate": 0.00016492781520692975,
      "loss": 0.7369,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.395626038312912,
      "learning_rate": 0.0001648893166506256,
      "loss": 0.7727,
      "step": 921
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3479551672935486,
      "learning_rate": 0.00016485081809432148,
      "loss": 0.7626,
      "step": 922
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4263276755809784,
      "learning_rate": 0.00016481231953801732,
      "loss": 0.6324,
      "step": 923
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4631369709968567,
      "learning_rate": 0.0001647738209817132,
      "loss": 0.7791,
      "step": 924
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4488198459148407,
      "learning_rate": 0.00016473532242540905,
      "loss": 0.8926,
      "step": 925
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3350141942501068,
      "learning_rate": 0.00016469682386910492,
      "loss": 0.8875,
      "step": 926
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39391931891441345,
      "learning_rate": 0.0001646583253128008,
      "loss": 0.7004,
      "step": 927
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4591343402862549,
      "learning_rate": 0.00016461982675649664,
      "loss": 0.7825,
      "step": 928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.38827601075172424,
      "learning_rate": 0.0001645813282001925,
      "loss": 0.6996,
      "step": 929
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5408360958099365,
      "learning_rate": 0.00016454282964388836,
      "loss": 0.7021,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4326247274875641,
      "learning_rate": 0.00016450433108758424,
      "loss": 0.6435,
      "step": 931
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4867457449436188,
      "learning_rate": 0.00016446583253128009,
      "loss": 0.7597,
      "step": 932
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3760989308357239,
      "learning_rate": 0.00016442733397497593,
      "loss": 0.6706,
      "step": 933
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3735730051994324,
      "learning_rate": 0.0001643888354186718,
      "loss": 0.7442,
      "step": 934
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.38337427377700806,
      "learning_rate": 0.00016435033686236768,
      "loss": 0.7391,
      "step": 935
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5188639163970947,
      "learning_rate": 0.00016431183830606353,
      "loss": 0.7199,
      "step": 936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.37170079350471497,
      "learning_rate": 0.0001642733397497594,
      "loss": 0.7128,
      "step": 937
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.36097222566604614,
      "learning_rate": 0.00016423484119345525,
      "loss": 0.8414,
      "step": 938
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43014106154441833,
      "learning_rate": 0.00016419634263715113,
      "loss": 0.7604,
      "step": 939
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4507324695587158,
      "learning_rate": 0.00016415784408084697,
      "loss": 0.8167,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4373815655708313,
      "learning_rate": 0.00016411934552454285,
      "loss": 0.7081,
      "step": 941
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40306782722473145,
      "learning_rate": 0.0001640808469682387,
      "loss": 0.6262,
      "step": 942
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4570135176181793,
      "learning_rate": 0.00016404234841193454,
      "loss": 0.7642,
      "step": 943
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46375465393066406,
      "learning_rate": 0.00016400384985563042,
      "loss": 0.7348,
      "step": 944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5628307461738586,
      "learning_rate": 0.0001639653512993263,
      "loss": 0.4934,
      "step": 945
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3285540044307709,
      "learning_rate": 0.00016392685274302214,
      "loss": 0.7409,
      "step": 946
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4342636466026306,
      "learning_rate": 0.000163888354186718,
      "loss": 0.6037,
      "step": 947
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46476995944976807,
      "learning_rate": 0.00016384985563041386,
      "loss": 0.7684,
      "step": 948
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.384127140045166,
      "learning_rate": 0.00016381135707410974,
      "loss": 0.722,
      "step": 949
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3942120373249054,
      "learning_rate": 0.00016377285851780558,
      "loss": 0.8695,
      "step": 950
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.352477103471756,
      "learning_rate": 0.00016373435996150146,
      "loss": 0.8088,
      "step": 951
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.35834285616874695,
      "learning_rate": 0.0001636958614051973,
      "loss": 0.7048,
      "step": 952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4362132251262665,
      "learning_rate": 0.00016365736284889318,
      "loss": 0.7584,
      "step": 953
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5655164122581482,
      "learning_rate": 0.00016361886429258903,
      "loss": 0.7591,
      "step": 954
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3786676824092865,
      "learning_rate": 0.0001635803657362849,
      "loss": 0.7533,
      "step": 955
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.432732492685318,
      "learning_rate": 0.00016354186717998078,
      "loss": 0.8608,
      "step": 956
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5503681898117065,
      "learning_rate": 0.00016350336862367662,
      "loss": 0.8209,
      "step": 957
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3569778800010681,
      "learning_rate": 0.00016346487006737247,
      "loss": 0.9292,
      "step": 958
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4056509733200073,
      "learning_rate": 0.00016342637151106835,
      "loss": 0.771,
      "step": 959
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.397250235080719,
      "learning_rate": 0.00016338787295476422,
      "loss": 0.8156,
      "step": 960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.401607483625412,
      "learning_rate": 0.00016334937439846007,
      "loss": 0.9892,
      "step": 961
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4879361093044281,
      "learning_rate": 0.00016331087584215591,
      "loss": 0.6769,
      "step": 962
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5391526222229004,
      "learning_rate": 0.0001632723772858518,
      "loss": 0.8177,
      "step": 963
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49405503273010254,
      "learning_rate": 0.00016323387872954766,
      "loss": 0.8344,
      "step": 964
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4291273057460785,
      "learning_rate": 0.0001631953801732435,
      "loss": 0.7129,
      "step": 965
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4620632827281952,
      "learning_rate": 0.00016315688161693939,
      "loss": 0.6563,
      "step": 966
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4600706100463867,
      "learning_rate": 0.00016311838306063523,
      "loss": 0.7658,
      "step": 967
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41418954730033875,
      "learning_rate": 0.00016307988450433108,
      "loss": 0.9749,
      "step": 968
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.31654787063598633,
      "learning_rate": 0.00016304138594802696,
      "loss": 0.802,
      "step": 969
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3953390121459961,
      "learning_rate": 0.00016300288739172283,
      "loss": 0.7323,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45991116762161255,
      "learning_rate": 0.00016296438883541868,
      "loss": 0.637,
      "step": 971
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.31873950362205505,
      "learning_rate": 0.00016292589027911452,
      "loss": 0.6832,
      "step": 972
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4046448767185211,
      "learning_rate": 0.0001628873917228104,
      "loss": 0.7325,
      "step": 973
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37110888957977295,
      "learning_rate": 0.00016284889316650627,
      "loss": 0.8734,
      "step": 974
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44934526085853577,
      "learning_rate": 0.00016281039461020212,
      "loss": 0.8081,
      "step": 975
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35538485646247864,
      "learning_rate": 0.00016277189605389797,
      "loss": 0.9444,
      "step": 976
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3702569007873535,
      "learning_rate": 0.00016273339749759384,
      "loss": 0.6102,
      "step": 977
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.32300740480422974,
      "learning_rate": 0.00016269489894128972,
      "loss": 0.7059,
      "step": 978
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.38859209418296814,
      "learning_rate": 0.00016265640038498556,
      "loss": 0.6427,
      "step": 979
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4092036187648773,
      "learning_rate": 0.00016261790182868144,
      "loss": 0.7174,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3881808817386627,
      "learning_rate": 0.0001625794032723773,
      "loss": 0.7007,
      "step": 981
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3992134630680084,
      "learning_rate": 0.00016254090471607316,
      "loss": 0.8398,
      "step": 982
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.46422716975212097,
      "learning_rate": 0.000162502406159769,
      "loss": 0.769,
      "step": 983
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.43485212326049805,
      "learning_rate": 0.00016246390760346488,
      "loss": 0.7374,
      "step": 984
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48495355248451233,
      "learning_rate": 0.00016242540904716076,
      "loss": 0.8433,
      "step": 985
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3639756739139557,
      "learning_rate": 0.0001623869104908566,
      "loss": 0.7457,
      "step": 986
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40549436211586,
      "learning_rate": 0.00016234841193455245,
      "loss": 0.596,
      "step": 987
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.36418217420578003,
      "learning_rate": 0.00016230991337824833,
      "loss": 0.742,
      "step": 988
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40171492099761963,
      "learning_rate": 0.0001622714148219442,
      "loss": 0.6389,
      "step": 989
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37999212741851807,
      "learning_rate": 0.00016223291626564005,
      "loss": 0.8567,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35829946398735046,
      "learning_rate": 0.0001621944177093359,
      "loss": 0.7595,
      "step": 991
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41418832540512085,
      "learning_rate": 0.00016215591915303177,
      "loss": 0.7844,
      "step": 992
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.33283162117004395,
      "learning_rate": 0.00016211742059672762,
      "loss": 0.7621,
      "step": 993
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41083329916000366,
      "learning_rate": 0.0001620789220404235,
      "loss": 0.7489,
      "step": 994
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4054572880268097,
      "learning_rate": 0.00016204042348411937,
      "loss": 0.9847,
      "step": 995
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48309609293937683,
      "learning_rate": 0.00016200192492781522,
      "loss": 0.7008,
      "step": 996
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3439509868621826,
      "learning_rate": 0.00016196342637151106,
      "loss": 0.8005,
      "step": 997
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4324743449687958,
      "learning_rate": 0.00016192492781520694,
      "loss": 0.8275,
      "step": 998
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41427528858184814,
      "learning_rate": 0.0001618864292589028,
      "loss": 0.6806,
      "step": 999
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4183162450790405,
      "learning_rate": 0.00016184793070259866,
      "loss": 0.8269,
      "step": 1000
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5142911672592163,
      "learning_rate": 0.0001618094321462945,
      "loss": 0.8053,
      "step": 1001
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4092613756656647,
      "learning_rate": 0.00016177093358999038,
      "loss": 0.7476,
      "step": 1002
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.38816404342651367,
      "learning_rate": 0.00016173243503368626,
      "loss": 0.59,
      "step": 1003
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.361930251121521,
      "learning_rate": 0.0001616939364773821,
      "loss": 0.7135,
      "step": 1004
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3976987898349762,
      "learning_rate": 0.00016165543792107795,
      "loss": 0.8899,
      "step": 1005
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.47700369358062744,
      "learning_rate": 0.00016161693936477382,
      "loss": 0.8206,
      "step": 1006
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.42015111446380615,
      "learning_rate": 0.0001615784408084697,
      "loss": 0.6419,
      "step": 1007
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.322148859500885,
      "learning_rate": 0.00016153994225216555,
      "loss": 0.8123,
      "step": 1008
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4050061106681824,
      "learning_rate": 0.00016150144369586142,
      "loss": 0.6976,
      "step": 1009
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.35987138748168945,
      "learning_rate": 0.00016146294513955727,
      "loss": 0.8419,
      "step": 1010
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.33031243085861206,
      "learning_rate": 0.00016142444658325314,
      "loss": 0.7068,
      "step": 1011
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37613943219184875,
      "learning_rate": 0.000161385948026949,
      "loss": 0.6742,
      "step": 1012
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.30047333240509033,
      "learning_rate": 0.00016134744947064487,
      "loss": 0.9531,
      "step": 1013
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.41578543186187744,
      "learning_rate": 0.00016130895091434074,
      "loss": 0.7668,
      "step": 1014
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3834519386291504,
      "learning_rate": 0.00016127045235803656,
      "loss": 0.6452,
      "step": 1015
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4907706677913666,
      "learning_rate": 0.00016123195380173243,
      "loss": 0.7805,
      "step": 1016
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4117744565010071,
      "learning_rate": 0.0001611934552454283,
      "loss": 0.7221,
      "step": 1017
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.37471017241477966,
      "learning_rate": 0.00016115495668912418,
      "loss": 0.5763,
      "step": 1018
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.40107065439224243,
      "learning_rate": 0.00016111645813282003,
      "loss": 0.6287,
      "step": 1019
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.34944072365760803,
      "learning_rate": 0.00016107795957651588,
      "loss": 0.7101,
      "step": 1020
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.37754085659980774,
      "learning_rate": 0.00016103946102021175,
      "loss": 0.8282,
      "step": 1021
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3539876639842987,
      "learning_rate": 0.0001610009624639076,
      "loss": 0.7358,
      "step": 1022
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3631936311721802,
      "learning_rate": 0.00016096246390760348,
      "loss": 0.6122,
      "step": 1023
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47914162278175354,
      "learning_rate": 0.00016092396535129935,
      "loss": 0.691,
      "step": 1024
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4048551023006439,
      "learning_rate": 0.0001608854667949952,
      "loss": 0.7443,
      "step": 1025
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6048703789710999,
      "learning_rate": 0.00016084696823869104,
      "loss": 0.8451,
      "step": 1026
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35409149527549744,
      "learning_rate": 0.00016080846968238692,
      "loss": 0.7463,
      "step": 1027
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.42525529861450195,
      "learning_rate": 0.0001607699711260828,
      "loss": 0.8458,
      "step": 1028
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4068790078163147,
      "learning_rate": 0.00016073147256977864,
      "loss": 0.6435,
      "step": 1029
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4333082139492035,
      "learning_rate": 0.0001606929740134745,
      "loss": 0.8844,
      "step": 1030
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4256124794483185,
      "learning_rate": 0.00016065447545717036,
      "loss": 0.7161,
      "step": 1031
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.36612895131111145,
      "learning_rate": 0.00016061597690086624,
      "loss": 0.6555,
      "step": 1032
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4030144214630127,
      "learning_rate": 0.00016057747834456208,
      "loss": 0.6805,
      "step": 1033
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4624347686767578,
      "learning_rate": 0.00016053897978825793,
      "loss": 0.682,
      "step": 1034
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4160405695438385,
      "learning_rate": 0.0001605004812319538,
      "loss": 0.809,
      "step": 1035
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6042136549949646,
      "learning_rate": 0.00016046198267564968,
      "loss": 0.7938,
      "step": 1036
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3848523795604706,
      "learning_rate": 0.00016042348411934553,
      "loss": 0.7986,
      "step": 1037
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4119400084018707,
      "learning_rate": 0.0001603849855630414,
      "loss": 0.7507,
      "step": 1038
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38147005438804626,
      "learning_rate": 0.00016034648700673725,
      "loss": 0.7639,
      "step": 1039
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38466325402259827,
      "learning_rate": 0.0001603079884504331,
      "loss": 0.5987,
      "step": 1040
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35815778374671936,
      "learning_rate": 0.00016026948989412897,
      "loss": 0.8265,
      "step": 1041
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4350082278251648,
      "learning_rate": 0.00016023099133782485,
      "loss": 0.8239,
      "step": 1042
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3755597770214081,
      "learning_rate": 0.00016019249278152072,
      "loss": 0.6357,
      "step": 1043
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3866950571537018,
      "learning_rate": 0.00016015399422521654,
      "loss": 0.7056,
      "step": 1044
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.39442890882492065,
      "learning_rate": 0.00016011549566891242,
      "loss": 0.6839,
      "step": 1045
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38096630573272705,
      "learning_rate": 0.0001600769971126083,
      "loss": 0.8712,
      "step": 1046
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.41441237926483154,
      "learning_rate": 0.00016003849855630414,
      "loss": 0.6685,
      "step": 1047
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3981308043003082,
      "learning_rate": 0.00016,
      "loss": 0.6351,
      "step": 1048
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.45708170533180237,
      "learning_rate": 0.00015996150144369586,
      "loss": 0.7258,
      "step": 1049
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38272976875305176,
      "learning_rate": 0.00015992300288739174,
      "loss": 0.789,
      "step": 1050
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.39918795228004456,
      "learning_rate": 0.00015988450433108758,
      "loss": 0.7441,
      "step": 1051
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3819565176963806,
      "learning_rate": 0.00015984600577478346,
      "loss": 0.9613,
      "step": 1052
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3901863992214203,
      "learning_rate": 0.00015980750721847933,
      "loss": 0.7707,
      "step": 1053
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4171031415462494,
      "learning_rate": 0.00015976900866217518,
      "loss": 0.859,
      "step": 1054
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.35221830010414124,
      "learning_rate": 0.00015973051010587103,
      "loss": 0.7238,
      "step": 1055
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3382309377193451,
      "learning_rate": 0.0001596920115495669,
      "loss": 0.8949,
      "step": 1056
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43097177147865295,
      "learning_rate": 0.00015965351299326278,
      "loss": 0.6984,
      "step": 1057
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.523605465888977,
      "learning_rate": 0.00015961501443695862,
      "loss": 0.8488,
      "step": 1058
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3962565064430237,
      "learning_rate": 0.00015957651588065447,
      "loss": 0.832,
      "step": 1059
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4559690058231354,
      "learning_rate": 0.00015953801732435034,
      "loss": 0.6859,
      "step": 1060
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4435402452945709,
      "learning_rate": 0.00015949951876804622,
      "loss": 0.6989,
      "step": 1061
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.41022989153862,
      "learning_rate": 0.00015946102021174207,
      "loss": 0.8035,
      "step": 1062
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3245035409927368,
      "learning_rate": 0.00015942252165543794,
      "loss": 0.6999,
      "step": 1063
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3887791633605957,
      "learning_rate": 0.0001593840230991338,
      "loss": 0.857,
      "step": 1064
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43856510519981384,
      "learning_rate": 0.00015934552454282964,
      "loss": 0.792,
      "step": 1065
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4955058693885803,
      "learning_rate": 0.0001593070259865255,
      "loss": 0.6905,
      "step": 1066
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4128498435020447,
      "learning_rate": 0.00015926852743022139,
      "loss": 0.7242,
      "step": 1067
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.46775028109550476,
      "learning_rate": 0.00015923002887391723,
      "loss": 0.7838,
      "step": 1068
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4442056119441986,
      "learning_rate": 0.00015919153031761308,
      "loss": 0.9226,
      "step": 1069
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4513077735900879,
      "learning_rate": 0.00015915303176130895,
      "loss": 0.7096,
      "step": 1070
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.37649473547935486,
      "learning_rate": 0.00015911453320500483,
      "loss": 0.8549,
      "step": 1071
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3761226236820221,
      "learning_rate": 0.00015907603464870068,
      "loss": 0.6773,
      "step": 1072
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.44938531517982483,
      "learning_rate": 0.00015903753609239652,
      "loss": 0.8688,
      "step": 1073
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3570939004421234,
      "learning_rate": 0.0001589990375360924,
      "loss": 0.6599,
      "step": 1074
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.391732782125473,
      "learning_rate": 0.00015896053897978827,
      "loss": 0.8761,
      "step": 1075
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3916613757610321,
      "learning_rate": 0.00015892204042348412,
      "loss": 0.907,
      "step": 1076
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49295851588249207,
      "learning_rate": 0.00015888354186718,
      "loss": 0.8555,
      "step": 1077
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5562530159950256,
      "learning_rate": 0.00015884504331087584,
      "loss": 0.6782,
      "step": 1078
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49062034487724304,
      "learning_rate": 0.00015880654475457172,
      "loss": 0.7649,
      "step": 1079
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3299710750579834,
      "learning_rate": 0.00015876804619826756,
      "loss": 0.6624,
      "step": 1080
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.45431676506996155,
      "learning_rate": 0.00015872954764196344,
      "loss": 0.7707,
      "step": 1081
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4144875109195709,
      "learning_rate": 0.0001586910490856593,
      "loss": 0.8769,
      "step": 1082
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4578436315059662,
      "learning_rate": 0.00015865255052935516,
      "loss": 0.8283,
      "step": 1083
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4305632710456848,
      "learning_rate": 0.000158614051973051,
      "loss": 0.8501,
      "step": 1084
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.36283501982688904,
      "learning_rate": 0.00015857555341674688,
      "loss": 0.6244,
      "step": 1085
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.38496094942092896,
      "learning_rate": 0.00015853705486044276,
      "loss": 0.8103,
      "step": 1086
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.43834495544433594,
      "learning_rate": 0.0001584985563041386,
      "loss": 0.8195,
      "step": 1087
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3856014609336853,
      "learning_rate": 0.00015846005774783445,
      "loss": 0.7114,
      "step": 1088
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.33795177936553955,
      "learning_rate": 0.00015842155919153033,
      "loss": 0.7954,
      "step": 1089
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.376462459564209,
      "learning_rate": 0.0001583830606352262,
      "loss": 0.7439,
      "step": 1090
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.48316308856010437,
      "learning_rate": 0.00015834456207892205,
      "loss": 0.7894,
      "step": 1091
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4347042739391327,
      "learning_rate": 0.00015830606352261792,
      "loss": 0.8222,
      "step": 1092
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3903662860393524,
      "learning_rate": 0.00015826756496631377,
      "loss": 0.7958,
      "step": 1093
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.34410256147384644,
      "learning_rate": 0.00015822906641000962,
      "loss": 0.7444,
      "step": 1094
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.34057170152664185,
      "learning_rate": 0.0001581905678537055,
      "loss": 1.0525,
      "step": 1095
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.39681077003479004,
      "learning_rate": 0.00015815206929740137,
      "loss": 0.8238,
      "step": 1096
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.42502957582473755,
      "learning_rate": 0.00015811357074109721,
      "loss": 0.6958,
      "step": 1097
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.43412235379219055,
      "learning_rate": 0.00015807507218479306,
      "loss": 0.8056,
      "step": 1098
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4639730155467987,
      "learning_rate": 0.00015803657362848894,
      "loss": 0.8045,
      "step": 1099
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3501754403114319,
      "learning_rate": 0.0001579980750721848,
      "loss": 0.9637,
      "step": 1100
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4487448036670685,
      "learning_rate": 0.00015795957651588066,
      "loss": 0.7817,
      "step": 1101
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3290480077266693,
      "learning_rate": 0.0001579210779595765,
      "loss": 0.6841,
      "step": 1102
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3948013186454773,
      "learning_rate": 0.00015788257940327238,
      "loss": 0.7926,
      "step": 1103
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3786340057849884,
      "learning_rate": 0.00015784408084696825,
      "loss": 0.7677,
      "step": 1104
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.40259552001953125,
      "learning_rate": 0.0001578055822906641,
      "loss": 0.7114,
      "step": 1105
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.41371214389801025,
      "learning_rate": 0.00015776708373435998,
      "loss": 0.6498,
      "step": 1106
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.36139020323753357,
      "learning_rate": 0.00015772858517805582,
      "loss": 0.6922,
      "step": 1107
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3744065761566162,
      "learning_rate": 0.0001576900866217517,
      "loss": 0.8142,
      "step": 1108
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4204704463481903,
      "learning_rate": 0.00015765158806544755,
      "loss": 1.0868,
      "step": 1109
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.36215659976005554,
      "learning_rate": 0.00015761308950914342,
      "loss": 0.6075,
      "step": 1110
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.530100405216217,
      "learning_rate": 0.0001575745909528393,
      "loss": 0.9125,
      "step": 1111
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4111427366733551,
      "learning_rate": 0.00015753609239653512,
      "loss": 0.7786,
      "step": 1112
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4359910786151886,
      "learning_rate": 0.000157497593840231,
      "loss": 0.7531,
      "step": 1113
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.39710521697998047,
      "learning_rate": 0.00015745909528392686,
      "loss": 0.6205,
      "step": 1114
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3554534614086151,
      "learning_rate": 0.00015742059672762274,
      "loss": 0.8446,
      "step": 1115
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4166891574859619,
      "learning_rate": 0.0001573820981713186,
      "loss": 0.672,
      "step": 1116
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4184480607509613,
      "learning_rate": 0.00015734359961501443,
      "loss": 0.6638,
      "step": 1117
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.37945467233657837,
      "learning_rate": 0.0001573051010587103,
      "loss": 0.7022,
      "step": 1118
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3724149465560913,
      "learning_rate": 0.00015726660250240616,
      "loss": 0.7179,
      "step": 1119
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.36571890115737915,
      "learning_rate": 0.00015722810394610203,
      "loss": 0.8142,
      "step": 1120
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43435412645339966,
      "learning_rate": 0.0001571896053897979,
      "loss": 0.5344,
      "step": 1121
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43020376563072205,
      "learning_rate": 0.00015715110683349375,
      "loss": 0.8112,
      "step": 1122
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3460918962955475,
      "learning_rate": 0.0001571126082771896,
      "loss": 0.7552,
      "step": 1123
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3977578282356262,
      "learning_rate": 0.00015707410972088547,
      "loss": 0.6842,
      "step": 1124
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.48570865392684937,
      "learning_rate": 0.00015703561116458135,
      "loss": 0.7387,
      "step": 1125
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.40693992376327515,
      "learning_rate": 0.0001569971126082772,
      "loss": 0.777,
      "step": 1126
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4439678192138672,
      "learning_rate": 0.00015695861405197304,
      "loss": 0.7193,
      "step": 1127
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46327605843544006,
      "learning_rate": 0.00015692011549566892,
      "loss": 0.7203,
      "step": 1128
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3540477156639099,
      "learning_rate": 0.0001568816169393648,
      "loss": 0.6745,
      "step": 1129
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.38922786712646484,
      "learning_rate": 0.00015684311838306064,
      "loss": 0.6775,
      "step": 1130
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5611504912376404,
      "learning_rate": 0.0001568046198267565,
      "loss": 0.7527,
      "step": 1131
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.31474006175994873,
      "learning_rate": 0.00015676612127045236,
      "loss": 0.6399,
      "step": 1132
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.44689998030662537,
      "learning_rate": 0.00015672762271414824,
      "loss": 0.8319,
      "step": 1133
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.32527533173561096,
      "learning_rate": 0.00015668912415784408,
      "loss": 0.7247,
      "step": 1134
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42637091875076294,
      "learning_rate": 0.00015665062560153996,
      "loss": 0.7363,
      "step": 1135
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.37939783930778503,
      "learning_rate": 0.0001566121270452358,
      "loss": 0.8506,
      "step": 1136
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.38763850927352905,
      "learning_rate": 0.00015657362848893168,
      "loss": 0.7845,
      "step": 1137
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.35469725728034973,
      "learning_rate": 0.00015653512993262753,
      "loss": 0.6412,
      "step": 1138
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42117586731910706,
      "learning_rate": 0.0001564966313763234,
      "loss": 0.7159,
      "step": 1139
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39332911372184753,
      "learning_rate": 0.00015645813282001928,
      "loss": 0.807,
      "step": 1140
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4328210949897766,
      "learning_rate": 0.0001564196342637151,
      "loss": 0.8745,
      "step": 1141
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3921777307987213,
      "learning_rate": 0.00015638113570741097,
      "loss": 0.8571,
      "step": 1142
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4740988314151764,
      "learning_rate": 0.00015634263715110685,
      "loss": 0.7963,
      "step": 1143
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.44173067808151245,
      "learning_rate": 0.0001563041385948027,
      "loss": 0.757,
      "step": 1144
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.32797256112098694,
      "learning_rate": 0.00015626564003849857,
      "loss": 0.7753,
      "step": 1145
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39528781175613403,
      "learning_rate": 0.00015622714148219442,
      "loss": 0.7109,
      "step": 1146
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39863264560699463,
      "learning_rate": 0.0001561886429258903,
      "loss": 0.7359,
      "step": 1147
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42865288257598877,
      "learning_rate": 0.00015615014436958614,
      "loss": 0.9774,
      "step": 1148
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.40217769145965576,
      "learning_rate": 0.000156111645813282,
      "loss": 0.7529,
      "step": 1149
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3679961860179901,
      "learning_rate": 0.0001560731472569779,
      "loss": 0.7246,
      "step": 1150
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3621695041656494,
      "learning_rate": 0.00015603464870067373,
      "loss": 0.809,
      "step": 1151
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.35603639483451843,
      "learning_rate": 0.00015599615014436958,
      "loss": 0.6261,
      "step": 1152
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46975716948509216,
      "learning_rate": 0.00015595765158806546,
      "loss": 0.7644,
      "step": 1153
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.40510255098342896,
      "learning_rate": 0.00015591915303176133,
      "loss": 0.661,
      "step": 1154
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46312135457992554,
      "learning_rate": 0.00015588065447545718,
      "loss": 0.7586,
      "step": 1155
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42839890718460083,
      "learning_rate": 0.00015584215591915303,
      "loss": 0.9198,
      "step": 1156
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5583325028419495,
      "learning_rate": 0.0001558036573628489,
      "loss": 0.8399,
      "step": 1157
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4485267698764801,
      "learning_rate": 0.00015576515880654477,
      "loss": 0.8856,
      "step": 1158
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4484996199607849,
      "learning_rate": 0.00015572666025024062,
      "loss": 0.82,
      "step": 1159
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.37229499220848083,
      "learning_rate": 0.00015568816169393647,
      "loss": 0.8151,
      "step": 1160
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3836243748664856,
      "learning_rate": 0.00015564966313763234,
      "loss": 0.7787,
      "step": 1161
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3747301995754242,
      "learning_rate": 0.00015561116458132822,
      "loss": 0.7317,
      "step": 1162
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4159163534641266,
      "learning_rate": 0.00015557266602502407,
      "loss": 0.7757,
      "step": 1163
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.35848599672317505,
      "learning_rate": 0.00015553416746871994,
      "loss": 0.7005,
      "step": 1164
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.38598203659057617,
      "learning_rate": 0.0001554956689124158,
      "loss": 0.6347,
      "step": 1165
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43064266443252563,
      "learning_rate": 0.00015545717035611164,
      "loss": 0.7328,
      "step": 1166
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4102381765842438,
      "learning_rate": 0.0001554186717998075,
      "loss": 0.7664,
      "step": 1167
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42717429995536804,
      "learning_rate": 0.00015538017324350338,
      "loss": 0.7261,
      "step": 1168
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3969756066799164,
      "learning_rate": 0.00015534167468719926,
      "loss": 0.988,
      "step": 1169
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4277059733867645,
      "learning_rate": 0.00015530317613089508,
      "loss": 0.8142,
      "step": 1170
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3972422182559967,
      "learning_rate": 0.00015526467757459095,
      "loss": 0.6252,
      "step": 1171
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.42406436800956726,
      "learning_rate": 0.00015522617901828683,
      "loss": 0.6827,
      "step": 1172
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.38090869784355164,
      "learning_rate": 0.00015518768046198268,
      "loss": 0.635,
      "step": 1173
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5245205760002136,
      "learning_rate": 0.00015514918190567855,
      "loss": 0.6449,
      "step": 1174
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3738233745098114,
      "learning_rate": 0.0001551106833493744,
      "loss": 0.7073,
      "step": 1175
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.42204442620277405,
      "learning_rate": 0.00015507218479307027,
      "loss": 0.6876,
      "step": 1176
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.413811057806015,
      "learning_rate": 0.00015503368623676612,
      "loss": 0.7898,
      "step": 1177
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4465698003768921,
      "learning_rate": 0.000154995187680462,
      "loss": 0.6242,
      "step": 1178
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4211638569831848,
      "learning_rate": 0.00015495668912415787,
      "loss": 0.6734,
      "step": 1179
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39296627044677734,
      "learning_rate": 0.00015491819056785372,
      "loss": 0.8385,
      "step": 1180
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.45707204937934875,
      "learning_rate": 0.00015487969201154956,
      "loss": 0.7797,
      "step": 1181
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5070324540138245,
      "learning_rate": 0.00015484119345524544,
      "loss": 0.8437,
      "step": 1182
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.44024863839149475,
      "learning_rate": 0.0001548026948989413,
      "loss": 0.8795,
      "step": 1183
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37814775109291077,
      "learning_rate": 0.00015476419634263716,
      "loss": 0.7748,
      "step": 1184
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37040790915489197,
      "learning_rate": 0.000154725697786333,
      "loss": 0.8153,
      "step": 1185
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.36610615253448486,
      "learning_rate": 0.00015468719923002888,
      "loss": 0.7506,
      "step": 1186
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.41679295897483826,
      "learning_rate": 0.00015464870067372476,
      "loss": 0.8521,
      "step": 1187
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.40299808979034424,
      "learning_rate": 0.0001546102021174206,
      "loss": 0.7421,
      "step": 1188
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3856588900089264,
      "learning_rate": 0.00015457170356111648,
      "loss": 0.8437,
      "step": 1189
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.35787302255630493,
      "learning_rate": 0.00015453320500481233,
      "loss": 0.8506,
      "step": 1190
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.34523940086364746,
      "learning_rate": 0.00015449470644850817,
      "loss": 0.8485,
      "step": 1191
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.38170987367630005,
      "learning_rate": 0.00015445620789220405,
      "loss": 0.6814,
      "step": 1192
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37243613600730896,
      "learning_rate": 0.00015441770933589992,
      "loss": 0.8571,
      "step": 1193
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39110085368156433,
      "learning_rate": 0.00015437921077959577,
      "loss": 0.7967,
      "step": 1194
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.46120139956474304,
      "learning_rate": 0.00015434071222329162,
      "loss": 0.7616,
      "step": 1195
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.491585373878479,
      "learning_rate": 0.0001543022136669875,
      "loss": 0.6762,
      "step": 1196
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3828129172325134,
      "learning_rate": 0.00015426371511068337,
      "loss": 0.8359,
      "step": 1197
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3328189253807068,
      "learning_rate": 0.00015422521655437921,
      "loss": 0.591,
      "step": 1198
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3250027000904083,
      "learning_rate": 0.00015418671799807506,
      "loss": 0.7838,
      "step": 1199
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.35278844833374023,
      "learning_rate": 0.00015414821944177094,
      "loss": 0.8331,
      "step": 1200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.35219067335128784,
      "learning_rate": 0.0001541097208854668,
      "loss": 0.7183,
      "step": 1201
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4565924108028412,
      "learning_rate": 0.00015407122232916266,
      "loss": 0.7753,
      "step": 1202
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3913572430610657,
      "learning_rate": 0.00015403272377285853,
      "loss": 0.7035,
      "step": 1203
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3244643807411194,
      "learning_rate": 0.00015399422521655438,
      "loss": 0.7814,
      "step": 1204
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.41972634196281433,
      "learning_rate": 0.00015395572666025025,
      "loss": 0.5791,
      "step": 1205
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4282330274581909,
      "learning_rate": 0.0001539172281039461,
      "loss": 0.7852,
      "step": 1206
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4206712543964386,
      "learning_rate": 0.00015387872954764198,
      "loss": 0.8797,
      "step": 1207
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3925241529941559,
      "learning_rate": 0.00015384023099133785,
      "loss": 0.8628,
      "step": 1208
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.46385809779167175,
      "learning_rate": 0.0001538017324350337,
      "loss": 0.7358,
      "step": 1209
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4132677912712097,
      "learning_rate": 0.00015376323387872955,
      "loss": 0.6425,
      "step": 1210
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3206253945827484,
      "learning_rate": 0.00015372473532242542,
      "loss": 0.9339,
      "step": 1211
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6679430603981018,
      "learning_rate": 0.0001536862367661213,
      "loss": 0.8193,
      "step": 1212
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5866867303848267,
      "learning_rate": 0.00015364773820981714,
      "loss": 0.8315,
      "step": 1213
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.503413736820221,
      "learning_rate": 0.000153609239653513,
      "loss": 0.6992,
      "step": 1214
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3816224932670593,
      "learning_rate": 0.00015357074109720886,
      "loss": 0.667,
      "step": 1215
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4119608402252197,
      "learning_rate": 0.0001535322425409047,
      "loss": 0.7139,
      "step": 1216
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3772684931755066,
      "learning_rate": 0.00015349374398460059,
      "loss": 0.6538,
      "step": 1217
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.331874281167984,
      "learning_rate": 0.00015345524542829646,
      "loss": 0.7934,
      "step": 1218
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.37601643800735474,
      "learning_rate": 0.0001534167468719923,
      "loss": 0.9004,
      "step": 1219
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.39214855432510376,
      "learning_rate": 0.00015337824831568816,
      "loss": 0.7811,
      "step": 1220
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4096325635910034,
      "learning_rate": 0.00015333974975938403,
      "loss": 0.4574,
      "step": 1221
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5163927674293518,
      "learning_rate": 0.0001533012512030799,
      "loss": 0.7136,
      "step": 1222
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.378543496131897,
      "learning_rate": 0.00015326275264677575,
      "loss": 0.7433,
      "step": 1223
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35357967019081116,
      "learning_rate": 0.0001532242540904716,
      "loss": 0.948,
      "step": 1224
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.39216411113739014,
      "learning_rate": 0.00015318575553416747,
      "loss": 0.8092,
      "step": 1225
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.34394603967666626,
      "learning_rate": 0.00015314725697786335,
      "loss": 0.8093,
      "step": 1226
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.34032198786735535,
      "learning_rate": 0.0001531087584215592,
      "loss": 0.8504,
      "step": 1227
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.38798490166664124,
      "learning_rate": 0.00015307025986525504,
      "loss": 0.8131,
      "step": 1228
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.359995037317276,
      "learning_rate": 0.00015303176130895092,
      "loss": 0.8589,
      "step": 1229
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.36750391125679016,
      "learning_rate": 0.0001529932627526468,
      "loss": 0.5993,
      "step": 1230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.39933866262435913,
      "learning_rate": 0.00015295476419634264,
      "loss": 0.8306,
      "step": 1231
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3552697002887726,
      "learning_rate": 0.00015291626564003851,
      "loss": 0.7849,
      "step": 1232
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4225974380970001,
      "learning_rate": 0.00015287776708373436,
      "loss": 0.8307,
      "step": 1233
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4953029155731201,
      "learning_rate": 0.00015283926852743024,
      "loss": 0.8045,
      "step": 1234
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3827214539051056,
      "learning_rate": 0.00015280076997112608,
      "loss": 0.7014,
      "step": 1235
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35699954628944397,
      "learning_rate": 0.00015276227141482196,
      "loss": 0.8127,
      "step": 1236
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.41991326212882996,
      "learning_rate": 0.00015272377285851783,
      "loss": 0.7286,
      "step": 1237
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33881086111068726,
      "learning_rate": 0.00015268527430221365,
      "loss": 0.7056,
      "step": 1238
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4219568967819214,
      "learning_rate": 0.00015264677574590953,
      "loss": 0.7692,
      "step": 1239
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.39442741870880127,
      "learning_rate": 0.0001526082771896054,
      "loss": 0.7731,
      "step": 1240
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.38032737374305725,
      "learning_rate": 0.00015256977863330128,
      "loss": 0.7972,
      "step": 1241
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33482059836387634,
      "learning_rate": 0.00015253128007699712,
      "loss": 0.9594,
      "step": 1242
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4163847863674164,
      "learning_rate": 0.00015249278152069297,
      "loss": 0.8304,
      "step": 1243
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3635527491569519,
      "learning_rate": 0.00015245428296438885,
      "loss": 0.6583,
      "step": 1244
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3936399519443512,
      "learning_rate": 0.0001524157844080847,
      "loss": 0.8757,
      "step": 1245
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3429082930088043,
      "learning_rate": 0.00015237728585178057,
      "loss": 0.8626,
      "step": 1246
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3856114149093628,
      "learning_rate": 0.00015233878729547644,
      "loss": 0.7019,
      "step": 1247
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.42772915959358215,
      "learning_rate": 0.0001523002887391723,
      "loss": 0.6167,
      "step": 1248
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4032495319843292,
      "learning_rate": 0.00015226179018286814,
      "loss": 0.7146,
      "step": 1249
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.46012309193611145,
      "learning_rate": 0.000152223291626564,
      "loss": 0.7841,
      "step": 1250
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5377299189567566,
      "learning_rate": 0.0001521847930702599,
      "loss": 0.7606,
      "step": 1251
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3929075598716736,
      "learning_rate": 0.00015214629451395573,
      "loss": 0.7055,
      "step": 1252
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.40822258591651917,
      "learning_rate": 0.00015210779595765158,
      "loss": 0.8892,
      "step": 1253
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3492578864097595,
      "learning_rate": 0.00015206929740134746,
      "loss": 0.756,
      "step": 1254
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3978988528251648,
      "learning_rate": 0.00015203079884504333,
      "loss": 0.6632,
      "step": 1255
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4819571375846863,
      "learning_rate": 0.00015199230028873918,
      "loss": 0.8676,
      "step": 1256
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3063124716281891,
      "learning_rate": 0.00015195380173243503,
      "loss": 0.7955,
      "step": 1257
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35990455746650696,
      "learning_rate": 0.0001519153031761309,
      "loss": 0.7876,
      "step": 1258
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.33189907670021057,
      "learning_rate": 0.00015187680461982677,
      "loss": 0.6341,
      "step": 1259
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4079800546169281,
      "learning_rate": 0.00015183830606352262,
      "loss": 0.5807,
      "step": 1260
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.38647302985191345,
      "learning_rate": 0.0001517998075072185,
      "loss": 0.7393,
      "step": 1261
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.32732075452804565,
      "learning_rate": 0.00015176130895091434,
      "loss": 0.9882,
      "step": 1262
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4003913998603821,
      "learning_rate": 0.0001517228103946102,
      "loss": 0.5764,
      "step": 1263
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4388103485107422,
      "learning_rate": 0.00015168431183830607,
      "loss": 0.9495,
      "step": 1264
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3771224617958069,
      "learning_rate": 0.00015164581328200194,
      "loss": 0.7242,
      "step": 1265
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4223957061767578,
      "learning_rate": 0.00015160731472569781,
      "loss": 0.6648,
      "step": 1266
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3785272538661957,
      "learning_rate": 0.00015156881616939364,
      "loss": 0.8301,
      "step": 1267
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4131834805011749,
      "learning_rate": 0.0001515303176130895,
      "loss": 0.6521,
      "step": 1268
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.35808467864990234,
      "learning_rate": 0.00015149181905678538,
      "loss": 0.6403,
      "step": 1269
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3442893922328949,
      "learning_rate": 0.00015145332050048123,
      "loss": 0.7729,
      "step": 1270
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3319410979747772,
      "learning_rate": 0.0001514148219441771,
      "loss": 0.9186,
      "step": 1271
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5436779260635376,
      "learning_rate": 0.00015137632338787295,
      "loss": 0.6794,
      "step": 1272
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.36657291650772095,
      "learning_rate": 0.00015133782483156883,
      "loss": 0.7594,
      "step": 1273
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3963451683521271,
      "learning_rate": 0.00015129932627526468,
      "loss": 0.6555,
      "step": 1274
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36523380875587463,
      "learning_rate": 0.00015126082771896055,
      "loss": 0.9055,
      "step": 1275
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3812717795372009,
      "learning_rate": 0.00015122232916265642,
      "loss": 0.8134,
      "step": 1276
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36425143480300903,
      "learning_rate": 0.00015118383060635227,
      "loss": 0.9836,
      "step": 1277
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4338679909706116,
      "learning_rate": 0.00015114533205004812,
      "loss": 0.7289,
      "step": 1278
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.35821253061294556,
      "learning_rate": 0.000151106833493744,
      "loss": 0.6587,
      "step": 1279
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.39651304483413696,
      "learning_rate": 0.00015106833493743987,
      "loss": 0.7677,
      "step": 1280
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4540548622608185,
      "learning_rate": 0.00015102983638113572,
      "loss": 0.684,
      "step": 1281
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.39740437269210815,
      "learning_rate": 0.00015099133782483156,
      "loss": 0.9521,
      "step": 1282
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4487561583518982,
      "learning_rate": 0.00015095283926852744,
      "loss": 0.7924,
      "step": 1283
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.37519922852516174,
      "learning_rate": 0.0001509143407122233,
      "loss": 0.7147,
      "step": 1284
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.41145941615104675,
      "learning_rate": 0.00015087584215591916,
      "loss": 0.8579,
      "step": 1285
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.38699883222579956,
      "learning_rate": 0.000150837343599615,
      "loss": 0.5547,
      "step": 1286
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.399982213973999,
      "learning_rate": 0.00015079884504331088,
      "loss": 0.7378,
      "step": 1287
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4065243899822235,
      "learning_rate": 0.00015076034648700676,
      "loss": 0.774,
      "step": 1288
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36400336027145386,
      "learning_rate": 0.0001507218479307026,
      "loss": 0.8186,
      "step": 1289
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36938580870628357,
      "learning_rate": 0.00015068334937439848,
      "loss": 0.6065,
      "step": 1290
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.39676472544670105,
      "learning_rate": 0.00015064485081809433,
      "loss": 0.7417,
      "step": 1291
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4532395601272583,
      "learning_rate": 0.00015060635226179017,
      "loss": 0.669,
      "step": 1292
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.49923408031463623,
      "learning_rate": 0.00015056785370548605,
      "loss": 0.8594,
      "step": 1293
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.364364892244339,
      "learning_rate": 0.00015052935514918192,
      "loss": 0.82,
      "step": 1294
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.47290465235710144,
      "learning_rate": 0.00015049085659287777,
      "loss": 0.6214,
      "step": 1295
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4195459485054016,
      "learning_rate": 0.00015045235803657362,
      "loss": 0.787,
      "step": 1296
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.32194480299949646,
      "learning_rate": 0.0001504138594802695,
      "loss": 0.6495,
      "step": 1297
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.41045573353767395,
      "learning_rate": 0.00015037536092396537,
      "loss": 0.744,
      "step": 1298
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3946152329444885,
      "learning_rate": 0.0001503368623676612,
      "loss": 0.8691,
      "step": 1299
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.40465399622917175,
      "learning_rate": 0.0001502983638113571,
      "loss": 0.7805,
      "step": 1300
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.44865813851356506,
      "learning_rate": 0.00015025986525505294,
      "loss": 0.7461,
      "step": 1301
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.37946686148643494,
      "learning_rate": 0.0001502213666987488,
      "loss": 0.7111,
      "step": 1302
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3577534854412079,
      "learning_rate": 0.00015018286814244466,
      "loss": 0.7652,
      "step": 1303
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5187150239944458,
      "learning_rate": 0.00015014436958614053,
      "loss": 0.847,
      "step": 1304
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4189605712890625,
      "learning_rate": 0.0001501058710298364,
      "loss": 0.8358,
      "step": 1305
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.46004951000213623,
      "learning_rate": 0.00015006737247353225,
      "loss": 0.7122,
      "step": 1306
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5376541614532471,
      "learning_rate": 0.0001500288739172281,
      "loss": 0.7888,
      "step": 1307
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4360598027706146,
      "learning_rate": 0.00014999037536092398,
      "loss": 0.8056,
      "step": 1308
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4408196806907654,
      "learning_rate": 0.00014995187680461985,
      "loss": 0.4963,
      "step": 1309
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36642003059387207,
      "learning_rate": 0.0001499133782483157,
      "loss": 0.6631,
      "step": 1310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3815830945968628,
      "learning_rate": 0.00014987487969201155,
      "loss": 0.5837,
      "step": 1311
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4319801330566406,
      "learning_rate": 0.00014983638113570742,
      "loss": 0.8688,
      "step": 1312
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.34592485427856445,
      "learning_rate": 0.0001497978825794033,
      "loss": 0.8808,
      "step": 1313
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.33562999963760376,
      "learning_rate": 0.00014975938402309914,
      "loss": 0.607,
      "step": 1314
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5357721447944641,
      "learning_rate": 0.00014972088546679502,
      "loss": 0.6738,
      "step": 1315
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4042273461818695,
      "learning_rate": 0.00014968238691049086,
      "loss": 0.7079,
      "step": 1316
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.38334885239601135,
      "learning_rate": 0.0001496438883541867,
      "loss": 0.6879,
      "step": 1317
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3976695239543915,
      "learning_rate": 0.00014960538979788259,
      "loss": 0.7409,
      "step": 1318
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3541370630264282,
      "learning_rate": 0.00014956689124157846,
      "loss": 0.7507,
      "step": 1319
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.44518333673477173,
      "learning_rate": 0.0001495283926852743,
      "loss": 0.9043,
      "step": 1320
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.36753326654434204,
      "learning_rate": 0.00014948989412897015,
      "loss": 0.8128,
      "step": 1321
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4933098256587982,
      "learning_rate": 0.00014945139557266603,
      "loss": 0.6383,
      "step": 1322
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.38790324330329895,
      "learning_rate": 0.0001494128970163619,
      "loss": 0.7678,
      "step": 1323
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4183103144168854,
      "learning_rate": 0.00014937439846005775,
      "loss": 0.7539,
      "step": 1324
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3307812809944153,
      "learning_rate": 0.0001493358999037536,
      "loss": 0.7851,
      "step": 1325
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.43115413188934326,
      "learning_rate": 0.00014929740134744947,
      "loss": 0.6899,
      "step": 1326
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42638832330703735,
      "learning_rate": 0.00014925890279114535,
      "loss": 0.7085,
      "step": 1327
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.44743022322654724,
      "learning_rate": 0.0001492204042348412,
      "loss": 0.655,
      "step": 1328
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4563879072666168,
      "learning_rate": 0.00014918190567853707,
      "loss": 0.8687,
      "step": 1329
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.45011451840400696,
      "learning_rate": 0.00014914340712223292,
      "loss": 0.718,
      "step": 1330
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.41595086455345154,
      "learning_rate": 0.0001491049085659288,
      "loss": 0.76,
      "step": 1331
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.36162069439888,
      "learning_rate": 0.00014906641000962464,
      "loss": 0.6916,
      "step": 1332
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4033454954624176,
      "learning_rate": 0.00014902791145332051,
      "loss": 0.7686,
      "step": 1333
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3447574973106384,
      "learning_rate": 0.0001489894128970164,
      "loss": 0.6239,
      "step": 1334
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.35008230805397034,
      "learning_rate": 0.0001489509143407122,
      "loss": 0.801,
      "step": 1335
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4806738793849945,
      "learning_rate": 0.00014891241578440808,
      "loss": 0.7814,
      "step": 1336
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38083821535110474,
      "learning_rate": 0.00014887391722810396,
      "loss": 0.702,
      "step": 1337
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4168788492679596,
      "learning_rate": 0.00014883541867179983,
      "loss": 0.6303,
      "step": 1338
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.448809951543808,
      "learning_rate": 0.00014879692011549568,
      "loss": 0.6932,
      "step": 1339
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3728683292865753,
      "learning_rate": 0.00014875842155919153,
      "loss": 0.7047,
      "step": 1340
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34912964701652527,
      "learning_rate": 0.0001487199230028874,
      "loss": 0.7607,
      "step": 1341
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4390076696872711,
      "learning_rate": 0.00014868142444658325,
      "loss": 0.6729,
      "step": 1342
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4820930063724518,
      "learning_rate": 0.00014864292589027912,
      "loss": 0.7259,
      "step": 1343
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5697134733200073,
      "learning_rate": 0.000148604427333975,
      "loss": 0.8682,
      "step": 1344
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38294899463653564,
      "learning_rate": 0.00014856592877767085,
      "loss": 0.7792,
      "step": 1345
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3923616111278534,
      "learning_rate": 0.0001485274302213667,
      "loss": 0.5965,
      "step": 1346
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34692272543907166,
      "learning_rate": 0.00014848893166506257,
      "loss": 0.7801,
      "step": 1347
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3724518120288849,
      "learning_rate": 0.00014845043310875844,
      "loss": 0.6863,
      "step": 1348
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.40255510807037354,
      "learning_rate": 0.0001484119345524543,
      "loss": 0.6725,
      "step": 1349
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3815781772136688,
      "learning_rate": 0.00014837343599615014,
      "loss": 0.6842,
      "step": 1350
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3960299491882324,
      "learning_rate": 0.000148334937439846,
      "loss": 0.6186,
      "step": 1351
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4321020841598511,
      "learning_rate": 0.00014829643888354189,
      "loss": 0.6603,
      "step": 1352
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.41685959696769714,
      "learning_rate": 0.00014825794032723773,
      "loss": 0.6641,
      "step": 1353
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4112638235092163,
      "learning_rate": 0.00014821944177093358,
      "loss": 0.9039,
      "step": 1354
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4214073419570923,
      "learning_rate": 0.00014818094321462946,
      "loss": 0.787,
      "step": 1355
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3562779426574707,
      "learning_rate": 0.00014814244465832533,
      "loss": 0.7769,
      "step": 1356
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.41511768102645874,
      "learning_rate": 0.00014810394610202118,
      "loss": 0.625,
      "step": 1357
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4222041368484497,
      "learning_rate": 0.00014806544754571705,
      "loss": 0.872,
      "step": 1358
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42403388023376465,
      "learning_rate": 0.0001480269489894129,
      "loss": 0.6557,
      "step": 1359
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38504841923713684,
      "learning_rate": 0.00014798845043310877,
      "loss": 0.691,
      "step": 1360
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.39949023723602295,
      "learning_rate": 0.00014794995187680462,
      "loss": 0.7854,
      "step": 1361
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42830222845077515,
      "learning_rate": 0.0001479114533205005,
      "loss": 0.7633,
      "step": 1362
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3392801880836487,
      "learning_rate": 0.00014787295476419637,
      "loss": 0.7135,
      "step": 1363
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.37388575077056885,
      "learning_rate": 0.0001478344562078922,
      "loss": 0.8847,
      "step": 1364
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2918330132961273,
      "learning_rate": 0.00014779595765158807,
      "loss": 0.8779,
      "step": 1365
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3693550229072571,
      "learning_rate": 0.00014775745909528394,
      "loss": 0.6318,
      "step": 1366
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.49290362000465393,
      "learning_rate": 0.0001477189605389798,
      "loss": 1.1533,
      "step": 1367
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34949061274528503,
      "learning_rate": 0.00014768046198267566,
      "loss": 0.685,
      "step": 1368
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4122130870819092,
      "learning_rate": 0.0001476419634263715,
      "loss": 0.806,
      "step": 1369
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.31010496616363525,
      "learning_rate": 0.00014760346487006738,
      "loss": 0.8315,
      "step": 1370
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.38803523778915405,
      "learning_rate": 0.00014756496631376323,
      "loss": 0.6647,
      "step": 1371
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5058902502059937,
      "learning_rate": 0.0001475264677574591,
      "loss": 0.6566,
      "step": 1372
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4917807877063751,
      "learning_rate": 0.00014748796920115498,
      "loss": 0.8042,
      "step": 1373
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4750266373157501,
      "learning_rate": 0.00014744947064485083,
      "loss": 0.7286,
      "step": 1374
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4035465121269226,
      "learning_rate": 0.00014741097208854667,
      "loss": 0.7336,
      "step": 1375
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.3939807415008545,
      "learning_rate": 0.00014737247353224255,
      "loss": 0.7624,
      "step": 1376
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4695783853530884,
      "learning_rate": 0.00014733397497593842,
      "loss": 0.8309,
      "step": 1377
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.36802953481674194,
      "learning_rate": 0.00014729547641963427,
      "loss": 0.6282,
      "step": 1378
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5804331302642822,
      "learning_rate": 0.00014725697786333012,
      "loss": 0.7663,
      "step": 1379
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45228201150894165,
      "learning_rate": 0.000147218479307026,
      "loss": 0.8354,
      "step": 1380
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36549699306488037,
      "learning_rate": 0.00014717998075072187,
      "loss": 0.771,
      "step": 1381
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3613891303539276,
      "learning_rate": 0.00014714148219441772,
      "loss": 0.9783,
      "step": 1382
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3905031383037567,
      "learning_rate": 0.00014710298363811356,
      "loss": 0.8148,
      "step": 1383
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45058301091194153,
      "learning_rate": 0.00014706448508180944,
      "loss": 0.7772,
      "step": 1384
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4114459753036499,
      "learning_rate": 0.0001470259865255053,
      "loss": 0.8144,
      "step": 1385
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.35647010803222656,
      "learning_rate": 0.00014698748796920116,
      "loss": 0.7109,
      "step": 1386
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.380900502204895,
      "learning_rate": 0.00014694898941289703,
      "loss": 0.8889,
      "step": 1387
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3947020173072815,
      "learning_rate": 0.00014691049085659288,
      "loss": 0.7986,
      "step": 1388
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4376294016838074,
      "learning_rate": 0.00014687199230028873,
      "loss": 0.7973,
      "step": 1389
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36957886815071106,
      "learning_rate": 0.0001468334937439846,
      "loss": 0.6679,
      "step": 1390
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.33011212944984436,
      "learning_rate": 0.00014679499518768048,
      "loss": 0.7851,
      "step": 1391
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.439411461353302,
      "learning_rate": 0.00014675649663137635,
      "loss": 0.8618,
      "step": 1392
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.37056806683540344,
      "learning_rate": 0.00014671799807507217,
      "loss": 0.7904,
      "step": 1393
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3330939710140228,
      "learning_rate": 0.00014667949951876805,
      "loss": 0.9421,
      "step": 1394
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3836989104747772,
      "learning_rate": 0.00014664100096246392,
      "loss": 0.7415,
      "step": 1395
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3616684079170227,
      "learning_rate": 0.00014660250240615977,
      "loss": 0.6191,
      "step": 1396
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.39104169607162476,
      "learning_rate": 0.00014656400384985564,
      "loss": 0.7924,
      "step": 1397
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3929220139980316,
      "learning_rate": 0.0001465255052935515,
      "loss": 0.6647,
      "step": 1398
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4051583707332611,
      "learning_rate": 0.00014648700673724737,
      "loss": 0.6997,
      "step": 1399
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.40521901845932007,
      "learning_rate": 0.0001464485081809432,
      "loss": 0.8465,
      "step": 1400
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3338389992713928,
      "learning_rate": 0.0001464100096246391,
      "loss": 0.8263,
      "step": 1401
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9067260026931763,
      "learning_rate": 0.00014637151106833496,
      "loss": 0.667,
      "step": 1402
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36239001154899597,
      "learning_rate": 0.0001463330125120308,
      "loss": 0.7062,
      "step": 1403
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3442286252975464,
      "learning_rate": 0.00014629451395572666,
      "loss": 0.8372,
      "step": 1404
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4096972942352295,
      "learning_rate": 0.00014625601539942253,
      "loss": 0.7832,
      "step": 1405
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4285643398761749,
      "learning_rate": 0.0001462175168431184,
      "loss": 0.7835,
      "step": 1406
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4272938072681427,
      "learning_rate": 0.00014617901828681425,
      "loss": 0.6545,
      "step": 1407
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3899366855621338,
      "learning_rate": 0.0001461405197305101,
      "loss": 0.6489,
      "step": 1408
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4704456031322479,
      "learning_rate": 0.00014610202117420598,
      "loss": 0.7336,
      "step": 1409
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.49960318207740784,
      "learning_rate": 0.00014606352261790185,
      "loss": 0.9843,
      "step": 1410
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3949795365333557,
      "learning_rate": 0.0001460250240615977,
      "loss": 0.8413,
      "step": 1411
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.397896945476532,
      "learning_rate": 0.00014598652550529354,
      "loss": 0.6761,
      "step": 1412
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4075417220592499,
      "learning_rate": 0.00014594802694898942,
      "loss": 0.7756,
      "step": 1413
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.39533472061157227,
      "learning_rate": 0.00014590952839268527,
      "loss": 0.7518,
      "step": 1414
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.39690345525741577,
      "learning_rate": 0.00014587102983638114,
      "loss": 0.7712,
      "step": 1415
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3817249834537506,
      "learning_rate": 0.00014583253128007702,
      "loss": 0.7178,
      "step": 1416
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4509667158126831,
      "learning_rate": 0.00014579403272377286,
      "loss": 0.5949,
      "step": 1417
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4072791635990143,
      "learning_rate": 0.0001457555341674687,
      "loss": 0.8177,
      "step": 1418
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4277591407299042,
      "learning_rate": 0.00014571703561116459,
      "loss": 0.6932,
      "step": 1419
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5568979382514954,
      "learning_rate": 0.00014567853705486046,
      "loss": 0.8833,
      "step": 1420
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3296930193901062,
      "learning_rate": 0.0001456400384985563,
      "loss": 0.5665,
      "step": 1421
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45492345094680786,
      "learning_rate": 0.00014560153994225215,
      "loss": 0.8541,
      "step": 1422
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.44894662499427795,
      "learning_rate": 0.00014556304138594803,
      "loss": 0.715,
      "step": 1423
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.315621018409729,
      "learning_rate": 0.0001455245428296439,
      "loss": 0.7897,
      "step": 1424
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3242446184158325,
      "learning_rate": 0.00014548604427333975,
      "loss": 0.7757,
      "step": 1425
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.42096954584121704,
      "learning_rate": 0.00014544754571703563,
      "loss": 0.5912,
      "step": 1426
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.38086050748825073,
      "learning_rate": 0.00014540904716073147,
      "loss": 0.7865,
      "step": 1427
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3793252408504486,
      "learning_rate": 0.00014537054860442735,
      "loss": 0.7235,
      "step": 1428
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4386788308620453,
      "learning_rate": 0.0001453320500481232,
      "loss": 0.6725,
      "step": 1429
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3798370659351349,
      "learning_rate": 0.00014529355149181907,
      "loss": 0.724,
      "step": 1430
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3301912546157837,
      "learning_rate": 0.00014525505293551494,
      "loss": 0.793,
      "step": 1431
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.40447521209716797,
      "learning_rate": 0.0001452165543792108,
      "loss": 0.9264,
      "step": 1432
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.31495293974876404,
      "learning_rate": 0.00014517805582290664,
      "loss": 0.7181,
      "step": 1433
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38305938243865967,
      "learning_rate": 0.0001451395572666025,
      "loss": 0.7778,
      "step": 1434
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4211389124393463,
      "learning_rate": 0.0001451010587102984,
      "loss": 0.7262,
      "step": 1435
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38681021332740784,
      "learning_rate": 0.00014506256015399424,
      "loss": 0.7883,
      "step": 1436
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4423278272151947,
      "learning_rate": 0.00014502406159769008,
      "loss": 0.6095,
      "step": 1437
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4545987546443939,
      "learning_rate": 0.00014498556304138596,
      "loss": 0.9278,
      "step": 1438
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.36197930574417114,
      "learning_rate": 0.00014494706448508183,
      "loss": 0.8498,
      "step": 1439
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.31141743063926697,
      "learning_rate": 0.00014490856592877768,
      "loss": 0.7077,
      "step": 1440
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4672178626060486,
      "learning_rate": 0.00014487006737247355,
      "loss": 0.7634,
      "step": 1441
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37700971961021423,
      "learning_rate": 0.0001448315688161694,
      "loss": 0.6998,
      "step": 1442
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4863782823085785,
      "learning_rate": 0.00014479307025986525,
      "loss": 0.9295,
      "step": 1443
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6989641785621643,
      "learning_rate": 0.00014475457170356112,
      "loss": 0.7656,
      "step": 1444
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.42613303661346436,
      "learning_rate": 0.000144716073147257,
      "loss": 0.7561,
      "step": 1445
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3764442205429077,
      "learning_rate": 0.00014467757459095285,
      "loss": 0.903,
      "step": 1446
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4822099804878235,
      "learning_rate": 0.0001446390760346487,
      "loss": 0.8782,
      "step": 1447
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35899126529693604,
      "learning_rate": 0.00014460057747834457,
      "loss": 0.6256,
      "step": 1448
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3341224491596222,
      "learning_rate": 0.00014456207892204044,
      "loss": 0.861,
      "step": 1449
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4075356125831604,
      "learning_rate": 0.0001445235803657363,
      "loss": 0.5969,
      "step": 1450
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.348312109708786,
      "learning_rate": 0.00014448508180943214,
      "loss": 0.6692,
      "step": 1451
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38794782757759094,
      "learning_rate": 0.000144446583253128,
      "loss": 1.0655,
      "step": 1452
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4974254369735718,
      "learning_rate": 0.00014440808469682389,
      "loss": 0.7471,
      "step": 1453
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.40620991587638855,
      "learning_rate": 0.00014436958614051973,
      "loss": 0.7293,
      "step": 1454
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34577950835227966,
      "learning_rate": 0.0001443310875842156,
      "loss": 0.8827,
      "step": 1455
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.41349712014198303,
      "learning_rate": 0.00014429258902791145,
      "loss": 0.807,
      "step": 1456
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4491455554962158,
      "learning_rate": 0.00014425409047160733,
      "loss": 0.7327,
      "step": 1457
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.38804686069488525,
      "learning_rate": 0.00014421559191530318,
      "loss": 0.8029,
      "step": 1458
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4248674809932709,
      "learning_rate": 0.00014417709335899905,
      "loss": 0.6416,
      "step": 1459
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.39156201481819153,
      "learning_rate": 0.00014413859480269493,
      "loss": 0.6094,
      "step": 1460
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37789207696914673,
      "learning_rate": 0.00014410009624639075,
      "loss": 0.7831,
      "step": 1461
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34010049700737,
      "learning_rate": 0.00014406159769008662,
      "loss": 0.7759,
      "step": 1462
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.45237600803375244,
      "learning_rate": 0.0001440230991337825,
      "loss": 0.7271,
      "step": 1463
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4482605755329132,
      "learning_rate": 0.00014398460057747837,
      "loss": 0.5984,
      "step": 1464
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4071075916290283,
      "learning_rate": 0.00014394610202117422,
      "loss": 0.8859,
      "step": 1465
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3312879800796509,
      "learning_rate": 0.00014390760346487006,
      "loss": 0.6294,
      "step": 1466
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.36655864119529724,
      "learning_rate": 0.00014386910490856594,
      "loss": 0.7265,
      "step": 1467
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4301626980304718,
      "learning_rate": 0.0001438306063522618,
      "loss": 0.5964,
      "step": 1468
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4448874890804291,
      "learning_rate": 0.00014379210779595766,
      "loss": 0.8078,
      "step": 1469
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4087071418762207,
      "learning_rate": 0.00014375360923965354,
      "loss": 0.7209,
      "step": 1470
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3637138307094574,
      "learning_rate": 0.00014371511068334938,
      "loss": 0.6961,
      "step": 1471
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4455239772796631,
      "learning_rate": 0.00014367661212704523,
      "loss": 0.8222,
      "step": 1472
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.44182777404785156,
      "learning_rate": 0.0001436381135707411,
      "loss": 0.8756,
      "step": 1473
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3474278151988983,
      "learning_rate": 0.00014359961501443698,
      "loss": 0.8,
      "step": 1474
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35048046708106995,
      "learning_rate": 0.00014356111645813283,
      "loss": 0.7333,
      "step": 1475
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3475911617279053,
      "learning_rate": 0.00014352261790182867,
      "loss": 0.7226,
      "step": 1476
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.47619014978408813,
      "learning_rate": 0.00014348411934552455,
      "loss": 0.8568,
      "step": 1477
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4496539533138275,
      "learning_rate": 0.00014344562078922042,
      "loss": 0.8339,
      "step": 1478
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.37419551610946655,
      "learning_rate": 0.00014340712223291627,
      "loss": 0.7501,
      "step": 1479
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.41199633479118347,
      "learning_rate": 0.00014336862367661212,
      "loss": 0.8488,
      "step": 1480
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35677751898765564,
      "learning_rate": 0.000143330125120308,
      "loss": 0.8064,
      "step": 1481
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4203978180885315,
      "learning_rate": 0.00014329162656400387,
      "loss": 0.7048,
      "step": 1482
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3763902485370636,
      "learning_rate": 0.00014325312800769971,
      "loss": 0.8048,
      "step": 1483
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4642752707004547,
      "learning_rate": 0.0001432146294513956,
      "loss": 0.7182,
      "step": 1484
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.46929505467414856,
      "learning_rate": 0.00014317613089509144,
      "loss": 0.964,
      "step": 1485
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.421288400888443,
      "learning_rate": 0.00014313763233878728,
      "loss": 0.8306,
      "step": 1486
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4062874913215637,
      "learning_rate": 0.00014309913378248316,
      "loss": 0.5158,
      "step": 1487
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.36967363953590393,
      "learning_rate": 0.00014306063522617903,
      "loss": 0.5516,
      "step": 1488
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.30587831139564514,
      "learning_rate": 0.0001430221366698749,
      "loss": 0.7265,
      "step": 1489
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4581137001514435,
      "learning_rate": 0.00014298363811357073,
      "loss": 0.7567,
      "step": 1490
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40735504031181335,
      "learning_rate": 0.0001429451395572666,
      "loss": 0.7432,
      "step": 1491
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4151352643966675,
      "learning_rate": 0.00014290664100096248,
      "loss": 0.5734,
      "step": 1492
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.35428139567375183,
      "learning_rate": 0.00014286814244465832,
      "loss": 0.8179,
      "step": 1493
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3373424708843231,
      "learning_rate": 0.0001428296438883542,
      "loss": 0.9254,
      "step": 1494
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5742853879928589,
      "learning_rate": 0.00014279114533205005,
      "loss": 0.7709,
      "step": 1495
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4647940695285797,
      "learning_rate": 0.00014275264677574592,
      "loss": 0.6927,
      "step": 1496
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3951655328273773,
      "learning_rate": 0.00014271414821944177,
      "loss": 0.6119,
      "step": 1497
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.33660322427749634,
      "learning_rate": 0.00014267564966313764,
      "loss": 0.5598,
      "step": 1498
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.44055283069610596,
      "learning_rate": 0.00014263715110683352,
      "loss": 0.7511,
      "step": 1499
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3654673099517822,
      "learning_rate": 0.00014259865255052936,
      "loss": 0.7278,
      "step": 1500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.41724953055381775,
      "learning_rate": 0.0001425601539942252,
      "loss": 0.7196,
      "step": 1501
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4162159860134125,
      "learning_rate": 0.0001425216554379211,
      "loss": 0.8592,
      "step": 1502
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4276358187198639,
      "learning_rate": 0.00014248315688161696,
      "loss": 0.7127,
      "step": 1503
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3896994888782501,
      "learning_rate": 0.0001424446583253128,
      "loss": 0.7715,
      "step": 1504
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3976505994796753,
      "learning_rate": 0.00014240615976900866,
      "loss": 0.5733,
      "step": 1505
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.48588672280311584,
      "learning_rate": 0.00014236766121270453,
      "loss": 0.7738,
      "step": 1506
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.36408373713493347,
      "learning_rate": 0.0001423291626564004,
      "loss": 0.6836,
      "step": 1507
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.37173113226890564,
      "learning_rate": 0.00014229066410009625,
      "loss": 0.4156,
      "step": 1508
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3982970118522644,
      "learning_rate": 0.0001422521655437921,
      "loss": 0.6794,
      "step": 1509
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40614432096481323,
      "learning_rate": 0.00014221366698748797,
      "loss": 0.8574,
      "step": 1510
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5904964804649353,
      "learning_rate": 0.00014217516843118385,
      "loss": 0.6801,
      "step": 1511
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3360234200954437,
      "learning_rate": 0.0001421366698748797,
      "loss": 0.7951,
      "step": 1512
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4758772552013397,
      "learning_rate": 0.00014209817131857557,
      "loss": 0.5487,
      "step": 1513
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6033499836921692,
      "learning_rate": 0.00014205967276227142,
      "loss": 0.6944,
      "step": 1514
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3756484091281891,
      "learning_rate": 0.00014202117420596727,
      "loss": 0.7468,
      "step": 1515
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.44715380668640137,
      "learning_rate": 0.00014198267564966314,
      "loss": 0.8043,
      "step": 1516
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.39437007904052734,
      "learning_rate": 0.00014194417709335902,
      "loss": 0.6732,
      "step": 1517
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.40290215611457825,
      "learning_rate": 0.00014190567853705486,
      "loss": 0.9011,
      "step": 1518
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4189807176589966,
      "learning_rate": 0.0001418671799807507,
      "loss": 0.6499,
      "step": 1519
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.44964954257011414,
      "learning_rate": 0.00014182868142444658,
      "loss": 0.9259,
      "step": 1520
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.41791167855262756,
      "learning_rate": 0.00014179018286814246,
      "loss": 0.7014,
      "step": 1521
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.35916003584861755,
      "learning_rate": 0.0001417516843118383,
      "loss": 0.6969,
      "step": 1522
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4154624342918396,
      "learning_rate": 0.00014171318575553418,
      "loss": 0.7409,
      "step": 1523
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4520215690135956,
      "learning_rate": 0.00014167468719923003,
      "loss": 0.7235,
      "step": 1524
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.37761420011520386,
      "learning_rate": 0.0001416361886429259,
      "loss": 0.7625,
      "step": 1525
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.36252060532569885,
      "learning_rate": 0.00014159769008662175,
      "loss": 0.8218,
      "step": 1526
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.369446724653244,
      "learning_rate": 0.00014155919153031762,
      "loss": 0.9081,
      "step": 1527
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4098937213420868,
      "learning_rate": 0.0001415206929740135,
      "loss": 0.5824,
      "step": 1528
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3583468198776245,
      "learning_rate": 0.00014148219441770935,
      "loss": 0.5531,
      "step": 1529
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.45929133892059326,
      "learning_rate": 0.0001414436958614052,
      "loss": 0.7474,
      "step": 1530
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3951960504055023,
      "learning_rate": 0.00014140519730510107,
      "loss": 0.705,
      "step": 1531
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4227710962295532,
      "learning_rate": 0.00014136669874879694,
      "loss": 0.6957,
      "step": 1532
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4815373122692108,
      "learning_rate": 0.0001413282001924928,
      "loss": 0.9581,
      "step": 1533
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.3978879749774933,
      "learning_rate": 0.00014128970163618864,
      "loss": 0.7452,
      "step": 1534
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.37745559215545654,
      "learning_rate": 0.0001412512030798845,
      "loss": 0.6166,
      "step": 1535
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3817947804927826,
      "learning_rate": 0.0001412127045235804,
      "loss": 0.8564,
      "step": 1536
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.35810956358909607,
      "learning_rate": 0.00014117420596727623,
      "loss": 0.7771,
      "step": 1537
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3649432957172394,
      "learning_rate": 0.00014113570741097208,
      "loss": 0.8107,
      "step": 1538
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4325377941131592,
      "learning_rate": 0.00014109720885466796,
      "loss": 0.8919,
      "step": 1539
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3856835961341858,
      "learning_rate": 0.0001410587102983638,
      "loss": 0.7702,
      "step": 1540
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.39901483058929443,
      "learning_rate": 0.00014102021174205968,
      "loss": 0.8541,
      "step": 1541
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4366486966609955,
      "learning_rate": 0.00014098171318575555,
      "loss": 0.6337,
      "step": 1542
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.34462934732437134,
      "learning_rate": 0.0001409432146294514,
      "loss": 0.7409,
      "step": 1543
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4649198651313782,
      "learning_rate": 0.00014090471607314725,
      "loss": 0.7314,
      "step": 1544
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4359591603279114,
      "learning_rate": 0.00014086621751684312,
      "loss": 0.6783,
      "step": 1545
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.34206679463386536,
      "learning_rate": 0.000140827718960539,
      "loss": 0.575,
      "step": 1546
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3956718444824219,
      "learning_rate": 0.00014078922040423484,
      "loss": 0.7121,
      "step": 1547
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4198899269104004,
      "learning_rate": 0.0001407507218479307,
      "loss": 0.6773,
      "step": 1548
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3591337502002716,
      "learning_rate": 0.00014071222329162657,
      "loss": 0.7062,
      "step": 1549
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.389431357383728,
      "learning_rate": 0.00014067372473532244,
      "loss": 0.6872,
      "step": 1550
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3773740828037262,
      "learning_rate": 0.0001406352261790183,
      "loss": 0.642,
      "step": 1551
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.41725844144821167,
      "learning_rate": 0.00014059672762271416,
      "loss": 0.7525,
      "step": 1552
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40896517038345337,
      "learning_rate": 0.00014055822906641,
      "loss": 0.699,
      "step": 1553
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38491711020469666,
      "learning_rate": 0.00014051973051010588,
      "loss": 0.8159,
      "step": 1554
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.46520179510116577,
      "learning_rate": 0.00014048123195380173,
      "loss": 0.8423,
      "step": 1555
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.45521703362464905,
      "learning_rate": 0.0001404427333974976,
      "loss": 0.6166,
      "step": 1556
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3531140983104706,
      "learning_rate": 0.00014040423484119348,
      "loss": 0.9282,
      "step": 1557
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3878195285797119,
      "learning_rate": 0.00014036573628488933,
      "loss": 0.9745,
      "step": 1558
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3718041181564331,
      "learning_rate": 0.00014032723772858518,
      "loss": 0.6256,
      "step": 1559
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40025416016578674,
      "learning_rate": 0.00014028873917228105,
      "loss": 0.8713,
      "step": 1560
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3893404006958008,
      "learning_rate": 0.00014025024061597693,
      "loss": 0.7639,
      "step": 1561
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3467596173286438,
      "learning_rate": 0.00014021174205967277,
      "loss": 0.8959,
      "step": 1562
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.37525826692581177,
      "learning_rate": 0.00014017324350336862,
      "loss": 0.7342,
      "step": 1563
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40908414125442505,
      "learning_rate": 0.0001401347449470645,
      "loss": 0.7127,
      "step": 1564
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.42671966552734375,
      "learning_rate": 0.00014009624639076034,
      "loss": 0.6568,
      "step": 1565
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4422747492790222,
      "learning_rate": 0.00014005774783445622,
      "loss": 0.6942,
      "step": 1566
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4033370316028595,
      "learning_rate": 0.0001400192492781521,
      "loss": 0.7971,
      "step": 1567
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.40380024909973145,
      "learning_rate": 0.00013998075072184794,
      "loss": 0.7051,
      "step": 1568
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4109905958175659,
      "learning_rate": 0.00013994225216554379,
      "loss": 0.702,
      "step": 1569
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.33700740337371826,
      "learning_rate": 0.00013990375360923966,
      "loss": 0.7846,
      "step": 1570
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38873425126075745,
      "learning_rate": 0.00013986525505293554,
      "loss": 0.7136,
      "step": 1571
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3607983887195587,
      "learning_rate": 0.00013982675649663138,
      "loss": 0.7545,
      "step": 1572
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4194868206977844,
      "learning_rate": 0.00013978825794032723,
      "loss": 0.7186,
      "step": 1573
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.318489134311676,
      "learning_rate": 0.0001397497593840231,
      "loss": 0.6699,
      "step": 1574
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.33481407165527344,
      "learning_rate": 0.00013971126082771898,
      "loss": 0.8222,
      "step": 1575
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38473716378211975,
      "learning_rate": 0.00013967276227141483,
      "loss": 0.6969,
      "step": 1576
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5189446806907654,
      "learning_rate": 0.00013963426371511067,
      "loss": 0.7413,
      "step": 1577
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3741241991519928,
      "learning_rate": 0.00013959576515880655,
      "loss": 0.7479,
      "step": 1578
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3304726481437683,
      "learning_rate": 0.00013955726660250242,
      "loss": 0.8581,
      "step": 1579
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3825192153453827,
      "learning_rate": 0.00013951876804619827,
      "loss": 0.7555,
      "step": 1580
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4167601466178894,
      "learning_rate": 0.00013948026948989414,
      "loss": 0.5336,
      "step": 1581
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.41052860021591187,
      "learning_rate": 0.00013944177093359,
      "loss": 0.7376,
      "step": 1582
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4525925815105438,
      "learning_rate": 0.00013940327237728587,
      "loss": 0.6835,
      "step": 1583
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.35832083225250244,
      "learning_rate": 0.00013936477382098171,
      "loss": 0.7489,
      "step": 1584
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.42001453042030334,
      "learning_rate": 0.0001393262752646776,
      "loss": 0.6521,
      "step": 1585
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4241701066493988,
      "learning_rate": 0.00013928777670837346,
      "loss": 0.7484,
      "step": 1586
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4400090277194977,
      "learning_rate": 0.00013924927815206928,
      "loss": 0.6373,
      "step": 1587
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3897201418876648,
      "learning_rate": 0.00013921077959576516,
      "loss": 0.6789,
      "step": 1588
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.37175726890563965,
      "learning_rate": 0.00013917228103946103,
      "loss": 0.7265,
      "step": 1589
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.42509186267852783,
      "learning_rate": 0.0001391337824831569,
      "loss": 0.6711,
      "step": 1590
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.447003573179245,
      "learning_rate": 0.00013909528392685275,
      "loss": 0.7685,
      "step": 1591
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.39999517798423767,
      "learning_rate": 0.0001390567853705486,
      "loss": 0.823,
      "step": 1592
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.45550888776779175,
      "learning_rate": 0.00013901828681424448,
      "loss": 0.9152,
      "step": 1593
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.48399633169174194,
      "learning_rate": 0.00013897978825794032,
      "loss": 0.8666,
      "step": 1594
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4638347625732422,
      "learning_rate": 0.0001389412897016362,
      "loss": 0.8066,
      "step": 1595
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36556369066238403,
      "learning_rate": 0.00013890279114533207,
      "loss": 0.64,
      "step": 1596
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4849199056625366,
      "learning_rate": 0.00013886429258902792,
      "loss": 0.7804,
      "step": 1597
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3687591254711151,
      "learning_rate": 0.00013882579403272377,
      "loss": 0.7187,
      "step": 1598
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.37151700258255005,
      "learning_rate": 0.00013878729547641964,
      "loss": 0.7048,
      "step": 1599
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3591022193431854,
      "learning_rate": 0.00013874879692011552,
      "loss": 0.6494,
      "step": 1600
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3878302276134491,
      "learning_rate": 0.00013871029836381136,
      "loss": 0.7105,
      "step": 1601
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.38657182455062866,
      "learning_rate": 0.0001386717998075072,
      "loss": 0.7981,
      "step": 1602
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3327498435974121,
      "learning_rate": 0.00013863330125120309,
      "loss": 0.8506,
      "step": 1603
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36444342136383057,
      "learning_rate": 0.00013859480269489896,
      "loss": 0.7725,
      "step": 1604
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4166974723339081,
      "learning_rate": 0.0001385563041385948,
      "loss": 0.7432,
      "step": 1605
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.44543522596359253,
      "learning_rate": 0.00013851780558229066,
      "loss": 0.6599,
      "step": 1606
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.43636053800582886,
      "learning_rate": 0.00013847930702598653,
      "loss": 0.8209,
      "step": 1607
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8520939946174622,
      "learning_rate": 0.0001384408084696824,
      "loss": 0.6589,
      "step": 1608
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4298171401023865,
      "learning_rate": 0.00013840230991337825,
      "loss": 0.7514,
      "step": 1609
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4358583986759186,
      "learning_rate": 0.00013836381135707413,
      "loss": 0.6972,
      "step": 1610
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4079870581626892,
      "learning_rate": 0.00013832531280076997,
      "loss": 0.8511,
      "step": 1611
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3052898347377777,
      "learning_rate": 0.00013828681424446582,
      "loss": 0.8268,
      "step": 1612
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.348302960395813,
      "learning_rate": 0.0001382483156881617,
      "loss": 0.7085,
      "step": 1613
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3869578242301941,
      "learning_rate": 0.00013820981713185757,
      "loss": 0.8189,
      "step": 1614
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4317513108253479,
      "learning_rate": 0.00013817131857555345,
      "loss": 0.8862,
      "step": 1615
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36576372385025024,
      "learning_rate": 0.00013813282001924927,
      "loss": 0.8001,
      "step": 1616
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4591612219810486,
      "learning_rate": 0.00013809432146294514,
      "loss": 0.7567,
      "step": 1617
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4079863727092743,
      "learning_rate": 0.00013805582290664101,
      "loss": 0.8334,
      "step": 1618
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.49138230085372925,
      "learning_rate": 0.00013801732435033686,
      "loss": 0.7302,
      "step": 1619
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3142023980617523,
      "learning_rate": 0.00013797882579403274,
      "loss": 0.645,
      "step": 1620
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.36179131269454956,
      "learning_rate": 0.00013794032723772858,
      "loss": 0.7214,
      "step": 1621
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4722699224948883,
      "learning_rate": 0.00013790182868142446,
      "loss": 0.6476,
      "step": 1622
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.45480406284332275,
      "learning_rate": 0.0001378633301251203,
      "loss": 0.7992,
      "step": 1623
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4382063150405884,
      "learning_rate": 0.00013782483156881618,
      "loss": 0.7281,
      "step": 1624
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4131746292114258,
      "learning_rate": 0.00013778633301251205,
      "loss": 0.7312,
      "step": 1625
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.40822479128837585,
      "learning_rate": 0.0001377478344562079,
      "loss": 0.7642,
      "step": 1626
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.43784642219543457,
      "learning_rate": 0.00013770933589990375,
      "loss": 0.8063,
      "step": 1627
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3665948808193207,
      "learning_rate": 0.00013767083734359962,
      "loss": 0.7785,
      "step": 1628
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.31331223249435425,
      "learning_rate": 0.0001376323387872955,
      "loss": 0.8009,
      "step": 1629
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3922223150730133,
      "learning_rate": 0.00013759384023099135,
      "loss": 0.736,
      "step": 1630
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3547876179218292,
      "learning_rate": 0.0001375553416746872,
      "loss": 0.7224,
      "step": 1631
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.34876400232315063,
      "learning_rate": 0.00013751684311838307,
      "loss": 0.7778,
      "step": 1632
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.43214476108551025,
      "learning_rate": 0.00013747834456207894,
      "loss": 0.7012,
      "step": 1633
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3520866930484772,
      "learning_rate": 0.0001374398460057748,
      "loss": 0.7684,
      "step": 1634
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.450449138879776,
      "learning_rate": 0.00013740134744947064,
      "loss": 0.842,
      "step": 1635
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4036320149898529,
      "learning_rate": 0.0001373628488931665,
      "loss": 0.8512,
      "step": 1636
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.39650535583496094,
      "learning_rate": 0.00013732435033686236,
      "loss": 0.7149,
      "step": 1637
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3623286783695221,
      "learning_rate": 0.00013728585178055823,
      "loss": 0.7136,
      "step": 1638
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4080308973789215,
      "learning_rate": 0.0001372473532242541,
      "loss": 0.6199,
      "step": 1639
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3572975993156433,
      "learning_rate": 0.00013720885466794996,
      "loss": 0.5816,
      "step": 1640
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37198346853256226,
      "learning_rate": 0.0001371703561116458,
      "loss": 0.7439,
      "step": 1641
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3775167465209961,
      "learning_rate": 0.00013713185755534168,
      "loss": 0.8065,
      "step": 1642
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3811580240726471,
      "learning_rate": 0.00013709335899903755,
      "loss": 0.7252,
      "step": 1643
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.40203985571861267,
      "learning_rate": 0.0001370548604427334,
      "loss": 0.7031,
      "step": 1644
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39736074209213257,
      "learning_rate": 0.00013701636188642925,
      "loss": 0.7453,
      "step": 1645
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.43544846773147583,
      "learning_rate": 0.00013697786333012512,
      "loss": 0.768,
      "step": 1646
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44889792799949646,
      "learning_rate": 0.000136939364773821,
      "loss": 0.7432,
      "step": 1647
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4444977045059204,
      "learning_rate": 0.00013690086621751684,
      "loss": 0.7652,
      "step": 1648
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.49672436714172363,
      "learning_rate": 0.00013686236766121272,
      "loss": 0.5914,
      "step": 1649
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39710909128189087,
      "learning_rate": 0.00013682386910490857,
      "loss": 0.6395,
      "step": 1650
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3436446189880371,
      "learning_rate": 0.00013678537054860444,
      "loss": 0.7844,
      "step": 1651
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3933045566082001,
      "learning_rate": 0.0001367468719923003,
      "loss": 0.7613,
      "step": 1652
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37771138548851013,
      "learning_rate": 0.00013670837343599616,
      "loss": 0.9281,
      "step": 1653
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.48370689153671265,
      "learning_rate": 0.00013666987487969204,
      "loss": 0.9259,
      "step": 1654
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.38230767846107483,
      "learning_rate": 0.00013663137632338788,
      "loss": 0.6707,
      "step": 1655
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.38562604784965515,
      "learning_rate": 0.00013659287776708373,
      "loss": 0.8062,
      "step": 1656
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37056785821914673,
      "learning_rate": 0.0001365543792107796,
      "loss": 0.7078,
      "step": 1657
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3348903954029083,
      "learning_rate": 0.00013651588065447548,
      "loss": 0.7176,
      "step": 1658
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42055249214172363,
      "learning_rate": 0.00013647738209817133,
      "loss": 0.6816,
      "step": 1659
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4233472943305969,
      "learning_rate": 0.00013643888354186718,
      "loss": 0.8808,
      "step": 1660
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.36042603850364685,
      "learning_rate": 0.00013640038498556305,
      "loss": 0.6623,
      "step": 1661
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4092336595058441,
      "learning_rate": 0.00013636188642925892,
      "loss": 0.7483,
      "step": 1662
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.377438485622406,
      "learning_rate": 0.00013632338787295477,
      "loss": 0.8286,
      "step": 1663
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.38256514072418213,
      "learning_rate": 0.00013628488931665062,
      "loss": 0.6785,
      "step": 1664
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42399805784225464,
      "learning_rate": 0.0001362463907603465,
      "loss": 0.6691,
      "step": 1665
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39225995540618896,
      "learning_rate": 0.00013620789220404234,
      "loss": 0.7567,
      "step": 1666
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4014180600643158,
      "learning_rate": 0.00013616939364773822,
      "loss": 0.7883,
      "step": 1667
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4168412387371063,
      "learning_rate": 0.0001361308950914341,
      "loss": 0.9683,
      "step": 1668
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4391365051269531,
      "learning_rate": 0.00013609239653512994,
      "loss": 0.739,
      "step": 1669
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4245762825012207,
      "learning_rate": 0.00013605389797882579,
      "loss": 0.8638,
      "step": 1670
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.48266762495040894,
      "learning_rate": 0.00013601539942252166,
      "loss": 0.8876,
      "step": 1671
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3626275062561035,
      "learning_rate": 0.00013597690086621753,
      "loss": 0.7757,
      "step": 1672
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.46704331040382385,
      "learning_rate": 0.00013593840230991338,
      "loss": 0.7822,
      "step": 1673
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3691776692867279,
      "learning_rate": 0.00013589990375360923,
      "loss": 0.7527,
      "step": 1674
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.40746834874153137,
      "learning_rate": 0.0001358614051973051,
      "loss": 0.6621,
      "step": 1675
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.37663254141807556,
      "learning_rate": 0.00013582290664100098,
      "loss": 0.6908,
      "step": 1676
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.45758894085884094,
      "learning_rate": 0.00013578440808469683,
      "loss": 0.8669,
      "step": 1677
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3463422358036041,
      "learning_rate": 0.0001357459095283927,
      "loss": 0.5698,
      "step": 1678
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3434551954269409,
      "learning_rate": 0.00013570741097208855,
      "loss": 0.6038,
      "step": 1679
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.39206233620643616,
      "learning_rate": 0.00013566891241578442,
      "loss": 0.6378,
      "step": 1680
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3318312168121338,
      "learning_rate": 0.00013563041385948027,
      "loss": 0.8374,
      "step": 1681
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.32353538274765015,
      "learning_rate": 0.00013559191530317614,
      "loss": 0.8738,
      "step": 1682
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.36158666014671326,
      "learning_rate": 0.00013555341674687202,
      "loss": 0.7062,
      "step": 1683
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.41721609234809875,
      "learning_rate": 0.00013551491819056784,
      "loss": 0.8962,
      "step": 1684
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.35123276710510254,
      "learning_rate": 0.00013547641963426371,
      "loss": 0.8678,
      "step": 1685
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3866021931171417,
      "learning_rate": 0.0001354379210779596,
      "loss": 0.5729,
      "step": 1686
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3580552935600281,
      "learning_rate": 0.00013539942252165546,
      "loss": 0.8675,
      "step": 1687
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3900417685508728,
      "learning_rate": 0.0001353609239653513,
      "loss": 0.7664,
      "step": 1688
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3078082501888275,
      "learning_rate": 0.00013532242540904716,
      "loss": 0.8107,
      "step": 1689
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3757234513759613,
      "learning_rate": 0.00013528392685274303,
      "loss": 0.7898,
      "step": 1690
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39455416798591614,
      "learning_rate": 0.00013524542829643888,
      "loss": 0.7326,
      "step": 1691
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38055068254470825,
      "learning_rate": 0.00013520692974013475,
      "loss": 0.6816,
      "step": 1692
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4642220735549927,
      "learning_rate": 0.00013516843118383063,
      "loss": 0.7931,
      "step": 1693
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.45477095246315,
      "learning_rate": 0.00013512993262752648,
      "loss": 0.8108,
      "step": 1694
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3501637279987335,
      "learning_rate": 0.00013509143407122232,
      "loss": 0.6283,
      "step": 1695
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.2790762484073639,
      "learning_rate": 0.0001350529355149182,
      "loss": 0.9388,
      "step": 1696
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4281442165374756,
      "learning_rate": 0.00013501443695861407,
      "loss": 0.6854,
      "step": 1697
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3663672208786011,
      "learning_rate": 0.00013497593840230992,
      "loss": 0.7257,
      "step": 1698
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.42238500714302063,
      "learning_rate": 0.00013493743984600577,
      "loss": 0.7815,
      "step": 1699
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.361511766910553,
      "learning_rate": 0.00013489894128970164,
      "loss": 0.7914,
      "step": 1700
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.44551175832748413,
      "learning_rate": 0.00013486044273339752,
      "loss": 0.5944,
      "step": 1701
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.322598397731781,
      "learning_rate": 0.00013482194417709336,
      "loss": 0.7393,
      "step": 1702
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.44727233052253723,
      "learning_rate": 0.0001347834456207892,
      "loss": 0.7253,
      "step": 1703
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47983914613723755,
      "learning_rate": 0.00013474494706448509,
      "loss": 0.6959,
      "step": 1704
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.42858752608299255,
      "learning_rate": 0.00013470644850818096,
      "loss": 0.6486,
      "step": 1705
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4047139286994934,
      "learning_rate": 0.0001346679499518768,
      "loss": 0.615,
      "step": 1706
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.426738440990448,
      "learning_rate": 0.00013462945139557268,
      "loss": 0.9417,
      "step": 1707
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3421737849712372,
      "learning_rate": 0.00013459095283926853,
      "loss": 0.8984,
      "step": 1708
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.37582096457481384,
      "learning_rate": 0.0001345524542829644,
      "loss": 0.629,
      "step": 1709
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4053765833377838,
      "learning_rate": 0.00013451395572666025,
      "loss": 0.7527,
      "step": 1710
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4354304373264313,
      "learning_rate": 0.00013447545717035613,
      "loss": 0.8466,
      "step": 1711
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38102301955223083,
      "learning_rate": 0.000134436958614052,
      "loss": 0.8259,
      "step": 1712
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4141985774040222,
      "learning_rate": 0.00013439846005774782,
      "loss": 0.7802,
      "step": 1713
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4680878818035126,
      "learning_rate": 0.0001343599615014437,
      "loss": 0.7206,
      "step": 1714
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38156476616859436,
      "learning_rate": 0.00013432146294513957,
      "loss": 0.8254,
      "step": 1715
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3689975440502167,
      "learning_rate": 0.00013428296438883542,
      "loss": 0.704,
      "step": 1716
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.33749666810035706,
      "learning_rate": 0.0001342444658325313,
      "loss": 0.8921,
      "step": 1717
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4280622899532318,
      "learning_rate": 0.00013420596727622714,
      "loss": 0.7264,
      "step": 1718
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4112262427806854,
      "learning_rate": 0.00013416746871992301,
      "loss": 0.8334,
      "step": 1719
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.36519521474838257,
      "learning_rate": 0.00013412897016361886,
      "loss": 0.7789,
      "step": 1720
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4080885648727417,
      "learning_rate": 0.00013409047160731474,
      "loss": 0.8359,
      "step": 1721
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3179738223552704,
      "learning_rate": 0.0001340519730510106,
      "loss": 0.7983,
      "step": 1722
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.38401511311531067,
      "learning_rate": 0.00013401347449470646,
      "loss": 0.6919,
      "step": 1723
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39707523584365845,
      "learning_rate": 0.0001339749759384023,
      "loss": 0.7107,
      "step": 1724
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3825884461402893,
      "learning_rate": 0.00013393647738209818,
      "loss": 0.6284,
      "step": 1725
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3741552233695984,
      "learning_rate": 0.00013389797882579405,
      "loss": 0.5956,
      "step": 1726
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3510701656341553,
      "learning_rate": 0.0001338594802694899,
      "loss": 0.7413,
      "step": 1727
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47350308299064636,
      "learning_rate": 0.00013382098171318575,
      "loss": 0.6876,
      "step": 1728
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3953753113746643,
      "learning_rate": 0.00013378248315688162,
      "loss": 0.8057,
      "step": 1729
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5187188982963562,
      "learning_rate": 0.0001337439846005775,
      "loss": 1.0065,
      "step": 1730
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4302092492580414,
      "learning_rate": 0.00013370548604427335,
      "loss": 0.6424,
      "step": 1731
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3670450747013092,
      "learning_rate": 0.0001336669874879692,
      "loss": 0.7948,
      "step": 1732
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.46210038661956787,
      "learning_rate": 0.00013362848893166507,
      "loss": 0.8077,
      "step": 1733
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4794730842113495,
      "learning_rate": 0.00013358999037536094,
      "loss": 0.8104,
      "step": 1734
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3713834583759308,
      "learning_rate": 0.0001335514918190568,
      "loss": 0.677,
      "step": 1735
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.428555965423584,
      "learning_rate": 0.00013351299326275266,
      "loss": 0.7721,
      "step": 1736
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4205116927623749,
      "learning_rate": 0.0001334744947064485,
      "loss": 0.8177,
      "step": 1737
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.32891568541526794,
      "learning_rate": 0.00013343599615014436,
      "loss": 0.9035,
      "step": 1738
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.331065833568573,
      "learning_rate": 0.00013339749759384023,
      "loss": 0.7236,
      "step": 1739
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.41253137588500977,
      "learning_rate": 0.0001333589990375361,
      "loss": 0.8883,
      "step": 1740
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.35336944460868835,
      "learning_rate": 0.00013332050048123198,
      "loss": 0.7508,
      "step": 1741
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39538848400115967,
      "learning_rate": 0.0001332820019249278,
      "loss": 0.8261,
      "step": 1742
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39146655797958374,
      "learning_rate": 0.00013324350336862368,
      "loss": 0.8598,
      "step": 1743
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4060017168521881,
      "learning_rate": 0.00013320500481231955,
      "loss": 0.5726,
      "step": 1744
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.489631712436676,
      "learning_rate": 0.0001331665062560154,
      "loss": 0.6755,
      "step": 1745
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.466908723115921,
      "learning_rate": 0.00013312800769971127,
      "loss": 0.8257,
      "step": 1746
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3647698163986206,
      "learning_rate": 0.00013308950914340712,
      "loss": 0.9009,
      "step": 1747
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4265061914920807,
      "learning_rate": 0.000133051010587103,
      "loss": 0.8946,
      "step": 1748
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4608971178531647,
      "learning_rate": 0.00013301251203079884,
      "loss": 0.7449,
      "step": 1749
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4591614902019501,
      "learning_rate": 0.00013297401347449472,
      "loss": 0.8035,
      "step": 1750
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4120148718357086,
      "learning_rate": 0.0001329355149181906,
      "loss": 0.8999,
      "step": 1751
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.36881500482559204,
      "learning_rate": 0.00013289701636188644,
      "loss": 0.818,
      "step": 1752
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4361303448677063,
      "learning_rate": 0.0001328585178055823,
      "loss": 0.7597,
      "step": 1753
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4416385591030121,
      "learning_rate": 0.00013282001924927816,
      "loss": 0.8448,
      "step": 1754
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3966282904148102,
      "learning_rate": 0.00013278152069297404,
      "loss": 0.6749,
      "step": 1755
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39678123593330383,
      "learning_rate": 0.00013274302213666988,
      "loss": 0.9125,
      "step": 1756
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.476730614900589,
      "learning_rate": 0.00013270452358036573,
      "loss": 0.5797,
      "step": 1757
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3988790512084961,
      "learning_rate": 0.0001326660250240616,
      "loss": 0.8358,
      "step": 1758
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.44026172161102295,
      "learning_rate": 0.00013262752646775748,
      "loss": 0.6879,
      "step": 1759
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.37759459018707275,
      "learning_rate": 0.00013258902791145333,
      "loss": 0.873,
      "step": 1760
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4016784727573395,
      "learning_rate": 0.00013255052935514918,
      "loss": 0.7861,
      "step": 1761
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39727985858917236,
      "learning_rate": 0.00013251203079884505,
      "loss": 0.6474,
      "step": 1762
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41534146666526794,
      "learning_rate": 0.0001324735322425409,
      "loss": 0.6465,
      "step": 1763
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.49826428294181824,
      "learning_rate": 0.00013243503368623677,
      "loss": 0.5081,
      "step": 1764
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.36738163232803345,
      "learning_rate": 0.00013239653512993265,
      "loss": 0.6787,
      "step": 1765
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41939955949783325,
      "learning_rate": 0.0001323580365736285,
      "loss": 0.7143,
      "step": 1766
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.35710862278938293,
      "learning_rate": 0.00013231953801732434,
      "loss": 0.7635,
      "step": 1767
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4553787112236023,
      "learning_rate": 0.00013228103946102022,
      "loss": 0.8108,
      "step": 1768
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3743007481098175,
      "learning_rate": 0.0001322425409047161,
      "loss": 0.8004,
      "step": 1769
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3668770492076874,
      "learning_rate": 0.00013220404234841194,
      "loss": 0.7373,
      "step": 1770
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4216722846031189,
      "learning_rate": 0.00013216554379210778,
      "loss": 0.6837,
      "step": 1771
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.44769206643104553,
      "learning_rate": 0.00013212704523580366,
      "loss": 0.7184,
      "step": 1772
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3925091028213501,
      "learning_rate": 0.00013208854667949953,
      "loss": 0.8648,
      "step": 1773
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.40613749623298645,
      "learning_rate": 0.00013205004812319538,
      "loss": 0.8594,
      "step": 1774
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4309766888618469,
      "learning_rate": 0.00013201154956689126,
      "loss": 0.7611,
      "step": 1775
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.38581958413124084,
      "learning_rate": 0.0001319730510105871,
      "loss": 0.8555,
      "step": 1776
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.37257885932922363,
      "learning_rate": 0.00013193455245428298,
      "loss": 0.9002,
      "step": 1777
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3504149615764618,
      "learning_rate": 0.00013189605389797883,
      "loss": 0.8699,
      "step": 1778
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4043499529361725,
      "learning_rate": 0.0001318575553416747,
      "loss": 0.8993,
      "step": 1779
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.35383516550064087,
      "learning_rate": 0.00013181905678537057,
      "loss": 0.7492,
      "step": 1780
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3652566373348236,
      "learning_rate": 0.00013178055822906642,
      "loss": 0.6588,
      "step": 1781
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.44949468970298767,
      "learning_rate": 0.00013174205967276227,
      "loss": 0.8642,
      "step": 1782
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3907475769519806,
      "learning_rate": 0.00013170356111645814,
      "loss": 0.8488,
      "step": 1783
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.45091649889945984,
      "learning_rate": 0.00013166506256015402,
      "loss": 0.8131,
      "step": 1784
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3817487955093384,
      "learning_rate": 0.00013162656400384987,
      "loss": 0.768,
      "step": 1785
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4341089427471161,
      "learning_rate": 0.0001315880654475457,
      "loss": 0.8932,
      "step": 1786
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4040856957435608,
      "learning_rate": 0.0001315495668912416,
      "loss": 0.8677,
      "step": 1787
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.48962685465812683,
      "learning_rate": 0.00013151106833493744,
      "loss": 0.581,
      "step": 1788
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4897845685482025,
      "learning_rate": 0.0001314725697786333,
      "loss": 0.7564,
      "step": 1789
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4242686331272125,
      "learning_rate": 0.00013143407122232916,
      "loss": 0.8015,
      "step": 1790
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4992380738258362,
      "learning_rate": 0.00013139557266602503,
      "loss": 0.7852,
      "step": 1791
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.39378622174263,
      "learning_rate": 0.00013135707410972088,
      "loss": 0.801,
      "step": 1792
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3587026596069336,
      "learning_rate": 0.00013131857555341675,
      "loss": 0.665,
      "step": 1793
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.41467753052711487,
      "learning_rate": 0.00013128007699711263,
      "loss": 0.7087,
      "step": 1794
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3516363501548767,
      "learning_rate": 0.00013124157844080848,
      "loss": 0.6985,
      "step": 1795
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4346103072166443,
      "learning_rate": 0.00013120307988450432,
      "loss": 0.6885,
      "step": 1796
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42545539140701294,
      "learning_rate": 0.0001311645813282002,
      "loss": 0.8076,
      "step": 1797
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3634584844112396,
      "learning_rate": 0.00013112608277189607,
      "loss": 0.7379,
      "step": 1798
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3166871666908264,
      "learning_rate": 0.00013108758421559192,
      "loss": 0.803,
      "step": 1799
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4216887354850769,
      "learning_rate": 0.00013104908565928777,
      "loss": 0.9611,
      "step": 1800
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.37665343284606934,
      "learning_rate": 0.00013101058710298364,
      "loss": 0.736,
      "step": 1801
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3316784203052521,
      "learning_rate": 0.00013097208854667952,
      "loss": 0.8301,
      "step": 1802
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3948574662208557,
      "learning_rate": 0.00013093358999037536,
      "loss": 0.7948,
      "step": 1803
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42535287141799927,
      "learning_rate": 0.00013089509143407124,
      "loss": 0.6082,
      "step": 1804
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45145320892333984,
      "learning_rate": 0.00013085659287776709,
      "loss": 0.8258,
      "step": 1805
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.41247326135635376,
      "learning_rate": 0.00013081809432146296,
      "loss": 0.7861,
      "step": 1806
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3567247688770294,
      "learning_rate": 0.0001307795957651588,
      "loss": 0.5375,
      "step": 1807
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.38506612181663513,
      "learning_rate": 0.00013074109720885468,
      "loss": 0.7448,
      "step": 1808
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.40983420610427856,
      "learning_rate": 0.00013070259865255056,
      "loss": 0.6629,
      "step": 1809
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3984203040599823,
      "learning_rate": 0.00013066410009624638,
      "loss": 0.6575,
      "step": 1810
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4499220550060272,
      "learning_rate": 0.00013062560153994225,
      "loss": 0.7661,
      "step": 1811
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3570815920829773,
      "learning_rate": 0.00013058710298363813,
      "loss": 0.6938,
      "step": 1812
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4945443868637085,
      "learning_rate": 0.000130548604427334,
      "loss": 0.814,
      "step": 1813
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.425142377614975,
      "learning_rate": 0.00013051010587102985,
      "loss": 0.8694,
      "step": 1814
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.35842636227607727,
      "learning_rate": 0.0001304716073147257,
      "loss": 0.8498,
      "step": 1815
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3513905107975006,
      "learning_rate": 0.00013043310875842157,
      "loss": 0.7484,
      "step": 1816
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3908533453941345,
      "learning_rate": 0.00013039461020211742,
      "loss": 0.6165,
      "step": 1817
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3497600257396698,
      "learning_rate": 0.0001303561116458133,
      "loss": 0.9604,
      "step": 1818
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.31747105717658997,
      "learning_rate": 0.00013031761308950917,
      "loss": 0.8938,
      "step": 1819
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.421970009803772,
      "learning_rate": 0.000130279114533205,
      "loss": 0.7894,
      "step": 1820
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.37083736062049866,
      "learning_rate": 0.00013024061597690086,
      "loss": 0.8704,
      "step": 1821
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4444059133529663,
      "learning_rate": 0.00013020211742059674,
      "loss": 0.8286,
      "step": 1822
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39304319024086,
      "learning_rate": 0.0001301636188642926,
      "loss": 0.6972,
      "step": 1823
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3517228066921234,
      "learning_rate": 0.00013012512030798846,
      "loss": 0.6674,
      "step": 1824
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45172977447509766,
      "learning_rate": 0.0001300866217516843,
      "loss": 0.9044,
      "step": 1825
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45259156823158264,
      "learning_rate": 0.00013004812319538018,
      "loss": 0.67,
      "step": 1826
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.40611517429351807,
      "learning_rate": 0.00013000962463907605,
      "loss": 0.7879,
      "step": 1827
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.342877060174942,
      "learning_rate": 0.0001299711260827719,
      "loss": 0.6913,
      "step": 1828
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.360265851020813,
      "learning_rate": 0.00012993262752646775,
      "loss": 0.7195,
      "step": 1829
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4196864068508148,
      "learning_rate": 0.00012989412897016362,
      "loss": 0.822,
      "step": 1830
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.36162206530570984,
      "learning_rate": 0.0001298556304138595,
      "loss": 0.7965,
      "step": 1831
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4311762750148773,
      "learning_rate": 0.00012981713185755535,
      "loss": 0.96,
      "step": 1832
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.46204665303230286,
      "learning_rate": 0.00012977863330125122,
      "loss": 0.8514,
      "step": 1833
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4710827171802521,
      "learning_rate": 0.00012974013474494707,
      "loss": 0.613,
      "step": 1834
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39967840909957886,
      "learning_rate": 0.00012970163618864291,
      "loss": 0.7719,
      "step": 1835
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4258590340614319,
      "learning_rate": 0.0001296631376323388,
      "loss": 0.6707,
      "step": 1836
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3759515583515167,
      "learning_rate": 0.00012962463907603466,
      "loss": 0.7592,
      "step": 1837
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3703937232494354,
      "learning_rate": 0.00012958614051973054,
      "loss": 0.8268,
      "step": 1838
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4929504990577698,
      "learning_rate": 0.00012954764196342636,
      "loss": 0.7373,
      "step": 1839
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3643803894519806,
      "learning_rate": 0.00012950914340712223,
      "loss": 0.773,
      "step": 1840
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4126928746700287,
      "learning_rate": 0.0001294706448508181,
      "loss": 0.8195,
      "step": 1841
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39850255846977234,
      "learning_rate": 0.00012943214629451395,
      "loss": 0.7887,
      "step": 1842
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4216155707836151,
      "learning_rate": 0.00012939364773820983,
      "loss": 0.6158,
      "step": 1843
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3541860282421112,
      "learning_rate": 0.00012935514918190568,
      "loss": 0.6684,
      "step": 1844
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.3919277489185333,
      "learning_rate": 0.00012931665062560155,
      "loss": 0.7254,
      "step": 1845
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.44354334473609924,
      "learning_rate": 0.0001292781520692974,
      "loss": 0.7323,
      "step": 1846
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3782220482826233,
      "learning_rate": 0.00012923965351299327,
      "loss": 0.9516,
      "step": 1847
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38252702355384827,
      "learning_rate": 0.00012920115495668915,
      "loss": 0.5062,
      "step": 1848
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3897949159145355,
      "learning_rate": 0.000129162656400385,
      "loss": 0.794,
      "step": 1849
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4504038989543915,
      "learning_rate": 0.00012912415784408084,
      "loss": 0.7374,
      "step": 1850
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5358611941337585,
      "learning_rate": 0.00012908565928777672,
      "loss": 0.7077,
      "step": 1851
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.37403053045272827,
      "learning_rate": 0.0001290471607314726,
      "loss": 0.9128,
      "step": 1852
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3812733590602875,
      "learning_rate": 0.00012900866217516844,
      "loss": 0.7707,
      "step": 1853
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3871363401412964,
      "learning_rate": 0.0001289701636188643,
      "loss": 0.6346,
      "step": 1854
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3475709855556488,
      "learning_rate": 0.00012893166506256016,
      "loss": 0.9545,
      "step": 1855
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.44716084003448486,
      "learning_rate": 0.00012889316650625604,
      "loss": 0.7429,
      "step": 1856
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3908954858779907,
      "learning_rate": 0.00012885466794995188,
      "loss": 0.7284,
      "step": 1857
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3515625596046448,
      "learning_rate": 0.00012881616939364773,
      "loss": 0.6963,
      "step": 1858
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3920833170413971,
      "learning_rate": 0.0001287776708373436,
      "loss": 0.681,
      "step": 1859
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3983509838581085,
      "learning_rate": 0.00012873917228103948,
      "loss": 0.8387,
      "step": 1860
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38083890080451965,
      "learning_rate": 0.00012870067372473533,
      "loss": 0.8664,
      "step": 1861
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4730418622493744,
      "learning_rate": 0.0001286621751684312,
      "loss": 0.7216,
      "step": 1862
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.39920854568481445,
      "learning_rate": 0.00012862367661212705,
      "loss": 0.7624,
      "step": 1863
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4217352867126465,
      "learning_rate": 0.0001285851780558229,
      "loss": 0.6897,
      "step": 1864
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38850855827331543,
      "learning_rate": 0.00012854667949951877,
      "loss": 0.7508,
      "step": 1865
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.43991467356681824,
      "learning_rate": 0.00012850818094321465,
      "loss": 0.8173,
      "step": 1866
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.31125056743621826,
      "learning_rate": 0.0001284696823869105,
      "loss": 0.7721,
      "step": 1867
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3797193169593811,
      "learning_rate": 0.00012843118383060634,
      "loss": 0.9471,
      "step": 1868
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4224429130554199,
      "learning_rate": 0.00012839268527430221,
      "loss": 0.6935,
      "step": 1869
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5061063170433044,
      "learning_rate": 0.0001283541867179981,
      "loss": 0.7046,
      "step": 1870
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.48780766129493713,
      "learning_rate": 0.00012831568816169394,
      "loss": 0.7875,
      "step": 1871
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4205755293369293,
      "learning_rate": 0.0001282771896053898,
      "loss": 0.5716,
      "step": 1872
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5090664625167847,
      "learning_rate": 0.00012823869104908566,
      "loss": 0.6772,
      "step": 1873
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.45707517862319946,
      "learning_rate": 0.00012820019249278153,
      "loss": 0.7296,
      "step": 1874
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.48018398880958557,
      "learning_rate": 0.00012816169393647738,
      "loss": 0.8971,
      "step": 1875
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3644025921821594,
      "learning_rate": 0.00012812319538017326,
      "loss": 0.8381,
      "step": 1876
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3494745194911957,
      "learning_rate": 0.00012808469682386913,
      "loss": 0.7066,
      "step": 1877
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.41221722960472107,
      "learning_rate": 0.00012804619826756498,
      "loss": 0.7723,
      "step": 1878
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3453875780105591,
      "learning_rate": 0.00012800769971126082,
      "loss": 0.962,
      "step": 1879
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.47477832436561584,
      "learning_rate": 0.0001279692011549567,
      "loss": 0.6965,
      "step": 1880
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.37314528226852417,
      "learning_rate": 0.00012793070259865257,
      "loss": 0.7089,
      "step": 1881
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.47785308957099915,
      "learning_rate": 0.00012789220404234842,
      "loss": 0.8714,
      "step": 1882
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38032662868499756,
      "learning_rate": 0.00012785370548604427,
      "loss": 0.6457,
      "step": 1883
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3759020268917084,
      "learning_rate": 0.00012781520692974014,
      "loss": 0.7573,
      "step": 1884
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3873295485973358,
      "learning_rate": 0.00012777670837343602,
      "loss": 0.8732,
      "step": 1885
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.35442495346069336,
      "learning_rate": 0.00012773820981713187,
      "loss": 0.8167,
      "step": 1886
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.38815587759017944,
      "learning_rate": 0.0001276997112608277,
      "loss": 0.6467,
      "step": 1887
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4207095801830292,
      "learning_rate": 0.0001276612127045236,
      "loss": 0.6392,
      "step": 1888
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4079640209674835,
      "learning_rate": 0.00012762271414821943,
      "loss": 0.6505,
      "step": 1889
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.475057989358902,
      "learning_rate": 0.0001275842155919153,
      "loss": 0.7512,
      "step": 1890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.48418885469436646,
      "learning_rate": 0.00012754571703561118,
      "loss": 0.5987,
      "step": 1891
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3562620282173157,
      "learning_rate": 0.00012750721847930703,
      "loss": 0.8723,
      "step": 1892
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.43781307339668274,
      "learning_rate": 0.00012746871992300288,
      "loss": 0.7518,
      "step": 1893
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4474557638168335,
      "learning_rate": 0.00012743022136669875,
      "loss": 0.6934,
      "step": 1894
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.42306774854660034,
      "learning_rate": 0.00012739172281039463,
      "loss": 0.8038,
      "step": 1895
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4244105815887451,
      "learning_rate": 0.00012735322425409047,
      "loss": 0.7325,
      "step": 1896
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3509678542613983,
      "learning_rate": 0.00012731472569778632,
      "loss": 0.7208,
      "step": 1897
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.39639490842819214,
      "learning_rate": 0.0001272762271414822,
      "loss": 0.8663,
      "step": 1898
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3530687987804413,
      "learning_rate": 0.00012723772858517807,
      "loss": 0.731,
      "step": 1899
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.32869061827659607,
      "learning_rate": 0.00012719923002887392,
      "loss": 0.7454,
      "step": 1900
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.380421906709671,
      "learning_rate": 0.0001271607314725698,
      "loss": 0.7217,
      "step": 1901
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.38393357396125793,
      "learning_rate": 0.00012712223291626564,
      "loss": 0.9215,
      "step": 1902
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3520403504371643,
      "learning_rate": 0.00012708373435996152,
      "loss": 0.7156,
      "step": 1903
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4328886568546295,
      "learning_rate": 0.00012704523580365736,
      "loss": 0.6459,
      "step": 1904
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.36250337958335876,
      "learning_rate": 0.00012700673724735324,
      "loss": 0.8772,
      "step": 1905
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.33598798513412476,
      "learning_rate": 0.0001269682386910491,
      "loss": 0.9344,
      "step": 1906
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40680235624313354,
      "learning_rate": 0.00012692974013474493,
      "loss": 0.8163,
      "step": 1907
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3694469928741455,
      "learning_rate": 0.0001268912415784408,
      "loss": 0.7975,
      "step": 1908
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3503014147281647,
      "learning_rate": 0.00012685274302213668,
      "loss": 0.7764,
      "step": 1909
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4201619327068329,
      "learning_rate": 0.00012681424446583256,
      "loss": 0.7064,
      "step": 1910
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.41038116812705994,
      "learning_rate": 0.0001267757459095284,
      "loss": 0.8704,
      "step": 1911
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.45049744844436646,
      "learning_rate": 0.00012673724735322425,
      "loss": 0.6221,
      "step": 1912
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.36259254813194275,
      "learning_rate": 0.00012669874879692013,
      "loss": 0.7693,
      "step": 1913
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.35794588923454285,
      "learning_rate": 0.00012666025024061597,
      "loss": 0.7066,
      "step": 1914
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3778039216995239,
      "learning_rate": 0.00012662175168431185,
      "loss": 0.6526,
      "step": 1915
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4403374195098877,
      "learning_rate": 0.0001265832531280077,
      "loss": 0.6521,
      "step": 1916
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.37176060676574707,
      "learning_rate": 0.00012654475457170357,
      "loss": 0.7329,
      "step": 1917
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5037533044815063,
      "learning_rate": 0.00012650625601539942,
      "loss": 0.7895,
      "step": 1918
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4459839463233948,
      "learning_rate": 0.0001264677574590953,
      "loss": 0.8182,
      "step": 1919
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4781947135925293,
      "learning_rate": 0.00012642925890279117,
      "loss": 0.8062,
      "step": 1920
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3782847225666046,
      "learning_rate": 0.000126390760346487,
      "loss": 0.641,
      "step": 1921
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.45465216040611267,
      "learning_rate": 0.00012635226179018286,
      "loss": 0.8257,
      "step": 1922
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40369531512260437,
      "learning_rate": 0.00012631376323387873,
      "loss": 0.7442,
      "step": 1923
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.39407670497894287,
      "learning_rate": 0.0001262752646775746,
      "loss": 0.5818,
      "step": 1924
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.35491541028022766,
      "learning_rate": 0.00012623676612127046,
      "loss": 0.7069,
      "step": 1925
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.41069719195365906,
      "learning_rate": 0.0001261982675649663,
      "loss": 0.6938,
      "step": 1926
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.38464608788490295,
      "learning_rate": 0.00012615976900866218,
      "loss": 0.8208,
      "step": 1927
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3080153465270996,
      "learning_rate": 0.00012612127045235805,
      "loss": 0.8452,
      "step": 1928
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4448833465576172,
      "learning_rate": 0.0001260827718960539,
      "loss": 0.6547,
      "step": 1929
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3585502803325653,
      "learning_rate": 0.00012604427333974978,
      "loss": 0.7322,
      "step": 1930
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4916130006313324,
      "learning_rate": 0.00012600577478344562,
      "loss": 0.6263,
      "step": 1931
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3735608160495758,
      "learning_rate": 0.0001259672762271415,
      "loss": 0.844,
      "step": 1932
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4147472083568573,
      "learning_rate": 0.00012592877767083734,
      "loss": 0.6432,
      "step": 1933
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4596444070339203,
      "learning_rate": 0.00012589027911453322,
      "loss": 0.6794,
      "step": 1934
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4263108968734741,
      "learning_rate": 0.0001258517805582291,
      "loss": 0.9283,
      "step": 1935
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40343740582466125,
      "learning_rate": 0.00012581328200192491,
      "loss": 0.8047,
      "step": 1936
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3231755495071411,
      "learning_rate": 0.0001257747834456208,
      "loss": 0.7539,
      "step": 1937
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3559107482433319,
      "learning_rate": 0.00012573628488931666,
      "loss": 0.6522,
      "step": 1938
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3448850214481354,
      "learning_rate": 0.0001256977863330125,
      "loss": 0.7133,
      "step": 1939
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.35919106006622314,
      "learning_rate": 0.00012565928777670839,
      "loss": 0.6377,
      "step": 1940
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3644396960735321,
      "learning_rate": 0.00012562078922040423,
      "loss": 0.641,
      "step": 1941
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.3526782989501953,
      "learning_rate": 0.0001255822906641001,
      "loss": 0.7777,
      "step": 1942
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.42084801197052,
      "learning_rate": 0.00012554379210779595,
      "loss": 0.613,
      "step": 1943
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4135233759880066,
      "learning_rate": 0.00012550529355149183,
      "loss": 0.7808,
      "step": 1944
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4561818838119507,
      "learning_rate": 0.0001254667949951877,
      "loss": 0.8051,
      "step": 1945
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.389324426651001,
      "learning_rate": 0.00012542829643888355,
      "loss": 0.9359,
      "step": 1946
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.42289772629737854,
      "learning_rate": 0.0001253897978825794,
      "loss": 0.8507,
      "step": 1947
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.40204256772994995,
      "learning_rate": 0.00012535129932627527,
      "loss": 0.7511,
      "step": 1948
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.41630515456199646,
      "learning_rate": 0.00012531280076997115,
      "loss": 0.7576,
      "step": 1949
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4155476689338684,
      "learning_rate": 0.000125274302213667,
      "loss": 0.8898,
      "step": 1950
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3869580030441284,
      "learning_rate": 0.00012523580365736284,
      "loss": 0.7584,
      "step": 1951
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4416559934616089,
      "learning_rate": 0.00012519730510105872,
      "loss": 0.677,
      "step": 1952
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3612990975379944,
      "learning_rate": 0.0001251588065447546,
      "loss": 0.822,
      "step": 1953
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5051171779632568,
      "learning_rate": 0.00012512030798845044,
      "loss": 0.7683,
      "step": 1954
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.44406336545944214,
      "learning_rate": 0.00012508180943214629,
      "loss": 0.5896,
      "step": 1955
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4227225184440613,
      "learning_rate": 0.00012504331087584216,
      "loss": 0.6263,
      "step": 1956
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4141536056995392,
      "learning_rate": 0.00012500481231953804,
      "loss": 0.8355,
      "step": 1957
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.38118410110473633,
      "learning_rate": 0.00012496631376323388,
      "loss": 0.7593,
      "step": 1958
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5263524651527405,
      "learning_rate": 0.00012492781520692976,
      "loss": 0.9206,
      "step": 1959
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.43957844376564026,
      "learning_rate": 0.0001248893166506256,
      "loss": 0.7309,
      "step": 1960
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.35311853885650635,
      "learning_rate": 0.00012485081809432145,
      "loss": 0.7148,
      "step": 1961
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.38100552558898926,
      "learning_rate": 0.00012481231953801733,
      "loss": 0.6235,
      "step": 1962
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.37844735383987427,
      "learning_rate": 0.0001247738209817132,
      "loss": 0.7104,
      "step": 1963
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3697439730167389,
      "learning_rate": 0.00012473532242540908,
      "loss": 0.9466,
      "step": 1964
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3669210374355316,
      "learning_rate": 0.0001246968238691049,
      "loss": 0.6652,
      "step": 1965
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.40461626648902893,
      "learning_rate": 0.00012465832531280077,
      "loss": 0.6421,
      "step": 1966
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.43144533038139343,
      "learning_rate": 0.00012461982675649665,
      "loss": 0.7366,
      "step": 1967
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4194335639476776,
      "learning_rate": 0.0001245813282001925,
      "loss": 0.7724,
      "step": 1968
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.36216244101524353,
      "learning_rate": 0.00012454282964388837,
      "loss": 0.8686,
      "step": 1969
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4813291132450104,
      "learning_rate": 0.00012450433108758421,
      "loss": 0.77,
      "step": 1970
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41711923480033875,
      "learning_rate": 0.0001244658325312801,
      "loss": 0.6592,
      "step": 1971
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3906590938568115,
      "learning_rate": 0.00012442733397497594,
      "loss": 0.8117,
      "step": 1972
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4016876816749573,
      "learning_rate": 0.0001243888354186718,
      "loss": 0.7499,
      "step": 1973
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.42538028955459595,
      "learning_rate": 0.00012435033686236769,
      "loss": 0.7417,
      "step": 1974
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.42690616846084595,
      "learning_rate": 0.00012431183830606353,
      "loss": 0.6353,
      "step": 1975
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4209519624710083,
      "learning_rate": 0.00012427333974975938,
      "loss": 0.7598,
      "step": 1976
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.39313405752182007,
      "learning_rate": 0.00012423484119345525,
      "loss": 0.7792,
      "step": 1977
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41112396121025085,
      "learning_rate": 0.00012419634263715113,
      "loss": 0.7569,
      "step": 1978
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.42747482657432556,
      "learning_rate": 0.00012415784408084698,
      "loss": 0.7651,
      "step": 1979
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4339894652366638,
      "learning_rate": 0.00012411934552454282,
      "loss": 0.8933,
      "step": 1980
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3783250153064728,
      "learning_rate": 0.0001240808469682387,
      "loss": 0.7773,
      "step": 1981
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.41081398725509644,
      "learning_rate": 0.00012404234841193457,
      "loss": 0.8325,
      "step": 1982
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4031309485435486,
      "learning_rate": 0.00012400384985563042,
      "loss": 0.8742,
      "step": 1983
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3886183202266693,
      "learning_rate": 0.00012396535129932627,
      "loss": 0.608,
      "step": 1984
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.34317609667778015,
      "learning_rate": 0.00012392685274302214,
      "loss": 0.5327,
      "step": 1985
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3442971408367157,
      "learning_rate": 0.000123888354186718,
      "loss": 0.7692,
      "step": 1986
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5018425583839417,
      "learning_rate": 0.00012384985563041386,
      "loss": 0.7431,
      "step": 1987
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3479405343532562,
      "learning_rate": 0.00012381135707410974,
      "loss": 0.7589,
      "step": 1988
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.37875115871429443,
      "learning_rate": 0.0001237728585178056,
      "loss": 0.7109,
      "step": 1989
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.465097039937973,
      "learning_rate": 0.00012373435996150143,
      "loss": 0.71,
      "step": 1990
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.34705832600593567,
      "learning_rate": 0.0001236958614051973,
      "loss": 0.8524,
      "step": 1991
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.38421595096588135,
      "learning_rate": 0.00012365736284889318,
      "loss": 0.6837,
      "step": 1992
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4191231429576874,
      "learning_rate": 0.00012361886429258903,
      "loss": 0.7636,
      "step": 1993
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3516117036342621,
      "learning_rate": 0.00012358036573628488,
      "loss": 0.6487,
      "step": 1994
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.35605189204216003,
      "learning_rate": 0.00012354186717998075,
      "loss": 0.7462,
      "step": 1995
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4098813235759735,
      "learning_rate": 0.00012350336862367663,
      "loss": 0.8966,
      "step": 1996
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3889295160770416,
      "learning_rate": 0.00012346487006737247,
      "loss": 0.7043,
      "step": 1997
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3662413954734802,
      "learning_rate": 0.00012342637151106835,
      "loss": 0.9537,
      "step": 1998
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3967229127883911,
      "learning_rate": 0.0001233878729547642,
      "loss": 0.8657,
      "step": 1999
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5388762950897217,
      "learning_rate": 0.00012334937439846007,
      "loss": 0.6561,
      "step": 2000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.408794641494751,
      "learning_rate": 0.00012331087584215592,
      "loss": 0.6652,
      "step": 2001
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4102582037448883,
      "learning_rate": 0.0001232723772858518,
      "loss": 1.0117,
      "step": 2002
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5139148235321045,
      "learning_rate": 0.00012323387872954767,
      "loss": 0.8468,
      "step": 2003
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.41571664810180664,
      "learning_rate": 0.00012319538017324351,
      "loss": 0.646,
      "step": 2004
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.47189584374427795,
      "learning_rate": 0.00012315688161693936,
      "loss": 0.6784,
      "step": 2005
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4329637587070465,
      "learning_rate": 0.00012311838306063524,
      "loss": 0.7658,
      "step": 2006
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4125763773918152,
      "learning_rate": 0.0001230798845043311,
      "loss": 0.676,
      "step": 2007
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.41062551736831665,
      "learning_rate": 0.00012304138594802696,
      "loss": 0.8575,
      "step": 2008
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3988594114780426,
      "learning_rate": 0.0001230028873917228,
      "loss": 0.8454,
      "step": 2009
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4611331820487976,
      "learning_rate": 0.00012296438883541868,
      "loss": 0.7585,
      "step": 2010
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4567878246307373,
      "learning_rate": 0.00012292589027911456,
      "loss": 0.6421,
      "step": 2011
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3517627716064453,
      "learning_rate": 0.0001228873917228104,
      "loss": 0.7759,
      "step": 2012
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.37134552001953125,
      "learning_rate": 0.00012284889316650625,
      "loss": 0.6598,
      "step": 2013
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5732856392860413,
      "learning_rate": 0.00012281039461020212,
      "loss": 0.7999,
      "step": 2014
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4829562306404114,
      "learning_rate": 0.00012277189605389797,
      "loss": 0.6875,
      "step": 2015
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.41672706604003906,
      "learning_rate": 0.00012273339749759385,
      "loss": 0.7306,
      "step": 2016
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3966820240020752,
      "learning_rate": 0.00012269489894128972,
      "loss": 0.7323,
      "step": 2017
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.35392627120018005,
      "learning_rate": 0.00012265640038498557,
      "loss": 0.6155,
      "step": 2018
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3570041060447693,
      "learning_rate": 0.00012261790182868142,
      "loss": 0.7711,
      "step": 2019
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.43094366788864136,
      "learning_rate": 0.0001225794032723773,
      "loss": 0.6572,
      "step": 2020
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.46118679642677307,
      "learning_rate": 0.00012254090471607316,
      "loss": 0.7388,
      "step": 2021
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4110174775123596,
      "learning_rate": 0.000122502406159769,
      "loss": 0.7633,
      "step": 2022
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.45007872581481934,
      "learning_rate": 0.00012246390760346486,
      "loss": 0.9979,
      "step": 2023
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4811002016067505,
      "learning_rate": 0.00012242540904716073,
      "loss": 0.8884,
      "step": 2024
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4139425456523895,
      "learning_rate": 0.0001223869104908566,
      "loss": 0.8244,
      "step": 2025
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3508036434650421,
      "learning_rate": 0.00012234841193455246,
      "loss": 0.6291,
      "step": 2026
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3564074635505676,
      "learning_rate": 0.00012230991337824833,
      "loss": 0.5993,
      "step": 2027
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.414589524269104,
      "learning_rate": 0.00012227141482194418,
      "loss": 0.852,
      "step": 2028
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3774373233318329,
      "learning_rate": 0.00012223291626564005,
      "loss": 0.7644,
      "step": 2029
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3742597997188568,
      "learning_rate": 0.0001221944177093359,
      "loss": 0.759,
      "step": 2030
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.44344642758369446,
      "learning_rate": 0.00012215591915303177,
      "loss": 0.8021,
      "step": 2031
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3895547389984131,
      "learning_rate": 0.00012211742059672765,
      "loss": 0.6419,
      "step": 2032
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.39308854937553406,
      "learning_rate": 0.00012207892204042347,
      "loss": 0.8102,
      "step": 2033
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3756394386291504,
      "learning_rate": 0.00012204042348411934,
      "loss": 0.8025,
      "step": 2034
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.473209023475647,
      "learning_rate": 0.00012200192492781522,
      "loss": 0.7383,
      "step": 2035
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.369880348443985,
      "learning_rate": 0.00012196342637151108,
      "loss": 0.8364,
      "step": 2036
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5240722894668579,
      "learning_rate": 0.00012192492781520694,
      "loss": 0.7232,
      "step": 2037
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4130686819553375,
      "learning_rate": 0.00012188642925890279,
      "loss": 0.7917,
      "step": 2038
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.43963950872421265,
      "learning_rate": 0.00012184793070259866,
      "loss": 0.6286,
      "step": 2039
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.37483248114585876,
      "learning_rate": 0.00012180943214629452,
      "loss": 0.8085,
      "step": 2040
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.367349237203598,
      "learning_rate": 0.00012177093358999038,
      "loss": 0.7864,
      "step": 2041
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3880409300327301,
      "learning_rate": 0.00012173243503368623,
      "loss": 0.8338,
      "step": 2042
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.38258102536201477,
      "learning_rate": 0.00012169393647738209,
      "loss": 0.7258,
      "step": 2043
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3926050662994385,
      "learning_rate": 0.00012165543792107797,
      "loss": 0.8641,
      "step": 2044
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.37094995379447937,
      "learning_rate": 0.00012161693936477383,
      "loss": 0.6142,
      "step": 2045
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4337383806705475,
      "learning_rate": 0.00012157844080846969,
      "loss": 0.7139,
      "step": 2046
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.47775086760520935,
      "learning_rate": 0.00012153994225216554,
      "loss": 0.7185,
      "step": 2047
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4545615613460541,
      "learning_rate": 0.00012150144369586141,
      "loss": 0.8431,
      "step": 2048
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4105686545372009,
      "learning_rate": 0.00012146294513955727,
      "loss": 0.8707,
      "step": 2049
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.439957857131958,
      "learning_rate": 0.00012142444658325313,
      "loss": 0.7798,
      "step": 2050
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.42720144987106323,
      "learning_rate": 0.00012138594802694901,
      "loss": 0.8267,
      "step": 2051
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4625844359397888,
      "learning_rate": 0.00012134744947064484,
      "loss": 0.7636,
      "step": 2052
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.42650502920150757,
      "learning_rate": 0.00012130895091434072,
      "loss": 0.6839,
      "step": 2053
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3767647445201874,
      "learning_rate": 0.00012127045235803658,
      "loss": 0.6378,
      "step": 2054
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5337833166122437,
      "learning_rate": 0.00012123195380173245,
      "loss": 0.7482,
      "step": 2055
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3877149224281311,
      "learning_rate": 0.00012119345524542831,
      "loss": 0.8567,
      "step": 2056
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4098486304283142,
      "learning_rate": 0.00012115495668912416,
      "loss": 0.8867,
      "step": 2057
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4096219539642334,
      "learning_rate": 0.00012111645813282002,
      "loss": 0.6185,
      "step": 2058
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.41645532846450806,
      "learning_rate": 0.00012107795957651588,
      "loss": 0.7481,
      "step": 2059
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.44036686420440674,
      "learning_rate": 0.00012103946102021176,
      "loss": 0.8522,
      "step": 2060
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3624647557735443,
      "learning_rate": 0.00012100096246390762,
      "loss": 0.9329,
      "step": 2061
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3435777723789215,
      "learning_rate": 0.00012096246390760347,
      "loss": 0.7418,
      "step": 2062
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3517408072948456,
      "learning_rate": 0.00012092396535129933,
      "loss": 0.839,
      "step": 2063
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3461979627609253,
      "learning_rate": 0.0001208854667949952,
      "loss": 0.7873,
      "step": 2064
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.41387102007865906,
      "learning_rate": 0.00012084696823869106,
      "loss": 0.7371,
      "step": 2065
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3783990740776062,
      "learning_rate": 0.00012080846968238692,
      "loss": 0.9437,
      "step": 2066
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3668247163295746,
      "learning_rate": 0.00012076997112608277,
      "loss": 0.7077,
      "step": 2067
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.45170772075653076,
      "learning_rate": 0.00012073147256977863,
      "loss": 0.9455,
      "step": 2068
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3328435719013214,
      "learning_rate": 0.0001206929740134745,
      "loss": 0.7731,
      "step": 2069
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4016663432121277,
      "learning_rate": 0.00012065447545717037,
      "loss": 0.8585,
      "step": 2070
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.349935382604599,
      "learning_rate": 0.00012061597690086624,
      "loss": 0.7813,
      "step": 2071
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4058588743209839,
      "learning_rate": 0.00012057747834456207,
      "loss": 0.8394,
      "step": 2072
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35471197962760925,
      "learning_rate": 0.00012053897978825795,
      "loss": 0.9745,
      "step": 2073
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.40163925290107727,
      "learning_rate": 0.00012050048123195381,
      "loss": 0.9427,
      "step": 2074
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.348477303981781,
      "learning_rate": 0.00012046198267564967,
      "loss": 0.7882,
      "step": 2075
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4035891592502594,
      "learning_rate": 0.00012042348411934552,
      "loss": 0.8257,
      "step": 2076
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.336616188287735,
      "learning_rate": 0.00012038498556304138,
      "loss": 0.8863,
      "step": 2077
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4254840314388275,
      "learning_rate": 0.00012034648700673725,
      "loss": 0.8186,
      "step": 2078
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3925730884075165,
      "learning_rate": 0.00012030798845043312,
      "loss": 0.7048,
      "step": 2079
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4888431429862976,
      "learning_rate": 0.00012026948989412899,
      "loss": 0.792,
      "step": 2080
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36251410841941833,
      "learning_rate": 0.00012023099133782482,
      "loss": 0.6641,
      "step": 2081
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.452556312084198,
      "learning_rate": 0.0001201924927815207,
      "loss": 1.0918,
      "step": 2082
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3192079961299896,
      "learning_rate": 0.00012015399422521656,
      "loss": 0.659,
      "step": 2083
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4449225068092346,
      "learning_rate": 0.00012011549566891242,
      "loss": 0.9653,
      "step": 2084
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4607343375682831,
      "learning_rate": 0.0001200769971126083,
      "loss": 0.6892,
      "step": 2085
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38626304268836975,
      "learning_rate": 0.00012003849855630414,
      "loss": 0.823,
      "step": 2086
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.39865872263908386,
      "learning_rate": 0.00012,
      "loss": 0.6312,
      "step": 2087
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3629981577396393,
      "learning_rate": 0.00011996150144369586,
      "loss": 0.5786,
      "step": 2088
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.33878591656684875,
      "learning_rate": 0.00011992300288739174,
      "loss": 0.6086,
      "step": 2089
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4121987521648407,
      "learning_rate": 0.0001198845043310876,
      "loss": 0.8919,
      "step": 2090
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.42842817306518555,
      "learning_rate": 0.00011984600577478345,
      "loss": 0.8634,
      "step": 2091
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3267122805118561,
      "learning_rate": 0.00011980750721847931,
      "loss": 0.8016,
      "step": 2092
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38008689880371094,
      "learning_rate": 0.00011976900866217517,
      "loss": 0.6774,
      "step": 2093
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.371703565120697,
      "learning_rate": 0.00011973051010587104,
      "loss": 0.6651,
      "step": 2094
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.40235620737075806,
      "learning_rate": 0.0001196920115495669,
      "loss": 0.57,
      "step": 2095
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36884161829948425,
      "learning_rate": 0.00011965351299326275,
      "loss": 0.8883,
      "step": 2096
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38928765058517456,
      "learning_rate": 0.00011961501443695861,
      "loss": 0.5824,
      "step": 2097
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4125731289386749,
      "learning_rate": 0.00011957651588065449,
      "loss": 0.6825,
      "step": 2098
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38826653361320496,
      "learning_rate": 0.00011953801732435035,
      "loss": 0.734,
      "step": 2099
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36381569504737854,
      "learning_rate": 0.00011949951876804621,
      "loss": 0.7878,
      "step": 2100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38993075489997864,
      "learning_rate": 0.00011946102021174206,
      "loss": 0.7783,
      "step": 2101
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35114869475364685,
      "learning_rate": 0.00011942252165543792,
      "loss": 0.8276,
      "step": 2102
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36438387632369995,
      "learning_rate": 0.00011938402309913379,
      "loss": 0.7548,
      "step": 2103
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38075965642929077,
      "learning_rate": 0.00011934552454282965,
      "loss": 0.5093,
      "step": 2104
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5186618566513062,
      "learning_rate": 0.0001193070259865255,
      "loss": 0.7995,
      "step": 2105
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35744789242744446,
      "learning_rate": 0.00011926852743022136,
      "loss": 0.8253,
      "step": 2106
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.46181604266166687,
      "learning_rate": 0.00011923002887391724,
      "loss": 0.7555,
      "step": 2107
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.41561734676361084,
      "learning_rate": 0.0001191915303176131,
      "loss": 0.67,
      "step": 2108
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5243691205978394,
      "learning_rate": 0.00011915303176130896,
      "loss": 0.8616,
      "step": 2109
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3749087154865265,
      "learning_rate": 0.0001191145332050048,
      "loss": 0.7561,
      "step": 2110
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3935352563858032,
      "learning_rate": 0.00011907603464870068,
      "loss": 0.4916,
      "step": 2111
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4450353682041168,
      "learning_rate": 0.00011903753609239654,
      "loss": 0.7837,
      "step": 2112
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.404316246509552,
      "learning_rate": 0.0001189990375360924,
      "loss": 0.7107,
      "step": 2113
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.39937281608581543,
      "learning_rate": 0.00011896053897978828,
      "loss": 0.628,
      "step": 2114
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.33659496903419495,
      "learning_rate": 0.00011892204042348411,
      "loss": 0.7332,
      "step": 2115
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4303329586982727,
      "learning_rate": 0.00011888354186717998,
      "loss": 0.7383,
      "step": 2116
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4730582535266876,
      "learning_rate": 0.00011884504331087585,
      "loss": 0.8185,
      "step": 2117
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.391056627035141,
      "learning_rate": 0.00011880654475457171,
      "loss": 0.788,
      "step": 2118
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4046691060066223,
      "learning_rate": 0.00011876804619826758,
      "loss": 0.6094,
      "step": 2119
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.36625105142593384,
      "learning_rate": 0.00011872954764196343,
      "loss": 0.7257,
      "step": 2120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.34632712602615356,
      "learning_rate": 0.00011869104908565929,
      "loss": 0.7336,
      "step": 2121
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4273027777671814,
      "learning_rate": 0.00011865255052935515,
      "loss": 0.7583,
      "step": 2122
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3731849491596222,
      "learning_rate": 0.00011861405197305103,
      "loss": 0.7226,
      "step": 2123
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4662467837333679,
      "learning_rate": 0.00011857555341674689,
      "loss": 0.7155,
      "step": 2124
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.38742488622665405,
      "learning_rate": 0.00011853705486044273,
      "loss": 0.725,
      "step": 2125
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4040181636810303,
      "learning_rate": 0.0001184985563041386,
      "loss": 0.7673,
      "step": 2126
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.30353009700775146,
      "learning_rate": 0.00011846005774783447,
      "loss": 0.8217,
      "step": 2127
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.36975014209747314,
      "learning_rate": 0.00011842155919153033,
      "loss": 0.7549,
      "step": 2128
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3579721450805664,
      "learning_rate": 0.00011838306063522619,
      "loss": 0.6209,
      "step": 2129
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.41974034905433655,
      "learning_rate": 0.00011834456207892204,
      "loss": 0.7765,
      "step": 2130
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3708135187625885,
      "learning_rate": 0.0001183060635226179,
      "loss": 0.6746,
      "step": 2131
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.40387025475502014,
      "learning_rate": 0.00011826756496631377,
      "loss": 0.8385,
      "step": 2132
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4114353060722351,
      "learning_rate": 0.00011822906641000964,
      "loss": 0.8504,
      "step": 2133
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.39249905943870544,
      "learning_rate": 0.0001181905678537055,
      "loss": 0.6662,
      "step": 2134
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4487074315547943,
      "learning_rate": 0.00011815206929740134,
      "loss": 0.7328,
      "step": 2135
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4329341948032379,
      "learning_rate": 0.00011811357074109722,
      "loss": 0.6605,
      "step": 2136
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.35302406549453735,
      "learning_rate": 0.00011807507218479308,
      "loss": 0.8785,
      "step": 2137
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.41990190744400024,
      "learning_rate": 0.00011803657362848894,
      "loss": 0.6838,
      "step": 2138
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3867860734462738,
      "learning_rate": 0.00011799807507218479,
      "loss": 0.64,
      "step": 2139
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.36581718921661377,
      "learning_rate": 0.00011795957651588065,
      "loss": 0.8618,
      "step": 2140
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.38583192229270935,
      "learning_rate": 0.00011792107795957652,
      "loss": 0.8423,
      "step": 2141
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4324902892112732,
      "learning_rate": 0.00011788257940327238,
      "loss": 0.9207,
      "step": 2142
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.37691575288772583,
      "learning_rate": 0.00011784408084696826,
      "loss": 0.781,
      "step": 2143
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.35415902733802795,
      "learning_rate": 0.00011780558229066409,
      "loss": 0.89,
      "step": 2144
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3834824562072754,
      "learning_rate": 0.00011776708373435997,
      "loss": 0.62,
      "step": 2145
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.35229063034057617,
      "learning_rate": 0.00011772858517805583,
      "loss": 0.8919,
      "step": 2146
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3849932849407196,
      "learning_rate": 0.00011769008662175169,
      "loss": 0.8604,
      "step": 2147
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4088347852230072,
      "learning_rate": 0.00011765158806544756,
      "loss": 0.5953,
      "step": 2148
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3911071717739105,
      "learning_rate": 0.0001176130895091434,
      "loss": 0.7384,
      "step": 2149
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3532554805278778,
      "learning_rate": 0.00011757459095283927,
      "loss": 0.9581,
      "step": 2150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.37079471349716187,
      "learning_rate": 0.00011753609239653513,
      "loss": 0.6157,
      "step": 2151
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3765881359577179,
      "learning_rate": 0.00011749759384023101,
      "loss": 0.7524,
      "step": 2152
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.37913039326667786,
      "learning_rate": 0.00011745909528392687,
      "loss": 0.59,
      "step": 2153
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.45149025321006775,
      "learning_rate": 0.00011742059672762272,
      "loss": 0.9526,
      "step": 2154
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.45502373576164246,
      "learning_rate": 0.00011738209817131858,
      "loss": 0.7003,
      "step": 2155
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.43611082434654236,
      "learning_rate": 0.00011734359961501444,
      "loss": 0.8076,
      "step": 2156
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3466450870037079,
      "learning_rate": 0.00011730510105871031,
      "loss": 0.7995,
      "step": 2157
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.43203219771385193,
      "learning_rate": 0.00011726660250240617,
      "loss": 0.6678,
      "step": 2158
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4337347447872162,
      "learning_rate": 0.00011722810394610202,
      "loss": 0.7053,
      "step": 2159
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3633384108543396,
      "learning_rate": 0.00011718960538979788,
      "loss": 0.8275,
      "step": 2160
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3544694185256958,
      "learning_rate": 0.00011715110683349376,
      "loss": 0.7186,
      "step": 2161
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.34964147210121155,
      "learning_rate": 0.00011711260827718962,
      "loss": 0.7391,
      "step": 2162
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3838012218475342,
      "learning_rate": 0.00011707410972088548,
      "loss": 0.8694,
      "step": 2163
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.37226739525794983,
      "learning_rate": 0.00011703561116458133,
      "loss": 0.706,
      "step": 2164
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.36740508675575256,
      "learning_rate": 0.00011699711260827719,
      "loss": 0.8952,
      "step": 2165
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.45933470129966736,
      "learning_rate": 0.00011695861405197306,
      "loss": 0.7205,
      "step": 2166
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.34722211956977844,
      "learning_rate": 0.00011692011549566892,
      "loss": 0.5792,
      "step": 2167
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39424246549606323,
      "learning_rate": 0.00011688161693936477,
      "loss": 0.7433,
      "step": 2168
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3727954626083374,
      "learning_rate": 0.00011684311838306063,
      "loss": 0.7183,
      "step": 2169
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.43588918447494507,
      "learning_rate": 0.0001168046198267565,
      "loss": 0.7547,
      "step": 2170
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3994671106338501,
      "learning_rate": 0.00011676612127045237,
      "loss": 0.8475,
      "step": 2171
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4374796748161316,
      "learning_rate": 0.00011672762271414823,
      "loss": 0.6487,
      "step": 2172
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3510798215866089,
      "learning_rate": 0.00011668912415784407,
      "loss": 0.8229,
      "step": 2173
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.31816792488098145,
      "learning_rate": 0.00011665062560153995,
      "loss": 0.5512,
      "step": 2174
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39799198508262634,
      "learning_rate": 0.00011661212704523581,
      "loss": 0.7265,
      "step": 2175
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3674633204936981,
      "learning_rate": 0.00011657362848893167,
      "loss": 0.8548,
      "step": 2176
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.41232773661613464,
      "learning_rate": 0.00011653512993262755,
      "loss": 0.7883,
      "step": 2177
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.31514766812324524,
      "learning_rate": 0.00011649663137632338,
      "loss": 0.735,
      "step": 2178
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3474244475364685,
      "learning_rate": 0.00011645813282001925,
      "loss": 0.7009,
      "step": 2179
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5831050276756287,
      "learning_rate": 0.00011641963426371511,
      "loss": 0.8299,
      "step": 2180
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.34989917278289795,
      "learning_rate": 0.00011638113570741098,
      "loss": 0.8585,
      "step": 2181
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39064136147499084,
      "learning_rate": 0.00011634263715110685,
      "loss": 0.6846,
      "step": 2182
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3657332956790924,
      "learning_rate": 0.0001163041385948027,
      "loss": 0.6809,
      "step": 2183
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4927739202976227,
      "learning_rate": 0.00011626564003849856,
      "loss": 0.9036,
      "step": 2184
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3519545793533325,
      "learning_rate": 0.00011622714148219442,
      "loss": 0.9329,
      "step": 2185
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3810443580150604,
      "learning_rate": 0.0001161886429258903,
      "loss": 0.814,
      "step": 2186
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.38749560713768005,
      "learning_rate": 0.00011615014436958616,
      "loss": 0.737,
      "step": 2187
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.38307780027389526,
      "learning_rate": 0.000116111645813282,
      "loss": 0.7107,
      "step": 2188
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.45294371247291565,
      "learning_rate": 0.00011607314725697786,
      "loss": 0.7368,
      "step": 2189
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3494775593280792,
      "learning_rate": 0.00011603464870067374,
      "loss": 0.8482,
      "step": 2190
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3788994252681732,
      "learning_rate": 0.0001159961501443696,
      "loss": 0.6443,
      "step": 2191
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.35197412967681885,
      "learning_rate": 0.00011595765158806546,
      "loss": 0.7006,
      "step": 2192
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3743210434913635,
      "learning_rate": 0.00011591915303176131,
      "loss": 0.6876,
      "step": 2193
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4382580816745758,
      "learning_rate": 0.00011588065447545717,
      "loss": 0.9875,
      "step": 2194
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.43281832337379456,
      "learning_rate": 0.00011584215591915304,
      "loss": 0.7739,
      "step": 2195
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5362384915351868,
      "learning_rate": 0.0001158036573628489,
      "loss": 0.7773,
      "step": 2196
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.33842676877975464,
      "learning_rate": 0.00011576515880654476,
      "loss": 0.6923,
      "step": 2197
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4255611002445221,
      "learning_rate": 0.00011572666025024061,
      "loss": 0.6065,
      "step": 2198
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.42196813225746155,
      "learning_rate": 0.00011568816169393649,
      "loss": 0.8991,
      "step": 2199
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6695072054862976,
      "learning_rate": 0.00011564966313763235,
      "loss": 0.7331,
      "step": 2200
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.37636908888816833,
      "learning_rate": 0.00011561116458132821,
      "loss": 0.7774,
      "step": 2201
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39924994111061096,
      "learning_rate": 0.00011557266602502406,
      "loss": 0.8166,
      "step": 2202
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4560956358909607,
      "learning_rate": 0.00011553416746871992,
      "loss": 0.7657,
      "step": 2203
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.38918790221214294,
      "learning_rate": 0.00011549566891241579,
      "loss": 0.8862,
      "step": 2204
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4045034348964691,
      "learning_rate": 0.00011545717035611165,
      "loss": 0.7936,
      "step": 2205
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3869166672229767,
      "learning_rate": 0.00011541867179980753,
      "loss": 0.7128,
      "step": 2206
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3621947467327118,
      "learning_rate": 0.00011538017324350336,
      "loss": 0.6448,
      "step": 2207
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.451094388961792,
      "learning_rate": 0.00011534167468719924,
      "loss": 0.672,
      "step": 2208
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.40903109312057495,
      "learning_rate": 0.0001153031761308951,
      "loss": 0.6931,
      "step": 2209
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4317462146282196,
      "learning_rate": 0.00011526467757459096,
      "loss": 0.6477,
      "step": 2210
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.45974451303482056,
      "learning_rate": 0.00011522617901828683,
      "loss": 0.7118,
      "step": 2211
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3950754702091217,
      "learning_rate": 0.00011518768046198267,
      "loss": 0.8234,
      "step": 2212
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.43915367126464844,
      "learning_rate": 0.00011514918190567854,
      "loss": 0.8549,
      "step": 2213
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3887704610824585,
      "learning_rate": 0.0001151106833493744,
      "loss": 0.9144,
      "step": 2214
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3834078013896942,
      "learning_rate": 0.00011507218479307028,
      "loss": 0.7304,
      "step": 2215
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.34007346630096436,
      "learning_rate": 0.00011503368623676614,
      "loss": 0.8786,
      "step": 2216
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.34697577357292175,
      "learning_rate": 0.00011499518768046198,
      "loss": 0.818,
      "step": 2217
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3561306893825531,
      "learning_rate": 0.00011495668912415785,
      "loss": 0.6732,
      "step": 2218
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4111763536930084,
      "learning_rate": 0.0001149181905678537,
      "loss": 0.6244,
      "step": 2219
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4119049906730652,
      "learning_rate": 0.00011487969201154958,
      "loss": 0.6451,
      "step": 2220
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5962485074996948,
      "learning_rate": 0.00011484119345524544,
      "loss": 0.6272,
      "step": 2221
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3762066066265106,
      "learning_rate": 0.00011480269489894129,
      "loss": 0.6962,
      "step": 2222
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.40572991967201233,
      "learning_rate": 0.00011476419634263715,
      "loss": 0.6708,
      "step": 2223
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4560997784137726,
      "learning_rate": 0.00011472569778633302,
      "loss": 0.6799,
      "step": 2224
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37530553340911865,
      "learning_rate": 0.00011468719923002889,
      "loss": 0.7117,
      "step": 2225
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5370792746543884,
      "learning_rate": 0.00011464870067372475,
      "loss": 0.8868,
      "step": 2226
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.39349594712257385,
      "learning_rate": 0.0001146102021174206,
      "loss": 0.65,
      "step": 2227
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.47389501333236694,
      "learning_rate": 0.00011457170356111646,
      "loss": 0.7197,
      "step": 2228
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.41830310225486755,
      "learning_rate": 0.00011453320500481233,
      "loss": 0.6879,
      "step": 2229
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4125405550003052,
      "learning_rate": 0.00011449470644850819,
      "loss": 0.5865,
      "step": 2230
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4581775367259979,
      "learning_rate": 0.00011445620789220404,
      "loss": 0.8667,
      "step": 2231
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3450378179550171,
      "learning_rate": 0.0001144177093358999,
      "loss": 0.714,
      "step": 2232
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.36255624890327454,
      "learning_rate": 0.00011437921077959577,
      "loss": 0.7251,
      "step": 2233
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.451427161693573,
      "learning_rate": 0.00011434071222329163,
      "loss": 0.7691,
      "step": 2234
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3887130618095398,
      "learning_rate": 0.0001143022136669875,
      "loss": 0.7635,
      "step": 2235
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4292912781238556,
      "learning_rate": 0.00011426371511068334,
      "loss": 0.7085,
      "step": 2236
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3934601843357086,
      "learning_rate": 0.00011422521655437922,
      "loss": 0.7259,
      "step": 2237
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4225533902645111,
      "learning_rate": 0.00011418671799807508,
      "loss": 0.731,
      "step": 2238
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37969255447387695,
      "learning_rate": 0.00011414821944177094,
      "loss": 0.7642,
      "step": 2239
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3569066524505615,
      "learning_rate": 0.00011410972088546681,
      "loss": 0.6758,
      "step": 2240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3293171525001526,
      "learning_rate": 0.00011407122232916265,
      "loss": 0.6727,
      "step": 2241
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3563540279865265,
      "learning_rate": 0.00011403272377285852,
      "loss": 0.8185,
      "step": 2242
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.38513055443763733,
      "learning_rate": 0.00011399422521655438,
      "loss": 0.7503,
      "step": 2243
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.39274439215660095,
      "learning_rate": 0.00011395572666025024,
      "loss": 0.5435,
      "step": 2244
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4159555435180664,
      "learning_rate": 0.00011391722810394612,
      "loss": 0.9383,
      "step": 2245
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4847348928451538,
      "learning_rate": 0.00011387872954764197,
      "loss": 0.7943,
      "step": 2246
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4440983831882477,
      "learning_rate": 0.00011384023099133783,
      "loss": 0.9087,
      "step": 2247
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.40952223539352417,
      "learning_rate": 0.00011380173243503369,
      "loss": 0.6278,
      "step": 2248
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3898506164550781,
      "learning_rate": 0.00011376323387872956,
      "loss": 0.8054,
      "step": 2249
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.43739867210388184,
      "learning_rate": 0.00011372473532242542,
      "loss": 0.7229,
      "step": 2250
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.29777491092681885,
      "learning_rate": 0.00011368623676612127,
      "loss": 0.8507,
      "step": 2251
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37370622158050537,
      "learning_rate": 0.00011364773820981713,
      "loss": 0.7598,
      "step": 2252
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37024766206741333,
      "learning_rate": 0.00011360923965351299,
      "loss": 0.6984,
      "step": 2253
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4456980228424072,
      "learning_rate": 0.00011357074109720887,
      "loss": 0.6366,
      "step": 2254
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.34074464440345764,
      "learning_rate": 0.00011353224254090473,
      "loss": 0.6394,
      "step": 2255
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3592866361141205,
      "learning_rate": 0.00011349374398460058,
      "loss": 0.6728,
      "step": 2256
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4990155100822449,
      "learning_rate": 0.00011345524542829644,
      "loss": 0.7981,
      "step": 2257
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3971361219882965,
      "learning_rate": 0.00011341674687199231,
      "loss": 0.7578,
      "step": 2258
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4726282060146332,
      "learning_rate": 0.00011337824831568817,
      "loss": 0.7665,
      "step": 2259
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3617214560508728,
      "learning_rate": 0.00011333974975938403,
      "loss": 0.8644,
      "step": 2260
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3469032347202301,
      "learning_rate": 0.00011330125120307988,
      "loss": 0.8264,
      "step": 2261
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3822077512741089,
      "learning_rate": 0.00011326275264677576,
      "loss": 0.7407,
      "step": 2262
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3991341292858124,
      "learning_rate": 0.00011322425409047162,
      "loss": 0.6754,
      "step": 2263
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43235301971435547,
      "learning_rate": 0.00011318575553416748,
      "loss": 0.5176,
      "step": 2264
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3917157053947449,
      "learning_rate": 0.00011314725697786332,
      "loss": 0.686,
      "step": 2265
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3825984299182892,
      "learning_rate": 0.00011310875842155919,
      "loss": 0.7495,
      "step": 2266
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.380463182926178,
      "learning_rate": 0.00011307025986525506,
      "loss": 0.7106,
      "step": 2267
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.42118051648139954,
      "learning_rate": 0.00011303176130895092,
      "loss": 0.6746,
      "step": 2268
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43703749775886536,
      "learning_rate": 0.00011299326275264678,
      "loss": 0.9715,
      "step": 2269
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4579017758369446,
      "learning_rate": 0.00011295476419634263,
      "loss": 0.7184,
      "step": 2270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.40276655554771423,
      "learning_rate": 0.0001129162656400385,
      "loss": 0.9976,
      "step": 2271
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4463086426258087,
      "learning_rate": 0.00011287776708373437,
      "loss": 0.7995,
      "step": 2272
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4307232201099396,
      "learning_rate": 0.00011283926852743023,
      "loss": 0.7266,
      "step": 2273
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3784542381763458,
      "learning_rate": 0.0001128007699711261,
      "loss": 0.8141,
      "step": 2274
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3715219795703888,
      "learning_rate": 0.00011276227141482193,
      "loss": 0.6447,
      "step": 2275
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33160173892974854,
      "learning_rate": 0.00011272377285851781,
      "loss": 0.6825,
      "step": 2276
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.43266379833221436,
      "learning_rate": 0.00011268527430221367,
      "loss": 0.7538,
      "step": 2277
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4119640588760376,
      "learning_rate": 0.00011264677574590954,
      "loss": 0.9136,
      "step": 2278
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4355044364929199,
      "learning_rate": 0.0001126082771896054,
      "loss": 0.7242,
      "step": 2279
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4403360188007355,
      "learning_rate": 0.00011256977863330125,
      "loss": 0.8253,
      "step": 2280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.38947322964668274,
      "learning_rate": 0.00011253128007699711,
      "loss": 0.7287,
      "step": 2281
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.458931028842926,
      "learning_rate": 0.00011249278152069298,
      "loss": 0.9275,
      "step": 2282
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.36456066370010376,
      "learning_rate": 0.00011245428296438885,
      "loss": 0.9106,
      "step": 2283
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5292866230010986,
      "learning_rate": 0.00011241578440808471,
      "loss": 0.7169,
      "step": 2284
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.34969237446784973,
      "learning_rate": 0.00011237728585178056,
      "loss": 0.8353,
      "step": 2285
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33650732040405273,
      "learning_rate": 0.00011233878729547642,
      "loss": 0.7964,
      "step": 2286
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.38508012890815735,
      "learning_rate": 0.0001123002887391723,
      "loss": 0.5989,
      "step": 2287
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.39526471495628357,
      "learning_rate": 0.00011226179018286815,
      "loss": 0.6714,
      "step": 2288
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.350534051656723,
      "learning_rate": 0.00011222329162656402,
      "loss": 0.7765,
      "step": 2289
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4445461630821228,
      "learning_rate": 0.00011218479307025986,
      "loss": 0.8326,
      "step": 2290
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4376275837421417,
      "learning_rate": 0.00011214629451395572,
      "loss": 0.7497,
      "step": 2291
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4612148106098175,
      "learning_rate": 0.0001121077959576516,
      "loss": 0.677,
      "step": 2292
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4444798529148102,
      "learning_rate": 0.00011206929740134746,
      "loss": 0.843,
      "step": 2293
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3846166133880615,
      "learning_rate": 0.00011203079884504331,
      "loss": 0.8211,
      "step": 2294
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.426296591758728,
      "learning_rate": 0.00011199230028873917,
      "loss": 0.8342,
      "step": 2295
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3999997675418854,
      "learning_rate": 0.00011195380173243504,
      "loss": 0.7201,
      "step": 2296
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.35047706961631775,
      "learning_rate": 0.0001119153031761309,
      "loss": 0.7547,
      "step": 2297
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33704060316085815,
      "learning_rate": 0.00011187680461982676,
      "loss": 0.6568,
      "step": 2298
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3626995384693146,
      "learning_rate": 0.00011183830606352261,
      "loss": 0.8075,
      "step": 2299
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3678150475025177,
      "learning_rate": 0.00011179980750721847,
      "loss": 0.535,
      "step": 2300
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.44119253754615784,
      "learning_rate": 0.00011176130895091435,
      "loss": 0.6779,
      "step": 2301
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.40295276045799255,
      "learning_rate": 0.00011172281039461021,
      "loss": 0.629,
      "step": 2302
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3215882182121277,
      "learning_rate": 0.00011168431183830608,
      "loss": 0.9204,
      "step": 2303
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.34080109000205994,
      "learning_rate": 0.00011164581328200192,
      "loss": 0.6843,
      "step": 2304
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.38247257471084595,
      "learning_rate": 0.00011160731472569779,
      "loss": 0.7238,
      "step": 2305
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.41464027762413025,
      "learning_rate": 0.00011156881616939365,
      "loss": 0.7843,
      "step": 2306
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3956071734428406,
      "learning_rate": 0.00011153031761308951,
      "loss": 0.7814,
      "step": 2307
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.44631510972976685,
      "learning_rate": 0.00011149181905678539,
      "loss": 0.8242,
      "step": 2308
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3873317241668701,
      "learning_rate": 0.00011145332050048124,
      "loss": 0.713,
      "step": 2309
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3849426209926605,
      "learning_rate": 0.0001114148219441771,
      "loss": 0.5627,
      "step": 2310
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.46417564153671265,
      "learning_rate": 0.00011137632338787296,
      "loss": 0.7249,
      "step": 2311
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4046604037284851,
      "learning_rate": 0.00011133782483156883,
      "loss": 0.849,
      "step": 2312
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.39463022351264954,
      "learning_rate": 0.00011129932627526469,
      "loss": 0.8241,
      "step": 2313
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3883354365825653,
      "learning_rate": 0.00011126082771896054,
      "loss": 0.8225,
      "step": 2314
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.46334436535835266,
      "learning_rate": 0.0001112223291626564,
      "loss": 0.7582,
      "step": 2315
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39377129077911377,
      "learning_rate": 0.00011118383060635226,
      "loss": 0.7537,
      "step": 2316
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.33363932371139526,
      "learning_rate": 0.00011114533205004814,
      "loss": 0.7518,
      "step": 2317
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.38473016023635864,
      "learning_rate": 0.000111106833493744,
      "loss": 0.7644,
      "step": 2318
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.34498131275177,
      "learning_rate": 0.00011106833493743984,
      "loss": 0.7808,
      "step": 2319
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.44471287727355957,
      "learning_rate": 0.0001110298363811357,
      "loss": 0.8422,
      "step": 2320
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4140911102294922,
      "learning_rate": 0.00011099133782483158,
      "loss": 0.6267,
      "step": 2321
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3590106964111328,
      "learning_rate": 0.00011095283926852744,
      "loss": 0.763,
      "step": 2322
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.43496426939964294,
      "learning_rate": 0.0001109143407122233,
      "loss": 0.7054,
      "step": 2323
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5209596157073975,
      "learning_rate": 0.00011087584215591915,
      "loss": 0.6405,
      "step": 2324
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4252814054489136,
      "learning_rate": 0.00011083734359961502,
      "loss": 0.6794,
      "step": 2325
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4579400420188904,
      "learning_rate": 0.00011079884504331089,
      "loss": 0.7631,
      "step": 2326
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3879834711551666,
      "learning_rate": 0.00011076034648700675,
      "loss": 0.7644,
      "step": 2327
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.47464868426322937,
      "learning_rate": 0.0001107218479307026,
      "loss": 0.7741,
      "step": 2328
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4251587986946106,
      "learning_rate": 0.00011068334937439845,
      "loss": 0.6253,
      "step": 2329
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3873426616191864,
      "learning_rate": 0.00011064485081809433,
      "loss": 0.7812,
      "step": 2330
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37440595030784607,
      "learning_rate": 0.00011060635226179019,
      "loss": 0.7137,
      "step": 2331
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3972944915294647,
      "learning_rate": 0.00011056785370548605,
      "loss": 0.5877,
      "step": 2332
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40689557790756226,
      "learning_rate": 0.0001105293551491819,
      "loss": 0.7028,
      "step": 2333
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3650725781917572,
      "learning_rate": 0.00011049085659287777,
      "loss": 0.7862,
      "step": 2334
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41022011637687683,
      "learning_rate": 0.00011045235803657363,
      "loss": 0.7118,
      "step": 2335
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39737942814826965,
      "learning_rate": 0.0001104138594802695,
      "loss": 0.6757,
      "step": 2336
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36400172114372253,
      "learning_rate": 0.00011037536092396537,
      "loss": 0.7087,
      "step": 2337
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3891964256763458,
      "learning_rate": 0.0001103368623676612,
      "loss": 0.6328,
      "step": 2338
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4111221432685852,
      "learning_rate": 0.00011029836381135708,
      "loss": 0.6792,
      "step": 2339
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40574342012405396,
      "learning_rate": 0.00011025986525505294,
      "loss": 0.74,
      "step": 2340
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.35706257820129395,
      "learning_rate": 0.00011022136669874881,
      "loss": 0.7392,
      "step": 2341
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4300258457660675,
      "learning_rate": 0.00011018286814244467,
      "loss": 0.7228,
      "step": 2342
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.33952802419662476,
      "learning_rate": 0.00011014436958614052,
      "loss": 0.7598,
      "step": 2343
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4344272017478943,
      "learning_rate": 0.00011010587102983638,
      "loss": 0.6776,
      "step": 2344
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4763488173484802,
      "learning_rate": 0.00011006737247353224,
      "loss": 0.6444,
      "step": 2345
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37266600131988525,
      "learning_rate": 0.00011002887391722812,
      "loss": 0.6925,
      "step": 2346
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4069986343383789,
      "learning_rate": 0.00010999037536092398,
      "loss": 0.7609,
      "step": 2347
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.38464513421058655,
      "learning_rate": 0.00010995187680461983,
      "loss": 0.722,
      "step": 2348
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3833748400211334,
      "learning_rate": 0.00010991337824831569,
      "loss": 0.8871,
      "step": 2349
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4405025541782379,
      "learning_rate": 0.00010987487969201156,
      "loss": 0.6784,
      "step": 2350
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.33842357993125916,
      "learning_rate": 0.00010983638113570742,
      "loss": 0.7432,
      "step": 2351
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41140973567962646,
      "learning_rate": 0.00010979788257940328,
      "loss": 0.812,
      "step": 2352
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39032095670700073,
      "learning_rate": 0.00010975938402309913,
      "loss": 0.6616,
      "step": 2353
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40140148997306824,
      "learning_rate": 0.00010972088546679499,
      "loss": 0.7673,
      "step": 2354
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39274275302886963,
      "learning_rate": 0.00010968238691049087,
      "loss": 0.5909,
      "step": 2355
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37527140974998474,
      "learning_rate": 0.00010964388835418673,
      "loss": 0.7377,
      "step": 2356
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41771450638771057,
      "learning_rate": 0.00010960538979788258,
      "loss": 0.6753,
      "step": 2357
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.34901154041290283,
      "learning_rate": 0.00010956689124157844,
      "loss": 0.7058,
      "step": 2358
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3821899890899658,
      "learning_rate": 0.00010952839268527431,
      "loss": 0.9096,
      "step": 2359
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4075283408164978,
      "learning_rate": 0.00010948989412897017,
      "loss": 0.721,
      "step": 2360
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3885054886341095,
      "learning_rate": 0.00010945139557266603,
      "loss": 0.9134,
      "step": 2361
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36912694573402405,
      "learning_rate": 0.00010941289701636188,
      "loss": 0.8379,
      "step": 2362
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4590597152709961,
      "learning_rate": 0.00010937439846005774,
      "loss": 0.7429,
      "step": 2363
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3710440397262573,
      "learning_rate": 0.00010933589990375362,
      "loss": 0.5216,
      "step": 2364
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.39545395970344543,
      "learning_rate": 0.00010929740134744948,
      "loss": 0.7839,
      "step": 2365
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3728938698768616,
      "learning_rate": 0.00010925890279114535,
      "loss": 0.7069,
      "step": 2366
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4875277578830719,
      "learning_rate": 0.00010922040423484119,
      "loss": 0.638,
      "step": 2367
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.472263365983963,
      "learning_rate": 0.00010918190567853706,
      "loss": 0.7518,
      "step": 2368
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39096471667289734,
      "learning_rate": 0.00010914340712223292,
      "loss": 0.6152,
      "step": 2369
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4162939190864563,
      "learning_rate": 0.00010910490856592878,
      "loss": 0.7758,
      "step": 2370
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7216567397117615,
      "learning_rate": 0.00010906641000962466,
      "loss": 0.7506,
      "step": 2371
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3610159754753113,
      "learning_rate": 0.0001090279114533205,
      "loss": 0.7787,
      "step": 2372
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.44025230407714844,
      "learning_rate": 0.00010898941289701636,
      "loss": 0.6573,
      "step": 2373
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.48516783118247986,
      "learning_rate": 0.00010895091434071223,
      "loss": 0.8196,
      "step": 2374
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.391536682844162,
      "learning_rate": 0.0001089124157844081,
      "loss": 0.7971,
      "step": 2375
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.44229811429977417,
      "learning_rate": 0.00010887391722810396,
      "loss": 0.704,
      "step": 2376
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.42935293912887573,
      "learning_rate": 0.00010883541867179981,
      "loss": 0.6974,
      "step": 2377
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4733726382255554,
      "learning_rate": 0.00010879692011549567,
      "loss": 0.7412,
      "step": 2378
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41009944677352905,
      "learning_rate": 0.00010875842155919153,
      "loss": 0.7394,
      "step": 2379
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5144756436347961,
      "learning_rate": 0.0001087199230028874,
      "loss": 0.9251,
      "step": 2380
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3374182879924774,
      "learning_rate": 0.00010868142444658327,
      "loss": 0.711,
      "step": 2381
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.40043482184410095,
      "learning_rate": 0.00010864292589027911,
      "loss": 0.7363,
      "step": 2382
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.392500102519989,
      "learning_rate": 0.00010860442733397497,
      "loss": 0.8894,
      "step": 2383
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39522337913513184,
      "learning_rate": 0.00010856592877767085,
      "loss": 0.5762,
      "step": 2384
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4278419017791748,
      "learning_rate": 0.00010852743022136671,
      "loss": 0.6512,
      "step": 2385
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5222858786582947,
      "learning_rate": 0.00010848893166506257,
      "loss": 0.7143,
      "step": 2386
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5088847875595093,
      "learning_rate": 0.00010845043310875842,
      "loss": 0.8155,
      "step": 2387
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3474803566932678,
      "learning_rate": 0.00010841193455245429,
      "loss": 0.7527,
      "step": 2388
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.33903735876083374,
      "learning_rate": 0.00010837343599615015,
      "loss": 0.6075,
      "step": 2389
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4357243776321411,
      "learning_rate": 0.00010833493743984601,
      "loss": 0.8038,
      "step": 2390
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4495459198951721,
      "learning_rate": 0.00010829643888354186,
      "loss": 0.6594,
      "step": 2391
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41215696930885315,
      "learning_rate": 0.00010825794032723772,
      "loss": 0.5705,
      "step": 2392
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.43066734075546265,
      "learning_rate": 0.0001082194417709336,
      "loss": 0.7671,
      "step": 2393
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39642664790153503,
      "learning_rate": 0.00010818094321462946,
      "loss": 0.6507,
      "step": 2394
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.43875041604042053,
      "learning_rate": 0.00010814244465832532,
      "loss": 0.8804,
      "step": 2395
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5127138495445251,
      "learning_rate": 0.00010810394610202117,
      "loss": 0.7297,
      "step": 2396
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4480130076408386,
      "learning_rate": 0.00010806544754571704,
      "loss": 0.8083,
      "step": 2397
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4779157042503357,
      "learning_rate": 0.0001080269489894129,
      "loss": 0.7412,
      "step": 2398
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3975629508495331,
      "learning_rate": 0.00010798845043310876,
      "loss": 0.7201,
      "step": 2399
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.48626387119293213,
      "learning_rate": 0.00010794995187680464,
      "loss": 0.6488,
      "step": 2400
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3893550932407379,
      "learning_rate": 0.00010791145332050047,
      "loss": 0.7231,
      "step": 2401
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.39619746804237366,
      "learning_rate": 0.00010787295476419635,
      "loss": 0.9375,
      "step": 2402
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.42466121912002563,
      "learning_rate": 0.00010783445620789221,
      "loss": 0.7703,
      "step": 2403
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4260205924510956,
      "learning_rate": 0.00010779595765158807,
      "loss": 0.7913,
      "step": 2404
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41400957107543945,
      "learning_rate": 0.00010775745909528394,
      "loss": 0.6578,
      "step": 2405
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4373241364955902,
      "learning_rate": 0.00010771896053897979,
      "loss": 0.6646,
      "step": 2406
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4760693609714508,
      "learning_rate": 0.00010768046198267565,
      "loss": 0.7379,
      "step": 2407
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.373685747385025,
      "learning_rate": 0.00010764196342637151,
      "loss": 0.6755,
      "step": 2408
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4167444407939911,
      "learning_rate": 0.00010760346487006739,
      "loss": 0.8616,
      "step": 2409
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.33050963282585144,
      "learning_rate": 0.00010756496631376325,
      "loss": 0.7417,
      "step": 2410
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.37958580255508423,
      "learning_rate": 0.0001075264677574591,
      "loss": 0.6462,
      "step": 2411
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3599099814891815,
      "learning_rate": 0.00010748796920115496,
      "loss": 0.7637,
      "step": 2412
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4238422214984894,
      "learning_rate": 0.00010744947064485083,
      "loss": 0.7517,
      "step": 2413
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4933719336986542,
      "learning_rate": 0.00010741097208854669,
      "loss": 0.6979,
      "step": 2414
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.45664355158805847,
      "learning_rate": 0.00010737247353224255,
      "loss": 0.7987,
      "step": 2415
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4060629904270172,
      "learning_rate": 0.0001073339749759384,
      "loss": 0.6155,
      "step": 2416
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4933921992778778,
      "learning_rate": 0.00010729547641963426,
      "loss": 0.8787,
      "step": 2417
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.41116487979888916,
      "learning_rate": 0.00010725697786333014,
      "loss": 0.849,
      "step": 2418
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3629951477050781,
      "learning_rate": 0.000107218479307026,
      "loss": 0.8611,
      "step": 2419
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4830476939678192,
      "learning_rate": 0.00010717998075072184,
      "loss": 0.6486,
      "step": 2420
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.41938549280166626,
      "learning_rate": 0.0001071414821944177,
      "loss": 0.6418,
      "step": 2421
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.42721328139305115,
      "learning_rate": 0.00010710298363811358,
      "loss": 0.7287,
      "step": 2422
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4458140730857849,
      "learning_rate": 0.00010706448508180944,
      "loss": 0.89,
      "step": 2423
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.49471187591552734,
      "learning_rate": 0.0001070259865255053,
      "loss": 0.7521,
      "step": 2424
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4991021454334259,
      "learning_rate": 0.00010698748796920115,
      "loss": 1.1311,
      "step": 2425
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3906738758087158,
      "learning_rate": 0.00010694898941289701,
      "loss": 0.7831,
      "step": 2426
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3895919620990753,
      "learning_rate": 0.00010691049085659288,
      "loss": 0.7001,
      "step": 2427
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.49465692043304443,
      "learning_rate": 0.00010687199230028875,
      "loss": 0.8675,
      "step": 2428
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37799057364463806,
      "learning_rate": 0.00010683349374398462,
      "loss": 0.776,
      "step": 2429
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39210665225982666,
      "learning_rate": 0.00010679499518768045,
      "loss": 0.8061,
      "step": 2430
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4115479588508606,
      "learning_rate": 0.00010675649663137633,
      "loss": 0.6569,
      "step": 2431
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4144365191459656,
      "learning_rate": 0.00010671799807507219,
      "loss": 0.7965,
      "step": 2432
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.44552552700042725,
      "learning_rate": 0.00010667949951876805,
      "loss": 0.6653,
      "step": 2433
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.46572089195251465,
      "learning_rate": 0.00010664100096246393,
      "loss": 0.751,
      "step": 2434
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3344278335571289,
      "learning_rate": 0.00010660250240615976,
      "loss": 0.7992,
      "step": 2435
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3466501832008362,
      "learning_rate": 0.00010656400384985563,
      "loss": 0.7365,
      "step": 2436
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.448806494474411,
      "learning_rate": 0.0001065255052935515,
      "loss": 0.7602,
      "step": 2437
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.41926589608192444,
      "learning_rate": 0.00010648700673724737,
      "loss": 0.6445,
      "step": 2438
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.47828710079193115,
      "learning_rate": 0.00010644850818094323,
      "loss": 0.7023,
      "step": 2439
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4155615270137787,
      "learning_rate": 0.00010641000962463908,
      "loss": 0.6808,
      "step": 2440
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37202009558677673,
      "learning_rate": 0.00010637151106833494,
      "loss": 0.6744,
      "step": 2441
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39455941319465637,
      "learning_rate": 0.0001063330125120308,
      "loss": 0.8144,
      "step": 2442
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.28369224071502686,
      "learning_rate": 0.00010629451395572667,
      "loss": 0.6837,
      "step": 2443
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3785744607448578,
      "learning_rate": 0.00010625601539942253,
      "loss": 0.741,
      "step": 2444
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3449590504169464,
      "learning_rate": 0.00010621751684311838,
      "loss": 0.7957,
      "step": 2445
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39042341709136963,
      "learning_rate": 0.00010617901828681424,
      "loss": 0.7669,
      "step": 2446
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37575051188468933,
      "learning_rate": 0.00010614051973051012,
      "loss": 0.6304,
      "step": 2447
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4370383024215698,
      "learning_rate": 0.00010610202117420598,
      "loss": 0.6967,
      "step": 2448
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.41294026374816895,
      "learning_rate": 0.00010606352261790184,
      "loss": 0.666,
      "step": 2449
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.44650569558143616,
      "learning_rate": 0.00010602502406159769,
      "loss": 0.695,
      "step": 2450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4378415644168854,
      "learning_rate": 0.00010598652550529355,
      "loss": 0.7769,
      "step": 2451
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4206666350364685,
      "learning_rate": 0.00010594802694898942,
      "loss": 0.8208,
      "step": 2452
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3981338143348694,
      "learning_rate": 0.00010590952839268528,
      "loss": 0.9173,
      "step": 2453
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3832845389842987,
      "learning_rate": 0.00010587102983638113,
      "loss": 0.7482,
      "step": 2454
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4273471534252167,
      "learning_rate": 0.00010583253128007699,
      "loss": 0.8739,
      "step": 2455
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.35656657814979553,
      "learning_rate": 0.00010579403272377287,
      "loss": 0.7599,
      "step": 2456
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3701593279838562,
      "learning_rate": 0.00010575553416746873,
      "loss": 0.67,
      "step": 2457
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.36156415939331055,
      "learning_rate": 0.00010571703561116459,
      "loss": 0.8042,
      "step": 2458
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7337693572044373,
      "learning_rate": 0.00010567853705486044,
      "loss": 0.7177,
      "step": 2459
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39362555742263794,
      "learning_rate": 0.00010564003849855631,
      "loss": 0.6684,
      "step": 2460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39397212862968445,
      "learning_rate": 0.00010560153994225217,
      "loss": 0.7021,
      "step": 2461
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.38539284467697144,
      "learning_rate": 0.00010556304138594803,
      "loss": 0.6501,
      "step": 2462
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.36503028869628906,
      "learning_rate": 0.00010552454282964391,
      "loss": 0.7818,
      "step": 2463
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39424991607666016,
      "learning_rate": 0.00010548604427333974,
      "loss": 0.6401,
      "step": 2464
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.40232083201408386,
      "learning_rate": 0.00010544754571703562,
      "loss": 0.7927,
      "step": 2465
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37082961201667786,
      "learning_rate": 0.00010540904716073148,
      "loss": 0.6639,
      "step": 2466
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.37345248460769653,
      "learning_rate": 0.00010537054860442734,
      "loss": 0.7498,
      "step": 2467
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.38427990674972534,
      "learning_rate": 0.00010533205004812321,
      "loss": 0.8139,
      "step": 2468
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4326833486557007,
      "learning_rate": 0.00010529355149181906,
      "loss": 0.6919,
      "step": 2469
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4030657410621643,
      "learning_rate": 0.00010525505293551492,
      "loss": 0.6273,
      "step": 2470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44224339723587036,
      "learning_rate": 0.00010521655437921078,
      "loss": 0.9079,
      "step": 2471
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.36092349886894226,
      "learning_rate": 0.00010517805582290666,
      "loss": 0.8248,
      "step": 2472
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44922709465026855,
      "learning_rate": 0.00010513955726660252,
      "loss": 0.6616,
      "step": 2473
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3882730007171631,
      "learning_rate": 0.00010510105871029836,
      "loss": 0.7248,
      "step": 2474
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4320143163204193,
      "learning_rate": 0.00010506256015399423,
      "loss": 0.864,
      "step": 2475
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.427635133266449,
      "learning_rate": 0.0001050240615976901,
      "loss": 0.7518,
      "step": 2476
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3647995591163635,
      "learning_rate": 0.00010498556304138596,
      "loss": 0.802,
      "step": 2477
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3850099444389343,
      "learning_rate": 0.00010494706448508182,
      "loss": 0.789,
      "step": 2478
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5306535363197327,
      "learning_rate": 0.00010490856592877767,
      "loss": 0.7186,
      "step": 2479
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4845297038555145,
      "learning_rate": 0.00010487006737247353,
      "loss": 0.8156,
      "step": 2480
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4271756410598755,
      "learning_rate": 0.0001048315688161694,
      "loss": 0.842,
      "step": 2481
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44169744849205017,
      "learning_rate": 0.00010479307025986527,
      "loss": 0.6954,
      "step": 2482
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3591703772544861,
      "learning_rate": 0.00010475457170356111,
      "loss": 0.6429,
      "step": 2483
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.32014140486717224,
      "learning_rate": 0.00010471607314725697,
      "loss": 0.8984,
      "step": 2484
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3563832640647888,
      "learning_rate": 0.00010467757459095285,
      "loss": 0.6218,
      "step": 2485
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.34702759981155396,
      "learning_rate": 0.00010463907603464871,
      "loss": 0.7596,
      "step": 2486
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.475062757730484,
      "learning_rate": 0.00010460057747834457,
      "loss": 0.722,
      "step": 2487
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.37916338443756104,
      "learning_rate": 0.00010456207892204042,
      "loss": 0.6358,
      "step": 2488
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4562825560569763,
      "learning_rate": 0.00010452358036573628,
      "loss": 0.8883,
      "step": 2489
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3856847286224365,
      "learning_rate": 0.00010448508180943215,
      "loss": 0.8971,
      "step": 2490
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3566306531429291,
      "learning_rate": 0.00010444658325312801,
      "loss": 0.6958,
      "step": 2491
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.35179609060287476,
      "learning_rate": 0.00010440808469682389,
      "loss": 0.8015,
      "step": 2492
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.380289763212204,
      "learning_rate": 0.00010436958614051972,
      "loss": 0.9263,
      "step": 2493
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5747924447059631,
      "learning_rate": 0.0001043310875842156,
      "loss": 0.7888,
      "step": 2494
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4178891181945801,
      "learning_rate": 0.00010429258902791146,
      "loss": 0.6376,
      "step": 2495
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4368913471698761,
      "learning_rate": 0.00010425409047160732,
      "loss": 0.6347,
      "step": 2496
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3705434501171112,
      "learning_rate": 0.0001042155919153032,
      "loss": 0.65,
      "step": 2497
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3721732795238495,
      "learning_rate": 0.00010417709335899903,
      "loss": 0.7796,
      "step": 2498
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3988465368747711,
      "learning_rate": 0.0001041385948026949,
      "loss": 0.7929,
      "step": 2499
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3996538519859314,
      "learning_rate": 0.00010410009624639076,
      "loss": 0.7482,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.48071402311325073,
      "learning_rate": 0.00010406159769008664,
      "loss": 0.631,
      "step": 2501
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3899560272693634,
      "learning_rate": 0.0001040230991337825,
      "loss": 0.8135,
      "step": 2502
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4035302400588989,
      "learning_rate": 0.00010398460057747835,
      "loss": 0.6386,
      "step": 2503
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3273959755897522,
      "learning_rate": 0.00010394610202117421,
      "loss": 0.8014,
      "step": 2504
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3374646008014679,
      "learning_rate": 0.00010390760346487007,
      "loss": 0.7513,
      "step": 2505
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3918435871601105,
      "learning_rate": 0.00010386910490856594,
      "loss": 0.7474,
      "step": 2506
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44908449053764343,
      "learning_rate": 0.0001038306063522618,
      "loss": 0.7021,
      "step": 2507
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4093625247478485,
      "learning_rate": 0.00010379210779595765,
      "loss": 0.7108,
      "step": 2508
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5031642317771912,
      "learning_rate": 0.00010375360923965351,
      "loss": 0.824,
      "step": 2509
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.40299123525619507,
      "learning_rate": 0.00010371511068334939,
      "loss": 0.7367,
      "step": 2510
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4251953661441803,
      "learning_rate": 0.00010367661212704525,
      "loss": 0.6676,
      "step": 2511
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.41666170954704285,
      "learning_rate": 0.00010363811357074111,
      "loss": 0.6754,
      "step": 2512
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.38444188237190247,
      "learning_rate": 0.00010359961501443696,
      "loss": 0.6828,
      "step": 2513
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.39448800683021545,
      "learning_rate": 0.00010356111645813282,
      "loss": 0.9123,
      "step": 2514
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3752245306968689,
      "learning_rate": 0.00010352261790182869,
      "loss": 0.8417,
      "step": 2515
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.43051615357398987,
      "learning_rate": 0.00010348411934552455,
      "loss": 0.6572,
      "step": 2516
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.34709376096725464,
      "learning_rate": 0.0001034456207892204,
      "loss": 0.8028,
      "step": 2517
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4100029170513153,
      "learning_rate": 0.00010340712223291626,
      "loss": 0.7308,
      "step": 2518
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4835284352302551,
      "learning_rate": 0.00010336862367661214,
      "loss": 0.6951,
      "step": 2519
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.479619562625885,
      "learning_rate": 0.000103330125120308,
      "loss": 0.9418,
      "step": 2520
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3415648937225342,
      "learning_rate": 0.00010329162656400386,
      "loss": 0.8003,
      "step": 2521
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3873975872993469,
      "learning_rate": 0.0001032531280076997,
      "loss": 0.9137,
      "step": 2522
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3694837987422943,
      "learning_rate": 0.00010321462945139558,
      "loss": 0.6446,
      "step": 2523
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3692682385444641,
      "learning_rate": 0.00010317613089509144,
      "loss": 0.7546,
      "step": 2524
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3238344192504883,
      "learning_rate": 0.0001031376323387873,
      "loss": 0.8592,
      "step": 2525
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41298216581344604,
      "learning_rate": 0.00010309913378248318,
      "loss": 0.6574,
      "step": 2526
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4157401919364929,
      "learning_rate": 0.00010306063522617901,
      "loss": 0.7527,
      "step": 2527
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.35542717576026917,
      "learning_rate": 0.00010302213666987488,
      "loss": 0.7417,
      "step": 2528
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37594878673553467,
      "learning_rate": 0.00010298363811357075,
      "loss": 0.7002,
      "step": 2529
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3743545114994049,
      "learning_rate": 0.0001029451395572666,
      "loss": 0.9866,
      "step": 2530
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.385532945394516,
      "learning_rate": 0.00010290664100096248,
      "loss": 0.6411,
      "step": 2531
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.32439833879470825,
      "learning_rate": 0.00010286814244465833,
      "loss": 0.9702,
      "step": 2532
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41891902685165405,
      "learning_rate": 0.00010282964388835419,
      "loss": 0.686,
      "step": 2533
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37079358100891113,
      "learning_rate": 0.00010279114533205005,
      "loss": 0.7318,
      "step": 2534
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3408580422401428,
      "learning_rate": 0.00010275264677574592,
      "loss": 0.6818,
      "step": 2535
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.415795236825943,
      "learning_rate": 0.00010271414821944179,
      "loss": 0.723,
      "step": 2536
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4153701364994049,
      "learning_rate": 0.00010267564966313763,
      "loss": 0.8586,
      "step": 2537
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40930286049842834,
      "learning_rate": 0.0001026371511068335,
      "loss": 0.7669,
      "step": 2538
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.38056835532188416,
      "learning_rate": 0.00010259865255052935,
      "loss": 0.6408,
      "step": 2539
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.34456145763397217,
      "learning_rate": 0.00010256015399422523,
      "loss": 0.9255,
      "step": 2540
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41792285442352295,
      "learning_rate": 0.00010252165543792109,
      "loss": 0.6779,
      "step": 2541
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3652982711791992,
      "learning_rate": 0.00010248315688161694,
      "loss": 0.8307,
      "step": 2542
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4799535274505615,
      "learning_rate": 0.0001024446583253128,
      "loss": 0.7321,
      "step": 2543
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.344407856464386,
      "learning_rate": 0.00010240615976900867,
      "loss": 0.8218,
      "step": 2544
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4030497670173645,
      "learning_rate": 0.00010236766121270453,
      "loss": 0.8392,
      "step": 2545
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.43066391348838806,
      "learning_rate": 0.00010232916265640038,
      "loss": 0.8087,
      "step": 2546
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.39469844102859497,
      "learning_rate": 0.00010229066410009624,
      "loss": 0.7308,
      "step": 2547
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3960837721824646,
      "learning_rate": 0.00010225216554379212,
      "loss": 0.67,
      "step": 2548
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4415815472602844,
      "learning_rate": 0.00010221366698748798,
      "loss": 0.6718,
      "step": 2549
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4354984760284424,
      "learning_rate": 0.00010217516843118384,
      "loss": 0.6976,
      "step": 2550
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.45369163155555725,
      "learning_rate": 0.00010213666987487969,
      "loss": 0.8301,
      "step": 2551
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37768101692199707,
      "learning_rate": 0.00010209817131857555,
      "loss": 0.6339,
      "step": 2552
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40513351559638977,
      "learning_rate": 0.00010205967276227142,
      "loss": 0.8907,
      "step": 2553
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4639405608177185,
      "learning_rate": 0.00010202117420596728,
      "loss": 0.9293,
      "step": 2554
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.37537869811058044,
      "learning_rate": 0.00010198267564966314,
      "loss": 0.7818,
      "step": 2555
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3522058129310608,
      "learning_rate": 0.00010194417709335899,
      "loss": 0.7707,
      "step": 2556
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.36954742670059204,
      "learning_rate": 0.00010190567853705487,
      "loss": 0.7296,
      "step": 2557
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.36441275477409363,
      "learning_rate": 0.00010186717998075073,
      "loss": 0.8048,
      "step": 2558
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4324532449245453,
      "learning_rate": 0.00010182868142444659,
      "loss": 0.6628,
      "step": 2559
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4019789397716522,
      "learning_rate": 0.00010179018286814246,
      "loss": 0.7619,
      "step": 2560
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3735848069190979,
      "learning_rate": 0.0001017516843118383,
      "loss": 0.6615,
      "step": 2561
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3188644051551819,
      "learning_rate": 0.00010171318575553417,
      "loss": 0.5551,
      "step": 2562
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40389353036880493,
      "learning_rate": 0.00010167468719923003,
      "loss": 0.7585,
      "step": 2563
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4187348484992981,
      "learning_rate": 0.0001016361886429259,
      "loss": 0.713,
      "step": 2564
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.41641777753829956,
      "learning_rate": 0.00010159769008662177,
      "loss": 0.6782,
      "step": 2565
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.40833693742752075,
      "learning_rate": 0.00010155919153031761,
      "loss": 0.701,
      "step": 2566
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3792363405227661,
      "learning_rate": 0.00010152069297401348,
      "loss": 0.5979,
      "step": 2567
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.378476619720459,
      "learning_rate": 0.00010148219441770934,
      "loss": 0.534,
      "step": 2568
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.46916088461875916,
      "learning_rate": 0.00010144369586140521,
      "loss": 0.7965,
      "step": 2569
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4249125123023987,
      "learning_rate": 0.00010140519730510107,
      "loss": 0.6347,
      "step": 2570
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4129938781261444,
      "learning_rate": 0.00010136669874879692,
      "loss": 0.8744,
      "step": 2571
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4037359058856964,
      "learning_rate": 0.00010132820019249278,
      "loss": 0.7367,
      "step": 2572
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.44239550828933716,
      "learning_rate": 0.00010128970163618866,
      "loss": 0.6232,
      "step": 2573
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4591420292854309,
      "learning_rate": 0.00010125120307988452,
      "loss": 0.7176,
      "step": 2574
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.45397794246673584,
      "learning_rate": 0.00010121270452358038,
      "loss": 0.7016,
      "step": 2575
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4130418300628662,
      "learning_rate": 0.00010117420596727622,
      "loss": 0.7513,
      "step": 2576
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3734782040119171,
      "learning_rate": 0.00010113570741097209,
      "loss": 0.9942,
      "step": 2577
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3790094256401062,
      "learning_rate": 0.00010109720885466796,
      "loss": 0.8067,
      "step": 2578
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3580275774002075,
      "learning_rate": 0.00010105871029836382,
      "loss": 0.8046,
      "step": 2579
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.442428320646286,
      "learning_rate": 0.00010102021174205967,
      "loss": 0.7117,
      "step": 2580
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4331128001213074,
      "learning_rate": 0.00010098171318575553,
      "loss": 0.773,
      "step": 2581
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3999486267566681,
      "learning_rate": 0.0001009432146294514,
      "loss": 0.704,
      "step": 2582
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3880247473716736,
      "learning_rate": 0.00010090471607314727,
      "loss": 0.6745,
      "step": 2583
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4232076406478882,
      "learning_rate": 0.00010086621751684313,
      "loss": 0.8143,
      "step": 2584
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3709017038345337,
      "learning_rate": 0.00010082771896053897,
      "loss": 0.979,
      "step": 2585
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.43612533807754517,
      "learning_rate": 0.00010078922040423483,
      "loss": 0.9127,
      "step": 2586
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.41326287388801575,
      "learning_rate": 0.00010075072184793071,
      "loss": 0.7431,
      "step": 2587
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4031268060207367,
      "learning_rate": 0.00010071222329162657,
      "loss": 0.6836,
      "step": 2588
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3634794354438782,
      "learning_rate": 0.00010067372473532244,
      "loss": 0.7565,
      "step": 2589
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3639274537563324,
      "learning_rate": 0.00010063522617901828,
      "loss": 0.6459,
      "step": 2590
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.421529084444046,
      "learning_rate": 0.00010059672762271415,
      "loss": 0.7654,
      "step": 2591
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.44208401441574097,
      "learning_rate": 0.00010055822906641001,
      "loss": 0.7975,
      "step": 2592
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.39977145195007324,
      "learning_rate": 0.00010051973051010587,
      "loss": 0.6649,
      "step": 2593
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3436776101589203,
      "learning_rate": 0.00010048123195380175,
      "loss": 0.7438,
      "step": 2594
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3004840910434723,
      "learning_rate": 0.0001004427333974976,
      "loss": 0.8425,
      "step": 2595
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3488222360610962,
      "learning_rate": 0.00010040423484119346,
      "loss": 0.6474,
      "step": 2596
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.338974267244339,
      "learning_rate": 0.00010036573628488932,
      "loss": 0.8054,
      "step": 2597
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3887273073196411,
      "learning_rate": 0.0001003272377285852,
      "loss": 0.7395,
      "step": 2598
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.34807851910591125,
      "learning_rate": 0.00010028873917228105,
      "loss": 0.6729,
      "step": 2599
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4023602306842804,
      "learning_rate": 0.0001002502406159769,
      "loss": 0.795,
      "step": 2600
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3544400930404663,
      "learning_rate": 0.00010021174205967276,
      "loss": 0.9121,
      "step": 2601
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4559398889541626,
      "learning_rate": 0.00010017324350336862,
      "loss": 0.8116,
      "step": 2602
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3570156395435333,
      "learning_rate": 0.0001001347449470645,
      "loss": 0.8127,
      "step": 2603
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3253714144229889,
      "learning_rate": 0.00010009624639076036,
      "loss": 0.787,
      "step": 2604
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3904109597206116,
      "learning_rate": 0.0001000577478344562,
      "loss": 0.5813,
      "step": 2605
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3942689001560211,
      "learning_rate": 0.00010001924927815207,
      "loss": 0.8463,
      "step": 2606
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3666599690914154,
      "learning_rate": 9.998075072184794e-05,
      "loss": 0.6241,
      "step": 2607
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.46651968359947205,
      "learning_rate": 9.994225216554379e-05,
      "loss": 0.7011,
      "step": 2608
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.35468071699142456,
      "learning_rate": 9.990375360923966e-05,
      "loss": 0.7134,
      "step": 2609
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4088934063911438,
      "learning_rate": 9.986525505293552e-05,
      "loss": 0.8918,
      "step": 2610
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.45155641436576843,
      "learning_rate": 9.982675649663139e-05,
      "loss": 0.7172,
      "step": 2611
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3660615384578705,
      "learning_rate": 9.978825794032725e-05,
      "loss": 0.6103,
      "step": 2612
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.47046220302581787,
      "learning_rate": 9.97497593840231e-05,
      "loss": 0.7398,
      "step": 2613
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.347634881734848,
      "learning_rate": 9.971126082771897e-05,
      "loss": 0.7151,
      "step": 2614
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3740624189376831,
      "learning_rate": 9.967276227141482e-05,
      "loss": 0.6964,
      "step": 2615
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.34971922636032104,
      "learning_rate": 9.963426371511069e-05,
      "loss": 0.6553,
      "step": 2616
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3481005132198334,
      "learning_rate": 9.959576515880655e-05,
      "loss": 0.9362,
      "step": 2617
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.42597150802612305,
      "learning_rate": 9.955726660250241e-05,
      "loss": 0.6124,
      "step": 2618
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.41528186202049255,
      "learning_rate": 9.951876804619827e-05,
      "loss": 0.9229,
      "step": 2619
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4176585078239441,
      "learning_rate": 9.948026948989413e-05,
      "loss": 0.696,
      "step": 2620
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.543842613697052,
      "learning_rate": 9.944177093359e-05,
      "loss": 0.7197,
      "step": 2621
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3558616042137146,
      "learning_rate": 9.940327237728586e-05,
      "loss": 0.7479,
      "step": 2622
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4272859990596771,
      "learning_rate": 9.936477382098172e-05,
      "loss": 0.9726,
      "step": 2623
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.41532647609710693,
      "learning_rate": 9.932627526467758e-05,
      "loss": 0.669,
      "step": 2624
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.36482369899749756,
      "learning_rate": 9.928777670837344e-05,
      "loss": 0.7795,
      "step": 2625
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.44944584369659424,
      "learning_rate": 9.92492781520693e-05,
      "loss": 0.7122,
      "step": 2626
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39764365553855896,
      "learning_rate": 9.921077959576518e-05,
      "loss": 0.8075,
      "step": 2627
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3625902831554413,
      "learning_rate": 9.917228103946102e-05,
      "loss": 0.6834,
      "step": 2628
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.45909276604652405,
      "learning_rate": 9.913378248315688e-05,
      "loss": 0.812,
      "step": 2629
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42261141538619995,
      "learning_rate": 9.909528392685274e-05,
      "loss": 0.6991,
      "step": 2630
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.43785494565963745,
      "learning_rate": 9.90567853705486e-05,
      "loss": 0.7846,
      "step": 2631
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.34957897663116455,
      "learning_rate": 9.901828681424447e-05,
      "loss": 0.9918,
      "step": 2632
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42457422614097595,
      "learning_rate": 9.897978825794033e-05,
      "loss": 0.7425,
      "step": 2633
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4469139277935028,
      "learning_rate": 9.89412897016362e-05,
      "loss": 0.7189,
      "step": 2634
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4049527943134308,
      "learning_rate": 9.890279114533205e-05,
      "loss": 0.5966,
      "step": 2635
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39370107650756836,
      "learning_rate": 9.886429258902792e-05,
      "loss": 0.741,
      "step": 2636
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.38606467843055725,
      "learning_rate": 9.882579403272377e-05,
      "loss": 0.7689,
      "step": 2637
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4060196578502655,
      "learning_rate": 9.878729547641963e-05,
      "loss": 0.7294,
      "step": 2638
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3409809172153473,
      "learning_rate": 9.874879692011551e-05,
      "loss": 0.7197,
      "step": 2639
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3114698827266693,
      "learning_rate": 9.871029836381135e-05,
      "loss": 0.9107,
      "step": 2640
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.30118328332901,
      "learning_rate": 9.867179980750723e-05,
      "loss": 0.6513,
      "step": 2641
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36824777722358704,
      "learning_rate": 9.863330125120308e-05,
      "loss": 0.726,
      "step": 2642
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36830776929855347,
      "learning_rate": 9.859480269489895e-05,
      "loss": 0.6927,
      "step": 2643
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4871748089790344,
      "learning_rate": 9.855630413859481e-05,
      "loss": 0.6131,
      "step": 2644
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.384880930185318,
      "learning_rate": 9.851780558229067e-05,
      "loss": 0.7973,
      "step": 2645
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39566418528556824,
      "learning_rate": 9.847930702598653e-05,
      "loss": 0.5089,
      "step": 2646
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.34621623158454895,
      "learning_rate": 9.84408084696824e-05,
      "loss": 0.6484,
      "step": 2647
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3409580588340759,
      "learning_rate": 9.840230991337826e-05,
      "loss": 0.7648,
      "step": 2648
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.35811856389045715,
      "learning_rate": 9.83638113570741e-05,
      "loss": 0.6353,
      "step": 2649
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5521526336669922,
      "learning_rate": 9.832531280076998e-05,
      "loss": 0.9373,
      "step": 2650
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.46870702505111694,
      "learning_rate": 9.828681424446584e-05,
      "loss": 0.6894,
      "step": 2651
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5914435386657715,
      "learning_rate": 9.82483156881617e-05,
      "loss": 0.6737,
      "step": 2652
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.40676915645599365,
      "learning_rate": 9.820981713185756e-05,
      "loss": 0.8397,
      "step": 2653
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.44660550355911255,
      "learning_rate": 9.817131857555342e-05,
      "loss": 0.8723,
      "step": 2654
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.49965110421180725,
      "learning_rate": 9.813282001924928e-05,
      "loss": 0.7745,
      "step": 2655
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4054611921310425,
      "learning_rate": 9.809432146294514e-05,
      "loss": 0.8466,
      "step": 2656
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.37791886925697327,
      "learning_rate": 9.8055822906641e-05,
      "loss": 0.8434,
      "step": 2657
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4496481418609619,
      "learning_rate": 9.801732435033687e-05,
      "loss": 0.7264,
      "step": 2658
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4039559066295624,
      "learning_rate": 9.797882579403273e-05,
      "loss": 0.8314,
      "step": 2659
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36064550280570984,
      "learning_rate": 9.794032723772859e-05,
      "loss": 0.6574,
      "step": 2660
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.32746902108192444,
      "learning_rate": 9.790182868142446e-05,
      "loss": 0.814,
      "step": 2661
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.45734986662864685,
      "learning_rate": 9.786333012512031e-05,
      "loss": 0.7732,
      "step": 2662
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4584044814109802,
      "learning_rate": 9.782483156881618e-05,
      "loss": 0.7671,
      "step": 2663
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.42239952087402344,
      "learning_rate": 9.778633301251203e-05,
      "loss": 0.6406,
      "step": 2664
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.39517053961753845,
      "learning_rate": 9.774783445620789e-05,
      "loss": 0.8316,
      "step": 2665
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3856295943260193,
      "learning_rate": 9.770933589990375e-05,
      "loss": 0.7031,
      "step": 2666
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3667305111885071,
      "learning_rate": 9.767083734359961e-05,
      "loss": 0.646,
      "step": 2667
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4343735873699188,
      "learning_rate": 9.763233878729549e-05,
      "loss": 0.7877,
      "step": 2668
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3634078800678253,
      "learning_rate": 9.759384023099134e-05,
      "loss": 0.6541,
      "step": 2669
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4146299958229065,
      "learning_rate": 9.755534167468721e-05,
      "loss": 0.7214,
      "step": 2670
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3450891673564911,
      "learning_rate": 9.751684311838306e-05,
      "loss": 0.7076,
      "step": 2671
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.38791990280151367,
      "learning_rate": 9.747834456207893e-05,
      "loss": 0.68,
      "step": 2672
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.38618192076683044,
      "learning_rate": 9.74398460057748e-05,
      "loss": 0.7117,
      "step": 2673
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.34496501088142395,
      "learning_rate": 9.740134744947065e-05,
      "loss": 0.9315,
      "step": 2674
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4337468147277832,
      "learning_rate": 9.736284889316652e-05,
      "loss": 0.6536,
      "step": 2675
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3299131989479065,
      "learning_rate": 9.732435033686236e-05,
      "loss": 0.695,
      "step": 2676
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.41560354828834534,
      "learning_rate": 9.728585178055824e-05,
      "loss": 0.77,
      "step": 2677
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4055533707141876,
      "learning_rate": 9.724735322425409e-05,
      "loss": 0.8147,
      "step": 2678
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3739679157733917,
      "learning_rate": 9.720885466794996e-05,
      "loss": 0.6544,
      "step": 2679
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38883379101753235,
      "learning_rate": 9.717035611164582e-05,
      "loss": 0.927,
      "step": 2680
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3955147862434387,
      "learning_rate": 9.713185755534168e-05,
      "loss": 0.793,
      "step": 2681
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4074682295322418,
      "learning_rate": 9.709335899903754e-05,
      "loss": 0.7504,
      "step": 2682
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4010629653930664,
      "learning_rate": 9.70548604427334e-05,
      "loss": 0.7805,
      "step": 2683
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5188684463500977,
      "learning_rate": 9.701636188642926e-05,
      "loss": 0.6821,
      "step": 2684
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42911797761917114,
      "learning_rate": 9.697786333012513e-05,
      "loss": 0.7896,
      "step": 2685
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.49286001920700073,
      "learning_rate": 9.693936477382099e-05,
      "loss": 0.7709,
      "step": 2686
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3598155081272125,
      "learning_rate": 9.690086621751685e-05,
      "loss": 0.7135,
      "step": 2687
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3726073205471039,
      "learning_rate": 9.686236766121271e-05,
      "loss": 0.7548,
      "step": 2688
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38944321870803833,
      "learning_rate": 9.682386910490857e-05,
      "loss": 0.8866,
      "step": 2689
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4093657433986664,
      "learning_rate": 9.678537054860443e-05,
      "loss": 0.7013,
      "step": 2690
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.397154301404953,
      "learning_rate": 9.674687199230029e-05,
      "loss": 0.727,
      "step": 2691
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.35011792182922363,
      "learning_rate": 9.670837343599615e-05,
      "loss": 0.8789,
      "step": 2692
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.43300482630729675,
      "learning_rate": 9.666987487969201e-05,
      "loss": 0.7087,
      "step": 2693
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37470895051956177,
      "learning_rate": 9.663137632338787e-05,
      "loss": 0.7031,
      "step": 2694
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.39725247025489807,
      "learning_rate": 9.659287776708374e-05,
      "loss": 0.7727,
      "step": 2695
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3705846667289734,
      "learning_rate": 9.65543792107796e-05,
      "loss": 0.7541,
      "step": 2696
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3693074882030487,
      "learning_rate": 9.651588065447547e-05,
      "loss": 0.5931,
      "step": 2697
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.45383843779563904,
      "learning_rate": 9.647738209817132e-05,
      "loss": 0.63,
      "step": 2698
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4746633768081665,
      "learning_rate": 9.643888354186719e-05,
      "loss": 0.7547,
      "step": 2699
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42711588740348816,
      "learning_rate": 9.640038498556304e-05,
      "loss": 0.9355,
      "step": 2700
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4309035837650299,
      "learning_rate": 9.63618864292589e-05,
      "loss": 0.6263,
      "step": 2701
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3983113169670105,
      "learning_rate": 9.632338787295478e-05,
      "loss": 0.6252,
      "step": 2702
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.40827110409736633,
      "learning_rate": 9.628488931665062e-05,
      "loss": 0.7479,
      "step": 2703
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.35438084602355957,
      "learning_rate": 9.62463907603465e-05,
      "loss": 0.799,
      "step": 2704
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.36741045117378235,
      "learning_rate": 9.620789220404235e-05,
      "loss": 0.7292,
      "step": 2705
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3866897225379944,
      "learning_rate": 9.616939364773822e-05,
      "loss": 0.7394,
      "step": 2706
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4621310830116272,
      "learning_rate": 9.613089509143408e-05,
      "loss": 0.8491,
      "step": 2707
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3753466308116913,
      "learning_rate": 9.609239653512994e-05,
      "loss": 0.7231,
      "step": 2708
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.34718993306159973,
      "learning_rate": 9.60538979788258e-05,
      "loss": 0.8003,
      "step": 2709
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.39184048771858215,
      "learning_rate": 9.601539942252166e-05,
      "loss": 0.8582,
      "step": 2710
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.39735668897628784,
      "learning_rate": 9.597690086621752e-05,
      "loss": 0.6262,
      "step": 2711
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.44474315643310547,
      "learning_rate": 9.593840230991337e-05,
      "loss": 0.8317,
      "step": 2712
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42861032485961914,
      "learning_rate": 9.589990375360925e-05,
      "loss": 0.7156,
      "step": 2713
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3818977177143097,
      "learning_rate": 9.586140519730511e-05,
      "loss": 0.5519,
      "step": 2714
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.46580058336257935,
      "learning_rate": 9.582290664100097e-05,
      "loss": 0.8786,
      "step": 2715
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.35603412985801697,
      "learning_rate": 9.578440808469683e-05,
      "loss": 0.8306,
      "step": 2716
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37628695368766785,
      "learning_rate": 9.574590952839269e-05,
      "loss": 0.6643,
      "step": 2717
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3828714191913605,
      "learning_rate": 9.570741097208855e-05,
      "loss": 1.0173,
      "step": 2718
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37890157103538513,
      "learning_rate": 9.566891241578441e-05,
      "loss": 0.7534,
      "step": 2719
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.41415390372276306,
      "learning_rate": 9.563041385948027e-05,
      "loss": 0.736,
      "step": 2720
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5296254754066467,
      "learning_rate": 9.559191530317613e-05,
      "loss": 0.7179,
      "step": 2721
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3670431971549988,
      "learning_rate": 9.5553416746872e-05,
      "loss": 0.7759,
      "step": 2722
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4312911331653595,
      "learning_rate": 9.551491819056786e-05,
      "loss": 0.6532,
      "step": 2723
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.38563641905784607,
      "learning_rate": 9.547641963426373e-05,
      "loss": 0.8344,
      "step": 2724
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3566568195819855,
      "learning_rate": 9.543792107795958e-05,
      "loss": 0.5668,
      "step": 2725
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.427213191986084,
      "learning_rate": 9.539942252165545e-05,
      "loss": 0.7799,
      "step": 2726
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.34794506430625916,
      "learning_rate": 9.53609239653513e-05,
      "loss": 0.8698,
      "step": 2727
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.49164533615112305,
      "learning_rate": 9.532242540904716e-05,
      "loss": 0.9732,
      "step": 2728
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.41152793169021606,
      "learning_rate": 9.528392685274302e-05,
      "loss": 0.8091,
      "step": 2729
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.46910563111305237,
      "learning_rate": 9.524542829643888e-05,
      "loss": 0.8117,
      "step": 2730
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3341697156429291,
      "learning_rate": 9.520692974013476e-05,
      "loss": 0.6104,
      "step": 2731
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5079325437545776,
      "learning_rate": 9.51684311838306e-05,
      "loss": 0.8432,
      "step": 2732
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.42191705107688904,
      "learning_rate": 9.512993262752648e-05,
      "loss": 0.6476,
      "step": 2733
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4585024416446686,
      "learning_rate": 9.509143407122233e-05,
      "loss": 0.7879,
      "step": 2734
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4160514771938324,
      "learning_rate": 9.50529355149182e-05,
      "loss": 0.5466,
      "step": 2735
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41245535016059875,
      "learning_rate": 9.501443695861406e-05,
      "loss": 0.6672,
      "step": 2736
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4548846185207367,
      "learning_rate": 9.497593840230991e-05,
      "loss": 1.051,
      "step": 2737
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41005784273147583,
      "learning_rate": 9.493743984600578e-05,
      "loss": 0.5998,
      "step": 2738
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4560503363609314,
      "learning_rate": 9.489894128970163e-05,
      "loss": 0.7634,
      "step": 2739
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4302331209182739,
      "learning_rate": 9.48604427333975e-05,
      "loss": 0.7022,
      "step": 2740
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.40021786093711853,
      "learning_rate": 9.482194417709335e-05,
      "loss": 0.5809,
      "step": 2741
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4216630458831787,
      "learning_rate": 9.478344562078923e-05,
      "loss": 0.7119,
      "step": 2742
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3351995050907135,
      "learning_rate": 9.474494706448509e-05,
      "loss": 0.8031,
      "step": 2743
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3647398352622986,
      "learning_rate": 9.470644850818095e-05,
      "loss": 0.7588,
      "step": 2744
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.378101646900177,
      "learning_rate": 9.466794995187681e-05,
      "loss": 0.5223,
      "step": 2745
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4245156943798065,
      "learning_rate": 9.462945139557267e-05,
      "loss": 0.6944,
      "step": 2746
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.42838868498802185,
      "learning_rate": 9.459095283926853e-05,
      "loss": 0.727,
      "step": 2747
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3747614324092865,
      "learning_rate": 9.45524542829644e-05,
      "loss": 0.7866,
      "step": 2748
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3732750713825226,
      "learning_rate": 9.451395572666026e-05,
      "loss": 0.6618,
      "step": 2749
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4157002568244934,
      "learning_rate": 9.447545717035612e-05,
      "loss": 0.8388,
      "step": 2750
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4553559720516205,
      "learning_rate": 9.443695861405198e-05,
      "loss": 0.7207,
      "step": 2751
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.37897419929504395,
      "learning_rate": 9.439846005774784e-05,
      "loss": 0.707,
      "step": 2752
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.46221840381622314,
      "learning_rate": 9.43599615014437e-05,
      "loss": 0.8537,
      "step": 2753
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.42768946290016174,
      "learning_rate": 9.432146294513956e-05,
      "loss": 0.9237,
      "step": 2754
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4406779408454895,
      "learning_rate": 9.428296438883542e-05,
      "loss": 0.5678,
      "step": 2755
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41388893127441406,
      "learning_rate": 9.424446583253128e-05,
      "loss": 0.655,
      "step": 2756
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.408597469329834,
      "learning_rate": 9.420596727622714e-05,
      "loss": 0.6185,
      "step": 2757
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45803266763687134,
      "learning_rate": 9.4167468719923e-05,
      "loss": 0.6642,
      "step": 2758
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45868343114852905,
      "learning_rate": 9.412897016361886e-05,
      "loss": 0.913,
      "step": 2759
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4235965311527252,
      "learning_rate": 9.409047160731474e-05,
      "loss": 0.7288,
      "step": 2760
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4753710925579071,
      "learning_rate": 9.405197305101059e-05,
      "loss": 0.7407,
      "step": 2761
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45380404591560364,
      "learning_rate": 9.401347449470646e-05,
      "loss": 0.5757,
      "step": 2762
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4321337938308716,
      "learning_rate": 9.397497593840231e-05,
      "loss": 0.6363,
      "step": 2763
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.46082526445388794,
      "learning_rate": 9.393647738209817e-05,
      "loss": 0.5783,
      "step": 2764
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41777241230010986,
      "learning_rate": 9.389797882579404e-05,
      "loss": 0.7253,
      "step": 2765
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.35176077485084534,
      "learning_rate": 9.385948026948989e-05,
      "loss": 0.7682,
      "step": 2766
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.45977091789245605,
      "learning_rate": 9.382098171318577e-05,
      "loss": 0.6427,
      "step": 2767
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41520360112190247,
      "learning_rate": 9.378248315688161e-05,
      "loss": 0.6642,
      "step": 2768
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.37321650981903076,
      "learning_rate": 9.374398460057749e-05,
      "loss": 0.7177,
      "step": 2769
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.36918535828590393,
      "learning_rate": 9.370548604427335e-05,
      "loss": 0.6132,
      "step": 2770
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4034837782382965,
      "learning_rate": 9.366698748796921e-05,
      "loss": 0.8139,
      "step": 2771
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3515503704547882,
      "learning_rate": 9.362848893166507e-05,
      "loss": 0.8852,
      "step": 2772
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4351012110710144,
      "learning_rate": 9.358999037536092e-05,
      "loss": 0.7767,
      "step": 2773
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.470998078584671,
      "learning_rate": 9.355149181905679e-05,
      "loss": 0.6098,
      "step": 2774
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.33775222301483154,
      "learning_rate": 9.351299326275264e-05,
      "loss": 0.6776,
      "step": 2775
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.40457963943481445,
      "learning_rate": 9.347449470644852e-05,
      "loss": 0.6759,
      "step": 2776
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3728804588317871,
      "learning_rate": 9.343599615014438e-05,
      "loss": 0.5816,
      "step": 2777
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3660212457180023,
      "learning_rate": 9.339749759384024e-05,
      "loss": 0.7322,
      "step": 2778
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3984057903289795,
      "learning_rate": 9.33589990375361e-05,
      "loss": 0.913,
      "step": 2779
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3831469714641571,
      "learning_rate": 9.332050048123196e-05,
      "loss": 0.7803,
      "step": 2780
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3171207010746002,
      "learning_rate": 9.328200192492782e-05,
      "loss": 0.7339,
      "step": 2781
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.37906327843666077,
      "learning_rate": 9.324350336862368e-05,
      "loss": 0.7626,
      "step": 2782
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4031168222427368,
      "learning_rate": 9.320500481231954e-05,
      "loss": 0.6172,
      "step": 2783
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.48304930329322815,
      "learning_rate": 9.31665062560154e-05,
      "loss": 0.6892,
      "step": 2784
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5125494599342346,
      "learning_rate": 9.312800769971126e-05,
      "loss": 0.7633,
      "step": 2785
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3571116328239441,
      "learning_rate": 9.308950914340712e-05,
      "loss": 0.8318,
      "step": 2786
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3991086483001709,
      "learning_rate": 9.3051010587103e-05,
      "loss": 0.7324,
      "step": 2787
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.45366477966308594,
      "learning_rate": 9.301251203079885e-05,
      "loss": 0.8019,
      "step": 2788
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4745069444179535,
      "learning_rate": 9.297401347449471e-05,
      "loss": 0.7918,
      "step": 2789
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6458076238632202,
      "learning_rate": 9.293551491819057e-05,
      "loss": 0.6993,
      "step": 2790
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36458152532577515,
      "learning_rate": 9.289701636188643e-05,
      "loss": 0.717,
      "step": 2791
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36609095335006714,
      "learning_rate": 9.285851780558229e-05,
      "loss": 0.7263,
      "step": 2792
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.39812082052230835,
      "learning_rate": 9.282001924927815e-05,
      "loss": 0.8768,
      "step": 2793
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3899972140789032,
      "learning_rate": 9.278152069297403e-05,
      "loss": 0.6938,
      "step": 2794
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.38520726561546326,
      "learning_rate": 9.274302213666987e-05,
      "loss": 0.8575,
      "step": 2795
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3379688262939453,
      "learning_rate": 9.270452358036575e-05,
      "loss": 0.7282,
      "step": 2796
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4168599843978882,
      "learning_rate": 9.26660250240616e-05,
      "loss": 0.7604,
      "step": 2797
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4539785385131836,
      "learning_rate": 9.262752646775747e-05,
      "loss": 0.7912,
      "step": 2798
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.40116366744041443,
      "learning_rate": 9.258902791145333e-05,
      "loss": 0.8382,
      "step": 2799
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4303094744682312,
      "learning_rate": 9.255052935514918e-05,
      "loss": 0.8188,
      "step": 2800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.44493377208709717,
      "learning_rate": 9.251203079884505e-05,
      "loss": 0.7916,
      "step": 2801
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3810407817363739,
      "learning_rate": 9.24735322425409e-05,
      "loss": 0.7109,
      "step": 2802
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.419050395488739,
      "learning_rate": 9.243503368623678e-05,
      "loss": 0.7605,
      "step": 2803
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.38970908522605896,
      "learning_rate": 9.239653512993262e-05,
      "loss": 0.6512,
      "step": 2804
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3724699914455414,
      "learning_rate": 9.23580365736285e-05,
      "loss": 0.699,
      "step": 2805
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4833805561065674,
      "learning_rate": 9.231953801732436e-05,
      "loss": 0.8053,
      "step": 2806
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3950551748275757,
      "learning_rate": 9.228103946102022e-05,
      "loss": 0.7248,
      "step": 2807
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3381422162055969,
      "learning_rate": 9.224254090471608e-05,
      "loss": 0.8029,
      "step": 2808
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4003801643848419,
      "learning_rate": 9.220404234841194e-05,
      "loss": 0.792,
      "step": 2809
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4134269654750824,
      "learning_rate": 9.21655437921078e-05,
      "loss": 0.7153,
      "step": 2810
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3668113052845001,
      "learning_rate": 9.212704523580366e-05,
      "loss": 0.7811,
      "step": 2811
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4028051793575287,
      "learning_rate": 9.208854667949952e-05,
      "loss": 0.9382,
      "step": 2812
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3918861150741577,
      "learning_rate": 9.205004812319538e-05,
      "loss": 0.6874,
      "step": 2813
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3845873475074768,
      "learning_rate": 9.201154956689125e-05,
      "loss": 0.5873,
      "step": 2814
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.388715535402298,
      "learning_rate": 9.197305101058711e-05,
      "loss": 0.6755,
      "step": 2815
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.35740038752555847,
      "learning_rate": 9.193455245428297e-05,
      "loss": 0.8547,
      "step": 2816
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4041628837585449,
      "learning_rate": 9.189605389797883e-05,
      "loss": 0.7188,
      "step": 2817
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.46415743231773376,
      "learning_rate": 9.185755534167469e-05,
      "loss": 0.8829,
      "step": 2818
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.365942120552063,
      "learning_rate": 9.181905678537055e-05,
      "loss": 0.8705,
      "step": 2819
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3230234980583191,
      "learning_rate": 9.178055822906641e-05,
      "loss": 0.5913,
      "step": 2820
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.485588937997818,
      "learning_rate": 9.174205967276227e-05,
      "loss": 0.8193,
      "step": 2821
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3983975946903229,
      "learning_rate": 9.170356111645813e-05,
      "loss": 0.7545,
      "step": 2822
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4771266579627991,
      "learning_rate": 9.166506256015401e-05,
      "loss": 0.6723,
      "step": 2823
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.37741178274154663,
      "learning_rate": 9.162656400384986e-05,
      "loss": 0.7654,
      "step": 2824
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3860509991645813,
      "learning_rate": 9.158806544754572e-05,
      "loss": 0.8365,
      "step": 2825
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3375798165798187,
      "learning_rate": 9.154956689124158e-05,
      "loss": 0.6837,
      "step": 2826
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36191824078559875,
      "learning_rate": 9.151106833493744e-05,
      "loss": 0.684,
      "step": 2827
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.40673625469207764,
      "learning_rate": 9.147256977863331e-05,
      "loss": 0.7576,
      "step": 2828
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4260772168636322,
      "learning_rate": 9.143407122232916e-05,
      "loss": 0.6361,
      "step": 2829
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.38121578097343445,
      "learning_rate": 9.139557266602504e-05,
      "loss": 0.7469,
      "step": 2830
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5164923667907715,
      "learning_rate": 9.135707410972088e-05,
      "loss": 0.6234,
      "step": 2831
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.395438015460968,
      "learning_rate": 9.131857555341676e-05,
      "loss": 0.7412,
      "step": 2832
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3232191801071167,
      "learning_rate": 9.128007699711262e-05,
      "loss": 0.5848,
      "step": 2833
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5802314877510071,
      "learning_rate": 9.124157844080848e-05,
      "loss": 0.6819,
      "step": 2834
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.44517797231674194,
      "learning_rate": 9.120307988450434e-05,
      "loss": 0.6694,
      "step": 2835
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.42143067717552185,
      "learning_rate": 9.116458132820019e-05,
      "loss": 0.6637,
      "step": 2836
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.43481990694999695,
      "learning_rate": 9.112608277189606e-05,
      "loss": 0.722,
      "step": 2837
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3496464192867279,
      "learning_rate": 9.108758421559191e-05,
      "loss": 0.7902,
      "step": 2838
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4002549350261688,
      "learning_rate": 9.104908565928778e-05,
      "loss": 0.8588,
      "step": 2839
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36089980602264404,
      "learning_rate": 9.101058710298364e-05,
      "loss": 0.7507,
      "step": 2840
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4186657965183258,
      "learning_rate": 9.09720885466795e-05,
      "loss": 0.7434,
      "step": 2841
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.35271862149238586,
      "learning_rate": 9.093358999037537e-05,
      "loss": 0.6929,
      "step": 2842
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.44647592306137085,
      "learning_rate": 9.089509143407123e-05,
      "loss": 0.7317,
      "step": 2843
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.37427327036857605,
      "learning_rate": 9.085659287776709e-05,
      "loss": 0.7493,
      "step": 2844
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.41690152883529663,
      "learning_rate": 9.081809432146295e-05,
      "loss": 0.6794,
      "step": 2845
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3804219365119934,
      "learning_rate": 9.077959576515881e-05,
      "loss": 0.7332,
      "step": 2846
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33989498019218445,
      "learning_rate": 9.074109720885467e-05,
      "loss": 0.7037,
      "step": 2847
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4020856022834778,
      "learning_rate": 9.070259865255053e-05,
      "loss": 0.8182,
      "step": 2848
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.35108479857444763,
      "learning_rate": 9.06641000962464e-05,
      "loss": 0.6341,
      "step": 2849
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33928540349006653,
      "learning_rate": 9.062560153994227e-05,
      "loss": 0.6192,
      "step": 2850
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33077698945999146,
      "learning_rate": 9.058710298363812e-05,
      "loss": 0.8419,
      "step": 2851
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.34697359800338745,
      "learning_rate": 9.054860442733398e-05,
      "loss": 0.7431,
      "step": 2852
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4845176041126251,
      "learning_rate": 9.051010587102984e-05,
      "loss": 0.6786,
      "step": 2853
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.41932523250579834,
      "learning_rate": 9.04716073147257e-05,
      "loss": 0.5909,
      "step": 2854
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3865486979484558,
      "learning_rate": 9.043310875842156e-05,
      "loss": 0.801,
      "step": 2855
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3709048628807068,
      "learning_rate": 9.039461020211742e-05,
      "loss": 0.7462,
      "step": 2856
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4040481746196747,
      "learning_rate": 9.03561116458133e-05,
      "loss": 0.7955,
      "step": 2857
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4533383846282959,
      "learning_rate": 9.031761308950914e-05,
      "loss": 0.6527,
      "step": 2858
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.40524983406066895,
      "learning_rate": 9.027911453320502e-05,
      "loss": 0.8632,
      "step": 2859
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4301786422729492,
      "learning_rate": 9.024061597690086e-05,
      "loss": 0.7756,
      "step": 2860
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36955997347831726,
      "learning_rate": 9.020211742059674e-05,
      "loss": 0.5456,
      "step": 2861
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.45608827471733093,
      "learning_rate": 9.01636188642926e-05,
      "loss": 0.7914,
      "step": 2862
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.32765597105026245,
      "learning_rate": 9.012512030798845e-05,
      "loss": 0.6205,
      "step": 2863
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.340890496969223,
      "learning_rate": 9.008662175168432e-05,
      "loss": 0.8615,
      "step": 2864
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.437499463558197,
      "learning_rate": 9.004812319538017e-05,
      "loss": 0.8559,
      "step": 2865
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36097609996795654,
      "learning_rate": 9.000962463907604e-05,
      "loss": 0.7927,
      "step": 2866
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4326573610305786,
      "learning_rate": 8.997112608277189e-05,
      "loss": 0.6842,
      "step": 2867
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4294595420360565,
      "learning_rate": 8.993262752646777e-05,
      "loss": 0.7752,
      "step": 2868
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.31293976306915283,
      "learning_rate": 8.989412897016363e-05,
      "loss": 0.8118,
      "step": 2869
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3660814166069031,
      "learning_rate": 8.985563041385949e-05,
      "loss": 1.0256,
      "step": 2870
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4098501205444336,
      "learning_rate": 8.981713185755535e-05,
      "loss": 0.7164,
      "step": 2871
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4167764186859131,
      "learning_rate": 8.97786333012512e-05,
      "loss": 0.7051,
      "step": 2872
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.42730122804641724,
      "learning_rate": 8.974013474494707e-05,
      "loss": 0.6536,
      "step": 2873
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4070715308189392,
      "learning_rate": 8.970163618864293e-05,
      "loss": 0.6284,
      "step": 2874
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.539680540561676,
      "learning_rate": 8.966313763233879e-05,
      "loss": 0.7446,
      "step": 2875
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3918716013431549,
      "learning_rate": 8.962463907603465e-05,
      "loss": 0.8508,
      "step": 2876
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.36316877603530884,
      "learning_rate": 8.958614051973051e-05,
      "loss": 0.7058,
      "step": 2877
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3337201476097107,
      "learning_rate": 8.954764196342638e-05,
      "loss": 0.8747,
      "step": 2878
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4683586061000824,
      "learning_rate": 8.950914340712224e-05,
      "loss": 0.8371,
      "step": 2879
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3896545469760895,
      "learning_rate": 8.94706448508181e-05,
      "loss": 0.8585,
      "step": 2880
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3878212571144104,
      "learning_rate": 8.943214629451396e-05,
      "loss": 0.6601,
      "step": 2881
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.34758320450782776,
      "learning_rate": 8.939364773820982e-05,
      "loss": 0.6657,
      "step": 2882
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4290383458137512,
      "learning_rate": 8.935514918190568e-05,
      "loss": 1.0621,
      "step": 2883
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.40262433886528015,
      "learning_rate": 8.931665062560154e-05,
      "loss": 0.7208,
      "step": 2884
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3899232745170593,
      "learning_rate": 8.92781520692974e-05,
      "loss": 0.6483,
      "step": 2885
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3759238123893738,
      "learning_rate": 8.923965351299328e-05,
      "loss": 0.7801,
      "step": 2886
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.42231032252311707,
      "learning_rate": 8.920115495668912e-05,
      "loss": 0.8101,
      "step": 2887
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3559333086013794,
      "learning_rate": 8.916265640038499e-05,
      "loss": 0.8507,
      "step": 2888
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.46276184916496277,
      "learning_rate": 8.912415784408085e-05,
      "loss": 0.7832,
      "step": 2889
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40699031949043274,
      "learning_rate": 8.908565928777671e-05,
      "loss": 0.6677,
      "step": 2890
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.37261641025543213,
      "learning_rate": 8.904716073147258e-05,
      "loss": 0.7519,
      "step": 2891
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3761143088340759,
      "learning_rate": 8.900866217516843e-05,
      "loss": 0.6834,
      "step": 2892
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.49081575870513916,
      "learning_rate": 8.89701636188643e-05,
      "loss": 0.6296,
      "step": 2893
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.48830530047416687,
      "learning_rate": 8.893166506256015e-05,
      "loss": 0.7815,
      "step": 2894
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40555036067962646,
      "learning_rate": 8.889316650625603e-05,
      "loss": 0.7023,
      "step": 2895
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3409014940261841,
      "learning_rate": 8.885466794995189e-05,
      "loss": 0.679,
      "step": 2896
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.34803691506385803,
      "learning_rate": 8.881616939364775e-05,
      "loss": 0.667,
      "step": 2897
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.34251976013183594,
      "learning_rate": 8.877767083734361e-05,
      "loss": 0.9499,
      "step": 2898
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3937492072582245,
      "learning_rate": 8.873917228103946e-05,
      "loss": 0.847,
      "step": 2899
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3814133405685425,
      "learning_rate": 8.870067372473533e-05,
      "loss": 0.919,
      "step": 2900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3986157476902008,
      "learning_rate": 8.866217516843118e-05,
      "loss": 0.7099,
      "step": 2901
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5054865479469299,
      "learning_rate": 8.862367661212705e-05,
      "loss": 0.6952,
      "step": 2902
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3693200349807739,
      "learning_rate": 8.858517805582291e-05,
      "loss": 0.9969,
      "step": 2903
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4748612940311432,
      "learning_rate": 8.854667949951877e-05,
      "loss": 0.6979,
      "step": 2904
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5188175439834595,
      "learning_rate": 8.850818094321464e-05,
      "loss": 0.7108,
      "step": 2905
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4080547094345093,
      "learning_rate": 8.84696823869105e-05,
      "loss": 0.695,
      "step": 2906
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3473585247993469,
      "learning_rate": 8.843118383060636e-05,
      "loss": 0.8173,
      "step": 2907
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.39433586597442627,
      "learning_rate": 8.839268527430222e-05,
      "loss": 0.7416,
      "step": 2908
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.43010690808296204,
      "learning_rate": 8.835418671799808e-05,
      "loss": 0.8107,
      "step": 2909
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.43029510974884033,
      "learning_rate": 8.831568816169394e-05,
      "loss": 0.6944,
      "step": 2910
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3851475119590759,
      "learning_rate": 8.82771896053898e-05,
      "loss": 0.8442,
      "step": 2911
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.34610864520072937,
      "learning_rate": 8.823869104908566e-05,
      "loss": 0.8208,
      "step": 2912
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.39209821820259094,
      "learning_rate": 8.820019249278154e-05,
      "loss": 0.5828,
      "step": 2913
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5107370615005493,
      "learning_rate": 8.816169393647738e-05,
      "loss": 0.7525,
      "step": 2914
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3296544849872589,
      "learning_rate": 8.812319538017325e-05,
      "loss": 0.7437,
      "step": 2915
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3933621346950531,
      "learning_rate": 8.80846968238691e-05,
      "loss": 0.7657,
      "step": 2916
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.37629860639572144,
      "learning_rate": 8.804619826756497e-05,
      "loss": 0.9121,
      "step": 2917
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.47256308794021606,
      "learning_rate": 8.800769971126083e-05,
      "loss": 0.7634,
      "step": 2918
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3793465495109558,
      "learning_rate": 8.796920115495669e-05,
      "loss": 0.6526,
      "step": 2919
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5061706900596619,
      "learning_rate": 8.793070259865256e-05,
      "loss": 0.6716,
      "step": 2920
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.35709261894226074,
      "learning_rate": 8.789220404234841e-05,
      "loss": 0.8166,
      "step": 2921
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.36971381306648254,
      "learning_rate": 8.785370548604429e-05,
      "loss": 0.7874,
      "step": 2922
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.32395830750465393,
      "learning_rate": 8.781520692974013e-05,
      "loss": 0.7758,
      "step": 2923
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.38003313541412354,
      "learning_rate": 8.7776708373436e-05,
      "loss": 0.6717,
      "step": 2924
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.41731560230255127,
      "learning_rate": 8.773820981713187e-05,
      "loss": 0.6497,
      "step": 2925
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5238102078437805,
      "learning_rate": 8.769971126082772e-05,
      "loss": 0.851,
      "step": 2926
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40814730525016785,
      "learning_rate": 8.766121270452359e-05,
      "loss": 0.7649,
      "step": 2927
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.42083796858787537,
      "learning_rate": 8.762271414821944e-05,
      "loss": 0.577,
      "step": 2928
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.44320690631866455,
      "learning_rate": 8.758421559191531e-05,
      "loss": 0.8005,
      "step": 2929
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4579533040523529,
      "learning_rate": 8.754571703561116e-05,
      "loss": 0.7082,
      "step": 2930
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.35686010122299194,
      "learning_rate": 8.750721847930703e-05,
      "loss": 0.65,
      "step": 2931
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3632524013519287,
      "learning_rate": 8.74687199230029e-05,
      "loss": 0.6835,
      "step": 2932
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4755534827709198,
      "learning_rate": 8.743022136669876e-05,
      "loss": 0.8268,
      "step": 2933
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3900643587112427,
      "learning_rate": 8.739172281039462e-05,
      "loss": 0.7471,
      "step": 2934
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.39191409945487976,
      "learning_rate": 8.735322425409046e-05,
      "loss": 0.8015,
      "step": 2935
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.47083425521850586,
      "learning_rate": 8.731472569778634e-05,
      "loss": 0.6387,
      "step": 2936
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3882507383823395,
      "learning_rate": 8.72762271414822e-05,
      "loss": 0.9305,
      "step": 2937
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3471020460128784,
      "learning_rate": 8.723772858517806e-05,
      "loss": 0.7584,
      "step": 2938
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.464735746383667,
      "learning_rate": 8.719923002887392e-05,
      "loss": 0.8403,
      "step": 2939
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4831490218639374,
      "learning_rate": 8.716073147256978e-05,
      "loss": 0.6777,
      "step": 2940
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.405985563993454,
      "learning_rate": 8.712223291626564e-05,
      "loss": 0.7235,
      "step": 2941
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39689281582832336,
      "learning_rate": 8.70837343599615e-05,
      "loss": 1.0458,
      "step": 2942
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4091799557209015,
      "learning_rate": 8.704523580365737e-05,
      "loss": 0.7484,
      "step": 2943
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3654005825519562,
      "learning_rate": 8.700673724735323e-05,
      "loss": 0.8205,
      "step": 2944
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3939017653465271,
      "learning_rate": 8.696823869104909e-05,
      "loss": 0.5875,
      "step": 2945
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.44400614500045776,
      "learning_rate": 8.692974013474495e-05,
      "loss": 0.8277,
      "step": 2946
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4408559799194336,
      "learning_rate": 8.689124157844081e-05,
      "loss": 0.7862,
      "step": 2947
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.36650896072387695,
      "learning_rate": 8.685274302213667e-05,
      "loss": 0.6283,
      "step": 2948
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4378194808959961,
      "learning_rate": 8.681424446583255e-05,
      "loss": 0.8628,
      "step": 2949
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3790963590145111,
      "learning_rate": 8.677574590952839e-05,
      "loss": 0.6326,
      "step": 2950
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39199042320251465,
      "learning_rate": 8.673724735322425e-05,
      "loss": 0.7979,
      "step": 2951
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3936658799648285,
      "learning_rate": 8.669874879692012e-05,
      "loss": 0.6993,
      "step": 2952
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.36705565452575684,
      "learning_rate": 8.666025024061598e-05,
      "loss": 0.7377,
      "step": 2953
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3873213827610016,
      "learning_rate": 8.662175168431185e-05,
      "loss": 0.772,
      "step": 2954
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4524272680282593,
      "learning_rate": 8.65832531280077e-05,
      "loss": 0.5508,
      "step": 2955
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.44556063413619995,
      "learning_rate": 8.654475457170357e-05,
      "loss": 0.713,
      "step": 2956
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39351359009742737,
      "learning_rate": 8.650625601539942e-05,
      "loss": 0.6233,
      "step": 2957
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3622664511203766,
      "learning_rate": 8.64677574590953e-05,
      "loss": 0.8046,
      "step": 2958
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.42846745252609253,
      "learning_rate": 8.642925890279116e-05,
      "loss": 0.8084,
      "step": 2959
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3746493458747864,
      "learning_rate": 8.639076034648702e-05,
      "loss": 0.8529,
      "step": 2960
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.37741994857788086,
      "learning_rate": 8.635226179018288e-05,
      "loss": 0.858,
      "step": 2961
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3826678991317749,
      "learning_rate": 8.631376323387872e-05,
      "loss": 0.7145,
      "step": 2962
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.45306047797203064,
      "learning_rate": 8.62752646775746e-05,
      "loss": 0.8812,
      "step": 2963
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.415784627199173,
      "learning_rate": 8.623676612127045e-05,
      "loss": 0.7826,
      "step": 2964
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39615491032600403,
      "learning_rate": 8.619826756496632e-05,
      "loss": 0.7365,
      "step": 2965
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.38244518637657166,
      "learning_rate": 8.615976900866218e-05,
      "loss": 0.7028,
      "step": 2966
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6230850219726562,
      "learning_rate": 8.612127045235804e-05,
      "loss": 0.7848,
      "step": 2967
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3664399981498718,
      "learning_rate": 8.60827718960539e-05,
      "loss": 0.8981,
      "step": 2968
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5149267315864563,
      "learning_rate": 8.604427333974977e-05,
      "loss": 0.6785,
      "step": 2969
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3640612065792084,
      "learning_rate": 8.600577478344563e-05,
      "loss": 0.7897,
      "step": 2970
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39035215973854065,
      "learning_rate": 8.596727622714149e-05,
      "loss": 0.7535,
      "step": 2971
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.43723925948143005,
      "learning_rate": 8.592877767083735e-05,
      "loss": 0.7027,
      "step": 2972
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.48142871260643005,
      "learning_rate": 8.589027911453321e-05,
      "loss": 0.7661,
      "step": 2973
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.434040904045105,
      "learning_rate": 8.585178055822907e-05,
      "loss": 0.8681,
      "step": 2974
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.37783241271972656,
      "learning_rate": 8.581328200192493e-05,
      "loss": 0.6025,
      "step": 2975
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.40306907892227173,
      "learning_rate": 8.577478344562079e-05,
      "loss": 0.7614,
      "step": 2976
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.37107524275779724,
      "learning_rate": 8.573628488931665e-05,
      "loss": 0.7245,
      "step": 2977
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4057290554046631,
      "learning_rate": 8.569778633301251e-05,
      "loss": 0.8704,
      "step": 2978
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39799946546554565,
      "learning_rate": 8.565928777670837e-05,
      "loss": 0.5533,
      "step": 2979
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.331628680229187,
      "learning_rate": 8.562078922040424e-05,
      "loss": 0.7831,
      "step": 2980
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3970165252685547,
      "learning_rate": 8.55822906641001e-05,
      "loss": 0.708,
      "step": 2981
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4301331043243408,
      "learning_rate": 8.554379210779596e-05,
      "loss": 0.6718,
      "step": 2982
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.33409005403518677,
      "learning_rate": 8.550529355149183e-05,
      "loss": 0.7458,
      "step": 2983
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3594038188457489,
      "learning_rate": 8.546679499518768e-05,
      "loss": 0.7709,
      "step": 2984
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.38728198409080505,
      "learning_rate": 8.542829643888355e-05,
      "loss": 0.7095,
      "step": 2985
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3721837103366852,
      "learning_rate": 8.53897978825794e-05,
      "loss": 0.7444,
      "step": 2986
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3624342679977417,
      "learning_rate": 8.535129932627526e-05,
      "loss": 0.7857,
      "step": 2987
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3952600359916687,
      "learning_rate": 8.531280076997114e-05,
      "loss": 0.7385,
      "step": 2988
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.3612956404685974,
      "learning_rate": 8.527430221366698e-05,
      "loss": 0.865,
      "step": 2989
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.335948646068573,
      "learning_rate": 8.523580365736286e-05,
      "loss": 0.6928,
      "step": 2990
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3487108647823334,
      "learning_rate": 8.51973051010587e-05,
      "loss": 0.8617,
      "step": 2991
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.36239027976989746,
      "learning_rate": 8.515880654475458e-05,
      "loss": 0.6305,
      "step": 2992
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4028669595718384,
      "learning_rate": 8.512030798845043e-05,
      "loss": 0.724,
      "step": 2993
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.37176331877708435,
      "learning_rate": 8.50818094321463e-05,
      "loss": 0.5042,
      "step": 2994
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.34827330708503723,
      "learning_rate": 8.504331087584216e-05,
      "loss": 0.7105,
      "step": 2995
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.41380688548088074,
      "learning_rate": 8.500481231953803e-05,
      "loss": 0.8361,
      "step": 2996
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.30160510540008545,
      "learning_rate": 8.496631376323389e-05,
      "loss": 0.6831,
      "step": 2997
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.40283289551734924,
      "learning_rate": 8.492781520692973e-05,
      "loss": 0.8428,
      "step": 2998
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.38722291588783264,
      "learning_rate": 8.488931665062561e-05,
      "loss": 0.7629,
      "step": 2999
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3990435004234314,
      "learning_rate": 8.485081809432147e-05,
      "loss": 0.9541,
      "step": 3000
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 1.6254093085581312e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6730445651651363,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.9766390323638916,
      "learning_rate": 4e-05,
      "loss": 1.7634,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.435124397277832,
      "learning_rate": 8e-05,
      "loss": 1.6829,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.5236518383026123,
      "learning_rate": 0.00012,
      "loss": 1.6805,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1257619857788086,
      "learning_rate": 0.00016,
      "loss": 1.7545,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.0642006397247314,
      "learning_rate": 0.0002,
      "loss": 1.6766,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.411266565322876,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.5088,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.639124631881714,
      "learning_rate": 0.00019992300288739173,
      "loss": 1.2468,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2554538249969482,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.0573,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1159424781799316,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.182,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9325945377349854,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.0295,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9144940376281738,
      "learning_rate": 0.00019976900866217518,
      "loss": 0.8971,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.706571340560913,
      "learning_rate": 0.00019973051010587105,
      "loss": 0.7713,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.6338694095611572,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.0035,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.232801079750061,
      "learning_rate": 0.00019965351299326277,
      "loss": 0.8582,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3732980489730835,
      "learning_rate": 0.00019961501443695862,
      "loss": 0.6596,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1462560892105103,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9916,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0849612951278687,
      "learning_rate": 0.00019953801732435037,
      "loss": 0.8837,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2592130899429321,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.9541,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2652932405471802,
      "learning_rate": 0.00019946102021174206,
      "loss": 0.9224,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3635163307189941,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.7145,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.273509979248047,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9682,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0948615074157715,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.6891,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.515223979949951,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.7041,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4680339097976685,
      "learning_rate": 0.00019926852743022138,
      "loss": 0.83,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2920639514923096,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.7418,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4675650596618652,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8998,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.405659794807434,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.5813,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2196124792099,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.7399,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.995840072631836,
      "learning_rate": 0.00019907603464870067,
      "loss": 1.1377,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8859715461730957,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.6972,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2927278280258179,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7877,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2092667818069458,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.924,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0641872882843018,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.844,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2754861116409302,
      "learning_rate": 0.00019888354186718,
      "loss": 0.833,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4720009565353394,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.6683,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1312196254730225,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7498,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4843389987945557,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.6933,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.737054467201233,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.8828,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.621341347694397,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.9389,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.10187566280365,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.6188,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1402729749679565,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.705,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.300221562385559,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.7825,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.351014494895935,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.691,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.7262177467346191,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.7756,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4864147901535034,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7574,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5389310121536255,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.7553,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6697019338607788,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.4816,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8021868467330933,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.5162,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5151989459991455,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.8018,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4660720825195312,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7437,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4324597120285034,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7255,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3882066011428833,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.7743,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1289256811141968,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.5449,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6433510780334473,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.615,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0964218378067017,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.9441,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0598076581954956,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.599,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1570210456848145,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.9157,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3224908113479614,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.757,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.027965545654297,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.9405,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0639221668243408,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8265,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3123269081115723,
      "learning_rate": 0.00019784408084696825,
      "loss": 1.1054,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0593514442443848,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.6289,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.927435576915741,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.8563,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.122362732887268,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.7896,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4112809896469116,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.6135,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1536827087402344,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7691,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2973562479019165,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.662,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1758365631103516,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.5567,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4415098428726196,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.6663,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4505945444107056,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.83,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0297611951828003,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.9364,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3291810750961304,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.5379,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4843671321868896,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.6709,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2337127923965454,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.4647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9915568828582764,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.6439,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1892094612121582,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7327,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4218144416809082,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.7468,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8900254964828491,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.5615,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2152378559112549,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.5918,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1518409252166748,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.7118,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9143003225326538,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.8193,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0710068941116333,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.5147,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.87776780128479,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.8635,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2822787761688232,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.6298,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.026825189590454,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.9106,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1366348266601562,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.9373,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3177250623703003,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.7351,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2249926328659058,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.5835,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.808040738105774,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.6813,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.277226209640503,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.5897,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3442306518554688,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7905,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1461127996444702,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.8015,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9360058903694153,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.8105,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2209837436676025,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7686,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0291593074798584,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.9542,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8803523182868958,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9003,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8462835550308228,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.6453,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.5406043529510498,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7514,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.086790084838867,
      "learning_rate": 0.000196381135707411,
      "loss": 0.6565,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8038688898086548,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8815,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7158440351486206,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.7875,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2155958414077759,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7357,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.961394727230072,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.8628,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.96473228931427,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.6931,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9059011340141296,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.7431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.253554344177246,
      "learning_rate": 0.000196111645813282,
      "loss": 0.716,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8613760471343994,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.9859,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2081166505813599,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.6575,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0867011547088623,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.7505,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1116654872894287,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.492,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4465603828430176,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.7577,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.988479733467102,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.6687,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8707459568977356,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8801,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4584712982177734,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.7284,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1217535734176636,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.6554,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6862573623657227,
      "learning_rate": 0.00019572666025024062,
      "loss": 0.7971,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4024852514266968,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.395,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3252756595611572,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.6865,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.124302864074707,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.4668,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1343193054199219,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.5322,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6102299690246582,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.575,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9591246843338013,
      "learning_rate": 0.00019549566891241578,
      "loss": 1.023,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0329092741012573,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.8113,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0736831426620483,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.4766,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9227723479270935,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.5173,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8723241090774536,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.8905,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6511275768280029,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.7647,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.005831003189087,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.7374,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8661340475082397,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.669,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7919161915779114,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7387,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0209808349609375,
      "learning_rate": 0.00019514918190567855,
      "loss": 1.0741,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.164157748222351,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.7856,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9031721949577332,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.6197,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9569196105003357,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.8645,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0174713134765625,
      "learning_rate": 0.000194995187680462,
      "loss": 0.793,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0296181440353394,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.7721,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8890597820281982,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.5771,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8176144957542419,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.9459,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8257383704185486,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.6564,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7403143644332886,
      "learning_rate": 0.0001948026948989413,
      "loss": 1.0655,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0076433420181274,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.517,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8821527361869812,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.7529,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": Infinity,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.9055,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.923977255821228,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5808,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8217901587486267,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7364,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9798531532287598,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.6119,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6735888719558716,
      "learning_rate": 0.00019457170356111648,
      "loss": 1.0526,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7803233861923218,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.8075,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1770597696304321,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.8079,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0164283514022827,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.4754,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9601749777793884,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.6892,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8489695191383362,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.5216,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7636417746543884,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.6582,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1955299377441406,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.4717,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8320456147193909,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.7358,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0133183002471924,
      "learning_rate": 0.0001942252165543792,
      "loss": 1.0343,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0720036029815674,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.5315,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0775949954986572,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6193,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7920546531677246,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.7595,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3015785217285156,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.9733,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8165020942687988,
      "learning_rate": 0.00019403272377285853,
      "loss": 0.7597,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4158751964569092,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.568,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.2686575651168823,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.6968,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3919662237167358,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8041,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9166744351387024,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.6156,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.136273741722107,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7026,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8245551586151123,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.8833,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9562796950340271,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.7529,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9529739022254944,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.8045,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4480829238891602,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.6155,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0233687162399292,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.6041,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7334891557693481,
      "learning_rate": 0.000193609239653513,
      "loss": 0.9663,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7895396947860718,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8324,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7623308300971985,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.8914,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8783438205718994,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.5553,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8427506685256958,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.5809,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.565274715423584,
      "learning_rate": 0.0001934167468719923,
      "loss": 1.1704,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8487130403518677,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.8637,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7599690556526184,
      "learning_rate": 0.00019333974975938403,
      "loss": 1.0428,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6733267307281494,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8145,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8760805130004883,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6674,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7678978443145752,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.6376,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7904714941978455,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6513,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7921337485313416,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.5813,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9006468057632446,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.8312,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9150775671005249,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.5722,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9657385349273682,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.7529,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.839449405670166,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.6083,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1582216024398804,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7123,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.140467882156372,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7309,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9428714513778687,
      "learning_rate": 0.00019287776708373439,
      "loss": 0.6775,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1014231443405151,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.4118,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0334292650222778,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.65,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1933209896087646,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6013,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8265478610992432,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7071,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8585402369499207,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.5727,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.787067711353302,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.7735,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1874279975891113,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.7179,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.971271276473999,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.6993,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.236193895339966,
      "learning_rate": 0.00019253128007699712,
      "loss": 1.0061,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9123310446739197,
      "learning_rate": 0.000192492781520693,
      "loss": 0.8033,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6489309072494507,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.7415,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0011146068572998,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.5747,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8328598737716675,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.5537,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.791504442691803,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7737,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7130611538887024,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.6439,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7929614186286926,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.755,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8132526278495789,
      "learning_rate": 0.000192223291626564,
      "loss": 0.6144,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9258521795272827,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7335,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9880536794662476,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.5069,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8288092613220215,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.7903,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9645191431045532,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.5626,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.09334397315979,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.5528,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7808449268341064,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.6246,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9576950073242188,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.552,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8885469436645508,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.6746,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9373623728752136,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7364,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6853724122047424,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.8125,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9469802975654602,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.6254,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0501898527145386,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.6862,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8763583302497864,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.8578,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.920737087726593,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.8214,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6409149765968323,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.6631,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8207921385765076,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.6582,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0325123071670532,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.5805,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9549276828765869,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.5267,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2399728298187256,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.7764,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7685335874557495,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.7752,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9186263680458069,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.6403,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1575677394866943,
      "learning_rate": 0.00019137632338787298,
      "loss": 1.0128,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6230560541152954,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.8143,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6135293841362,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.9284,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9068969488143921,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.7929,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0303515195846558,
      "learning_rate": 0.00019122232916265642,
      "loss": 1.0166,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8789127469062805,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.828,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.932952880859375,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.7154,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3748090267181396,
      "learning_rate": 0.000191106833493744,
      "loss": 0.4858,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7238903641700745,
      "learning_rate": 0.00019106833493743986,
      "loss": 1.0197,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8612135052680969,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.6402,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0058850049972534,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.5625,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7587082982063293,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.7146,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8537068963050842,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.6575,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8969892263412476,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.6438,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6655741333961487,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7692,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6944710612297058,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.8478,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8596721887588501,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.5002,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.586476445198059,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.5461,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0440481901168823,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.6742,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8207206726074219,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.6833,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0530555248260498,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.5616,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7683369517326355,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.5294,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0457940101623535,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.6963,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6145095825195312,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8594,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8121146559715271,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.6559,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.220907211303711,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.5442,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7089275121688843,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.7317,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9419508576393127,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.8281,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.628293514251709,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7145,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7072062492370605,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.683,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7283824682235718,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.8467,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1346855163574219,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.6207,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7329082489013672,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.6492,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7539021372795105,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.5169,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6919435262680054,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7795,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9497821927070618,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7684,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7363495230674744,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.7672,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7237761616706848,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.6591,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6229631304740906,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.8745,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.452817440032959,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.6145,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6157515048980713,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.744,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9306153059005737,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.4724,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1150598526000977,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.9032,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8624481558799744,
      "learning_rate": 0.000189720885466795,
      "loss": 0.7131,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7226539850234985,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.8181,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7369751930236816,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.7088,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8418794274330139,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7236,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.08870530128479,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.5989,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7107866406440735,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.6236,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9303227066993713,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5213,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6057505011558533,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9274,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7860249876976013,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.5527,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8407137393951416,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.438,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.788601279258728,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.5906,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7538231015205383,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.4701,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7311952710151672,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.6179,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0561766624450684,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.4345,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6438183188438416,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.8134,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.743452250957489,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.536,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5953269600868225,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.7504,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6800954341888428,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.5422,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7698876857757568,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.4952,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7443271279335022,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.8343,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2300752401351929,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.6186,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8002804517745972,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.5712,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0497325658798218,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.845,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6107672452926636,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8377,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7461987137794495,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.8034,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7233768105506897,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8044,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9682684540748596,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.8155,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0884222984313965,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.8066,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8505268692970276,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.4212,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8903761506080627,
      "learning_rate": 0.000188604427333975,
      "loss": 0.4617,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8329160213470459,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.646,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7580491900444031,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.6545,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5973345041275024,
      "learning_rate": 0.00018848893166506256,
      "loss": 1.0677,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7318881750106812,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.6773,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7885010838508606,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.7792,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8507166504859924,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.9515,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6224185824394226,
      "learning_rate": 0.000188334937439846,
      "loss": 0.793,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.718784511089325,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6929,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8589291572570801,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.8126,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8662039637565613,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.4193,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5792511701583862,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.5858,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8806815147399902,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.5773,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8599536418914795,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.6636,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5740275979042053,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.9467,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6886740326881409,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.8395,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9049243330955505,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.6245,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7558502554893494,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.688,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8135894536972046,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6968,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8597134947776794,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.5344,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6497805714607239,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.7432,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.624045193195343,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.5921,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7488207817077637,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.9047,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2660577297210693,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.5851,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1815978288650513,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.5468,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6585094928741455,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.5055,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6599869728088379,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.8755,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8747279644012451,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.9256,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0177969932556152,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.2889,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8498440980911255,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7156,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6891127228736877,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.7287,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7740240693092346,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.8368,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7449020743370056,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.4807,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4376306533813477,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.9404,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.736077070236206,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8668,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6683731079101562,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.6029,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7797954082489014,
      "learning_rate": 0.000187218479307026,
      "loss": 0.5901,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5687959790229797,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8516,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6512517333030701,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7347,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.565966010093689,
      "learning_rate": 0.00018710298363811359,
      "loss": 1.0649,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9909862279891968,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.4288,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7884112596511841,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.6397,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7323040962219238,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7309,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7657570242881775,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.8031,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8743228316307068,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6299,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9807490110397339,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6752,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7816490530967712,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.7282,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6959101557731628,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.6651,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7261993288993835,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8877,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6144199371337891,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.8319,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6571177244186401,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.7135,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0807875394821167,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7566,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8185086846351624,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.5601,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6865718960762024,
      "learning_rate": 0.00018656400384985564,
      "loss": 1.1941,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7527123689651489,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.6283,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.633386492729187,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.7949,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7434275150299072,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.749,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3395079374313354,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.9689,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6887421011924744,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.7547,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5965858697891235,
      "learning_rate": 0.0001863330125120308,
      "loss": 1.0431,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9297249913215637,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.809,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5710415244102478,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6837,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.623849093914032,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.7247,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9221763014793396,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.518,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.48956894874572754,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.8311,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5858659744262695,
      "learning_rate": 0.000186102021174206,
      "loss": 0.7148,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9408402442932129,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.6661,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8599625825881958,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.4558,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6531791090965271,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.7232,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7258799076080322,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.6838,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7172141671180725,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.6849,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5655890107154846,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.8398,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5579836964607239,
      "learning_rate": 0.000185832531280077,
      "loss": 0.8208,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8500748872756958,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.7686,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7076826095581055,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.646,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.750829815864563,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.5834,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7004405856132507,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.6413,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6903966665267944,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.6479,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.628515362739563,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7402,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.009565830230713,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.5636,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.736901044845581,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.6898,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8011174201965332,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.9058,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5748683214187622,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.684,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6112973093986511,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.6892,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8286272883415222,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7102,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.933481752872467,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.4317,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7664060592651367,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8973,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.57676100730896,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7021,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7917118668556213,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7848,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9117770791053772,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.456,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8564830422401428,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.3618,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9490712285041809,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.5153,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7518885731697083,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.7539,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7193209528923035,
      "learning_rate": 0.0001850240615976901,
      "loss": 1.0002,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7111209034919739,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7467,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9438728094100952,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6184,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8447867631912231,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.9111,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5188901424407959,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.6593,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7598814368247986,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.881,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5978820323944092,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.6949,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7871193885803223,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.5207,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7425273060798645,
      "learning_rate": 0.000184716073147257,
      "loss": 0.8033,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5325318574905396,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7403,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6582126021385193,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.6868,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5985537767410278,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.704,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8908801674842834,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.719,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7575201392173767,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.7543,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8175365328788757,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.6602,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6037975549697876,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8361,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5509572625160217,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.4216,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7482405304908752,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.3945,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8625118136405945,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.7002,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7192174792289734,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6841,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7142515182495117,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.6865,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7495271563529968,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.7471,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7775553464889526,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.6908,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5583651065826416,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.5281,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7792724370956421,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6543,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6158411502838135,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7052,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7116422653198242,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.8469,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2091479301452637,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.687,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8763923048973083,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.701,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7194721102714539,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5902,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.622972846031189,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.7281,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8785674571990967,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.7788,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.561694860458374,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.7398,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5931367874145508,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.9208,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8336869478225708,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.4492,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7663393616676331,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6691,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6989089846611023,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.8855,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5969981551170349,
      "learning_rate": 0.00018359961501443698,
      "loss": 0.8035,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.556025505065918,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.9405,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5868527293205261,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.927,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.747269332408905,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7711,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5778203010559082,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.5097,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7665207982063293,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7753,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6795540452003479,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.6638,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7306339144706726,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.4294,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.641844630241394,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.6496,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.660853385925293,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.5296,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7177244424819946,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.4683,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2018318176269531,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.9297,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8318695425987244,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.6177,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5980833172798157,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.5037,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7439042329788208,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7146,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8085542917251587,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.6122,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6640565395355225,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.5139,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0524460077285767,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.7783,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.617692232131958,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.9802,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.122811198234558,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.6802,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8143771290779114,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.6618,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6935192346572876,
      "learning_rate": 0.00018279114533205007,
      "loss": 1.1362,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7444424033164978,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8607,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5704548358917236,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5804,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5939321517944336,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.7454,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.974220335483551,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.5903,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.843052864074707,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.6173,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6161561012268066,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.5802,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8895635008811951,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.3974,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5754928588867188,
      "learning_rate": 0.00018248315688161696,
      "loss": 0.7096,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7855966091156006,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7746,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6445358395576477,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7296,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5740096569061279,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8779,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7613345384597778,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.5638,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7333557605743408,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.5855,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7124179005622864,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.7167,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.638280987739563,
      "learning_rate": 0.000182213666987488,
      "loss": 0.9548,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9654234051704407,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.7242,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7197368144989014,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.6723,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5494047999382019,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8031,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5353728532791138,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.8029,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6315490007400513,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.5837,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7555389404296875,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7125,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8384435772895813,
      "learning_rate": 0.000181944177093359,
      "loss": 0.5034,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5619967579841614,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8396,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7444220185279846,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.8219,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5551384091377258,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.7687,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7309958338737488,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.6539,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.614891767501831,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.5977,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7716305255889893,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7605,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7078102827072144,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8178,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7726227641105652,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.7639,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.777751624584198,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.6402,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9366869926452637,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.8419,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7884979248046875,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.4486,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8710904121398926,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.5999,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6384978294372559,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7706,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7797781825065613,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.5892,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6219421029090881,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.6704,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9979626536369324,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.4893,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6125726699829102,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.5604,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6936690807342529,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.6456,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6553232073783875,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.8872,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7319735288619995,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.5098,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6700308918952942,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8333,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8183261156082153,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6948,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9010966420173645,
      "learning_rate": 0.0001810587102983638,
      "loss": 0.3522,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9813642501831055,
      "learning_rate": 0.00018102021174205968,
      "loss": 0.5139,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.735927939414978,
      "learning_rate": 0.00018098171318575555,
      "loss": 0.9666,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7688445448875427,
      "learning_rate": 0.0001809432146294514,
      "loss": 0.654,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7212250232696533,
      "learning_rate": 0.00018090471607314727,
      "loss": 0.4753,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6220759153366089,
      "learning_rate": 0.00018086621751684312,
      "loss": 0.6951,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.552781879901886,
      "learning_rate": 0.000180827718960539,
      "loss": 0.8248,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7625164985656738,
      "learning_rate": 0.00018078922040423484,
      "loss": 0.4531,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5779299139976501,
      "learning_rate": 0.00018075072184793072,
      "loss": 0.7087,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5191786289215088,
      "learning_rate": 0.0001807122232916266,
      "loss": 0.9063,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6027359962463379,
      "learning_rate": 0.00018067372473532244,
      "loss": 0.8213,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7313194274902344,
      "learning_rate": 0.00018063522617901828,
      "loss": 0.516,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5989764928817749,
      "learning_rate": 0.00018059672762271416,
      "loss": 1.0973,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7442408800125122,
      "learning_rate": 0.00018055822906641003,
      "loss": 0.5786,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6334717273712158,
      "learning_rate": 0.00018051973051010588,
      "loss": 0.4938,
      "step": 512
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5559924244880676,
      "learning_rate": 0.00018048123195380173,
      "loss": 0.8648,
      "step": 513
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5963814854621887,
      "learning_rate": 0.0001804427333974976,
      "loss": 0.5543,
      "step": 514
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8214461207389832,
      "learning_rate": 0.00018040423484119348,
      "loss": 0.7705,
      "step": 515
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8785788416862488,
      "learning_rate": 0.00018036573628488933,
      "loss": 0.4427,
      "step": 516
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7951868176460266,
      "learning_rate": 0.0001803272377285852,
      "loss": 0.5326,
      "step": 517
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6466233730316162,
      "learning_rate": 0.00018028873917228105,
      "loss": 0.6987,
      "step": 518
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7211444973945618,
      "learning_rate": 0.0001802502406159769,
      "loss": 0.7709,
      "step": 519
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.931510329246521,
      "learning_rate": 0.00018021174205967277,
      "loss": 0.5353,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.726398766040802,
      "learning_rate": 0.00018017324350336864,
      "loss": 0.4566,
      "step": 521
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9202558994293213,
      "learning_rate": 0.0001801347449470645,
      "loss": 0.8507,
      "step": 522
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6638332605361938,
      "learning_rate": 0.00018009624639076034,
      "loss": 0.7436,
      "step": 523
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.832954466342926,
      "learning_rate": 0.0001800577478344562,
      "loss": 0.5198,
      "step": 524
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8316726088523865,
      "learning_rate": 0.0001800192492781521,
      "loss": 0.5822,
      "step": 525
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6892343759536743,
      "learning_rate": 0.00017998075072184794,
      "loss": 0.769,
      "step": 526
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7093865275382996,
      "learning_rate": 0.00017994225216554378,
      "loss": 0.9413,
      "step": 527
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6044589281082153,
      "learning_rate": 0.00017990375360923966,
      "loss": 0.6977,
      "step": 528
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7711941599845886,
      "learning_rate": 0.00017986525505293553,
      "loss": 0.9329,
      "step": 529
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8691420555114746,
      "learning_rate": 0.00017982675649663138,
      "loss": 0.5256,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5082821846008301,
      "learning_rate": 0.00017978825794032725,
      "loss": 0.7816,
      "step": 531
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.570527195930481,
      "learning_rate": 0.0001797497593840231,
      "loss": 0.6493,
      "step": 532
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6981233358383179,
      "learning_rate": 0.00017971126082771898,
      "loss": 0.9473,
      "step": 533
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6987241506576538,
      "learning_rate": 0.00017967276227141482,
      "loss": 0.7451,
      "step": 534
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5137880444526672,
      "learning_rate": 0.0001796342637151107,
      "loss": 0.8249,
      "step": 535
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9250155687332153,
      "learning_rate": 0.00017959576515880657,
      "loss": 0.6099,
      "step": 536
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6776856184005737,
      "learning_rate": 0.0001795572666025024,
      "loss": 0.6047,
      "step": 537
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6719252467155457,
      "learning_rate": 0.00017951876804619827,
      "loss": 0.7126,
      "step": 538
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.590328574180603,
      "learning_rate": 0.00017948026948989414,
      "loss": 1.0215,
      "step": 539
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6601207852363586,
      "learning_rate": 0.00017944177093359002,
      "loss": 0.5115,
      "step": 540
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6893088817596436,
      "learning_rate": 0.00017940327237728586,
      "loss": 0.7127,
      "step": 541
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.621976375579834,
      "learning_rate": 0.0001793647738209817,
      "loss": 0.6285,
      "step": 542
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7940705418586731,
      "learning_rate": 0.00017932627526467759,
      "loss": 0.5925,
      "step": 543
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6036211848258972,
      "learning_rate": 0.00017928777670837343,
      "loss": 0.4134,
      "step": 544
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.587741494178772,
      "learning_rate": 0.0001792492781520693,
      "loss": 0.5489,
      "step": 545
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6074514985084534,
      "learning_rate": 0.00017921077959576518,
      "loss": 0.7261,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.035722255706787,
      "learning_rate": 0.00017917228103946103,
      "loss": 0.6641,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9030612707138062,
      "learning_rate": 0.00017913378248315688,
      "loss": 0.865,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5708800554275513,
      "learning_rate": 0.00017909528392685275,
      "loss": 0.6536,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7275450825691223,
      "learning_rate": 0.00017905678537054863,
      "loss": 0.4152,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5675240159034729,
      "learning_rate": 0.00017901828681424447,
      "loss": 0.5793,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6410626173019409,
      "learning_rate": 0.00017897978825794032,
      "loss": 0.6824,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7726817727088928,
      "learning_rate": 0.0001789412897016362,
      "loss": 0.7125,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8998408913612366,
      "learning_rate": 0.00017890279114533207,
      "loss": 0.3345,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6513839364051819,
      "learning_rate": 0.00017886429258902792,
      "loss": 0.5045,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.727322518825531,
      "learning_rate": 0.0001788257940327238,
      "loss": 0.7322,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6974987983703613,
      "learning_rate": 0.00017878729547641964,
      "loss": 0.6009,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7905023694038391,
      "learning_rate": 0.0001787487969201155,
      "loss": 0.6988,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9839308857917786,
      "learning_rate": 0.00017871029836381136,
      "loss": 0.6749,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7490098476409912,
      "learning_rate": 0.00017867179980750724,
      "loss": 0.6961,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0670418739318848,
      "learning_rate": 0.00017863330125120308,
      "loss": 0.5953,
      "step": 561
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.593356192111969,
      "learning_rate": 0.00017859480269489896,
      "loss": 0.7749,
      "step": 562
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7387890815734863,
      "learning_rate": 0.0001785563041385948,
      "loss": 0.5965,
      "step": 563
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6877281069755554,
      "learning_rate": 0.00017851780558229068,
      "loss": 0.6064,
      "step": 564
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5250972509384155,
      "learning_rate": 0.00017847930702598655,
      "loss": 0.7343,
      "step": 565
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6507566571235657,
      "learning_rate": 0.00017844080846968237,
      "loss": 0.7547,
      "step": 566
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6374786496162415,
      "learning_rate": 0.00017840230991337825,
      "loss": 0.7447,
      "step": 567
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5923673510551453,
      "learning_rate": 0.00017836381135707412,
      "loss": 0.6631,
      "step": 568
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5488978028297424,
      "learning_rate": 0.00017832531280076997,
      "loss": 0.6709,
      "step": 569
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0043591260910034,
      "learning_rate": 0.00017828681424446585,
      "loss": 0.6065,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7207235097885132,
      "learning_rate": 0.0001782483156881617,
      "loss": 0.6428,
      "step": 571
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6688354015350342,
      "learning_rate": 0.00017820981713185757,
      "loss": 0.7885,
      "step": 572
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7515926361083984,
      "learning_rate": 0.00017817131857555341,
      "loss": 0.5332,
      "step": 573
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0833226442337036,
      "learning_rate": 0.0001781328200192493,
      "loss": 0.7669,
      "step": 574
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8054810166358948,
      "learning_rate": 0.00017809432146294516,
      "loss": 0.6776,
      "step": 575
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6206085681915283,
      "learning_rate": 0.000178055822906641,
      "loss": 0.559,
      "step": 576
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7385501861572266,
      "learning_rate": 0.00017801732435033686,
      "loss": 0.7062,
      "step": 577
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8732308745384216,
      "learning_rate": 0.00017797882579403273,
      "loss": 0.5078,
      "step": 578
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6646142601966858,
      "learning_rate": 0.0001779403272377286,
      "loss": 0.6726,
      "step": 579
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5578314065933228,
      "learning_rate": 0.00017790182868142445,
      "loss": 1.0685,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7208375334739685,
      "learning_rate": 0.0001778633301251203,
      "loss": 0.692,
      "step": 581
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9988183975219727,
      "learning_rate": 0.00017782483156881618,
      "loss": 0.758,
      "step": 582
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7599869966506958,
      "learning_rate": 0.00017778633301251205,
      "loss": 0.4665,
      "step": 583
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8353445529937744,
      "learning_rate": 0.0001777478344562079,
      "loss": 0.4908,
      "step": 584
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7772532105445862,
      "learning_rate": 0.00017770933589990377,
      "loss": 0.5119,
      "step": 585
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7856645584106445,
      "learning_rate": 0.00017767083734359962,
      "loss": 0.6478,
      "step": 586
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7736432552337646,
      "learning_rate": 0.0001776323387872955,
      "loss": 0.6798,
      "step": 587
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.662562370300293,
      "learning_rate": 0.00017759384023099134,
      "loss": 0.5114,
      "step": 588
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.737090528011322,
      "learning_rate": 0.00017755534167468722,
      "loss": 0.7474,
      "step": 589
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6457744240760803,
      "learning_rate": 0.00017751684311838306,
      "loss": 0.5693,
      "step": 590
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9803255796432495,
      "learning_rate": 0.0001774783445620789,
      "loss": 0.7573,
      "step": 591
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.612112283706665,
      "learning_rate": 0.0001774398460057748,
      "loss": 0.7371,
      "step": 592
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9148984551429749,
      "learning_rate": 0.00017740134744947066,
      "loss": 0.724,
      "step": 593
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6975201964378357,
      "learning_rate": 0.0001773628488931665,
      "loss": 0.7316,
      "step": 594
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5441070795059204,
      "learning_rate": 0.00017732435033686236,
      "loss": 0.9123,
      "step": 595
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6095752120018005,
      "learning_rate": 0.00017728585178055823,
      "loss": 0.7638,
      "step": 596
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6558985114097595,
      "learning_rate": 0.0001772473532242541,
      "loss": 0.7515,
      "step": 597
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5151351094245911,
      "learning_rate": 0.00017720885466794995,
      "loss": 0.6675,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7533324360847473,
      "learning_rate": 0.00017717035611164583,
      "loss": 0.686,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6827309727668762,
      "learning_rate": 0.00017713185755534167,
      "loss": 0.5808,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8595276474952698,
      "learning_rate": 0.00017709335899903755,
      "loss": 0.5858,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6526479125022888,
      "learning_rate": 0.0001770548604427334,
      "loss": 0.6608,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7959790825843811,
      "learning_rate": 0.00017701636188642927,
      "loss": 0.6459,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9957267045974731,
      "learning_rate": 0.00017697786333012515,
      "loss": 0.7617,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1645805835723877,
      "learning_rate": 0.000176939364773821,
      "loss": 0.61,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6415759325027466,
      "learning_rate": 0.00017690086621751684,
      "loss": 0.7222,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8523719310760498,
      "learning_rate": 0.00017686236766121271,
      "loss": 0.8409,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.960444450378418,
      "learning_rate": 0.0001768238691049086,
      "loss": 0.5689,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8182255029678345,
      "learning_rate": 0.00017678537054860444,
      "loss": 0.4445,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7716516852378845,
      "learning_rate": 0.00017674687199230028,
      "loss": 0.3699,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9049159288406372,
      "learning_rate": 0.00017670837343599616,
      "loss": 0.8016,
      "step": 611
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5800634622573853,
      "learning_rate": 0.00017666987487969203,
      "loss": 0.9866,
      "step": 612
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8045703768730164,
      "learning_rate": 0.00017663137632338788,
      "loss": 0.6985,
      "step": 613
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7679507732391357,
      "learning_rate": 0.00017659287776708376,
      "loss": 0.618,
      "step": 614
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6198709011077881,
      "learning_rate": 0.0001765543792107796,
      "loss": 0.9051,
      "step": 615
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5902866721153259,
      "learning_rate": 0.00017651588065447545,
      "loss": 1.0978,
      "step": 616
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5553480386734009,
      "learning_rate": 0.00017647738209817132,
      "loss": 0.7345,
      "step": 617
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9051225781440735,
      "learning_rate": 0.0001764388835418672,
      "loss": 0.6342,
      "step": 618
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8280664682388306,
      "learning_rate": 0.00017640038498556307,
      "loss": 0.8419,
      "step": 619
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7987625002861023,
      "learning_rate": 0.0001763618864292589,
      "loss": 0.7314,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4194488525390625,
      "learning_rate": 0.00017632338787295477,
      "loss": 0.6009,
      "step": 621
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5878939032554626,
      "learning_rate": 0.00017628488931665064,
      "loss": 0.6127,
      "step": 622
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7140704989433289,
      "learning_rate": 0.0001762463907603465,
      "loss": 0.6811,
      "step": 623
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6153066754341125,
      "learning_rate": 0.00017620789220404234,
      "loss": 0.6095,
      "step": 624
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6382792592048645,
      "learning_rate": 0.0001761693936477382,
      "loss": 0.7885,
      "step": 625
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7713308334350586,
      "learning_rate": 0.0001761308950914341,
      "loss": 0.6111,
      "step": 626
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5835039615631104,
      "learning_rate": 0.00017609239653512993,
      "loss": 0.7126,
      "step": 627
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7846230864524841,
      "learning_rate": 0.0001760538979788258,
      "loss": 0.7349,
      "step": 628
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8369488716125488,
      "learning_rate": 0.00017601539942252166,
      "loss": 0.6081,
      "step": 629
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0105968713760376,
      "learning_rate": 0.00017597690086621753,
      "loss": 0.8593,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7178121209144592,
      "learning_rate": 0.00017593840230991338,
      "loss": 0.7101,
      "step": 631
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.814546525478363,
      "learning_rate": 0.00017589990375360925,
      "loss": 0.8779,
      "step": 632
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7966509461402893,
      "learning_rate": 0.00017586140519730513,
      "loss": 0.72,
      "step": 633
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8122262954711914,
      "learning_rate": 0.00017582290664100097,
      "loss": 0.5069,
      "step": 634
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8662346601486206,
      "learning_rate": 0.00017578440808469682,
      "loss": 0.6848,
      "step": 635
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.808278501033783,
      "learning_rate": 0.0001757459095283927,
      "loss": 0.668,
      "step": 636
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5995301008224487,
      "learning_rate": 0.00017570741097208857,
      "loss": 0.5213,
      "step": 637
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4677468538284302,
      "learning_rate": 0.00017566891241578442,
      "loss": 0.6333,
      "step": 638
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6823005676269531,
      "learning_rate": 0.00017563041385948027,
      "loss": 0.6939,
      "step": 639
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4946478009223938,
      "learning_rate": 0.00017559191530317614,
      "loss": 0.7331,
      "step": 640
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.585574209690094,
      "learning_rate": 0.000175553416746872,
      "loss": 0.6717,
      "step": 641
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7856736183166504,
      "learning_rate": 0.00017551491819056786,
      "loss": 0.4537,
      "step": 642
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7468209266662598,
      "learning_rate": 0.00017547641963426374,
      "loss": 0.3988,
      "step": 643
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.663483202457428,
      "learning_rate": 0.00017543792107795958,
      "loss": 0.525,
      "step": 644
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5496599674224854,
      "learning_rate": 0.00017539942252165543,
      "loss": 0.6177,
      "step": 645
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7893540859222412,
      "learning_rate": 0.0001753609239653513,
      "loss": 0.5153,
      "step": 646
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5082350969314575,
      "learning_rate": 0.00017532242540904718,
      "loss": 0.9337,
      "step": 647
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6387757658958435,
      "learning_rate": 0.00017528392685274303,
      "loss": 0.5653,
      "step": 648
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5962136387825012,
      "learning_rate": 0.00017524542829643888,
      "loss": 0.6799,
      "step": 649
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5888770818710327,
      "learning_rate": 0.00017520692974013475,
      "loss": 0.6807,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6050287485122681,
      "learning_rate": 0.00017516843118383063,
      "loss": 0.6633,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9544339776039124,
      "learning_rate": 0.00017512993262752647,
      "loss": 0.9371,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.730651319026947,
      "learning_rate": 0.00017509143407122232,
      "loss": 0.6864,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7352924942970276,
      "learning_rate": 0.0001750529355149182,
      "loss": 0.7243,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8686752319335938,
      "learning_rate": 0.00017501443695861407,
      "loss": 0.4024,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8120374083518982,
      "learning_rate": 0.00017497593840230992,
      "loss": 0.3866,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6852021217346191,
      "learning_rate": 0.0001749374398460058,
      "loss": 0.4215,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5634097456932068,
      "learning_rate": 0.00017489894128970164,
      "loss": 0.7206,
      "step": 658
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7309567332267761,
      "learning_rate": 0.0001748604427333975,
      "loss": 0.4515,
      "step": 659
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5597043037414551,
      "learning_rate": 0.00017482194417709336,
      "loss": 0.7859,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.774241030216217,
      "learning_rate": 0.00017478344562078923,
      "loss": 0.5952,
      "step": 661
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8863543272018433,
      "learning_rate": 0.0001747449470644851,
      "loss": 0.3879,
      "step": 662
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6434614658355713,
      "learning_rate": 0.00017470644850818093,
      "loss": 0.8632,
      "step": 663
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8221364617347717,
      "learning_rate": 0.0001746679499518768,
      "loss": 0.6685,
      "step": 664
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.75003981590271,
      "learning_rate": 0.00017462945139557268,
      "loss": 0.6803,
      "step": 665
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7057366371154785,
      "learning_rate": 0.00017459095283926855,
      "loss": 0.5605,
      "step": 666
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5842887163162231,
      "learning_rate": 0.0001745524542829644,
      "loss": 0.594,
      "step": 667
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5622215270996094,
      "learning_rate": 0.00017451395572666025,
      "loss": 1.0226,
      "step": 668
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6369432806968689,
      "learning_rate": 0.00017447545717035612,
      "loss": 0.9267,
      "step": 669
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5875369310379028,
      "learning_rate": 0.00017443695861405197,
      "loss": 0.743,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.951618492603302,
      "learning_rate": 0.00017439846005774784,
      "loss": 0.475,
      "step": 671
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.60471510887146,
      "learning_rate": 0.00017435996150144372,
      "loss": 0.4755,
      "step": 672
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5699655413627625,
      "learning_rate": 0.00017432146294513957,
      "loss": 0.7449,
      "step": 673
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9288299083709717,
      "learning_rate": 0.00017428296438883541,
      "loss": 0.5567,
      "step": 674
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.789043664932251,
      "learning_rate": 0.0001742444658325313,
      "loss": 0.6825,
      "step": 675
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5014984607696533,
      "learning_rate": 0.00017420596727622716,
      "loss": 0.7945,
      "step": 676
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.899013876914978,
      "learning_rate": 0.000174167468719923,
      "loss": 0.5108,
      "step": 677
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7104153037071228,
      "learning_rate": 0.00017412897016361886,
      "loss": 0.9547,
      "step": 678
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5267176628112793,
      "learning_rate": 0.00017409047160731473,
      "loss": 0.6264,
      "step": 679
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.846923291683197,
      "learning_rate": 0.0001740519730510106,
      "loss": 0.5874,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.48755204677581787,
      "learning_rate": 0.00017401347449470645,
      "loss": 0.8508,
      "step": 681
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.099907636642456,
      "learning_rate": 0.00017397497593840233,
      "loss": 0.401,
      "step": 682
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5264143943786621,
      "learning_rate": 0.00017393647738209818,
      "loss": 0.7577,
      "step": 683
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5646629333496094,
      "learning_rate": 0.00017389797882579405,
      "loss": 0.7911,
      "step": 684
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7983838319778442,
      "learning_rate": 0.0001738594802694899,
      "loss": 0.5762,
      "step": 685
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6316927671432495,
      "learning_rate": 0.00017382098171318577,
      "loss": 0.5952,
      "step": 686
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5015628933906555,
      "learning_rate": 0.00017378248315688162,
      "loss": 0.7939,
      "step": 687
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5893049836158752,
      "learning_rate": 0.00017374398460057747,
      "loss": 0.7664,
      "step": 688
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7587557435035706,
      "learning_rate": 0.00017370548604427334,
      "loss": 0.4553,
      "step": 689
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7824079990386963,
      "learning_rate": 0.00017366698748796922,
      "loss": 0.5953,
      "step": 690
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6611518263816833,
      "learning_rate": 0.0001736284889316651,
      "loss": 0.8156,
      "step": 691
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7224558591842651,
      "learning_rate": 0.0001735899903753609,
      "loss": 0.9078,
      "step": 692
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5992814898490906,
      "learning_rate": 0.00017355149181905679,
      "loss": 0.6275,
      "step": 693
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6290112137794495,
      "learning_rate": 0.00017351299326275266,
      "loss": 0.4064,
      "step": 694
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7407623529434204,
      "learning_rate": 0.0001734744947064485,
      "loss": 0.7741,
      "step": 695
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6758849024772644,
      "learning_rate": 0.00017343599615014438,
      "loss": 0.8718,
      "step": 696
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5055411458015442,
      "learning_rate": 0.00017339749759384023,
      "loss": 0.6955,
      "step": 697
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6418925523757935,
      "learning_rate": 0.0001733589990375361,
      "loss": 0.5726,
      "step": 698
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.544043242931366,
      "learning_rate": 0.00017332050048123195,
      "loss": 0.8035,
      "step": 699
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5846039652824402,
      "learning_rate": 0.00017328200192492783,
      "loss": 0.9237,
      "step": 700
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7197829484939575,
      "learning_rate": 0.0001732435033686237,
      "loss": 0.7812,
      "step": 701
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6238186955451965,
      "learning_rate": 0.00017320500481231955,
      "loss": 0.7466,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.727378785610199,
      "learning_rate": 0.0001731665062560154,
      "loss": 0.5334,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5501028299331665,
      "learning_rate": 0.00017312800769971127,
      "loss": 0.8214,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2805166244506836,
      "learning_rate": 0.00017308950914340715,
      "loss": 0.7995,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7582862973213196,
      "learning_rate": 0.000173051010587103,
      "loss": 0.6,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5532718300819397,
      "learning_rate": 0.00017301251203079884,
      "loss": 0.8732,
      "step": 707
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7867195010185242,
      "learning_rate": 0.00017297401347449471,
      "loss": 0.4442,
      "step": 708
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8325200080871582,
      "learning_rate": 0.0001729355149181906,
      "loss": 0.8357,
      "step": 709
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6667035818099976,
      "learning_rate": 0.00017289701636188644,
      "loss": 0.512,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.560309886932373,
      "learning_rate": 0.0001728585178055823,
      "loss": 0.7318,
      "step": 711
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6525481343269348,
      "learning_rate": 0.00017282001924927816,
      "loss": 0.4812,
      "step": 712
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6163297891616821,
      "learning_rate": 0.00017278152069297403,
      "loss": 0.7147,
      "step": 713
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7186746001243591,
      "learning_rate": 0.00017274302213666988,
      "loss": 0.5202,
      "step": 714
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6319488286972046,
      "learning_rate": 0.00017270452358036575,
      "loss": 0.6177,
      "step": 715
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5327817797660828,
      "learning_rate": 0.0001726660250240616,
      "loss": 0.8867,
      "step": 716
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.631850004196167,
      "learning_rate": 0.00017262752646775745,
      "loss": 0.5904,
      "step": 717
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0348049402236938,
      "learning_rate": 0.00017258902791145332,
      "loss": 0.6731,
      "step": 718
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8771058917045593,
      "learning_rate": 0.0001725505293551492,
      "loss": 0.6187,
      "step": 719
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6889843344688416,
      "learning_rate": 0.00017251203079884505,
      "loss": 0.4958,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3221871852874756,
      "learning_rate": 0.0001724735322425409,
      "loss": 0.6228,
      "step": 721
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.657353401184082,
      "learning_rate": 0.00017243503368623677,
      "loss": 0.8238,
      "step": 722
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6382782459259033,
      "learning_rate": 0.00017239653512993264,
      "loss": 0.5587,
      "step": 723
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7012105584144592,
      "learning_rate": 0.0001723580365736285,
      "loss": 0.8,
      "step": 724
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5702588558197021,
      "learning_rate": 0.00017231953801732436,
      "loss": 0.7373,
      "step": 725
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.580787181854248,
      "learning_rate": 0.0001722810394610202,
      "loss": 0.6532,
      "step": 726
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9424101710319519,
      "learning_rate": 0.0001722425409047161,
      "loss": 0.691,
      "step": 727
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5700766444206238,
      "learning_rate": 0.00017220404234841193,
      "loss": 0.9479,
      "step": 728
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8822431564331055,
      "learning_rate": 0.0001721655437921078,
      "loss": 0.7931,
      "step": 729
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.60028076171875,
      "learning_rate": 0.00017212704523580368,
      "loss": 0.853,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6144394874572754,
      "learning_rate": 0.00017208854667949953,
      "loss": 0.5604,
      "step": 731
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5580691695213318,
      "learning_rate": 0.00017205004812319538,
      "loss": 0.9066,
      "step": 732
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8239931464195251,
      "learning_rate": 0.00017201154956689125,
      "loss": 0.6029,
      "step": 733
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.631584644317627,
      "learning_rate": 0.00017197305101058713,
      "loss": 0.8749,
      "step": 734
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5895825028419495,
      "learning_rate": 0.00017193455245428297,
      "loss": 1.0,
      "step": 735
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7585741877555847,
      "learning_rate": 0.00017189605389797882,
      "loss": 0.5066,
      "step": 736
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5624192357063293,
      "learning_rate": 0.0001718575553416747,
      "loss": 0.8899,
      "step": 737
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6331326365470886,
      "learning_rate": 0.00017181905678537057,
      "loss": 0.7708,
      "step": 738
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6612368822097778,
      "learning_rate": 0.00017178055822906642,
      "loss": 0.7908,
      "step": 739
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.537795901298523,
      "learning_rate": 0.0001717420596727623,
      "loss": 1.0507,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.63994961977005,
      "learning_rate": 0.00017170356111645814,
      "loss": 0.741,
      "step": 741
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5982149243354797,
      "learning_rate": 0.000171665062560154,
      "loss": 0.9094,
      "step": 742
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6481786966323853,
      "learning_rate": 0.00017162656400384986,
      "loss": 0.8208,
      "step": 743
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7011485695838928,
      "learning_rate": 0.00017158806544754574,
      "loss": 0.5921,
      "step": 744
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5335140228271484,
      "learning_rate": 0.00017154956689124158,
      "loss": 0.6913,
      "step": 745
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5654804706573486,
      "learning_rate": 0.00017151106833493743,
      "loss": 0.6341,
      "step": 746
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7928334474563599,
      "learning_rate": 0.0001714725697786333,
      "loss": 0.6874,
      "step": 747
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.664972186088562,
      "learning_rate": 0.00017143407122232918,
      "loss": 0.3183,
      "step": 748
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.590420663356781,
      "learning_rate": 0.00017139557266602503,
      "loss": 0.6657,
      "step": 749
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6630308628082275,
      "learning_rate": 0.00017135707410972088,
      "loss": 0.5156,
      "step": 750
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.747826337814331,
      "learning_rate": 0.00017131857555341675,
      "loss": 0.6854,
      "step": 751
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6466501355171204,
      "learning_rate": 0.00017128007699711262,
      "loss": 0.4931,
      "step": 752
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5631003975868225,
      "learning_rate": 0.00017124157844080847,
      "loss": 0.7544,
      "step": 753
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7567971348762512,
      "learning_rate": 0.00017120307988450435,
      "loss": 0.6292,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7276394963264465,
      "learning_rate": 0.0001711645813282002,
      "loss": 0.7828,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7270777821540833,
      "learning_rate": 0.00017112608277189607,
      "loss": 0.7011,
      "step": 756
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7072964310646057,
      "learning_rate": 0.00017108758421559192,
      "loss": 0.8898,
      "step": 757
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6416227221488953,
      "learning_rate": 0.0001710490856592878,
      "loss": 0.7439,
      "step": 758
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6943629384040833,
      "learning_rate": 0.00017101058710298366,
      "loss": 0.3518,
      "step": 759
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6809807419776917,
      "learning_rate": 0.00017097208854667949,
      "loss": 0.5327,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6298185586929321,
      "learning_rate": 0.00017093358999037536,
      "loss": 0.4947,
      "step": 761
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6605240702629089,
      "learning_rate": 0.00017089509143407123,
      "loss": 0.7841,
      "step": 762
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6261136531829834,
      "learning_rate": 0.0001708565928777671,
      "loss": 0.6676,
      "step": 763
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6623320579528809,
      "learning_rate": 0.00017081809432146296,
      "loss": 0.4637,
      "step": 764
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5202741622924805,
      "learning_rate": 0.0001707795957651588,
      "loss": 0.6615,
      "step": 765
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.781020998954773,
      "learning_rate": 0.00017074109720885468,
      "loss": 0.4888,
      "step": 766
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7154417037963867,
      "learning_rate": 0.00017070259865255053,
      "loss": 0.7341,
      "step": 767
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7510635256767273,
      "learning_rate": 0.0001706641000962464,
      "loss": 0.7151,
      "step": 768
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7465168237686157,
      "learning_rate": 0.00017062560153994227,
      "loss": 0.451,
      "step": 769
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5354093909263611,
      "learning_rate": 0.00017058710298363812,
      "loss": 0.628,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8772189021110535,
      "learning_rate": 0.00017054860442733397,
      "loss": 0.6218,
      "step": 771
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.585827648639679,
      "learning_rate": 0.00017051010587102984,
      "loss": 0.7159,
      "step": 772
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6923907399177551,
      "learning_rate": 0.00017047160731472572,
      "loss": 0.6357,
      "step": 773
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6226284503936768,
      "learning_rate": 0.00017043310875842157,
      "loss": 1.0871,
      "step": 774
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6244713068008423,
      "learning_rate": 0.0001703946102021174,
      "loss": 0.6863,
      "step": 775
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6152127385139465,
      "learning_rate": 0.0001703561116458133,
      "loss": 0.7153,
      "step": 776
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6817339062690735,
      "learning_rate": 0.00017031761308950916,
      "loss": 0.6311,
      "step": 777
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5896717309951782,
      "learning_rate": 0.000170279114533205,
      "loss": 0.7819,
      "step": 778
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7084118127822876,
      "learning_rate": 0.00017024061597690086,
      "loss": 0.5395,
      "step": 779
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9470891356468201,
      "learning_rate": 0.00017020211742059673,
      "loss": 0.7325,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6593203544616699,
      "learning_rate": 0.0001701636188642926,
      "loss": 0.7159,
      "step": 781
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7264378070831299,
      "learning_rate": 0.00017012512030798845,
      "loss": 0.6538,
      "step": 782
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5907986164093018,
      "learning_rate": 0.00017008662175168433,
      "loss": 0.6971,
      "step": 783
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7287831902503967,
      "learning_rate": 0.00017004812319538018,
      "loss": 0.7411,
      "step": 784
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7446874976158142,
      "learning_rate": 0.00017000962463907605,
      "loss": 0.678,
      "step": 785
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7808102965354919,
      "learning_rate": 0.0001699711260827719,
      "loss": 0.5798,
      "step": 786
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7400268316268921,
      "learning_rate": 0.00016993262752646777,
      "loss": 0.6782,
      "step": 787
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6220332384109497,
      "learning_rate": 0.00016989412897016365,
      "loss": 0.5347,
      "step": 788
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6541516780853271,
      "learning_rate": 0.00016985563041385947,
      "loss": 0.6945,
      "step": 789
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.674069344997406,
      "learning_rate": 0.00016981713185755534,
      "loss": 0.839,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8589106798171997,
      "learning_rate": 0.00016977863330125122,
      "loss": 0.3321,
      "step": 791
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.650364875793457,
      "learning_rate": 0.00016974013474494706,
      "loss": 0.6517,
      "step": 792
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6298140287399292,
      "learning_rate": 0.00016970163618864294,
      "loss": 0.5756,
      "step": 793
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6950608491897583,
      "learning_rate": 0.00016966313763233879,
      "loss": 0.9298,
      "step": 794
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6557475924491882,
      "learning_rate": 0.00016962463907603466,
      "loss": 0.553,
      "step": 795
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7760496139526367,
      "learning_rate": 0.0001695861405197305,
      "loss": 0.6943,
      "step": 796
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6061364412307739,
      "learning_rate": 0.00016954764196342638,
      "loss": 0.6477,
      "step": 797
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5182318091392517,
      "learning_rate": 0.00016950914340712226,
      "loss": 0.7018,
      "step": 798
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.507469117641449,
      "learning_rate": 0.0001694706448508181,
      "loss": 0.8711,
      "step": 799
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7543202042579651,
      "learning_rate": 0.00016943214629451395,
      "loss": 0.5413,
      "step": 800
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5509201884269714,
      "learning_rate": 0.00016939364773820983,
      "loss": 0.9482,
      "step": 801
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6850157380104065,
      "learning_rate": 0.0001693551491819057,
      "loss": 0.734,
      "step": 802
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8136283755302429,
      "learning_rate": 0.00016931665062560155,
      "loss": 0.3779,
      "step": 803
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6029354333877563,
      "learning_rate": 0.0001692781520692974,
      "loss": 0.575,
      "step": 804
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7049925327301025,
      "learning_rate": 0.00016923965351299327,
      "loss": 0.4586,
      "step": 805
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.592093288898468,
      "learning_rate": 0.00016920115495668914,
      "loss": 0.4208,
      "step": 806
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5438862442970276,
      "learning_rate": 0.000169162656400385,
      "loss": 0.8563,
      "step": 807
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6113837361335754,
      "learning_rate": 0.00016912415784408087,
      "loss": 0.6691,
      "step": 808
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6554896235466003,
      "learning_rate": 0.00016908565928777671,
      "loss": 0.5728,
      "step": 809
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6518779993057251,
      "learning_rate": 0.0001690471607314726,
      "loss": 0.7557,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6213161945343018,
      "learning_rate": 0.00016900866217516844,
      "loss": 0.9093,
      "step": 811
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7025657296180725,
      "learning_rate": 0.0001689701636188643,
      "loss": 0.5286,
      "step": 812
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.620762050151825,
      "learning_rate": 0.00016893166506256016,
      "loss": 0.4259,
      "step": 813
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6192619800567627,
      "learning_rate": 0.000168893166506256,
      "loss": 0.883,
      "step": 814
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5870999097824097,
      "learning_rate": 0.00016885466794995188,
      "loss": 0.4531,
      "step": 815
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6501561403274536,
      "learning_rate": 0.00016881616939364775,
      "loss": 0.526,
      "step": 816
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7252989411354065,
      "learning_rate": 0.00016877767083734363,
      "loss": 0.4033,
      "step": 817
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5101154446601868,
      "learning_rate": 0.00016873917228103945,
      "loss": 0.6646,
      "step": 818
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6377429962158203,
      "learning_rate": 0.00016870067372473532,
      "loss": 0.425,
      "step": 819
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6790304780006409,
      "learning_rate": 0.0001686621751684312,
      "loss": 0.6064,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6745540499687195,
      "learning_rate": 0.00016862367661212705,
      "loss": 0.4713,
      "step": 821
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5900378823280334,
      "learning_rate": 0.00016858517805582292,
      "loss": 0.4642,
      "step": 822
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8406713008880615,
      "learning_rate": 0.00016854667949951877,
      "loss": 0.5647,
      "step": 823
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7246276140213013,
      "learning_rate": 0.00016850818094321464,
      "loss": 0.5944,
      "step": 824
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.729605495929718,
      "learning_rate": 0.0001684696823869105,
      "loss": 0.8003,
      "step": 825
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5967618227005005,
      "learning_rate": 0.00016843118383060636,
      "loss": 0.7253,
      "step": 826
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5960533022880554,
      "learning_rate": 0.00016839268527430224,
      "loss": 0.5132,
      "step": 827
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6901223063468933,
      "learning_rate": 0.00016835418671799809,
      "loss": 0.6704,
      "step": 828
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7164360880851746,
      "learning_rate": 0.00016831568816169393,
      "loss": 0.7785,
      "step": 829
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7042586207389832,
      "learning_rate": 0.0001682771896053898,
      "loss": 0.633,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7049960494041443,
      "learning_rate": 0.00016823869104908568,
      "loss": 0.6966,
      "step": 831
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.650780975818634,
      "learning_rate": 0.00016820019249278153,
      "loss": 0.9112,
      "step": 832
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7429491877555847,
      "learning_rate": 0.00016816169393647738,
      "loss": 0.451,
      "step": 833
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8485577702522278,
      "learning_rate": 0.00016812319538017325,
      "loss": 0.712,
      "step": 834
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6208774447441101,
      "learning_rate": 0.00016808469682386913,
      "loss": 0.9166,
      "step": 835
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7442309260368347,
      "learning_rate": 0.00016804619826756497,
      "loss": 0.5191,
      "step": 836
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6214428544044495,
      "learning_rate": 0.00016800769971126085,
      "loss": 1.036,
      "step": 837
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.561028003692627,
      "learning_rate": 0.0001679692011549567,
      "loss": 0.7306,
      "step": 838
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6167818307876587,
      "learning_rate": 0.00016793070259865254,
      "loss": 0.8272,
      "step": 839
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6941654682159424,
      "learning_rate": 0.00016789220404234842,
      "loss": 0.6402,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8015614151954651,
      "learning_rate": 0.0001678537054860443,
      "loss": 0.5014,
      "step": 841
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5019364356994629,
      "learning_rate": 0.00016781520692974014,
      "loss": 0.6128,
      "step": 842
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.7343227863311768,
      "learning_rate": 0.000167776708373436,
      "loss": 0.8232,
      "step": 843
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8433186411857605,
      "learning_rate": 0.00016773820981713186,
      "loss": 0.6303,
      "step": 844
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9831601977348328,
      "learning_rate": 0.00016769971126082774,
      "loss": 0.5791,
      "step": 845
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6429057717323303,
      "learning_rate": 0.00016766121270452358,
      "loss": 0.723,
      "step": 846
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6961003541946411,
      "learning_rate": 0.00016762271414821943,
      "loss": 0.5658,
      "step": 847
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8514600396156311,
      "learning_rate": 0.0001675842155919153,
      "loss": 0.6071,
      "step": 848
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5562446713447571,
      "learning_rate": 0.00016754571703561118,
      "loss": 0.6296,
      "step": 849
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6539165377616882,
      "learning_rate": 0.00016750721847930703,
      "loss": 0.5737,
      "step": 850
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.685072660446167,
      "learning_rate": 0.0001674687199230029,
      "loss": 0.7883,
      "step": 851
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8172012567520142,
      "learning_rate": 0.00016743022136669875,
      "loss": 0.5847,
      "step": 852
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6637850999832153,
      "learning_rate": 0.00016739172281039462,
      "loss": 0.7267,
      "step": 853
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9587538838386536,
      "learning_rate": 0.00016735322425409047,
      "loss": 0.5408,
      "step": 854
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6579755544662476,
      "learning_rate": 0.00016731472569778635,
      "loss": 0.7071,
      "step": 855
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5417776107788086,
      "learning_rate": 0.00016727622714148222,
      "loss": 0.9095,
      "step": 856
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.77644282579422,
      "learning_rate": 0.00016723772858517807,
      "loss": 0.6109,
      "step": 857
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6420778036117554,
      "learning_rate": 0.00016719923002887392,
      "loss": 0.6785,
      "step": 858
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6844477653503418,
      "learning_rate": 0.0001671607314725698,
      "loss": 0.645,
      "step": 859
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5882246494293213,
      "learning_rate": 0.00016712223291626566,
      "loss": 0.7978,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6891993284225464,
      "learning_rate": 0.0001670837343599615,
      "loss": 0.7003,
      "step": 861
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7371298670768738,
      "learning_rate": 0.00016704523580365736,
      "loss": 0.7108,
      "step": 862
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7596960067749023,
      "learning_rate": 0.00016700673724735323,
      "loss": 0.725,
      "step": 863
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8753847479820251,
      "learning_rate": 0.0001669682386910491,
      "loss": 0.3398,
      "step": 864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5705381631851196,
      "learning_rate": 0.00016692974013474496,
      "loss": 0.6416,
      "step": 865
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5781949758529663,
      "learning_rate": 0.00016689124157844083,
      "loss": 0.7469,
      "step": 866
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7435440421104431,
      "learning_rate": 0.00016685274302213668,
      "loss": 0.5541,
      "step": 867
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6507339477539062,
      "learning_rate": 0.00016681424446583253,
      "loss": 0.7938,
      "step": 868
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7827209234237671,
      "learning_rate": 0.0001667757459095284,
      "loss": 0.7759,
      "step": 869
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7459266185760498,
      "learning_rate": 0.00016673724735322427,
      "loss": 0.5668,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7030891180038452,
      "learning_rate": 0.00016669874879692012,
      "loss": 0.4744,
      "step": 871
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6184287071228027,
      "learning_rate": 0.00016666025024061597,
      "loss": 0.6239,
      "step": 872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6977325081825256,
      "learning_rate": 0.00016662175168431184,
      "loss": 0.7472,
      "step": 873
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5548222661018372,
      "learning_rate": 0.00016658325312800772,
      "loss": 0.6034,
      "step": 874
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.767720103263855,
      "learning_rate": 0.00016654475457170357,
      "loss": 0.7184,
      "step": 875
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6386733651161194,
      "learning_rate": 0.0001665062560153994,
      "loss": 1.0008,
      "step": 876
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.804498016834259,
      "learning_rate": 0.0001664677574590953,
      "loss": 0.6764,
      "step": 877
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6173493266105652,
      "learning_rate": 0.00016642925890279116,
      "loss": 0.5462,
      "step": 878
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.698773741722107,
      "learning_rate": 0.000166390760346487,
      "loss": 0.61,
      "step": 879
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7850584387779236,
      "learning_rate": 0.00016635226179018288,
      "loss": 0.7905,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.732761025428772,
      "learning_rate": 0.00016631376323387873,
      "loss": 0.4881,
      "step": 881
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7245400547981262,
      "learning_rate": 0.0001662752646775746,
      "loss": 0.7452,
      "step": 882
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5255295634269714,
      "learning_rate": 0.00016623676612127045,
      "loss": 0.6612,
      "step": 883
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5276505947113037,
      "learning_rate": 0.00016619826756496633,
      "loss": 0.8135,
      "step": 884
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6914088726043701,
      "learning_rate": 0.0001661597690086622,
      "loss": 0.8099,
      "step": 885
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7663986682891846,
      "learning_rate": 0.00016612127045235802,
      "loss": 0.5437,
      "step": 886
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8458823561668396,
      "learning_rate": 0.0001660827718960539,
      "loss": 0.6179,
      "step": 887
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6551546454429626,
      "learning_rate": 0.00016604427333974977,
      "loss": 0.5903,
      "step": 888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5023525357246399,
      "learning_rate": 0.00016600577478344565,
      "loss": 0.988,
      "step": 889
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5599257946014404,
      "learning_rate": 0.0001659672762271415,
      "loss": 0.6622,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8117944598197937,
      "learning_rate": 0.00016592877767083734,
      "loss": 0.7773,
      "step": 891
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7767010927200317,
      "learning_rate": 0.00016589027911453322,
      "loss": 0.8024,
      "step": 892
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6088848114013672,
      "learning_rate": 0.00016585178055822906,
      "loss": 0.6926,
      "step": 893
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5286434888839722,
      "learning_rate": 0.00016581328200192494,
      "loss": 0.6858,
      "step": 894
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5697369575500488,
      "learning_rate": 0.0001657747834456208,
      "loss": 1.1228,
      "step": 895
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.643172025680542,
      "learning_rate": 0.00016573628488931666,
      "loss": 0.6541,
      "step": 896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8290871977806091,
      "learning_rate": 0.0001656977863330125,
      "loss": 0.6177,
      "step": 897
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6258559823036194,
      "learning_rate": 0.00016565928777670838,
      "loss": 0.8617,
      "step": 898
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.663238525390625,
      "learning_rate": 0.00016562078922040426,
      "loss": 0.6367,
      "step": 899
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.589301586151123,
      "learning_rate": 0.0001655822906641001,
      "loss": 0.6624,
      "step": 900
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6248452663421631,
      "learning_rate": 0.00016554379210779595,
      "loss": 0.8319,
      "step": 901
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.705293595790863,
      "learning_rate": 0.00016550529355149183,
      "loss": 0.6169,
      "step": 902
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6331523656845093,
      "learning_rate": 0.0001654667949951877,
      "loss": 0.7537,
      "step": 903
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7134804129600525,
      "learning_rate": 0.00016542829643888355,
      "loss": 0.3086,
      "step": 904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6021867394447327,
      "learning_rate": 0.0001653897978825794,
      "loss": 0.5772,
      "step": 905
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7428727149963379,
      "learning_rate": 0.00016535129932627527,
      "loss": 0.6407,
      "step": 906
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6161805391311646,
      "learning_rate": 0.00016531280076997114,
      "loss": 0.5114,
      "step": 907
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7714093327522278,
      "learning_rate": 0.000165274302213667,
      "loss": 0.7504,
      "step": 908
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.49686864018440247,
      "learning_rate": 0.00016523580365736287,
      "loss": 0.6508,
      "step": 909
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4398133456707001,
      "learning_rate": 0.0001651973051010587,
      "loss": 0.9456,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6514369249343872,
      "learning_rate": 0.00016515880654475456,
      "loss": 0.6558,
      "step": 911
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5922074317932129,
      "learning_rate": 0.00016512030798845044,
      "loss": 0.9348,
      "step": 912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4994887709617615,
      "learning_rate": 0.0001650818094321463,
      "loss": 0.7882,
      "step": 913
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.610044002532959,
      "learning_rate": 0.00016504331087584218,
      "loss": 0.7296,
      "step": 914
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.541244387626648,
      "learning_rate": 0.000165004812319538,
      "loss": 0.6041,
      "step": 915
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.647895097732544,
      "learning_rate": 0.00016496631376323388,
      "loss": 0.8545,
      "step": 916
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5057229399681091,
      "learning_rate": 0.00016492781520692975,
      "loss": 0.5429,
      "step": 917
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5948362946510315,
      "learning_rate": 0.0001648893166506256,
      "loss": 0.5938,
      "step": 918
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4885636270046234,
      "learning_rate": 0.00016485081809432148,
      "loss": 0.8054,
      "step": 919
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7152469754219055,
      "learning_rate": 0.00016481231953801732,
      "loss": 0.3783,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7695571780204773,
      "learning_rate": 0.0001647738209817132,
      "loss": 0.8633,
      "step": 921
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6682639718055725,
      "learning_rate": 0.00016473532242540905,
      "loss": 0.4561,
      "step": 922
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5497984290122986,
      "learning_rate": 0.00016469682386910492,
      "loss": 0.8941,
      "step": 923
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5009626746177673,
      "learning_rate": 0.0001646583253128008,
      "loss": 0.7276,
      "step": 924
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6433472633361816,
      "learning_rate": 0.00016461982675649664,
      "loss": 0.779,
      "step": 925
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6610133647918701,
      "learning_rate": 0.0001645813282001925,
      "loss": 0.4956,
      "step": 926
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8454409241676331,
      "learning_rate": 0.00016454282964388836,
      "loss": 0.5986,
      "step": 927
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.823089599609375,
      "learning_rate": 0.00016450433108758424,
      "loss": 0.4776,
      "step": 928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6618831753730774,
      "learning_rate": 0.00016446583253128009,
      "loss": 1.0351,
      "step": 929
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6922567486763,
      "learning_rate": 0.00016442733397497593,
      "loss": 0.6166,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6896581649780273,
      "learning_rate": 0.0001643888354186718,
      "loss": 0.5528,
      "step": 931
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5492984652519226,
      "learning_rate": 0.00016435033686236768,
      "loss": 0.6829,
      "step": 932
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6111686825752258,
      "learning_rate": 0.00016431183830606353,
      "loss": 0.4542,
      "step": 933
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5228378176689148,
      "learning_rate": 0.0001642733397497594,
      "loss": 0.8278,
      "step": 934
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5937458872795105,
      "learning_rate": 0.00016423484119345525,
      "loss": 0.7656,
      "step": 935
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5819987058639526,
      "learning_rate": 0.00016419634263715113,
      "loss": 0.681,
      "step": 936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6114551424980164,
      "learning_rate": 0.00016415784408084697,
      "loss": 0.5076,
      "step": 937
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5311870574951172,
      "learning_rate": 0.00016411934552454285,
      "loss": 0.9386,
      "step": 938
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8823957443237305,
      "learning_rate": 0.0001640808469682387,
      "loss": 0.3993,
      "step": 939
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7315829396247864,
      "learning_rate": 0.00016404234841193454,
      "loss": 0.7517,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6242652535438538,
      "learning_rate": 0.00016400384985563042,
      "loss": 0.907,
      "step": 941
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7685766220092773,
      "learning_rate": 0.0001639653512993263,
      "loss": 0.4934,
      "step": 942
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6275731921195984,
      "learning_rate": 0.00016392685274302214,
      "loss": 0.5533,
      "step": 943
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6179074048995972,
      "learning_rate": 0.000163888354186718,
      "loss": 0.5926,
      "step": 944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9582035541534424,
      "learning_rate": 0.00016384985563041386,
      "loss": 0.406,
      "step": 945
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6250560283660889,
      "learning_rate": 0.00016381135707410974,
      "loss": 0.4709,
      "step": 946
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7713592648506165,
      "learning_rate": 0.00016377285851780558,
      "loss": 0.596,
      "step": 947
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8489186763763428,
      "learning_rate": 0.00016373435996150146,
      "loss": 0.3098,
      "step": 948
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8424249887466431,
      "learning_rate": 0.0001636958614051973,
      "loss": 0.4872,
      "step": 949
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7226042151451111,
      "learning_rate": 0.00016365736284889318,
      "loss": 0.6179,
      "step": 950
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7214240431785583,
      "learning_rate": 0.00016361886429258903,
      "loss": 0.5751,
      "step": 951
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6577856540679932,
      "learning_rate": 0.0001635803657362849,
      "loss": 0.5976,
      "step": 952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6834031343460083,
      "learning_rate": 0.00016354186717998078,
      "loss": 0.6292,
      "step": 953
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7686372995376587,
      "learning_rate": 0.00016350336862367662,
      "loss": 0.8163,
      "step": 954
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7353248000144958,
      "learning_rate": 0.00016346487006737247,
      "loss": 0.727,
      "step": 955
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4837473928928375,
      "learning_rate": 0.00016342637151106835,
      "loss": 0.8925,
      "step": 956
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6428776383399963,
      "learning_rate": 0.00016338787295476422,
      "loss": 1.0072,
      "step": 957
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6094738841056824,
      "learning_rate": 0.00016334937439846007,
      "loss": 0.6839,
      "step": 958
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.489730566740036,
      "learning_rate": 0.00016331087584215591,
      "loss": 0.6526,
      "step": 959
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5202955603599548,
      "learning_rate": 0.0001632723772858518,
      "loss": 0.7389,
      "step": 960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7180712819099426,
      "learning_rate": 0.00016323387872954766,
      "loss": 0.8853,
      "step": 961
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.583791196346283,
      "learning_rate": 0.0001631953801732435,
      "loss": 0.592,
      "step": 962
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6560325622558594,
      "learning_rate": 0.00016315688161693939,
      "loss": 0.6612,
      "step": 963
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7163086533546448,
      "learning_rate": 0.00016311838306063523,
      "loss": 0.6241,
      "step": 964
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.3557342290878296,
      "learning_rate": 0.00016307988450433108,
      "loss": 0.4299,
      "step": 965
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5866108536720276,
      "learning_rate": 0.00016304138594802696,
      "loss": 0.7868,
      "step": 966
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8693161606788635,
      "learning_rate": 0.00016300288739172283,
      "loss": 0.4393,
      "step": 967
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6918577551841736,
      "learning_rate": 0.00016296438883541868,
      "loss": 0.6609,
      "step": 968
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9720010757446289,
      "learning_rate": 0.00016292589027911452,
      "loss": 0.8191,
      "step": 969
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6472270488739014,
      "learning_rate": 0.0001628873917228104,
      "loss": 0.5592,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6011863350868225,
      "learning_rate": 0.00016284889316650627,
      "loss": 0.7172,
      "step": 971
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5597042441368103,
      "learning_rate": 0.00016281039461020212,
      "loss": 0.6144,
      "step": 972
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5586633682250977,
      "learning_rate": 0.00016277189605389797,
      "loss": 0.7462,
      "step": 973
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6528881192207336,
      "learning_rate": 0.00016273339749759384,
      "loss": 0.6172,
      "step": 974
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6383774876594543,
      "learning_rate": 0.00016269489894128972,
      "loss": 0.6746,
      "step": 975
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6202871203422546,
      "learning_rate": 0.00016265640038498556,
      "loss": 0.5734,
      "step": 976
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5673164129257202,
      "learning_rate": 0.00016261790182868144,
      "loss": 0.7574,
      "step": 977
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.668799877166748,
      "learning_rate": 0.0001625794032723773,
      "loss": 0.6404,
      "step": 978
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8498870730400085,
      "learning_rate": 0.00016254090471607316,
      "loss": 0.853,
      "step": 979
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7376070022583008,
      "learning_rate": 0.000162502406159769,
      "loss": 0.6124,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5754876732826233,
      "learning_rate": 0.00016246390760346488,
      "loss": 0.642,
      "step": 981
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6460099220275879,
      "learning_rate": 0.00016242540904716076,
      "loss": 0.6156,
      "step": 982
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6274104118347168,
      "learning_rate": 0.0001623869104908566,
      "loss": 0.4884,
      "step": 983
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8286557197570801,
      "learning_rate": 0.00016234841193455245,
      "loss": 0.6296,
      "step": 984
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7251535654067993,
      "learning_rate": 0.00016230991337824833,
      "loss": 0.7966,
      "step": 985
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7144703269004822,
      "learning_rate": 0.0001622714148219442,
      "loss": 0.7701,
      "step": 986
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5392202734947205,
      "learning_rate": 0.00016223291626564005,
      "loss": 0.7186,
      "step": 987
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5329578518867493,
      "learning_rate": 0.0001621944177093359,
      "loss": 0.6202,
      "step": 988
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7284709811210632,
      "learning_rate": 0.00016215591915303177,
      "loss": 0.8303,
      "step": 989
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7865099906921387,
      "learning_rate": 0.00016211742059672762,
      "loss": 0.7128,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8105828166007996,
      "learning_rate": 0.0001620789220404235,
      "loss": 0.6968,
      "step": 991
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6783756017684937,
      "learning_rate": 0.00016204042348411937,
      "loss": 0.7015,
      "step": 992
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.583478569984436,
      "learning_rate": 0.00016200192492781522,
      "loss": 0.7363,
      "step": 993
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49142903089523315,
      "learning_rate": 0.00016196342637151106,
      "loss": 0.7277,
      "step": 994
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5943036675453186,
      "learning_rate": 0.00016192492781520694,
      "loss": 0.7628,
      "step": 995
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7128115296363831,
      "learning_rate": 0.0001618864292589028,
      "loss": 0.8404,
      "step": 996
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6578225493431091,
      "learning_rate": 0.00016184793070259866,
      "loss": 0.8409,
      "step": 997
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6048220992088318,
      "learning_rate": 0.0001618094321462945,
      "loss": 0.6295,
      "step": 998
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5259882807731628,
      "learning_rate": 0.00016177093358999038,
      "loss": 0.7369,
      "step": 999
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5089165568351746,
      "learning_rate": 0.00016173243503368626,
      "loss": 0.9018,
      "step": 1000
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6050861477851868,
      "learning_rate": 0.0001616939364773821,
      "loss": 0.809,
      "step": 1001
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.59051114320755,
      "learning_rate": 0.00016165543792107795,
      "loss": 0.5482,
      "step": 1002
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.668228805065155,
      "learning_rate": 0.00016161693936477382,
      "loss": 0.5315,
      "step": 1003
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6473144292831421,
      "learning_rate": 0.0001615784408084697,
      "loss": 0.7916,
      "step": 1004
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.559569239616394,
      "learning_rate": 0.00016153994225216555,
      "loss": 0.9101,
      "step": 1005
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.549785315990448,
      "learning_rate": 0.00016150144369586142,
      "loss": 0.4666,
      "step": 1006
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5968616604804993,
      "learning_rate": 0.00016146294513955727,
      "loss": 0.7016,
      "step": 1007
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5257424712181091,
      "learning_rate": 0.00016142444658325314,
      "loss": 0.6878,
      "step": 1008
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7404627203941345,
      "learning_rate": 0.000161385948026949,
      "loss": 0.7444,
      "step": 1009
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7520713210105896,
      "learning_rate": 0.00016134744947064487,
      "loss": 0.7026,
      "step": 1010
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8451860547065735,
      "learning_rate": 0.00016130895091434074,
      "loss": 0.4751,
      "step": 1011
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7231723070144653,
      "learning_rate": 0.00016127045235803656,
      "loss": 0.6151,
      "step": 1012
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7246952056884766,
      "learning_rate": 0.00016123195380173243,
      "loss": 0.8536,
      "step": 1013
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6855695843696594,
      "learning_rate": 0.0001611934552454283,
      "loss": 0.5719,
      "step": 1014
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5510358810424805,
      "learning_rate": 0.00016115495668912418,
      "loss": 1.0573,
      "step": 1015
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7026839852333069,
      "learning_rate": 0.00016111645813282003,
      "loss": 0.6545,
      "step": 1016
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5820688605308533,
      "learning_rate": 0.00016107795957651588,
      "loss": 0.878,
      "step": 1017
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.993475079536438,
      "learning_rate": 0.00016103946102021175,
      "loss": 0.3525,
      "step": 1018
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6891927719116211,
      "learning_rate": 0.0001610009624639076,
      "loss": 0.4149,
      "step": 1019
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5482773184776306,
      "learning_rate": 0.00016096246390760348,
      "loss": 0.7322,
      "step": 1020
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6247751116752625,
      "learning_rate": 0.00016092396535129935,
      "loss": 0.5589,
      "step": 1021
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5784123539924622,
      "learning_rate": 0.0001608854667949952,
      "loss": 0.7719,
      "step": 1022
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5684001445770264,
      "learning_rate": 0.00016084696823869104,
      "loss": 0.7288,
      "step": 1023
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6931840777397156,
      "learning_rate": 0.00016080846968238692,
      "loss": 0.5414,
      "step": 1024
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8244776129722595,
      "learning_rate": 0.0001607699711260828,
      "loss": 0.6376,
      "step": 1025
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6041722893714905,
      "learning_rate": 0.00016073147256977864,
      "loss": 0.8035,
      "step": 1026
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.582593560218811,
      "learning_rate": 0.0001606929740134745,
      "loss": 0.8301,
      "step": 1027
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7372128367424011,
      "learning_rate": 0.00016065447545717036,
      "loss": 0.7642,
      "step": 1028
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6923209428787231,
      "learning_rate": 0.00016061597690086624,
      "loss": 0.5078,
      "step": 1029
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5389984846115112,
      "learning_rate": 0.00016057747834456208,
      "loss": 0.7924,
      "step": 1030
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7745808959007263,
      "learning_rate": 0.00016053897978825793,
      "loss": 0.5128,
      "step": 1031
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7530668377876282,
      "learning_rate": 0.0001605004812319538,
      "loss": 0.5776,
      "step": 1032
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8713141679763794,
      "learning_rate": 0.00016046198267564968,
      "loss": 0.5874,
      "step": 1033
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6368699669837952,
      "learning_rate": 0.00016042348411934553,
      "loss": 0.8277,
      "step": 1034
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6671217679977417,
      "learning_rate": 0.0001603849855630414,
      "loss": 0.7146,
      "step": 1035
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9834448099136353,
      "learning_rate": 0.00016034648700673725,
      "loss": 0.8093,
      "step": 1036
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9151608943939209,
      "learning_rate": 0.0001603079884504331,
      "loss": 0.786,
      "step": 1037
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.216202735900879,
      "learning_rate": 0.00016026948989412897,
      "loss": 0.7106,
      "step": 1038
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7819514274597168,
      "learning_rate": 0.00016023099133782485,
      "loss": 0.6133,
      "step": 1039
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5415997505187988,
      "learning_rate": 0.00016019249278152072,
      "loss": 0.8512,
      "step": 1040
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9623203873634338,
      "learning_rate": 0.00016015399422521654,
      "loss": 0.6506,
      "step": 1041
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.624600350856781,
      "learning_rate": 0.00016011549566891242,
      "loss": 0.7378,
      "step": 1042
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.556650996208191,
      "learning_rate": 0.0001600769971126083,
      "loss": 0.5687,
      "step": 1043
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8099840879440308,
      "learning_rate": 0.00016003849855630414,
      "loss": 0.5503,
      "step": 1044
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6660192608833313,
      "learning_rate": 0.00016,
      "loss": 0.7449,
      "step": 1045
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5758103132247925,
      "learning_rate": 0.00015996150144369586,
      "loss": 0.6213,
      "step": 1046
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5485714077949524,
      "learning_rate": 0.00015992300288739174,
      "loss": 0.7396,
      "step": 1047
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7980797290802002,
      "learning_rate": 0.00015988450433108758,
      "loss": 0.6041,
      "step": 1048
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7551158666610718,
      "learning_rate": 0.00015984600577478346,
      "loss": 0.581,
      "step": 1049
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7218193411827087,
      "learning_rate": 0.00015980750721847933,
      "loss": 0.7485,
      "step": 1050
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8393481969833374,
      "learning_rate": 0.00015976900866217518,
      "loss": 0.6978,
      "step": 1051
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7220890522003174,
      "learning_rate": 0.00015973051010587103,
      "loss": 0.5906,
      "step": 1052
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6070945262908936,
      "learning_rate": 0.0001596920115495669,
      "loss": 0.6646,
      "step": 1053
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6153214573860168,
      "learning_rate": 0.00015965351299326278,
      "loss": 0.6761,
      "step": 1054
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6349591612815857,
      "learning_rate": 0.00015961501443695862,
      "loss": 0.6054,
      "step": 1055
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5632799863815308,
      "learning_rate": 0.00015957651588065447,
      "loss": 0.7,
      "step": 1056
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.572062075138092,
      "learning_rate": 0.00015953801732435034,
      "loss": 0.8355,
      "step": 1057
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7255899906158447,
      "learning_rate": 0.00015949951876804622,
      "loss": 0.8052,
      "step": 1058
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.722072958946228,
      "learning_rate": 0.00015946102021174207,
      "loss": 0.6466,
      "step": 1059
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6027347445487976,
      "learning_rate": 0.00015942252165543794,
      "loss": 0.5209,
      "step": 1060
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6282886266708374,
      "learning_rate": 0.0001593840230991338,
      "loss": 0.5438,
      "step": 1061
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.536647617816925,
      "learning_rate": 0.00015934552454282964,
      "loss": 0.9322,
      "step": 1062
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6283189058303833,
      "learning_rate": 0.0001593070259865255,
      "loss": 0.8046,
      "step": 1063
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6387714147567749,
      "learning_rate": 0.00015926852743022139,
      "loss": 0.6993,
      "step": 1064
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5033554434776306,
      "learning_rate": 0.00015923002887391723,
      "loss": 0.8846,
      "step": 1065
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6062630414962769,
      "learning_rate": 0.00015919153031761308,
      "loss": 0.6687,
      "step": 1066
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8938087224960327,
      "learning_rate": 0.00015915303176130895,
      "loss": 0.4096,
      "step": 1067
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5791472792625427,
      "learning_rate": 0.00015911453320500483,
      "loss": 0.6223,
      "step": 1068
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8800079822540283,
      "learning_rate": 0.00015907603464870068,
      "loss": 0.6337,
      "step": 1069
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7527818083763123,
      "learning_rate": 0.00015903753609239652,
      "loss": 0.4398,
      "step": 1070
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9407803416252136,
      "learning_rate": 0.0001589990375360924,
      "loss": 0.488,
      "step": 1071
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.3401373624801636,
      "learning_rate": 0.00015896053897978827,
      "loss": 0.5787,
      "step": 1072
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5810390114784241,
      "learning_rate": 0.00015892204042348412,
      "loss": 0.8694,
      "step": 1073
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9111753702163696,
      "learning_rate": 0.00015888354186718,
      "loss": 0.5841,
      "step": 1074
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7245570421218872,
      "learning_rate": 0.00015884504331087584,
      "loss": 0.4573,
      "step": 1075
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6708487272262573,
      "learning_rate": 0.00015880654475457172,
      "loss": 0.4001,
      "step": 1076
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7308405637741089,
      "learning_rate": 0.00015876804619826756,
      "loss": 0.5814,
      "step": 1077
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6623454093933105,
      "learning_rate": 0.00015872954764196344,
      "loss": 0.6673,
      "step": 1078
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6986986398696899,
      "learning_rate": 0.0001586910490856593,
      "loss": 0.7797,
      "step": 1079
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6734797358512878,
      "learning_rate": 0.00015865255052935516,
      "loss": 0.732,
      "step": 1080
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5938836336135864,
      "learning_rate": 0.000158614051973051,
      "loss": 0.6579,
      "step": 1081
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5549873113632202,
      "learning_rate": 0.00015857555341674688,
      "loss": 0.5462,
      "step": 1082
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.63886958360672,
      "learning_rate": 0.00015853705486044276,
      "loss": 0.4975,
      "step": 1083
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7553693056106567,
      "learning_rate": 0.0001584985563041386,
      "loss": 0.5791,
      "step": 1084
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2152680158615112,
      "learning_rate": 0.00015846005774783445,
      "loss": 0.7655,
      "step": 1085
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8016358613967896,
      "learning_rate": 0.00015842155919153033,
      "loss": 0.7236,
      "step": 1086
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6708122491836548,
      "learning_rate": 0.0001583830606352262,
      "loss": 0.6105,
      "step": 1087
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.80450439453125,
      "learning_rate": 0.00015834456207892205,
      "loss": 0.5373,
      "step": 1088
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5739531517028809,
      "learning_rate": 0.00015830606352261792,
      "loss": 0.5436,
      "step": 1089
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4307832717895508,
      "learning_rate": 0.00015826756496631377,
      "loss": 0.7211,
      "step": 1090
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4431876242160797,
      "learning_rate": 0.00015822906641000962,
      "loss": 0.693,
      "step": 1091
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5798433423042297,
      "learning_rate": 0.0001581905678537055,
      "loss": 0.6383,
      "step": 1092
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7890993356704712,
      "learning_rate": 0.00015815206929740137,
      "loss": 0.7222,
      "step": 1093
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5920421481132507,
      "learning_rate": 0.00015811357074109721,
      "loss": 0.8896,
      "step": 1094
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49582916498184204,
      "learning_rate": 0.00015807507218479306,
      "loss": 0.9485,
      "step": 1095
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5789178013801575,
      "learning_rate": 0.00015803657362848894,
      "loss": 0.4686,
      "step": 1096
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5209294557571411,
      "learning_rate": 0.0001579980750721848,
      "loss": 0.7277,
      "step": 1097
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6931360363960266,
      "learning_rate": 0.00015795957651588066,
      "loss": 0.5346,
      "step": 1098
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.576304018497467,
      "learning_rate": 0.0001579210779595765,
      "loss": 0.4652,
      "step": 1099
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.558350682258606,
      "learning_rate": 0.00015788257940327238,
      "loss": 0.5005,
      "step": 1100
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5766429305076599,
      "learning_rate": 0.00015784408084696825,
      "loss": 0.6201,
      "step": 1101
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.609963595867157,
      "learning_rate": 0.0001578055822906641,
      "loss": 0.7996,
      "step": 1102
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6396650671958923,
      "learning_rate": 0.00015776708373435998,
      "loss": 0.6368,
      "step": 1103
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6079216003417969,
      "learning_rate": 0.00015772858517805582,
      "loss": 0.7987,
      "step": 1104
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6727197766304016,
      "learning_rate": 0.0001576900866217517,
      "loss": 0.5177,
      "step": 1105
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.564319372177124,
      "learning_rate": 0.00015765158806544755,
      "loss": 0.9275,
      "step": 1106
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4854680299758911,
      "learning_rate": 0.00015761308950914342,
      "loss": 0.8529,
      "step": 1107
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5108237266540527,
      "learning_rate": 0.0001575745909528393,
      "loss": 0.7113,
      "step": 1108
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6625758409500122,
      "learning_rate": 0.00015753609239653512,
      "loss": 0.564,
      "step": 1109
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.48964017629623413,
      "learning_rate": 0.000157497593840231,
      "loss": 0.8158,
      "step": 1110
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5887210369110107,
      "learning_rate": 0.00015745909528392686,
      "loss": 0.5813,
      "step": 1111
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7943276762962341,
      "learning_rate": 0.00015742059672762274,
      "loss": 0.7038,
      "step": 1112
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.604762077331543,
      "learning_rate": 0.0001573820981713186,
      "loss": 0.8983,
      "step": 1113
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8718379735946655,
      "learning_rate": 0.00015734359961501443,
      "loss": 0.5614,
      "step": 1114
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6089176535606384,
      "learning_rate": 0.0001573051010587103,
      "loss": 1.102,
      "step": 1115
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6654770374298096,
      "learning_rate": 0.00015726660250240616,
      "loss": 0.762,
      "step": 1116
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5941739678382874,
      "learning_rate": 0.00015722810394610203,
      "loss": 0.7362,
      "step": 1117
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6108391284942627,
      "learning_rate": 0.0001571896053897979,
      "loss": 0.6706,
      "step": 1118
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8305339217185974,
      "learning_rate": 0.00015715110683349375,
      "loss": 0.5765,
      "step": 1119
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6020849347114563,
      "learning_rate": 0.0001571126082771896,
      "loss": 0.4583,
      "step": 1120
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.832979679107666,
      "learning_rate": 0.00015707410972088547,
      "loss": 0.8116,
      "step": 1121
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0371918678283691,
      "learning_rate": 0.00015703561116458135,
      "loss": 0.3804,
      "step": 1122
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7185341715812683,
      "learning_rate": 0.0001569971126082772,
      "loss": 0.4932,
      "step": 1123
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7079818844795227,
      "learning_rate": 0.00015695861405197304,
      "loss": 0.5506,
      "step": 1124
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7471815347671509,
      "learning_rate": 0.00015692011549566892,
      "loss": 0.6165,
      "step": 1125
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6546742916107178,
      "learning_rate": 0.0001568816169393648,
      "loss": 0.9492,
      "step": 1126
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5115396976470947,
      "learning_rate": 0.00015684311838306064,
      "loss": 0.7117,
      "step": 1127
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7167044281959534,
      "learning_rate": 0.0001568046198267565,
      "loss": 0.445,
      "step": 1128
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7172253131866455,
      "learning_rate": 0.00015676612127045236,
      "loss": 0.7845,
      "step": 1129
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6229810118675232,
      "learning_rate": 0.00015672762271414824,
      "loss": 0.676,
      "step": 1130
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7732219099998474,
      "learning_rate": 0.00015668912415784408,
      "loss": 0.595,
      "step": 1131
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6236416697502136,
      "learning_rate": 0.00015665062560153996,
      "loss": 0.531,
      "step": 1132
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6249062418937683,
      "learning_rate": 0.0001566121270452358,
      "loss": 0.7824,
      "step": 1133
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6092472076416016,
      "learning_rate": 0.00015657362848893168,
      "loss": 0.6567,
      "step": 1134
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.798481285572052,
      "learning_rate": 0.00015653512993262753,
      "loss": 0.5361,
      "step": 1135
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5823736786842346,
      "learning_rate": 0.0001564966313763234,
      "loss": 0.6915,
      "step": 1136
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7345625162124634,
      "learning_rate": 0.00015645813282001928,
      "loss": 0.8569,
      "step": 1137
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.020438551902771,
      "learning_rate": 0.0001564196342637151,
      "loss": 0.5174,
      "step": 1138
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6417597532272339,
      "learning_rate": 0.00015638113570741097,
      "loss": 0.6604,
      "step": 1139
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7086973786354065,
      "learning_rate": 0.00015634263715110685,
      "loss": 0.8057,
      "step": 1140
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6364134550094604,
      "learning_rate": 0.0001563041385948027,
      "loss": 0.7453,
      "step": 1141
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7083284258842468,
      "learning_rate": 0.00015626564003849857,
      "loss": 0.5474,
      "step": 1142
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7884374260902405,
      "learning_rate": 0.00015622714148219442,
      "loss": 0.537,
      "step": 1143
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6327049732208252,
      "learning_rate": 0.0001561886429258903,
      "loss": 0.5381,
      "step": 1144
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5660977363586426,
      "learning_rate": 0.00015615014436958614,
      "loss": 0.878,
      "step": 1145
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.927993893623352,
      "learning_rate": 0.000156111645813282,
      "loss": 0.9046,
      "step": 1146
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.6073461771011353,
      "learning_rate": 0.0001560731472569779,
      "loss": 0.935,
      "step": 1147
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7982702851295471,
      "learning_rate": 0.00015603464870067373,
      "loss": 0.5733,
      "step": 1148
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8835765719413757,
      "learning_rate": 0.00015599615014436958,
      "loss": 0.4536,
      "step": 1149
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8675446510314941,
      "learning_rate": 0.00015595765158806546,
      "loss": 0.4512,
      "step": 1150
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8041766285896301,
      "learning_rate": 0.00015591915303176133,
      "loss": 0.5658,
      "step": 1151
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6199082732200623,
      "learning_rate": 0.00015588065447545718,
      "loss": 0.6004,
      "step": 1152
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.542233943939209,
      "learning_rate": 0.00015584215591915303,
      "loss": 0.8671,
      "step": 1153
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4906879961490631,
      "learning_rate": 0.0001558036573628489,
      "loss": 0.9241,
      "step": 1154
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7853452563285828,
      "learning_rate": 0.00015576515880654477,
      "loss": 0.7578,
      "step": 1155
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5504077672958374,
      "learning_rate": 0.00015572666025024062,
      "loss": 0.8151,
      "step": 1156
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6421082019805908,
      "learning_rate": 0.00015568816169393647,
      "loss": 0.5077,
      "step": 1157
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8135775327682495,
      "learning_rate": 0.00015564966313763234,
      "loss": 0.8091,
      "step": 1158
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.59921795129776,
      "learning_rate": 0.00015561116458132822,
      "loss": 0.7644,
      "step": 1159
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7178299427032471,
      "learning_rate": 0.00015557266602502407,
      "loss": 0.756,
      "step": 1160
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6948160529136658,
      "learning_rate": 0.00015553416746871994,
      "loss": 0.6171,
      "step": 1161
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6302603483200073,
      "learning_rate": 0.0001554956689124158,
      "loss": 0.5684,
      "step": 1162
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7824051380157471,
      "learning_rate": 0.00015545717035611164,
      "loss": 0.653,
      "step": 1163
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5375508666038513,
      "learning_rate": 0.0001554186717998075,
      "loss": 0.703,
      "step": 1164
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.502137303352356,
      "learning_rate": 0.00015538017324350338,
      "loss": 0.6841,
      "step": 1165
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7102673649787903,
      "learning_rate": 0.00015534167468719926,
      "loss": 0.8887,
      "step": 1166
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5140697360038757,
      "learning_rate": 0.00015530317613089508,
      "loss": 0.8108,
      "step": 1167
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7309038043022156,
      "learning_rate": 0.00015526467757459095,
      "loss": 0.4629,
      "step": 1168
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5280519127845764,
      "learning_rate": 0.00015522617901828683,
      "loss": 0.5317,
      "step": 1169
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.49354228377342224,
      "learning_rate": 0.00015518768046198268,
      "loss": 0.5122,
      "step": 1170
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6465975046157837,
      "learning_rate": 0.00015514918190567855,
      "loss": 0.3934,
      "step": 1171
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5229207873344421,
      "learning_rate": 0.0001551106833493744,
      "loss": 0.796,
      "step": 1172
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6981282234191895,
      "learning_rate": 0.00015507218479307027,
      "loss": 0.5522,
      "step": 1173
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6014683246612549,
      "learning_rate": 0.00015503368623676612,
      "loss": 0.7744,
      "step": 1174
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5938352346420288,
      "learning_rate": 0.000154995187680462,
      "loss": 0.6288,
      "step": 1175
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9871916174888611,
      "learning_rate": 0.00015495668912415787,
      "loss": 0.44,
      "step": 1176
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8898782730102539,
      "learning_rate": 0.00015491819056785372,
      "loss": 0.5959,
      "step": 1177
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5672719478607178,
      "learning_rate": 0.00015487969201154956,
      "loss": 0.8207,
      "step": 1178
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8012008666992188,
      "learning_rate": 0.00015484119345524544,
      "loss": 0.3729,
      "step": 1179
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6547687649726868,
      "learning_rate": 0.0001548026948989413,
      "loss": 0.7076,
      "step": 1180
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5998208522796631,
      "learning_rate": 0.00015476419634263716,
      "loss": 0.5561,
      "step": 1181
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7576836347579956,
      "learning_rate": 0.000154725697786333,
      "loss": 0.7135,
      "step": 1182
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6925976872444153,
      "learning_rate": 0.00015468719923002888,
      "loss": 0.6313,
      "step": 1183
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8556327223777771,
      "learning_rate": 0.00015464870067372476,
      "loss": 0.8667,
      "step": 1184
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8684877157211304,
      "learning_rate": 0.0001546102021174206,
      "loss": 0.6329,
      "step": 1185
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6709431409835815,
      "learning_rate": 0.00015457170356111648,
      "loss": 0.9169,
      "step": 1186
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.601678729057312,
      "learning_rate": 0.00015453320500481233,
      "loss": 0.686,
      "step": 1187
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7624363303184509,
      "learning_rate": 0.00015449470644850817,
      "loss": 0.5857,
      "step": 1188
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7496986985206604,
      "learning_rate": 0.00015445620789220405,
      "loss": 0.5006,
      "step": 1189
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6235130429267883,
      "learning_rate": 0.00015441770933589992,
      "loss": 0.6681,
      "step": 1190
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.539176344871521,
      "learning_rate": 0.00015437921077959577,
      "loss": 0.5846,
      "step": 1191
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5771207213401794,
      "learning_rate": 0.00015434071222329162,
      "loss": 0.7073,
      "step": 1192
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5217157602310181,
      "learning_rate": 0.0001543022136669875,
      "loss": 0.7459,
      "step": 1193
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5465582609176636,
      "learning_rate": 0.00015426371511068337,
      "loss": 0.6121,
      "step": 1194
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8062999844551086,
      "learning_rate": 0.00015422521655437921,
      "loss": 0.5817,
      "step": 1195
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5662956237792969,
      "learning_rate": 0.00015418671799807506,
      "loss": 0.7793,
      "step": 1196
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6580455899238586,
      "learning_rate": 0.00015414821944177094,
      "loss": 0.5048,
      "step": 1197
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8030519485473633,
      "learning_rate": 0.0001541097208854668,
      "loss": 0.6933,
      "step": 1198
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7230435013771057,
      "learning_rate": 0.00015407122232916266,
      "loss": 0.4582,
      "step": 1199
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4768448770046234,
      "learning_rate": 0.00015403272377285853,
      "loss": 0.8131,
      "step": 1200
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7210882306098938,
      "learning_rate": 0.00015399422521655438,
      "loss": 0.67,
      "step": 1201
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.48776933550834656,
      "learning_rate": 0.00015395572666025025,
      "loss": 0.8564,
      "step": 1202
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.648502767086029,
      "learning_rate": 0.0001539172281039461,
      "loss": 0.9132,
      "step": 1203
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7381972670555115,
      "learning_rate": 0.00015387872954764198,
      "loss": 0.5256,
      "step": 1204
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.592212975025177,
      "learning_rate": 0.00015384023099133785,
      "loss": 0.9673,
      "step": 1205
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6195204854011536,
      "learning_rate": 0.0001538017324350337,
      "loss": 0.8968,
      "step": 1206
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5750266909599304,
      "learning_rate": 0.00015376323387872955,
      "loss": 0.598,
      "step": 1207
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5547700524330139,
      "learning_rate": 0.00015372473532242542,
      "loss": 0.7073,
      "step": 1208
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7188200950622559,
      "learning_rate": 0.0001536862367661213,
      "loss": 0.6744,
      "step": 1209
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5443454384803772,
      "learning_rate": 0.00015364773820981714,
      "loss": 0.7287,
      "step": 1210
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6104772090911865,
      "learning_rate": 0.000153609239653513,
      "loss": 0.5915,
      "step": 1211
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6621307730674744,
      "learning_rate": 0.00015357074109720886,
      "loss": 0.7938,
      "step": 1212
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5903645157814026,
      "learning_rate": 0.0001535322425409047,
      "loss": 1.059,
      "step": 1213
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.49845418334007263,
      "learning_rate": 0.00015349374398460059,
      "loss": 0.4907,
      "step": 1214
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7890710234642029,
      "learning_rate": 0.00015345524542829646,
      "loss": 0.7977,
      "step": 1215
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7283629179000854,
      "learning_rate": 0.0001534167468719923,
      "loss": 0.6712,
      "step": 1216
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6659552454948425,
      "learning_rate": 0.00015337824831568816,
      "loss": 0.6925,
      "step": 1217
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7042405605316162,
      "learning_rate": 0.00015333974975938403,
      "loss": 0.5265,
      "step": 1218
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9253318309783936,
      "learning_rate": 0.0001533012512030799,
      "loss": 0.4038,
      "step": 1219
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7331382632255554,
      "learning_rate": 0.00015326275264677575,
      "loss": 0.68,
      "step": 1220
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5408669710159302,
      "learning_rate": 0.0001532242540904716,
      "loss": 0.9413,
      "step": 1221
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6915638446807861,
      "learning_rate": 0.00015318575553416747,
      "loss": 0.6652,
      "step": 1222
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7025106549263,
      "learning_rate": 0.00015314725697786335,
      "loss": 0.7245,
      "step": 1223
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7864883542060852,
      "learning_rate": 0.0001531087584215592,
      "loss": 0.5685,
      "step": 1224
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5014062523841858,
      "learning_rate": 0.00015307025986525504,
      "loss": 0.8864,
      "step": 1225
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9132343530654907,
      "learning_rate": 0.00015303176130895092,
      "loss": 0.688,
      "step": 1226
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6292924880981445,
      "learning_rate": 0.0001529932627526468,
      "loss": 0.5492,
      "step": 1227
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6424588561058044,
      "learning_rate": 0.00015295476419634264,
      "loss": 0.6339,
      "step": 1228
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.772096574306488,
      "learning_rate": 0.00015291626564003851,
      "loss": 0.5964,
      "step": 1229
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5151877403259277,
      "learning_rate": 0.00015287776708373436,
      "loss": 0.8334,
      "step": 1230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6712440848350525,
      "learning_rate": 0.00015283926852743024,
      "loss": 0.6727,
      "step": 1231
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5587252378463745,
      "learning_rate": 0.00015280076997112608,
      "loss": 0.7039,
      "step": 1232
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5892365574836731,
      "learning_rate": 0.00015276227141482196,
      "loss": 0.7397,
      "step": 1233
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7969204187393188,
      "learning_rate": 0.00015272377285851783,
      "loss": 0.8187,
      "step": 1234
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6750072240829468,
      "learning_rate": 0.00015268527430221365,
      "loss": 0.7224,
      "step": 1235
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5549777150154114,
      "learning_rate": 0.00015264677574590953,
      "loss": 0.8076,
      "step": 1236
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9722518920898438,
      "learning_rate": 0.0001526082771896054,
      "loss": 0.6007,
      "step": 1237
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5065214037895203,
      "learning_rate": 0.00015256977863330128,
      "loss": 0.8719,
      "step": 1238
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6935814023017883,
      "learning_rate": 0.00015253128007699712,
      "loss": 0.6247,
      "step": 1239
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.686376690864563,
      "learning_rate": 0.00015249278152069297,
      "loss": 0.7518,
      "step": 1240
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.551851212978363,
      "learning_rate": 0.00015245428296438885,
      "loss": 0.4879,
      "step": 1241
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6394504904747009,
      "learning_rate": 0.0001524157844080847,
      "loss": 0.6751,
      "step": 1242
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7190869450569153,
      "learning_rate": 0.00015237728585178057,
      "loss": 0.7425,
      "step": 1243
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.47244513034820557,
      "learning_rate": 0.00015233878729547644,
      "loss": 1.0858,
      "step": 1244
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5383063554763794,
      "learning_rate": 0.0001523002887391723,
      "loss": 0.9561,
      "step": 1245
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.605799674987793,
      "learning_rate": 0.00015226179018286814,
      "loss": 0.9145,
      "step": 1246
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.466583251953125,
      "learning_rate": 0.000152223291626564,
      "loss": 0.7847,
      "step": 1247
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7582305669784546,
      "learning_rate": 0.0001521847930702599,
      "loss": 0.7454,
      "step": 1248
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6798508763313293,
      "learning_rate": 0.00015214629451395573,
      "loss": 0.522,
      "step": 1249
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5257065892219543,
      "learning_rate": 0.00015210779595765158,
      "loss": 0.5894,
      "step": 1250
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0464253425598145,
      "learning_rate": 0.00015206929740134746,
      "loss": 1.0252,
      "step": 1251
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5751603841781616,
      "learning_rate": 0.00015203079884504333,
      "loss": 0.5788,
      "step": 1252
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7651917338371277,
      "learning_rate": 0.00015199230028873918,
      "loss": 0.6626,
      "step": 1253
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5777443051338196,
      "learning_rate": 0.00015195380173243503,
      "loss": 0.7997,
      "step": 1254
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6311572790145874,
      "learning_rate": 0.0001519153031761309,
      "loss": 0.6419,
      "step": 1255
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8792654275894165,
      "learning_rate": 0.00015187680461982677,
      "loss": 0.4145,
      "step": 1256
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5886335372924805,
      "learning_rate": 0.00015183830606352262,
      "loss": 0.5207,
      "step": 1257
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5889449715614319,
      "learning_rate": 0.0001517998075072185,
      "loss": 0.6567,
      "step": 1258
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7657090425491333,
      "learning_rate": 0.00015176130895091434,
      "loss": 0.7012,
      "step": 1259
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6340703964233398,
      "learning_rate": 0.0001517228103946102,
      "loss": 0.7728,
      "step": 1260
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6111266016960144,
      "learning_rate": 0.00015168431183830607,
      "loss": 0.5711,
      "step": 1261
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6296623945236206,
      "learning_rate": 0.00015164581328200194,
      "loss": 0.6201,
      "step": 1262
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6322306990623474,
      "learning_rate": 0.00015160731472569781,
      "loss": 0.4739,
      "step": 1263
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6466207504272461,
      "learning_rate": 0.00015156881616939364,
      "loss": 0.7385,
      "step": 1264
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5545743107795715,
      "learning_rate": 0.0001515303176130895,
      "loss": 0.7422,
      "step": 1265
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.5432958602905273,
      "learning_rate": 0.00015149181905678538,
      "loss": 0.5106,
      "step": 1266
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5808126926422119,
      "learning_rate": 0.00015145332050048123,
      "loss": 0.3577,
      "step": 1267
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6188709139823914,
      "learning_rate": 0.0001514148219441771,
      "loss": 0.6708,
      "step": 1268
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6459255218505859,
      "learning_rate": 0.00015137632338787295,
      "loss": 0.7895,
      "step": 1269
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4821586310863495,
      "learning_rate": 0.00015133782483156883,
      "loss": 0.4423,
      "step": 1270
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6078227758407593,
      "learning_rate": 0.00015129932627526468,
      "loss": 0.975,
      "step": 1271
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9202126264572144,
      "learning_rate": 0.00015126082771896055,
      "loss": 0.5847,
      "step": 1272
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1905313730239868,
      "learning_rate": 0.00015122232916265642,
      "loss": 0.6668,
      "step": 1273
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7391711473464966,
      "learning_rate": 0.00015118383060635227,
      "loss": 0.4843,
      "step": 1274
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5911352634429932,
      "learning_rate": 0.00015114533205004812,
      "loss": 0.585,
      "step": 1275
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7560420036315918,
      "learning_rate": 0.000151106833493744,
      "loss": 0.6823,
      "step": 1276
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7567138671875,
      "learning_rate": 0.00015106833493743987,
      "loss": 0.4759,
      "step": 1277
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6683733463287354,
      "learning_rate": 0.00015102983638113572,
      "loss": 0.8868,
      "step": 1278
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7923148274421692,
      "learning_rate": 0.00015099133782483156,
      "loss": 0.5776,
      "step": 1279
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6936268210411072,
      "learning_rate": 0.00015095283926852744,
      "loss": 0.9186,
      "step": 1280
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6433857679367065,
      "learning_rate": 0.0001509143407122233,
      "loss": 0.8965,
      "step": 1281
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5510537624359131,
      "learning_rate": 0.00015087584215591916,
      "loss": 0.7606,
      "step": 1282
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5570456385612488,
      "learning_rate": 0.000150837343599615,
      "loss": 0.7924,
      "step": 1283
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6711983680725098,
      "learning_rate": 0.00015079884504331088,
      "loss": 0.8007,
      "step": 1284
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7021318674087524,
      "learning_rate": 0.00015076034648700676,
      "loss": 0.6066,
      "step": 1285
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7159093022346497,
      "learning_rate": 0.0001507218479307026,
      "loss": 0.565,
      "step": 1286
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7015601396560669,
      "learning_rate": 0.00015068334937439848,
      "loss": 0.6656,
      "step": 1287
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6235617995262146,
      "learning_rate": 0.00015064485081809433,
      "loss": 0.8135,
      "step": 1288
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.48980236053466797,
      "learning_rate": 0.00015060635226179017,
      "loss": 0.9058,
      "step": 1289
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6794515252113342,
      "learning_rate": 0.00015056785370548605,
      "loss": 0.5707,
      "step": 1290
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6380992531776428,
      "learning_rate": 0.00015052935514918192,
      "loss": 0.6606,
      "step": 1291
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9269274473190308,
      "learning_rate": 0.00015049085659287777,
      "loss": 0.6432,
      "step": 1292
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.45581144094467163,
      "learning_rate": 0.00015045235803657362,
      "loss": 0.7157,
      "step": 1293
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6875152587890625,
      "learning_rate": 0.0001504138594802695,
      "loss": 0.4055,
      "step": 1294
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8626847267150879,
      "learning_rate": 0.00015037536092396537,
      "loss": 0.4381,
      "step": 1295
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5549584031105042,
      "learning_rate": 0.0001503368623676612,
      "loss": 0.722,
      "step": 1296
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6187148690223694,
      "learning_rate": 0.0001502983638113571,
      "loss": 0.6418,
      "step": 1297
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5087569355964661,
      "learning_rate": 0.00015025986525505294,
      "loss": 0.7524,
      "step": 1298
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5031057596206665,
      "learning_rate": 0.0001502213666987488,
      "loss": 1.0084,
      "step": 1299
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6818915009498596,
      "learning_rate": 0.00015018286814244466,
      "loss": 0.6323,
      "step": 1300
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6704615354537964,
      "learning_rate": 0.00015014436958614053,
      "loss": 0.6778,
      "step": 1301
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5554025769233704,
      "learning_rate": 0.0001501058710298364,
      "loss": 1.053,
      "step": 1302
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6017436981201172,
      "learning_rate": 0.00015006737247353225,
      "loss": 0.5987,
      "step": 1303
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6788583993911743,
      "learning_rate": 0.0001500288739172281,
      "loss": 0.7905,
      "step": 1304
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.755353569984436,
      "learning_rate": 0.00014999037536092398,
      "loss": 0.7256,
      "step": 1305
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7414215207099915,
      "learning_rate": 0.00014995187680461985,
      "loss": 0.6091,
      "step": 1306
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6212363243103027,
      "learning_rate": 0.0001499133782483157,
      "loss": 0.7329,
      "step": 1307
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0026686191558838,
      "learning_rate": 0.00014987487969201155,
      "loss": 0.3683,
      "step": 1308
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6132370233535767,
      "learning_rate": 0.00014983638113570742,
      "loss": 0.6537,
      "step": 1309
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6168157458305359,
      "learning_rate": 0.0001497978825794033,
      "loss": 0.6709,
      "step": 1310
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6028796434402466,
      "learning_rate": 0.00014975938402309914,
      "loss": 0.9594,
      "step": 1311
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5695993304252625,
      "learning_rate": 0.00014972088546679502,
      "loss": 0.8995,
      "step": 1312
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0561786890029907,
      "learning_rate": 0.00014968238691049086,
      "loss": 0.8095,
      "step": 1313
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.48491552472114563,
      "learning_rate": 0.0001496438883541867,
      "loss": 0.8442,
      "step": 1314
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7416078448295593,
      "learning_rate": 0.00014960538979788259,
      "loss": 0.477,
      "step": 1315
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5893939733505249,
      "learning_rate": 0.00014956689124157846,
      "loss": 0.6219,
      "step": 1316
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7226527333259583,
      "learning_rate": 0.0001495283926852743,
      "loss": 0.5068,
      "step": 1317
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7758738994598389,
      "learning_rate": 0.00014948989412897015,
      "loss": 0.5314,
      "step": 1318
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8220066428184509,
      "learning_rate": 0.00014945139557266603,
      "loss": 0.7511,
      "step": 1319
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6189173460006714,
      "learning_rate": 0.0001494128970163619,
      "loss": 0.6614,
      "step": 1320
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6695892214775085,
      "learning_rate": 0.00014937439846005775,
      "loss": 0.6722,
      "step": 1321
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8004169464111328,
      "learning_rate": 0.0001493358999037536,
      "loss": 0.9183,
      "step": 1322
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5758053660392761,
      "learning_rate": 0.00014929740134744947,
      "loss": 0.6798,
      "step": 1323
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5412952899932861,
      "learning_rate": 0.00014925890279114535,
      "loss": 0.7053,
      "step": 1324
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6373320817947388,
      "learning_rate": 0.0001492204042348412,
      "loss": 0.6702,
      "step": 1325
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5615422129631042,
      "learning_rate": 0.00014918190567853707,
      "loss": 0.6675,
      "step": 1326
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6707826256752014,
      "learning_rate": 0.00014914340712223292,
      "loss": 0.8273,
      "step": 1327
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7382500171661377,
      "learning_rate": 0.0001491049085659288,
      "loss": 0.4027,
      "step": 1328
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6395971179008484,
      "learning_rate": 0.00014906641000962464,
      "loss": 0.5786,
      "step": 1329
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4982270896434784,
      "learning_rate": 0.00014902791145332051,
      "loss": 0.7093,
      "step": 1330
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.643460750579834,
      "learning_rate": 0.0001489894128970164,
      "loss": 0.6637,
      "step": 1331
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6062449216842651,
      "learning_rate": 0.0001489509143407122,
      "loss": 0.7504,
      "step": 1332
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6678824424743652,
      "learning_rate": 0.00014891241578440808,
      "loss": 0.7846,
      "step": 1333
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5185498595237732,
      "learning_rate": 0.00014887391722810396,
      "loss": 0.6655,
      "step": 1334
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6281014680862427,
      "learning_rate": 0.00014883541867179983,
      "loss": 0.7117,
      "step": 1335
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6153769493103027,
      "learning_rate": 0.00014879692011549568,
      "loss": 0.706,
      "step": 1336
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6457135081291199,
      "learning_rate": 0.00014875842155919153,
      "loss": 0.9633,
      "step": 1337
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7883987426757812,
      "learning_rate": 0.0001487199230028874,
      "loss": 0.5725,
      "step": 1338
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8454897403717041,
      "learning_rate": 0.00014868142444658325,
      "loss": 0.4078,
      "step": 1339
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6171913146972656,
      "learning_rate": 0.00014864292589027912,
      "loss": 0.8015,
      "step": 1340
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.6012579202651978,
      "learning_rate": 0.000148604427333975,
      "loss": 0.7811,
      "step": 1341
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8006978631019592,
      "learning_rate": 0.00014856592877767085,
      "loss": 0.4889,
      "step": 1342
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5647371411323547,
      "learning_rate": 0.0001485274302213667,
      "loss": 0.476,
      "step": 1343
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8838139176368713,
      "learning_rate": 0.00014848893166506257,
      "loss": 0.6194,
      "step": 1344
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.987582802772522,
      "learning_rate": 0.00014845043310875844,
      "loss": 0.6395,
      "step": 1345
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5843784213066101,
      "learning_rate": 0.0001484119345524543,
      "loss": 0.7236,
      "step": 1346
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6351253986358643,
      "learning_rate": 0.00014837343599615014,
      "loss": 0.8051,
      "step": 1347
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.651024341583252,
      "learning_rate": 0.000148334937439846,
      "loss": 0.6955,
      "step": 1348
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6681203842163086,
      "learning_rate": 0.00014829643888354189,
      "loss": 0.5028,
      "step": 1349
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5304802060127258,
      "learning_rate": 0.00014825794032723773,
      "loss": 0.7661,
      "step": 1350
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7675022482872009,
      "learning_rate": 0.00014821944177093358,
      "loss": 0.8278,
      "step": 1351
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.763292133808136,
      "learning_rate": 0.00014818094321462946,
      "loss": 0.609,
      "step": 1352
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5235008001327515,
      "learning_rate": 0.00014814244465832533,
      "loss": 0.5031,
      "step": 1353
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5474405884742737,
      "learning_rate": 0.00014810394610202118,
      "loss": 0.9533,
      "step": 1354
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7131478786468506,
      "learning_rate": 0.00014806544754571705,
      "loss": 0.5595,
      "step": 1355
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7487879991531372,
      "learning_rate": 0.0001480269489894129,
      "loss": 0.6046,
      "step": 1356
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7010971307754517,
      "learning_rate": 0.00014798845043310877,
      "loss": 0.8182,
      "step": 1357
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.60377436876297,
      "learning_rate": 0.00014794995187680462,
      "loss": 0.7719,
      "step": 1358
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5415779948234558,
      "learning_rate": 0.0001479114533205005,
      "loss": 0.9064,
      "step": 1359
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9041222333908081,
      "learning_rate": 0.00014787295476419637,
      "loss": 0.8437,
      "step": 1360
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4513777494430542,
      "learning_rate": 0.0001478344562078922,
      "loss": 0.9558,
      "step": 1361
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6363309621810913,
      "learning_rate": 0.00014779595765158807,
      "loss": 0.6587,
      "step": 1362
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5671623945236206,
      "learning_rate": 0.00014775745909528394,
      "loss": 0.6961,
      "step": 1363
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7101476192474365,
      "learning_rate": 0.0001477189605389798,
      "loss": 0.6057,
      "step": 1364
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6576650142669678,
      "learning_rate": 0.00014768046198267566,
      "loss": 0.7114,
      "step": 1365
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6541823744773865,
      "learning_rate": 0.0001476419634263715,
      "loss": 0.5553,
      "step": 1366
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6717711687088013,
      "learning_rate": 0.00014760346487006738,
      "loss": 0.7172,
      "step": 1367
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5841948986053467,
      "learning_rate": 0.00014756496631376323,
      "loss": 0.5665,
      "step": 1368
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6707032918930054,
      "learning_rate": 0.0001475264677574591,
      "loss": 0.7479,
      "step": 1369
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5897465348243713,
      "learning_rate": 0.00014748796920115498,
      "loss": 0.7194,
      "step": 1370
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6110122203826904,
      "learning_rate": 0.00014744947064485083,
      "loss": 0.6919,
      "step": 1371
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5399303436279297,
      "learning_rate": 0.00014741097208854667,
      "loss": 0.5179,
      "step": 1372
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6729580163955688,
      "learning_rate": 0.00014737247353224255,
      "loss": 0.3367,
      "step": 1373
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7498751878738403,
      "learning_rate": 0.00014733397497593842,
      "loss": 0.9307,
      "step": 1374
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5890470743179321,
      "learning_rate": 0.00014729547641963427,
      "loss": 0.7588,
      "step": 1375
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6138090491294861,
      "learning_rate": 0.00014725697786333012,
      "loss": 0.4375,
      "step": 1376
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5732904672622681,
      "learning_rate": 0.000147218479307026,
      "loss": 0.6154,
      "step": 1377
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5135437250137329,
      "learning_rate": 0.00014717998075072187,
      "loss": 0.7883,
      "step": 1378
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7244787216186523,
      "learning_rate": 0.00014714148219441772,
      "loss": 0.8858,
      "step": 1379
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7217301726341248,
      "learning_rate": 0.00014710298363811356,
      "loss": 0.5995,
      "step": 1380
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.971966564655304,
      "learning_rate": 0.00014706448508180944,
      "loss": 0.8896,
      "step": 1381
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7081308960914612,
      "learning_rate": 0.0001470259865255053,
      "loss": 0.4746,
      "step": 1382
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5948877334594727,
      "learning_rate": 0.00014698748796920116,
      "loss": 0.663,
      "step": 1383
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8026362657546997,
      "learning_rate": 0.00014694898941289703,
      "loss": 0.3033,
      "step": 1384
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7716660499572754,
      "learning_rate": 0.00014691049085659288,
      "loss": 0.6981,
      "step": 1385
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5945294499397278,
      "learning_rate": 0.00014687199230028873,
      "loss": 0.556,
      "step": 1386
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6514450907707214,
      "learning_rate": 0.0001468334937439846,
      "loss": 0.7528,
      "step": 1387
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6222717761993408,
      "learning_rate": 0.00014679499518768048,
      "loss": 0.6834,
      "step": 1388
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.606906533241272,
      "learning_rate": 0.00014675649663137635,
      "loss": 0.9292,
      "step": 1389
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7552218437194824,
      "learning_rate": 0.00014671799807507217,
      "loss": 0.4032,
      "step": 1390
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5256270170211792,
      "learning_rate": 0.00014667949951876805,
      "loss": 0.572,
      "step": 1391
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6853538155555725,
      "learning_rate": 0.00014664100096246392,
      "loss": 0.5308,
      "step": 1392
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5630068778991699,
      "learning_rate": 0.00014660250240615977,
      "loss": 0.801,
      "step": 1393
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6381216049194336,
      "learning_rate": 0.00014656400384985564,
      "loss": 0.6014,
      "step": 1394
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7051904797554016,
      "learning_rate": 0.0001465255052935515,
      "loss": 0.5872,
      "step": 1395
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8050947785377502,
      "learning_rate": 0.00014648700673724737,
      "loss": 0.5776,
      "step": 1396
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0596263408660889,
      "learning_rate": 0.0001464485081809432,
      "loss": 0.5577,
      "step": 1397
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.708707869052887,
      "learning_rate": 0.0001464100096246391,
      "loss": 0.8005,
      "step": 1398
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7057616710662842,
      "learning_rate": 0.00014637151106833496,
      "loss": 0.6303,
      "step": 1399
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7064105272293091,
      "learning_rate": 0.0001463330125120308,
      "loss": 0.6019,
      "step": 1400
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6369332671165466,
      "learning_rate": 0.00014629451395572666,
      "loss": 1.0074,
      "step": 1401
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7446849346160889,
      "learning_rate": 0.00014625601539942253,
      "loss": 0.5754,
      "step": 1402
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6324319839477539,
      "learning_rate": 0.0001462175168431184,
      "loss": 0.8292,
      "step": 1403
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7192289233207703,
      "learning_rate": 0.00014617901828681425,
      "loss": 0.6559,
      "step": 1404
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7633714079856873,
      "learning_rate": 0.0001461405197305101,
      "loss": 0.905,
      "step": 1405
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5284935235977173,
      "learning_rate": 0.00014610202117420598,
      "loss": 0.898,
      "step": 1406
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5805268883705139,
      "learning_rate": 0.00014606352261790185,
      "loss": 0.6274,
      "step": 1407
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5324015617370605,
      "learning_rate": 0.0001460250240615977,
      "loss": 0.7753,
      "step": 1408
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7146843671798706,
      "learning_rate": 0.00014598652550529354,
      "loss": 0.4809,
      "step": 1409
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6154520511627197,
      "learning_rate": 0.00014594802694898942,
      "loss": 0.7664,
      "step": 1410
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6948551535606384,
      "learning_rate": 0.00014590952839268527,
      "loss": 0.6059,
      "step": 1411
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6139600872993469,
      "learning_rate": 0.00014587102983638114,
      "loss": 0.5674,
      "step": 1412
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6319997310638428,
      "learning_rate": 0.00014583253128007702,
      "loss": 0.6746,
      "step": 1413
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6742022037506104,
      "learning_rate": 0.00014579403272377286,
      "loss": 0.6913,
      "step": 1414
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8073755502700806,
      "learning_rate": 0.0001457555341674687,
      "loss": 0.8254,
      "step": 1415
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6054401993751526,
      "learning_rate": 0.00014571703561116459,
      "loss": 0.8566,
      "step": 1416
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9209439158439636,
      "learning_rate": 0.00014567853705486046,
      "loss": 0.4545,
      "step": 1417
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7747774720191956,
      "learning_rate": 0.0001456400384985563,
      "loss": 0.5347,
      "step": 1418
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.728064239025116,
      "learning_rate": 0.00014560153994225215,
      "loss": 0.3944,
      "step": 1419
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5774431228637695,
      "learning_rate": 0.00014556304138594803,
      "loss": 0.5941,
      "step": 1420
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5275643467903137,
      "learning_rate": 0.0001455245428296439,
      "loss": 0.8471,
      "step": 1421
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.661464273929596,
      "learning_rate": 0.00014548604427333975,
      "loss": 0.5105,
      "step": 1422
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7094376087188721,
      "learning_rate": 0.00014544754571703563,
      "loss": 0.5714,
      "step": 1423
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6544142365455627,
      "learning_rate": 0.00014540904716073147,
      "loss": 0.8538,
      "step": 1424
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6854254007339478,
      "learning_rate": 0.00014537054860442735,
      "loss": 0.598,
      "step": 1425
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6545953750610352,
      "learning_rate": 0.0001453320500481232,
      "loss": 0.6726,
      "step": 1426
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5309637784957886,
      "learning_rate": 0.00014529355149181907,
      "loss": 0.7267,
      "step": 1427
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6242709159851074,
      "learning_rate": 0.00014525505293551494,
      "loss": 0.8474,
      "step": 1428
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7210476398468018,
      "learning_rate": 0.0001452165543792108,
      "loss": 0.6764,
      "step": 1429
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5968273878097534,
      "learning_rate": 0.00014517805582290664,
      "loss": 1.0235,
      "step": 1430
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7337419986724854,
      "learning_rate": 0.0001451395572666025,
      "loss": 0.7175,
      "step": 1431
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7433585524559021,
      "learning_rate": 0.0001451010587102984,
      "loss": 0.7391,
      "step": 1432
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5746875405311584,
      "learning_rate": 0.00014506256015399424,
      "loss": 0.8911,
      "step": 1433
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6863663792610168,
      "learning_rate": 0.00014502406159769008,
      "loss": 0.558,
      "step": 1434
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6606706976890564,
      "learning_rate": 0.00014498556304138596,
      "loss": 0.4673,
      "step": 1435
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8211389183998108,
      "learning_rate": 0.00014494706448508183,
      "loss": 0.5442,
      "step": 1436
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9006323218345642,
      "learning_rate": 0.00014490856592877768,
      "loss": 0.7807,
      "step": 1437
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5586189031600952,
      "learning_rate": 0.00014487006737247355,
      "loss": 0.7991,
      "step": 1438
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.550622284412384,
      "learning_rate": 0.0001448315688161694,
      "loss": 0.8339,
      "step": 1439
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4462200701236725,
      "learning_rate": 0.00014479307025986525,
      "loss": 0.9028,
      "step": 1440
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8460965752601624,
      "learning_rate": 0.00014475457170356112,
      "loss": 0.9463,
      "step": 1441
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7755482196807861,
      "learning_rate": 0.000144716073147257,
      "loss": 0.6495,
      "step": 1442
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6310715079307556,
      "learning_rate": 0.00014467757459095285,
      "loss": 0.6939,
      "step": 1443
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8472463488578796,
      "learning_rate": 0.0001446390760346487,
      "loss": 0.7009,
      "step": 1444
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7025449872016907,
      "learning_rate": 0.00014460057747834457,
      "loss": 0.4579,
      "step": 1445
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7489273548126221,
      "learning_rate": 0.00014456207892204044,
      "loss": 0.8322,
      "step": 1446
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6002949476242065,
      "learning_rate": 0.0001445235803657363,
      "loss": 0.7742,
      "step": 1447
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7779114842414856,
      "learning_rate": 0.00014448508180943214,
      "loss": 0.7273,
      "step": 1448
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7122015953063965,
      "learning_rate": 0.000144446583253128,
      "loss": 0.6974,
      "step": 1449
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8873491883277893,
      "learning_rate": 0.00014440808469682389,
      "loss": 0.5036,
      "step": 1450
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5128334164619446,
      "learning_rate": 0.00014436958614051973,
      "loss": 0.8263,
      "step": 1451
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6856284737586975,
      "learning_rate": 0.0001443310875842156,
      "loss": 0.3357,
      "step": 1452
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7493555545806885,
      "learning_rate": 0.00014429258902791145,
      "loss": 0.9356,
      "step": 1453
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5262126922607422,
      "learning_rate": 0.00014425409047160733,
      "loss": 0.7651,
      "step": 1454
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7725269198417664,
      "learning_rate": 0.00014421559191530318,
      "loss": 0.3983,
      "step": 1455
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7577784657478333,
      "learning_rate": 0.00014417709335899905,
      "loss": 0.7022,
      "step": 1456
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6192813515663147,
      "learning_rate": 0.00014413859480269493,
      "loss": 0.6773,
      "step": 1457
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5806599855422974,
      "learning_rate": 0.00014410009624639075,
      "loss": 0.6439,
      "step": 1458
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6867038011550903,
      "learning_rate": 0.00014406159769008662,
      "loss": 0.6278,
      "step": 1459
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6808427572250366,
      "learning_rate": 0.0001440230991337825,
      "loss": 0.3843,
      "step": 1460
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8367462754249573,
      "learning_rate": 0.00014398460057747837,
      "loss": 0.8929,
      "step": 1461
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7694380879402161,
      "learning_rate": 0.00014394610202117422,
      "loss": 0.4936,
      "step": 1462
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9558953642845154,
      "learning_rate": 0.00014390760346487006,
      "loss": 0.4954,
      "step": 1463
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6795295476913452,
      "learning_rate": 0.00014386910490856594,
      "loss": 0.7068,
      "step": 1464
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7743596434593201,
      "learning_rate": 0.0001438306063522618,
      "loss": 0.9316,
      "step": 1465
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7848799228668213,
      "learning_rate": 0.00014379210779595766,
      "loss": 0.4503,
      "step": 1466
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.567105233669281,
      "learning_rate": 0.00014375360923965354,
      "loss": 0.8569,
      "step": 1467
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5573074221611023,
      "learning_rate": 0.00014371511068334938,
      "loss": 0.8618,
      "step": 1468
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8543345928192139,
      "learning_rate": 0.00014367661212704523,
      "loss": 0.8086,
      "step": 1469
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6646953225135803,
      "learning_rate": 0.0001436381135707411,
      "loss": 0.4331,
      "step": 1470
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6782646775245667,
      "learning_rate": 0.00014359961501443698,
      "loss": 0.5252,
      "step": 1471
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6705033183097839,
      "learning_rate": 0.00014356111645813283,
      "loss": 0.4507,
      "step": 1472
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7929595708847046,
      "learning_rate": 0.00014352261790182867,
      "loss": 0.7021,
      "step": 1473
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5654114484786987,
      "learning_rate": 0.00014348411934552455,
      "loss": 0.8309,
      "step": 1474
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.49887922406196594,
      "learning_rate": 0.00014344562078922042,
      "loss": 0.6147,
      "step": 1475
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6343759894371033,
      "learning_rate": 0.00014340712223291627,
      "loss": 0.5323,
      "step": 1476
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5008484721183777,
      "learning_rate": 0.00014336862367661212,
      "loss": 0.6446,
      "step": 1477
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6976091265678406,
      "learning_rate": 0.000143330125120308,
      "loss": 0.5281,
      "step": 1478
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7184232473373413,
      "learning_rate": 0.00014329162656400387,
      "loss": 0.6799,
      "step": 1479
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.733703076839447,
      "learning_rate": 0.00014325312800769971,
      "loss": 0.402,
      "step": 1480
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8669086694717407,
      "learning_rate": 0.0001432146294513956,
      "loss": 0.4651,
      "step": 1481
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6876360177993774,
      "learning_rate": 0.00014317613089509144,
      "loss": 0.5126,
      "step": 1482
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7537530660629272,
      "learning_rate": 0.00014313763233878728,
      "loss": 0.6483,
      "step": 1483
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6407130360603333,
      "learning_rate": 0.00014309913378248316,
      "loss": 0.757,
      "step": 1484
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.718572735786438,
      "learning_rate": 0.00014306063522617903,
      "loss": 0.7226,
      "step": 1485
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5881627202033997,
      "learning_rate": 0.0001430221366698749,
      "loss": 0.5702,
      "step": 1486
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6413272023200989,
      "learning_rate": 0.00014298363811357073,
      "loss": 0.9229,
      "step": 1487
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6483608484268188,
      "learning_rate": 0.0001429451395572666,
      "loss": 1.174,
      "step": 1488
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7721209526062012,
      "learning_rate": 0.00014290664100096248,
      "loss": 0.7595,
      "step": 1489
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6490495800971985,
      "learning_rate": 0.00014286814244465832,
      "loss": 0.8352,
      "step": 1490
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6624196171760559,
      "learning_rate": 0.0001428296438883542,
      "loss": 0.7559,
      "step": 1491
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8821606636047363,
      "learning_rate": 0.00014279114533205005,
      "loss": 0.5057,
      "step": 1492
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6934391856193542,
      "learning_rate": 0.00014275264677574592,
      "loss": 0.7575,
      "step": 1493
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5837476849555969,
      "learning_rate": 0.00014271414821944177,
      "loss": 0.7511,
      "step": 1494
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0228513479232788,
      "learning_rate": 0.00014267564966313764,
      "loss": 0.7452,
      "step": 1495
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5253191590309143,
      "learning_rate": 0.00014263715110683352,
      "loss": 0.8309,
      "step": 1496
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6020295023918152,
      "learning_rate": 0.00014259865255052936,
      "loss": 0.6413,
      "step": 1497
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6443186402320862,
      "learning_rate": 0.0001425601539942252,
      "loss": 0.7271,
      "step": 1498
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7767975330352783,
      "learning_rate": 0.0001425216554379211,
      "loss": 0.4388,
      "step": 1499
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7819966077804565,
      "learning_rate": 0.00014248315688161696,
      "loss": 0.6845,
      "step": 1500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8390392661094666,
      "learning_rate": 0.0001424446583253128,
      "loss": 0.6022,
      "step": 1501
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7439218163490295,
      "learning_rate": 0.00014240615976900866,
      "loss": 0.5757,
      "step": 1502
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.838767945766449,
      "learning_rate": 0.00014236766121270453,
      "loss": 0.4898,
      "step": 1503
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7219753861427307,
      "learning_rate": 0.0001423291626564004,
      "loss": 0.8862,
      "step": 1504
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.729271650314331,
      "learning_rate": 0.00014229066410009625,
      "loss": 1.0409,
      "step": 1505
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7476184964179993,
      "learning_rate": 0.0001422521655437921,
      "loss": 0.655,
      "step": 1506
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6462342739105225,
      "learning_rate": 0.00014221366698748797,
      "loss": 0.7252,
      "step": 1507
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5620452165603638,
      "learning_rate": 0.00014217516843118385,
      "loss": 0.6209,
      "step": 1508
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5944390296936035,
      "learning_rate": 0.0001421366698748797,
      "loss": 0.6791,
      "step": 1509
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5511245131492615,
      "learning_rate": 0.00014209817131857557,
      "loss": 0.7811,
      "step": 1510
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6885793805122375,
      "learning_rate": 0.00014205967276227142,
      "loss": 0.875,
      "step": 1511
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6086034774780273,
      "learning_rate": 0.00014202117420596727,
      "loss": 0.7858,
      "step": 1512
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7111740708351135,
      "learning_rate": 0.00014198267564966314,
      "loss": 0.5757,
      "step": 1513
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6075944304466248,
      "learning_rate": 0.00014194417709335902,
      "loss": 0.531,
      "step": 1514
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6547199487686157,
      "learning_rate": 0.00014190567853705486,
      "loss": 0.5674,
      "step": 1515
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5410038232803345,
      "learning_rate": 0.0001418671799807507,
      "loss": 0.4401,
      "step": 1516
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8410864472389221,
      "learning_rate": 0.00014182868142444658,
      "loss": 0.9933,
      "step": 1517
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6341779828071594,
      "learning_rate": 0.00014179018286814246,
      "loss": 0.588,
      "step": 1518
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8286982178688049,
      "learning_rate": 0.0001417516843118383,
      "loss": 0.4302,
      "step": 1519
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7104580402374268,
      "learning_rate": 0.00014171318575553418,
      "loss": 0.7709,
      "step": 1520
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6354122161865234,
      "learning_rate": 0.00014167468719923003,
      "loss": 0.5592,
      "step": 1521
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6431111097335815,
      "learning_rate": 0.0001416361886429259,
      "loss": 0.4737,
      "step": 1522
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6400704979896545,
      "learning_rate": 0.00014159769008662175,
      "loss": 0.5871,
      "step": 1523
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6876863241195679,
      "learning_rate": 0.00014155919153031762,
      "loss": 1.085,
      "step": 1524
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7693227529525757,
      "learning_rate": 0.0001415206929740135,
      "loss": 1.0473,
      "step": 1525
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8743484616279602,
      "learning_rate": 0.00014148219441770935,
      "loss": 0.5837,
      "step": 1526
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6584872007369995,
      "learning_rate": 0.0001414436958614052,
      "loss": 0.6192,
      "step": 1527
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7589495778083801,
      "learning_rate": 0.00014140519730510107,
      "loss": 0.7992,
      "step": 1528
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6039993166923523,
      "learning_rate": 0.00014136669874879694,
      "loss": 0.642,
      "step": 1529
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6450189352035522,
      "learning_rate": 0.0001413282001924928,
      "loss": 0.8168,
      "step": 1530
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7115229368209839,
      "learning_rate": 0.00014128970163618864,
      "loss": 0.8459,
      "step": 1531
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7233977913856506,
      "learning_rate": 0.0001412512030798845,
      "loss": 0.6308,
      "step": 1532
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5920286774635315,
      "learning_rate": 0.0001412127045235804,
      "loss": 0.5562,
      "step": 1533
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5484565496444702,
      "learning_rate": 0.00014117420596727623,
      "loss": 0.8016,
      "step": 1534
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6586856245994568,
      "learning_rate": 0.00014113570741097208,
      "loss": 0.5294,
      "step": 1535
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6635604500770569,
      "learning_rate": 0.00014109720885466796,
      "loss": 0.6958,
      "step": 1536
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5555028319358826,
      "learning_rate": 0.0001410587102983638,
      "loss": 0.8113,
      "step": 1537
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6115401983261108,
      "learning_rate": 0.00014102021174205968,
      "loss": 0.7317,
      "step": 1538
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6466290354728699,
      "learning_rate": 0.00014098171318575555,
      "loss": 0.8458,
      "step": 1539
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6965384483337402,
      "learning_rate": 0.0001409432146294514,
      "loss": 0.6324,
      "step": 1540
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7594019174575806,
      "learning_rate": 0.00014090471607314725,
      "loss": 0.7405,
      "step": 1541
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6086500883102417,
      "learning_rate": 0.00014086621751684312,
      "loss": 0.7666,
      "step": 1542
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5741179585456848,
      "learning_rate": 0.000140827718960539,
      "loss": 0.6401,
      "step": 1543
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7619177103042603,
      "learning_rate": 0.00014078922040423484,
      "loss": 0.7596,
      "step": 1544
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6843228936195374,
      "learning_rate": 0.0001407507218479307,
      "loss": 0.6407,
      "step": 1545
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5152499079704285,
      "learning_rate": 0.00014071222329162657,
      "loss": 0.5488,
      "step": 1546
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6878284811973572,
      "learning_rate": 0.00014067372473532244,
      "loss": 0.5537,
      "step": 1547
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7467910647392273,
      "learning_rate": 0.0001406352261790183,
      "loss": 0.8403,
      "step": 1548
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8448255658149719,
      "learning_rate": 0.00014059672762271416,
      "loss": 0.5094,
      "step": 1549
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6904172301292419,
      "learning_rate": 0.00014055822906641,
      "loss": 0.8652,
      "step": 1550
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.530450701713562,
      "learning_rate": 0.00014051973051010588,
      "loss": 0.6309,
      "step": 1551
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5211743116378784,
      "learning_rate": 0.00014048123195380173,
      "loss": 0.8883,
      "step": 1552
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.701526403427124,
      "learning_rate": 0.0001404427333974976,
      "loss": 0.647,
      "step": 1553
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8288761973381042,
      "learning_rate": 0.00014040423484119348,
      "loss": 0.3671,
      "step": 1554
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7259957194328308,
      "learning_rate": 0.00014036573628488933,
      "loss": 0.4665,
      "step": 1555
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.46677306294441223,
      "learning_rate": 0.00014032723772858518,
      "loss": 0.6873,
      "step": 1556
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6430769562721252,
      "learning_rate": 0.00014028873917228105,
      "loss": 0.5719,
      "step": 1557
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5781065225601196,
      "learning_rate": 0.00014025024061597693,
      "loss": 0.9837,
      "step": 1558
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8098629713058472,
      "learning_rate": 0.00014021174205967277,
      "loss": 0.3471,
      "step": 1559
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7362998127937317,
      "learning_rate": 0.00014017324350336862,
      "loss": 0.5851,
      "step": 1560
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7111606597900391,
      "learning_rate": 0.0001401347449470645,
      "loss": 0.8957,
      "step": 1561
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6403584480285645,
      "learning_rate": 0.00014009624639076034,
      "loss": 0.9284,
      "step": 1562
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.616226851940155,
      "learning_rate": 0.00014005774783445622,
      "loss": 0.4595,
      "step": 1563
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0490682125091553,
      "learning_rate": 0.0001400192492781521,
      "loss": 0.3141,
      "step": 1564
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6821502447128296,
      "learning_rate": 0.00013998075072184794,
      "loss": 0.6706,
      "step": 1565
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4142857491970062,
      "learning_rate": 0.00013994225216554379,
      "loss": 0.8865,
      "step": 1566
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6085253953933716,
      "learning_rate": 0.00013990375360923966,
      "loss": 0.6288,
      "step": 1567
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.629554033279419,
      "learning_rate": 0.00013986525505293554,
      "loss": 0.5281,
      "step": 1568
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.584473729133606,
      "learning_rate": 0.00013982675649663138,
      "loss": 0.5842,
      "step": 1569
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5009206533432007,
      "learning_rate": 0.00013978825794032723,
      "loss": 0.5424,
      "step": 1570
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5542975664138794,
      "learning_rate": 0.0001397497593840231,
      "loss": 0.5642,
      "step": 1571
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6274932026863098,
      "learning_rate": 0.00013971126082771898,
      "loss": 0.7893,
      "step": 1572
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6576313376426697,
      "learning_rate": 0.00013967276227141483,
      "loss": 0.5087,
      "step": 1573
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6863459348678589,
      "learning_rate": 0.00013963426371511067,
      "loss": 0.5348,
      "step": 1574
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5885846018791199,
      "learning_rate": 0.00013959576515880655,
      "loss": 0.7332,
      "step": 1575
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5309919714927673,
      "learning_rate": 0.00013955726660250242,
      "loss": 0.87,
      "step": 1576
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6511451601982117,
      "learning_rate": 0.00013951876804619827,
      "loss": 0.9366,
      "step": 1577
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6628212332725525,
      "learning_rate": 0.00013948026948989414,
      "loss": 0.5462,
      "step": 1578
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5767272710800171,
      "learning_rate": 0.00013944177093359,
      "loss": 0.6754,
      "step": 1579
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5357952117919922,
      "learning_rate": 0.00013940327237728587,
      "loss": 0.7122,
      "step": 1580
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6441416144371033,
      "learning_rate": 0.00013936477382098171,
      "loss": 0.7031,
      "step": 1581
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5282220244407654,
      "learning_rate": 0.0001393262752646776,
      "loss": 0.835,
      "step": 1582
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6425369381904602,
      "learning_rate": 0.00013928777670837346,
      "loss": 0.5802,
      "step": 1583
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6369295716285706,
      "learning_rate": 0.00013924927815206928,
      "loss": 0.5499,
      "step": 1584
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6119851469993591,
      "learning_rate": 0.00013921077959576516,
      "loss": 0.6356,
      "step": 1585
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7318561673164368,
      "learning_rate": 0.00013917228103946103,
      "loss": 0.5156,
      "step": 1586
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8687228560447693,
      "learning_rate": 0.0001391337824831569,
      "loss": 0.7448,
      "step": 1587
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5631123781204224,
      "learning_rate": 0.00013909528392685275,
      "loss": 0.6747,
      "step": 1588
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5730329155921936,
      "learning_rate": 0.0001390567853705486,
      "loss": 0.821,
      "step": 1589
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5581062436103821,
      "learning_rate": 0.00013901828681424448,
      "loss": 0.8369,
      "step": 1590
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0251195430755615,
      "learning_rate": 0.00013897978825794032,
      "loss": 0.8849,
      "step": 1591
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7399737238883972,
      "learning_rate": 0.0001389412897016362,
      "loss": 0.4545,
      "step": 1592
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5832752585411072,
      "learning_rate": 0.00013890279114533207,
      "loss": 0.5755,
      "step": 1593
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7094857692718506,
      "learning_rate": 0.00013886429258902792,
      "loss": 0.6544,
      "step": 1594
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6644660234451294,
      "learning_rate": 0.00013882579403272377,
      "loss": 0.5943,
      "step": 1595
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6009017825126648,
      "learning_rate": 0.00013878729547641964,
      "loss": 0.5344,
      "step": 1596
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8579927682876587,
      "learning_rate": 0.00013874879692011552,
      "loss": 0.7695,
      "step": 1597
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6615369319915771,
      "learning_rate": 0.00013871029836381136,
      "loss": 0.8102,
      "step": 1598
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6569204330444336,
      "learning_rate": 0.0001386717998075072,
      "loss": 0.693,
      "step": 1599
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5475621819496155,
      "learning_rate": 0.00013863330125120309,
      "loss": 0.7099,
      "step": 1600
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6571213603019714,
      "learning_rate": 0.00013859480269489896,
      "loss": 0.7856,
      "step": 1601
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6767455339431763,
      "learning_rate": 0.0001385563041385948,
      "loss": 0.5887,
      "step": 1602
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6433900594711304,
      "learning_rate": 0.00013851780558229066,
      "loss": 0.6512,
      "step": 1603
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.522840678691864,
      "learning_rate": 0.00013847930702598653,
      "loss": 0.71,
      "step": 1604
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9874762892723083,
      "learning_rate": 0.0001384408084696824,
      "loss": 0.3552,
      "step": 1605
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5966570377349854,
      "learning_rate": 0.00013840230991337825,
      "loss": 0.7969,
      "step": 1606
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6255959272384644,
      "learning_rate": 0.00013836381135707413,
      "loss": 0.8647,
      "step": 1607
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6650389432907104,
      "learning_rate": 0.00013832531280076997,
      "loss": 0.6786,
      "step": 1608
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4758155941963196,
      "learning_rate": 0.00013828681424446582,
      "loss": 0.6422,
      "step": 1609
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6938294172286987,
      "learning_rate": 0.0001382483156881617,
      "loss": 0.7067,
      "step": 1610
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6387040019035339,
      "learning_rate": 0.00013820981713185757,
      "loss": 1.069,
      "step": 1611
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.975475013256073,
      "learning_rate": 0.00013817131857555345,
      "loss": 0.7045,
      "step": 1612
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.691346287727356,
      "learning_rate": 0.00013813282001924927,
      "loss": 0.6546,
      "step": 1613
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.621786892414093,
      "learning_rate": 0.00013809432146294514,
      "loss": 0.7981,
      "step": 1614
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7405052185058594,
      "learning_rate": 0.00013805582290664101,
      "loss": 0.6991,
      "step": 1615
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5647872090339661,
      "learning_rate": 0.00013801732435033686,
      "loss": 0.6621,
      "step": 1616
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6385883688926697,
      "learning_rate": 0.00013797882579403274,
      "loss": 0.6451,
      "step": 1617
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.47182464599609375,
      "learning_rate": 0.00013794032723772858,
      "loss": 0.7816,
      "step": 1618
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8318517208099365,
      "learning_rate": 0.00013790182868142446,
      "loss": 0.6912,
      "step": 1619
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5195856094360352,
      "learning_rate": 0.0001378633301251203,
      "loss": 0.689,
      "step": 1620
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.57353276014328,
      "learning_rate": 0.00013782483156881618,
      "loss": 0.8256,
      "step": 1621
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6760950684547424,
      "learning_rate": 0.00013778633301251205,
      "loss": 0.6526,
      "step": 1622
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.690898060798645,
      "learning_rate": 0.0001377478344562079,
      "loss": 0.8296,
      "step": 1623
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6682827472686768,
      "learning_rate": 0.00013770933589990375,
      "loss": 0.473,
      "step": 1624
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6258114576339722,
      "learning_rate": 0.00013767083734359962,
      "loss": 0.4965,
      "step": 1625
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6277592182159424,
      "learning_rate": 0.0001376323387872955,
      "loss": 0.7303,
      "step": 1626
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.820322573184967,
      "learning_rate": 0.00013759384023099135,
      "loss": 0.676,
      "step": 1627
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7134851217269897,
      "learning_rate": 0.0001375553416746872,
      "loss": 0.8848,
      "step": 1628
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6966696381568909,
      "learning_rate": 0.00013751684311838307,
      "loss": 0.4825,
      "step": 1629
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7819444537162781,
      "learning_rate": 0.00013747834456207894,
      "loss": 0.4207,
      "step": 1630
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5971934199333191,
      "learning_rate": 0.0001374398460057748,
      "loss": 0.5449,
      "step": 1631
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6905423998832703,
      "learning_rate": 0.00013740134744947064,
      "loss": 0.8429,
      "step": 1632
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8800337314605713,
      "learning_rate": 0.0001373628488931665,
      "loss": 0.7278,
      "step": 1633
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8251979947090149,
      "learning_rate": 0.00013732435033686236,
      "loss": 0.5772,
      "step": 1634
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6285210847854614,
      "learning_rate": 0.00013728585178055823,
      "loss": 0.8063,
      "step": 1635
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6997886896133423,
      "learning_rate": 0.0001372473532242541,
      "loss": 0.505,
      "step": 1636
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6520582437515259,
      "learning_rate": 0.00013720885466794996,
      "loss": 0.5791,
      "step": 1637
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8979899287223816,
      "learning_rate": 0.0001371703561116458,
      "loss": 0.8846,
      "step": 1638
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7332537770271301,
      "learning_rate": 0.00013713185755534168,
      "loss": 0.4843,
      "step": 1639
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7673537731170654,
      "learning_rate": 0.00013709335899903755,
      "loss": 0.6646,
      "step": 1640
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5921697020530701,
      "learning_rate": 0.0001370548604427334,
      "loss": 0.6177,
      "step": 1641
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6067012548446655,
      "learning_rate": 0.00013701636188642925,
      "loss": 0.9739,
      "step": 1642
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8221336007118225,
      "learning_rate": 0.00013697786333012512,
      "loss": 0.5008,
      "step": 1643
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.48248064517974854,
      "learning_rate": 0.000136939364773821,
      "loss": 0.7419,
      "step": 1644
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5814521312713623,
      "learning_rate": 0.00013690086621751684,
      "loss": 0.7495,
      "step": 1645
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.805400013923645,
      "learning_rate": 0.00013686236766121272,
      "loss": 0.7699,
      "step": 1646
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8068500757217407,
      "learning_rate": 0.00013682386910490857,
      "loss": 0.5105,
      "step": 1647
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4927408695220947,
      "learning_rate": 0.00013678537054860444,
      "loss": 0.5291,
      "step": 1648
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.861734926700592,
      "learning_rate": 0.0001367468719923003,
      "loss": 0.8983,
      "step": 1649
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5605782270431519,
      "learning_rate": 0.00013670837343599616,
      "loss": 0.614,
      "step": 1650
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5910292863845825,
      "learning_rate": 0.00013666987487969204,
      "loss": 0.4783,
      "step": 1651
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7945719361305237,
      "learning_rate": 0.00013663137632338788,
      "loss": 0.7482,
      "step": 1652
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7092686891555786,
      "learning_rate": 0.00013659287776708373,
      "loss": 0.6342,
      "step": 1653
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8687300086021423,
      "learning_rate": 0.0001365543792107796,
      "loss": 0.6072,
      "step": 1654
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6206451058387756,
      "learning_rate": 0.00013651588065447548,
      "loss": 0.6137,
      "step": 1655
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6200854182243347,
      "learning_rate": 0.00013647738209817133,
      "loss": 0.6496,
      "step": 1656
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5545670390129089,
      "learning_rate": 0.00013643888354186718,
      "loss": 0.8677,
      "step": 1657
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6220670342445374,
      "learning_rate": 0.00013640038498556305,
      "loss": 0.7462,
      "step": 1658
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6387078762054443,
      "learning_rate": 0.00013636188642925892,
      "loss": 1.0381,
      "step": 1659
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6802729368209839,
      "learning_rate": 0.00013632338787295477,
      "loss": 0.7376,
      "step": 1660
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7956215143203735,
      "learning_rate": 0.00013628488931665062,
      "loss": 0.51,
      "step": 1661
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5910376906394958,
      "learning_rate": 0.0001362463907603465,
      "loss": 0.6996,
      "step": 1662
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7046131491661072,
      "learning_rate": 0.00013620789220404234,
      "loss": 0.6559,
      "step": 1663
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4329988360404968,
      "learning_rate": 0.00013616939364773822,
      "loss": 0.6812,
      "step": 1664
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42770349979400635,
      "learning_rate": 0.0001361308950914341,
      "loss": 0.8738,
      "step": 1665
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5669314861297607,
      "learning_rate": 0.00013609239653512994,
      "loss": 0.5386,
      "step": 1666
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7607151865959167,
      "learning_rate": 0.00013605389797882579,
      "loss": 0.4001,
      "step": 1667
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7398149967193604,
      "learning_rate": 0.00013601539942252166,
      "loss": 0.5759,
      "step": 1668
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7973078489303589,
      "learning_rate": 0.00013597690086621753,
      "loss": 0.4877,
      "step": 1669
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.698209822177887,
      "learning_rate": 0.00013593840230991338,
      "loss": 0.8985,
      "step": 1670
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6213039755821228,
      "learning_rate": 0.00013589990375360923,
      "loss": 0.6953,
      "step": 1671
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6834368109703064,
      "learning_rate": 0.0001358614051973051,
      "loss": 0.629,
      "step": 1672
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5330613851547241,
      "learning_rate": 0.00013582290664100098,
      "loss": 0.9549,
      "step": 1673
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6973683834075928,
      "learning_rate": 0.00013578440808469683,
      "loss": 0.538,
      "step": 1674
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6241787075996399,
      "learning_rate": 0.0001357459095283927,
      "loss": 0.7517,
      "step": 1675
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.587544858455658,
      "learning_rate": 0.00013570741097208855,
      "loss": 0.5547,
      "step": 1676
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8707454204559326,
      "learning_rate": 0.00013566891241578442,
      "loss": 0.6246,
      "step": 1677
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6149507761001587,
      "learning_rate": 0.00013563041385948027,
      "loss": 0.5511,
      "step": 1678
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.633466899394989,
      "learning_rate": 0.00013559191530317614,
      "loss": 0.6809,
      "step": 1679
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42528972029685974,
      "learning_rate": 0.00013555341674687202,
      "loss": 0.8057,
      "step": 1680
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.605224609375,
      "learning_rate": 0.00013551491819056784,
      "loss": 0.6431,
      "step": 1681
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4699912369251251,
      "learning_rate": 0.00013547641963426371,
      "loss": 0.6702,
      "step": 1682
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7327447533607483,
      "learning_rate": 0.0001354379210779596,
      "loss": 0.6331,
      "step": 1683
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8337651491165161,
      "learning_rate": 0.00013539942252165546,
      "loss": 0.4458,
      "step": 1684
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7761366367340088,
      "learning_rate": 0.0001353609239653513,
      "loss": 0.9748,
      "step": 1685
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9396290183067322,
      "learning_rate": 0.00013532242540904716,
      "loss": 0.4784,
      "step": 1686
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8501251935958862,
      "learning_rate": 0.00013528392685274303,
      "loss": 0.632,
      "step": 1687
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5954477787017822,
      "learning_rate": 0.00013524542829643888,
      "loss": 0.5648,
      "step": 1688
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6807321906089783,
      "learning_rate": 0.00013520692974013475,
      "loss": 0.314,
      "step": 1689
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6922959089279175,
      "learning_rate": 0.00013516843118383063,
      "loss": 0.4019,
      "step": 1690
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5946378707885742,
      "learning_rate": 0.00013512993262752648,
      "loss": 0.4252,
      "step": 1691
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6311765313148499,
      "learning_rate": 0.00013509143407122232,
      "loss": 0.5978,
      "step": 1692
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.53957599401474,
      "learning_rate": 0.0001350529355149182,
      "loss": 0.7436,
      "step": 1693
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6062160730361938,
      "learning_rate": 0.00013501443695861407,
      "loss": 0.7361,
      "step": 1694
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.705089271068573,
      "learning_rate": 0.00013497593840230992,
      "loss": 0.5767,
      "step": 1695
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5212675929069519,
      "learning_rate": 0.00013493743984600577,
      "loss": 0.703,
      "step": 1696
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5944328904151917,
      "learning_rate": 0.00013489894128970164,
      "loss": 0.6172,
      "step": 1697
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.567273736000061,
      "learning_rate": 0.00013486044273339752,
      "loss": 0.9268,
      "step": 1698
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4465082287788391,
      "learning_rate": 0.00013482194417709336,
      "loss": 0.7766,
      "step": 1699
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.658098578453064,
      "learning_rate": 0.0001347834456207892,
      "loss": 0.628,
      "step": 1700
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6421599984169006,
      "learning_rate": 0.00013474494706448509,
      "loss": 0.6457,
      "step": 1701
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.49229586124420166,
      "learning_rate": 0.00013470644850818096,
      "loss": 0.9181,
      "step": 1702
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5386154055595398,
      "learning_rate": 0.0001346679499518768,
      "loss": 0.8659,
      "step": 1703
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.514549195766449,
      "learning_rate": 0.00013462945139557268,
      "loss": 0.7861,
      "step": 1704
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5712001323699951,
      "learning_rate": 0.00013459095283926853,
      "loss": 0.6708,
      "step": 1705
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5438080430030823,
      "learning_rate": 0.0001345524542829644,
      "loss": 0.5639,
      "step": 1706
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4866657257080078,
      "learning_rate": 0.00013451395572666025,
      "loss": 0.6833,
      "step": 1707
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6243268251419067,
      "learning_rate": 0.00013447545717035613,
      "loss": 0.6465,
      "step": 1708
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.602708101272583,
      "learning_rate": 0.000134436958614052,
      "loss": 0.6198,
      "step": 1709
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5228620171546936,
      "learning_rate": 0.00013439846005774782,
      "loss": 0.9581,
      "step": 1710
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.561578631401062,
      "learning_rate": 0.0001343599615014437,
      "loss": 0.6651,
      "step": 1711
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6030598878860474,
      "learning_rate": 0.00013432146294513957,
      "loss": 0.7255,
      "step": 1712
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5121151804924011,
      "learning_rate": 0.00013428296438883542,
      "loss": 0.7204,
      "step": 1713
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47459957003593445,
      "learning_rate": 0.0001342444658325313,
      "loss": 0.8925,
      "step": 1714
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7468253970146179,
      "learning_rate": 0.00013420596727622714,
      "loss": 0.4487,
      "step": 1715
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5039793848991394,
      "learning_rate": 0.00013416746871992301,
      "loss": 0.7305,
      "step": 1716
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4391893446445465,
      "learning_rate": 0.00013412897016361886,
      "loss": 0.6447,
      "step": 1717
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8127920031547546,
      "learning_rate": 0.00013409047160731474,
      "loss": 0.5527,
      "step": 1718
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8600163459777832,
      "learning_rate": 0.0001340519730510106,
      "loss": 0.8519,
      "step": 1719
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6696404218673706,
      "learning_rate": 0.00013401347449470646,
      "loss": 0.6338,
      "step": 1720
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6605486869812012,
      "learning_rate": 0.0001339749759384023,
      "loss": 0.7714,
      "step": 1721
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5171564817428589,
      "learning_rate": 0.00013393647738209818,
      "loss": 0.4891,
      "step": 1722
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.48022347688674927,
      "learning_rate": 0.00013389797882579405,
      "loss": 0.8401,
      "step": 1723
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7264454364776611,
      "learning_rate": 0.0001338594802694899,
      "loss": 0.5094,
      "step": 1724
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6720702052116394,
      "learning_rate": 0.00013382098171318575,
      "loss": 0.6383,
      "step": 1725
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7396647334098816,
      "learning_rate": 0.00013378248315688162,
      "loss": 0.7484,
      "step": 1726
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7261969447135925,
      "learning_rate": 0.0001337439846005775,
      "loss": 0.4523,
      "step": 1727
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6904476881027222,
      "learning_rate": 0.00013370548604427335,
      "loss": 0.5829,
      "step": 1728
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1365165710449219,
      "learning_rate": 0.0001336669874879692,
      "loss": 0.5938,
      "step": 1729
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4733924865722656,
      "learning_rate": 0.00013362848893166507,
      "loss": 0.7944,
      "step": 1730
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5770873427391052,
      "learning_rate": 0.00013358999037536094,
      "loss": 0.5638,
      "step": 1731
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6357304453849792,
      "learning_rate": 0.0001335514918190568,
      "loss": 0.7096,
      "step": 1732
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.43708500266075134,
      "learning_rate": 0.00013351299326275266,
      "loss": 0.5664,
      "step": 1733
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6533929705619812,
      "learning_rate": 0.0001334744947064485,
      "loss": 0.8319,
      "step": 1734
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5955623388290405,
      "learning_rate": 0.00013343599615014436,
      "loss": 0.7912,
      "step": 1735
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7788638472557068,
      "learning_rate": 0.00013339749759384023,
      "loss": 0.4794,
      "step": 1736
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.41785019636154175,
      "learning_rate": 0.0001333589990375361,
      "loss": 0.7598,
      "step": 1737
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4763592481613159,
      "learning_rate": 0.00013332050048123198,
      "loss": 0.9187,
      "step": 1738
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6042160391807556,
      "learning_rate": 0.0001332820019249278,
      "loss": 0.6247,
      "step": 1739
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5112022757530212,
      "learning_rate": 0.00013324350336862368,
      "loss": 0.7224,
      "step": 1740
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6143046617507935,
      "learning_rate": 0.00013320500481231955,
      "loss": 0.7388,
      "step": 1741
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5973278880119324,
      "learning_rate": 0.0001331665062560154,
      "loss": 0.7445,
      "step": 1742
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5994184017181396,
      "learning_rate": 0.00013312800769971127,
      "loss": 0.7239,
      "step": 1743
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.674239993095398,
      "learning_rate": 0.00013308950914340712,
      "loss": 0.551,
      "step": 1744
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6058774590492249,
      "learning_rate": 0.000133051010587103,
      "loss": 0.6031,
      "step": 1745
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.622861921787262,
      "learning_rate": 0.00013301251203079884,
      "loss": 0.5456,
      "step": 1746
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.507794976234436,
      "learning_rate": 0.00013297401347449472,
      "loss": 0.7746,
      "step": 1747
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5016210079193115,
      "learning_rate": 0.0001329355149181906,
      "loss": 0.7467,
      "step": 1748
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5637462139129639,
      "learning_rate": 0.00013289701636188644,
      "loss": 0.7384,
      "step": 1749
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5154562592506409,
      "learning_rate": 0.0001328585178055823,
      "loss": 0.8016,
      "step": 1750
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5572887659072876,
      "learning_rate": 0.00013282001924927816,
      "loss": 0.6026,
      "step": 1751
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5270084738731384,
      "learning_rate": 0.00013278152069297404,
      "loss": 0.7749,
      "step": 1752
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7092399001121521,
      "learning_rate": 0.00013274302213666988,
      "loss": 0.5003,
      "step": 1753
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5419059991836548,
      "learning_rate": 0.00013270452358036573,
      "loss": 0.8835,
      "step": 1754
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6319900751113892,
      "learning_rate": 0.0001326660250240616,
      "loss": 0.7256,
      "step": 1755
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6434536576271057,
      "learning_rate": 0.00013262752646775748,
      "loss": 0.7016,
      "step": 1756
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6301695108413696,
      "learning_rate": 0.00013258902791145333,
      "loss": 0.6177,
      "step": 1757
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6629579067230225,
      "learning_rate": 0.00013255052935514918,
      "loss": 0.5267,
      "step": 1758
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7753622531890869,
      "learning_rate": 0.00013251203079884505,
      "loss": 0.5778,
      "step": 1759
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5756561160087585,
      "learning_rate": 0.0001324735322425409,
      "loss": 0.8201,
      "step": 1760
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7777136564254761,
      "learning_rate": 0.00013243503368623677,
      "loss": 0.473,
      "step": 1761
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6167535781860352,
      "learning_rate": 0.00013239653512993265,
      "loss": 0.5336,
      "step": 1762
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7404996752738953,
      "learning_rate": 0.0001323580365736285,
      "loss": 0.6145,
      "step": 1763
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8522276878356934,
      "learning_rate": 0.00013231953801732434,
      "loss": 0.3975,
      "step": 1764
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.42812806367874146,
      "learning_rate": 0.00013228103946102022,
      "loss": 0.9693,
      "step": 1765
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5981918573379517,
      "learning_rate": 0.0001322425409047161,
      "loss": 0.6777,
      "step": 1766
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5964804887771606,
      "learning_rate": 0.00013220404234841194,
      "loss": 0.9841,
      "step": 1767
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6191985011100769,
      "learning_rate": 0.00013216554379210778,
      "loss": 0.7284,
      "step": 1768
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.607237696647644,
      "learning_rate": 0.00013212704523580366,
      "loss": 0.6436,
      "step": 1769
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5778822898864746,
      "learning_rate": 0.00013208854667949953,
      "loss": 0.5701,
      "step": 1770
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7544608116149902,
      "learning_rate": 0.00013205004812319538,
      "loss": 0.5402,
      "step": 1771
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6045485138893127,
      "learning_rate": 0.00013201154956689126,
      "loss": 0.5891,
      "step": 1772
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.49818292260169983,
      "learning_rate": 0.0001319730510105871,
      "loss": 0.8154,
      "step": 1773
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4250953197479248,
      "learning_rate": 0.00013193455245428298,
      "loss": 0.8242,
      "step": 1774
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6637367606163025,
      "learning_rate": 0.00013189605389797883,
      "loss": 0.6453,
      "step": 1775
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6174427270889282,
      "learning_rate": 0.0001318575553416747,
      "loss": 0.5652,
      "step": 1776
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.53737473487854,
      "learning_rate": 0.00013181905678537057,
      "loss": 0.7299,
      "step": 1777
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6208964586257935,
      "learning_rate": 0.00013178055822906642,
      "loss": 0.4883,
      "step": 1778
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6696799397468567,
      "learning_rate": 0.00013174205967276227,
      "loss": 0.7042,
      "step": 1779
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6054333448410034,
      "learning_rate": 0.00013170356111645814,
      "loss": 0.6949,
      "step": 1780
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5172533988952637,
      "learning_rate": 0.00013166506256015402,
      "loss": 0.6201,
      "step": 1781
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.420571893453598,
      "learning_rate": 0.00013162656400384987,
      "loss": 0.6407,
      "step": 1782
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5484623312950134,
      "learning_rate": 0.0001315880654475457,
      "loss": 0.7634,
      "step": 1783
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5423629879951477,
      "learning_rate": 0.0001315495668912416,
      "loss": 1.0975,
      "step": 1784
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5246188044548035,
      "learning_rate": 0.00013151106833493744,
      "loss": 0.7853,
      "step": 1785
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6306942701339722,
      "learning_rate": 0.0001314725697786333,
      "loss": 0.7007,
      "step": 1786
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5235528349876404,
      "learning_rate": 0.00013143407122232916,
      "loss": 0.7811,
      "step": 1787
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6945245862007141,
      "learning_rate": 0.00013139557266602503,
      "loss": 0.6483,
      "step": 1788
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5400440692901611,
      "learning_rate": 0.00013135707410972088,
      "loss": 1.0213,
      "step": 1789
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5390788912773132,
      "learning_rate": 0.00013131857555341675,
      "loss": 0.4871,
      "step": 1790
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4592798948287964,
      "learning_rate": 0.00013128007699711263,
      "loss": 0.8874,
      "step": 1791
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.43852856755256653,
      "learning_rate": 0.00013124157844080848,
      "loss": 0.7747,
      "step": 1792
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5351750254631042,
      "learning_rate": 0.00013120307988450432,
      "loss": 0.8607,
      "step": 1793
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5775420665740967,
      "learning_rate": 0.0001311645813282002,
      "loss": 0.9344,
      "step": 1794
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6153382062911987,
      "learning_rate": 0.00013112608277189607,
      "loss": 0.709,
      "step": 1795
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5786885619163513,
      "learning_rate": 0.00013108758421559192,
      "loss": 0.8492,
      "step": 1796
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5372244715690613,
      "learning_rate": 0.00013104908565928777,
      "loss": 0.7128,
      "step": 1797
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6687289476394653,
      "learning_rate": 0.00013101058710298364,
      "loss": 0.3493,
      "step": 1798
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5267163515090942,
      "learning_rate": 0.00013097208854667952,
      "loss": 0.8696,
      "step": 1799
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7073330879211426,
      "learning_rate": 0.00013093358999037536,
      "loss": 0.7071,
      "step": 1800
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6514666080474854,
      "learning_rate": 0.00013089509143407124,
      "loss": 0.6927,
      "step": 1801
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6948337554931641,
      "learning_rate": 0.00013085659287776709,
      "loss": 0.5872,
      "step": 1802
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6468212008476257,
      "learning_rate": 0.00013081809432146296,
      "loss": 0.4622,
      "step": 1803
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5250908136367798,
      "learning_rate": 0.0001307795957651588,
      "loss": 0.8713,
      "step": 1804
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6043336391448975,
      "learning_rate": 0.00013074109720885468,
      "loss": 0.6561,
      "step": 1805
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5664190649986267,
      "learning_rate": 0.00013070259865255056,
      "loss": 0.8406,
      "step": 1806
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7055228352546692,
      "learning_rate": 0.00013066410009624638,
      "loss": 0.8147,
      "step": 1807
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8810431361198425,
      "learning_rate": 0.00013062560153994225,
      "loss": 0.7426,
      "step": 1808
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7940276861190796,
      "learning_rate": 0.00013058710298363813,
      "loss": 0.8827,
      "step": 1809
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6559934020042419,
      "learning_rate": 0.000130548604427334,
      "loss": 0.5793,
      "step": 1810
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.847409725189209,
      "learning_rate": 0.00013051010587102985,
      "loss": 0.5987,
      "step": 1811
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6262015104293823,
      "learning_rate": 0.0001304716073147257,
      "loss": 0.6327,
      "step": 1812
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7257842421531677,
      "learning_rate": 0.00013043310875842157,
      "loss": 0.7883,
      "step": 1813
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5952643156051636,
      "learning_rate": 0.00013039461020211742,
      "loss": 0.7057,
      "step": 1814
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.567611038684845,
      "learning_rate": 0.0001303561116458133,
      "loss": 0.7059,
      "step": 1815
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6279333829879761,
      "learning_rate": 0.00013031761308950917,
      "loss": 0.5903,
      "step": 1816
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5087338089942932,
      "learning_rate": 0.000130279114533205,
      "loss": 0.6268,
      "step": 1817
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5449573993682861,
      "learning_rate": 0.00013024061597690086,
      "loss": 0.816,
      "step": 1818
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6183302998542786,
      "learning_rate": 0.00013020211742059674,
      "loss": 0.7301,
      "step": 1819
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0695836544036865,
      "learning_rate": 0.0001301636188642926,
      "loss": 0.7218,
      "step": 1820
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9241111278533936,
      "learning_rate": 0.00013012512030798846,
      "loss": 0.7347,
      "step": 1821
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5585509538650513,
      "learning_rate": 0.0001300866217516843,
      "loss": 0.6868,
      "step": 1822
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5809900760650635,
      "learning_rate": 0.00013004812319538018,
      "loss": 0.5113,
      "step": 1823
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6051921248435974,
      "learning_rate": 0.00013000962463907605,
      "loss": 0.7109,
      "step": 1824
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7000371813774109,
      "learning_rate": 0.0001299711260827719,
      "loss": 0.4587,
      "step": 1825
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6166704297065735,
      "learning_rate": 0.00012993262752646775,
      "loss": 0.7315,
      "step": 1826
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.687282383441925,
      "learning_rate": 0.00012989412897016362,
      "loss": 0.6852,
      "step": 1827
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6723230481147766,
      "learning_rate": 0.0001298556304138595,
      "loss": 0.8152,
      "step": 1828
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5465150475502014,
      "learning_rate": 0.00012981713185755535,
      "loss": 0.8356,
      "step": 1829
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6479633450508118,
      "learning_rate": 0.00012977863330125122,
      "loss": 0.6394,
      "step": 1830
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6180844902992249,
      "learning_rate": 0.00012974013474494707,
      "loss": 0.5438,
      "step": 1831
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6998152732849121,
      "learning_rate": 0.00012970163618864291,
      "loss": 0.4538,
      "step": 1832
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5092435479164124,
      "learning_rate": 0.0001296631376323388,
      "loss": 0.7599,
      "step": 1833
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6921501755714417,
      "learning_rate": 0.00012962463907603466,
      "loss": 0.72,
      "step": 1834
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6418219804763794,
      "learning_rate": 0.00012958614051973054,
      "loss": 0.7168,
      "step": 1835
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6218831539154053,
      "learning_rate": 0.00012954764196342636,
      "loss": 0.6018,
      "step": 1836
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.016654133796692,
      "learning_rate": 0.00012950914340712223,
      "loss": 0.7169,
      "step": 1837
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5717986822128296,
      "learning_rate": 0.0001294706448508181,
      "loss": 0.6898,
      "step": 1838
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5861942172050476,
      "learning_rate": 0.00012943214629451395,
      "loss": 0.6032,
      "step": 1839
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5368156433105469,
      "learning_rate": 0.00012939364773820983,
      "loss": 0.6458,
      "step": 1840
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5989863872528076,
      "learning_rate": 0.00012935514918190568,
      "loss": 0.9796,
      "step": 1841
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5241777300834656,
      "learning_rate": 0.00012931665062560155,
      "loss": 0.7473,
      "step": 1842
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5754107236862183,
      "learning_rate": 0.0001292781520692974,
      "loss": 0.6352,
      "step": 1843
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5214626789093018,
      "learning_rate": 0.00012923965351299327,
      "loss": 0.3988,
      "step": 1844
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7687956690788269,
      "learning_rate": 0.00012920115495668915,
      "loss": 0.6286,
      "step": 1845
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5529030561447144,
      "learning_rate": 0.000129162656400385,
      "loss": 0.4111,
      "step": 1846
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7495878338813782,
      "learning_rate": 0.00012912415784408084,
      "loss": 0.6328,
      "step": 1847
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6179913282394409,
      "learning_rate": 0.00012908565928777672,
      "loss": 0.5536,
      "step": 1848
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5168277621269226,
      "learning_rate": 0.0001290471607314726,
      "loss": 0.8184,
      "step": 1849
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6800773739814758,
      "learning_rate": 0.00012900866217516844,
      "loss": 0.5831,
      "step": 1850
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8205670118331909,
      "learning_rate": 0.0001289701636188643,
      "loss": 0.5278,
      "step": 1851
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6239596009254456,
      "learning_rate": 0.00012893166506256016,
      "loss": 0.7423,
      "step": 1852
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7756689190864563,
      "learning_rate": 0.00012889316650625604,
      "loss": 0.648,
      "step": 1853
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6058743000030518,
      "learning_rate": 0.00012885466794995188,
      "loss": 0.6637,
      "step": 1854
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.580424427986145,
      "learning_rate": 0.00012881616939364773,
      "loss": 0.7471,
      "step": 1855
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6386114358901978,
      "learning_rate": 0.0001287776708373436,
      "loss": 0.5489,
      "step": 1856
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5655244588851929,
      "learning_rate": 0.00012873917228103948,
      "loss": 0.8241,
      "step": 1857
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4783247709274292,
      "learning_rate": 0.00012870067372473533,
      "loss": 0.8104,
      "step": 1858
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7306551933288574,
      "learning_rate": 0.0001286621751684312,
      "loss": 0.5938,
      "step": 1859
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6884995698928833,
      "learning_rate": 0.00012862367661212705,
      "loss": 0.5919,
      "step": 1860
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7793060541152954,
      "learning_rate": 0.0001285851780558229,
      "loss": 0.5303,
      "step": 1861
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6108075380325317,
      "learning_rate": 0.00012854667949951877,
      "loss": 0.6631,
      "step": 1862
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6257457137107849,
      "learning_rate": 0.00012850818094321465,
      "loss": 0.8339,
      "step": 1863
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5449333190917969,
      "learning_rate": 0.0001284696823869105,
      "loss": 0.711,
      "step": 1864
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5932379961013794,
      "learning_rate": 0.00012843118383060634,
      "loss": 0.7278,
      "step": 1865
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6139468550682068,
      "learning_rate": 0.00012839268527430221,
      "loss": 0.6871,
      "step": 1866
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7339085936546326,
      "learning_rate": 0.0001283541867179981,
      "loss": 0.4283,
      "step": 1867
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7180920243263245,
      "learning_rate": 0.00012831568816169394,
      "loss": 0.4267,
      "step": 1868
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.659973680973053,
      "learning_rate": 0.0001282771896053898,
      "loss": 0.7725,
      "step": 1869
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7085214853286743,
      "learning_rate": 0.00012823869104908566,
      "loss": 0.5474,
      "step": 1870
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7682948112487793,
      "learning_rate": 0.00012820019249278153,
      "loss": 0.7404,
      "step": 1871
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7531403303146362,
      "learning_rate": 0.00012816169393647738,
      "loss": 0.4938,
      "step": 1872
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6624100208282471,
      "learning_rate": 0.00012812319538017326,
      "loss": 0.5494,
      "step": 1873
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7966387271881104,
      "learning_rate": 0.00012808469682386913,
      "loss": 0.3561,
      "step": 1874
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5807605385780334,
      "learning_rate": 0.00012804619826756498,
      "loss": 0.602,
      "step": 1875
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6782401204109192,
      "learning_rate": 0.00012800769971126082,
      "loss": 0.9528,
      "step": 1876
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5015867948532104,
      "learning_rate": 0.0001279692011549567,
      "loss": 0.6993,
      "step": 1877
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9556828141212463,
      "learning_rate": 0.00012793070259865257,
      "loss": 0.8115,
      "step": 1878
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6102689504623413,
      "learning_rate": 0.00012789220404234842,
      "loss": 0.9801,
      "step": 1879
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7077298760414124,
      "learning_rate": 0.00012785370548604427,
      "loss": 0.4829,
      "step": 1880
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6043858528137207,
      "learning_rate": 0.00012781520692974014,
      "loss": 0.4931,
      "step": 1881
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6979725956916809,
      "learning_rate": 0.00012777670837343602,
      "loss": 0.7226,
      "step": 1882
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6658673882484436,
      "learning_rate": 0.00012773820981713187,
      "loss": 0.5406,
      "step": 1883
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5709940195083618,
      "learning_rate": 0.0001276997112608277,
      "loss": 0.9245,
      "step": 1884
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5893299579620361,
      "learning_rate": 0.0001276612127045236,
      "loss": 0.6269,
      "step": 1885
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5454053282737732,
      "learning_rate": 0.00012762271414821943,
      "loss": 0.5831,
      "step": 1886
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8415330648422241,
      "learning_rate": 0.0001275842155919153,
      "loss": 0.675,
      "step": 1887
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2825108766555786,
      "learning_rate": 0.00012754571703561118,
      "loss": 0.6897,
      "step": 1888
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7884512543678284,
      "learning_rate": 0.00012750721847930703,
      "loss": 0.9519,
      "step": 1889
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5048503875732422,
      "learning_rate": 0.00012746871992300288,
      "loss": 0.6283,
      "step": 1890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7665786147117615,
      "learning_rate": 0.00012743022136669875,
      "loss": 0.677,
      "step": 1891
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5940256714820862,
      "learning_rate": 0.00012739172281039463,
      "loss": 0.6287,
      "step": 1892
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.504614531993866,
      "learning_rate": 0.00012735322425409047,
      "loss": 0.6941,
      "step": 1893
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5970924496650696,
      "learning_rate": 0.00012731472569778632,
      "loss": 0.6209,
      "step": 1894
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5585225224494934,
      "learning_rate": 0.0001272762271414822,
      "loss": 0.8578,
      "step": 1895
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5141816139221191,
      "learning_rate": 0.00012723772858517807,
      "loss": 0.5335,
      "step": 1896
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6749102473258972,
      "learning_rate": 0.00012719923002887392,
      "loss": 0.6692,
      "step": 1897
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6740930676460266,
      "learning_rate": 0.0001271607314725698,
      "loss": 0.7062,
      "step": 1898
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5875928997993469,
      "learning_rate": 0.00012712223291626564,
      "loss": 0.5577,
      "step": 1899
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5679300427436829,
      "learning_rate": 0.00012708373435996152,
      "loss": 0.6223,
      "step": 1900
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6278038620948792,
      "learning_rate": 0.00012704523580365736,
      "loss": 0.6079,
      "step": 1901
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5573702454566956,
      "learning_rate": 0.00012700673724735324,
      "loss": 0.5501,
      "step": 1902
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5201683044433594,
      "learning_rate": 0.0001269682386910491,
      "loss": 0.7032,
      "step": 1903
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6053997874259949,
      "learning_rate": 0.00012692974013474493,
      "loss": 0.7583,
      "step": 1904
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.737331748008728,
      "learning_rate": 0.0001268912415784408,
      "loss": 0.7864,
      "step": 1905
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.596876323223114,
      "learning_rate": 0.00012685274302213668,
      "loss": 0.509,
      "step": 1906
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6073601841926575,
      "learning_rate": 0.00012681424446583256,
      "loss": 0.6706,
      "step": 1907
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6994699835777283,
      "learning_rate": 0.0001267757459095284,
      "loss": 0.4866,
      "step": 1908
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5340166687965393,
      "learning_rate": 0.00012673724735322425,
      "loss": 1.0079,
      "step": 1909
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6012325286865234,
      "learning_rate": 0.00012669874879692013,
      "loss": 0.638,
      "step": 1910
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6311020851135254,
      "learning_rate": 0.00012666025024061597,
      "loss": 0.697,
      "step": 1911
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5592195987701416,
      "learning_rate": 0.00012662175168431185,
      "loss": 0.6851,
      "step": 1912
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8121064305305481,
      "learning_rate": 0.0001265832531280077,
      "loss": 0.3852,
      "step": 1913
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5440016984939575,
      "learning_rate": 0.00012654475457170357,
      "loss": 0.9302,
      "step": 1914
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.49923497438430786,
      "learning_rate": 0.00012650625601539942,
      "loss": 0.7097,
      "step": 1915
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6140123605728149,
      "learning_rate": 0.0001264677574590953,
      "loss": 0.5335,
      "step": 1916
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7011561393737793,
      "learning_rate": 0.00012642925890279117,
      "loss": 0.483,
      "step": 1917
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6720527410507202,
      "learning_rate": 0.000126390760346487,
      "loss": 0.9694,
      "step": 1918
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7185110449790955,
      "learning_rate": 0.00012635226179018286,
      "loss": 0.6978,
      "step": 1919
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6269097924232483,
      "learning_rate": 0.00012631376323387873,
      "loss": 0.7563,
      "step": 1920
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5105812549591064,
      "learning_rate": 0.0001262752646775746,
      "loss": 0.7205,
      "step": 1921
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6797268390655518,
      "learning_rate": 0.00012623676612127046,
      "loss": 0.7364,
      "step": 1922
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4791325032711029,
      "learning_rate": 0.0001261982675649663,
      "loss": 0.7114,
      "step": 1923
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6188709139823914,
      "learning_rate": 0.00012615976900866218,
      "loss": 0.9249,
      "step": 1924
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6436751484870911,
      "learning_rate": 0.00012612127045235805,
      "loss": 0.6861,
      "step": 1925
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9612260460853577,
      "learning_rate": 0.0001260827718960539,
      "loss": 0.6604,
      "step": 1926
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6380037069320679,
      "learning_rate": 0.00012604427333974978,
      "loss": 0.6021,
      "step": 1927
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9645226001739502,
      "learning_rate": 0.00012600577478344562,
      "loss": 0.7124,
      "step": 1928
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5523340702056885,
      "learning_rate": 0.0001259672762271415,
      "loss": 0.654,
      "step": 1929
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5864350199699402,
      "learning_rate": 0.00012592877767083734,
      "loss": 0.5528,
      "step": 1930
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8753622770309448,
      "learning_rate": 0.00012589027911453322,
      "loss": 0.5877,
      "step": 1931
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6807810664176941,
      "learning_rate": 0.0001258517805582291,
      "loss": 0.8054,
      "step": 1932
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5834801197052002,
      "learning_rate": 0.00012581328200192491,
      "loss": 0.681,
      "step": 1933
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5726195573806763,
      "learning_rate": 0.0001257747834456208,
      "loss": 0.7156,
      "step": 1934
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6285164952278137,
      "learning_rate": 0.00012573628488931666,
      "loss": 0.5407,
      "step": 1935
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5365082025527954,
      "learning_rate": 0.0001256977863330125,
      "loss": 0.6382,
      "step": 1936
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5777384638786316,
      "learning_rate": 0.00012565928777670839,
      "loss": 0.7196,
      "step": 1937
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5752362012863159,
      "learning_rate": 0.00012562078922040423,
      "loss": 0.6835,
      "step": 1938
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7848861217498779,
      "learning_rate": 0.0001255822906641001,
      "loss": 0.6511,
      "step": 1939
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.668402910232544,
      "learning_rate": 0.00012554379210779595,
      "loss": 0.4651,
      "step": 1940
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6514251828193665,
      "learning_rate": 0.00012550529355149183,
      "loss": 0.4825,
      "step": 1941
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5853440165519714,
      "learning_rate": 0.0001254667949951877,
      "loss": 0.6495,
      "step": 1942
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9148367643356323,
      "learning_rate": 0.00012542829643888355,
      "loss": 0.9259,
      "step": 1943
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6774194240570068,
      "learning_rate": 0.0001253897978825794,
      "loss": 0.716,
      "step": 1944
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6711391806602478,
      "learning_rate": 0.00012535129932627527,
      "loss": 0.7888,
      "step": 1945
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6230437159538269,
      "learning_rate": 0.00012531280076997115,
      "loss": 0.7474,
      "step": 1946
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6114274263381958,
      "learning_rate": 0.000125274302213667,
      "loss": 0.7529,
      "step": 1947
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9491918683052063,
      "learning_rate": 0.00012523580365736284,
      "loss": 0.5703,
      "step": 1948
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6996601819992065,
      "learning_rate": 0.00012519730510105872,
      "loss": 0.6153,
      "step": 1949
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7869441509246826,
      "learning_rate": 0.0001251588065447546,
      "loss": 0.6316,
      "step": 1950
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.749352216720581,
      "learning_rate": 0.00012512030798845044,
      "loss": 0.3289,
      "step": 1951
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5965579152107239,
      "learning_rate": 0.00012508180943214629,
      "loss": 0.5065,
      "step": 1952
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7119035720825195,
      "learning_rate": 0.00012504331087584216,
      "loss": 0.5902,
      "step": 1953
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6892595887184143,
      "learning_rate": 0.00012500481231953804,
      "loss": 0.7593,
      "step": 1954
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4977797269821167,
      "learning_rate": 0.00012496631376323388,
      "loss": 0.5846,
      "step": 1955
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6799194812774658,
      "learning_rate": 0.00012492781520692976,
      "loss": 0.6532,
      "step": 1956
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5413656234741211,
      "learning_rate": 0.0001248893166506256,
      "loss": 0.6685,
      "step": 1957
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7521079778671265,
      "learning_rate": 0.00012485081809432145,
      "loss": 0.5868,
      "step": 1958
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5557287931442261,
      "learning_rate": 0.00012481231953801733,
      "loss": 0.7281,
      "step": 1959
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.56269770860672,
      "learning_rate": 0.0001247738209817132,
      "loss": 0.7382,
      "step": 1960
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7385743260383606,
      "learning_rate": 0.00012473532242540908,
      "loss": 0.4237,
      "step": 1961
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7741246819496155,
      "learning_rate": 0.0001246968238691049,
      "loss": 0.5095,
      "step": 1962
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7472075819969177,
      "learning_rate": 0.00012465832531280077,
      "loss": 0.6215,
      "step": 1963
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6419203877449036,
      "learning_rate": 0.00012461982675649665,
      "loss": 0.6956,
      "step": 1964
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4582994282245636,
      "learning_rate": 0.0001245813282001925,
      "loss": 0.7627,
      "step": 1965
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6624303460121155,
      "learning_rate": 0.00012454282964388837,
      "loss": 0.9171,
      "step": 1966
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6243951916694641,
      "learning_rate": 0.00012450433108758421,
      "loss": 0.7254,
      "step": 1967
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.979499876499176,
      "learning_rate": 0.0001244658325312801,
      "loss": 0.7171,
      "step": 1968
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.67156583070755,
      "learning_rate": 0.00012442733397497594,
      "loss": 0.5536,
      "step": 1969
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5756434202194214,
      "learning_rate": 0.0001243888354186718,
      "loss": 0.9392,
      "step": 1970
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5680772066116333,
      "learning_rate": 0.00012435033686236769,
      "loss": 0.6087,
      "step": 1971
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6982653737068176,
      "learning_rate": 0.00012431183830606353,
      "loss": 0.6484,
      "step": 1972
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7528694272041321,
      "learning_rate": 0.00012427333974975938,
      "loss": 0.7052,
      "step": 1973
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6491179466247559,
      "learning_rate": 0.00012423484119345525,
      "loss": 0.7303,
      "step": 1974
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6661299467086792,
      "learning_rate": 0.00012419634263715113,
      "loss": 0.5979,
      "step": 1975
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.606228232383728,
      "learning_rate": 0.00012415784408084698,
      "loss": 0.6727,
      "step": 1976
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8426294326782227,
      "learning_rate": 0.00012411934552454282,
      "loss": 0.4708,
      "step": 1977
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6607711315155029,
      "learning_rate": 0.0001240808469682387,
      "loss": 0.8231,
      "step": 1978
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5860126614570618,
      "learning_rate": 0.00012404234841193457,
      "loss": 0.9794,
      "step": 1979
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6653693318367004,
      "learning_rate": 0.00012400384985563042,
      "loss": 1.1124,
      "step": 1980
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5407781600952148,
      "learning_rate": 0.00012396535129932627,
      "loss": 1.0173,
      "step": 1981
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5622276067733765,
      "learning_rate": 0.00012392685274302214,
      "loss": 0.5585,
      "step": 1982
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.876147449016571,
      "learning_rate": 0.000123888354186718,
      "loss": 0.4711,
      "step": 1983
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4420551657676697,
      "learning_rate": 0.00012384985563041386,
      "loss": 0.6466,
      "step": 1984
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5523685216903687,
      "learning_rate": 0.00012381135707410974,
      "loss": 0.5912,
      "step": 1985
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.529365599155426,
      "learning_rate": 0.0001237728585178056,
      "loss": 0.7224,
      "step": 1986
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7671646475791931,
      "learning_rate": 0.00012373435996150143,
      "loss": 0.5277,
      "step": 1987
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5595332980155945,
      "learning_rate": 0.0001236958614051973,
      "loss": 0.8745,
      "step": 1988
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5248603820800781,
      "learning_rate": 0.00012365736284889318,
      "loss": 0.7619,
      "step": 1989
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6084541082382202,
      "learning_rate": 0.00012361886429258903,
      "loss": 0.7461,
      "step": 1990
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5073636770248413,
      "learning_rate": 0.00012358036573628488,
      "loss": 0.6355,
      "step": 1991
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7375236749649048,
      "learning_rate": 0.00012354186717998075,
      "loss": 0.6767,
      "step": 1992
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4807255268096924,
      "learning_rate": 0.00012350336862367663,
      "loss": 0.5554,
      "step": 1993
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5243448615074158,
      "learning_rate": 0.00012346487006737247,
      "loss": 0.8431,
      "step": 1994
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5261726975440979,
      "learning_rate": 0.00012342637151106835,
      "loss": 0.7923,
      "step": 1995
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.46297094225883484,
      "learning_rate": 0.0001233878729547642,
      "loss": 0.6708,
      "step": 1996
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6631423830986023,
      "learning_rate": 0.00012334937439846007,
      "loss": 0.5973,
      "step": 1997
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6401545405387878,
      "learning_rate": 0.00012331087584215592,
      "loss": 0.3947,
      "step": 1998
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6269503831863403,
      "learning_rate": 0.0001232723772858518,
      "loss": 0.3359,
      "step": 1999
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5524480938911438,
      "learning_rate": 0.00012323387872954767,
      "loss": 0.5673,
      "step": 2000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.742557168006897,
      "learning_rate": 0.00012319538017324351,
      "loss": 0.6484,
      "step": 2001
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7859886884689331,
      "learning_rate": 0.00012315688161693936,
      "loss": 0.7438,
      "step": 2002
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6489876508712769,
      "learning_rate": 0.00012311838306063524,
      "loss": 0.5558,
      "step": 2003
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8800199031829834,
      "learning_rate": 0.0001230798845043311,
      "loss": 0.3983,
      "step": 2004
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5714797973632812,
      "learning_rate": 0.00012304138594802696,
      "loss": 0.5425,
      "step": 2005
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6814557909965515,
      "learning_rate": 0.0001230028873917228,
      "loss": 0.8805,
      "step": 2006
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5968981385231018,
      "learning_rate": 0.00012296438883541868,
      "loss": 0.7234,
      "step": 2007
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7469682097434998,
      "learning_rate": 0.00012292589027911456,
      "loss": 0.7493,
      "step": 2008
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0239769220352173,
      "learning_rate": 0.0001228873917228104,
      "loss": 0.9507,
      "step": 2009
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5739884376525879,
      "learning_rate": 0.00012284889316650625,
      "loss": 1.073,
      "step": 2010
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6252111792564392,
      "learning_rate": 0.00012281039461020212,
      "loss": 0.6088,
      "step": 2011
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6902915239334106,
      "learning_rate": 0.00012277189605389797,
      "loss": 0.8394,
      "step": 2012
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6184666156768799,
      "learning_rate": 0.00012273339749759385,
      "loss": 0.5805,
      "step": 2013
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5575597286224365,
      "learning_rate": 0.00012269489894128972,
      "loss": 0.7534,
      "step": 2014
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4736398458480835,
      "learning_rate": 0.00012265640038498557,
      "loss": 0.8201,
      "step": 2015
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5303353071212769,
      "learning_rate": 0.00012261790182868142,
      "loss": 0.8429,
      "step": 2016
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6805256605148315,
      "learning_rate": 0.0001225794032723773,
      "loss": 0.7139,
      "step": 2017
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7295402884483337,
      "learning_rate": 0.00012254090471607316,
      "loss": 0.6671,
      "step": 2018
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6054564714431763,
      "learning_rate": 0.000122502406159769,
      "loss": 0.7039,
      "step": 2019
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5073196291923523,
      "learning_rate": 0.00012246390760346486,
      "loss": 0.7001,
      "step": 2020
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7058408260345459,
      "learning_rate": 0.00012242540904716073,
      "loss": 0.827,
      "step": 2021
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6197201013565063,
      "learning_rate": 0.0001223869104908566,
      "loss": 0.3873,
      "step": 2022
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7690449953079224,
      "learning_rate": 0.00012234841193455246,
      "loss": 0.7295,
      "step": 2023
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5954878926277161,
      "learning_rate": 0.00012230991337824833,
      "loss": 0.8291,
      "step": 2024
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.579882800579071,
      "learning_rate": 0.00012227141482194418,
      "loss": 0.6175,
      "step": 2025
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8283370733261108,
      "learning_rate": 0.00012223291626564005,
      "loss": 0.369,
      "step": 2026
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6182541847229004,
      "learning_rate": 0.0001221944177093359,
      "loss": 0.5019,
      "step": 2027
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7956016659736633,
      "learning_rate": 0.00012215591915303177,
      "loss": 0.7363,
      "step": 2028
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6877994537353516,
      "learning_rate": 0.00012211742059672765,
      "loss": 0.4796,
      "step": 2029
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5093246698379517,
      "learning_rate": 0.00012207892204042347,
      "loss": 0.9475,
      "step": 2030
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.44780853390693665,
      "learning_rate": 0.00012204042348411934,
      "loss": 0.9864,
      "step": 2031
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5267164707183838,
      "learning_rate": 0.00012200192492781522,
      "loss": 0.5414,
      "step": 2032
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6876372694969177,
      "learning_rate": 0.00012196342637151108,
      "loss": 0.6026,
      "step": 2033
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.692188560962677,
      "learning_rate": 0.00012192492781520694,
      "loss": 0.6651,
      "step": 2034
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6715821623802185,
      "learning_rate": 0.00012188642925890279,
      "loss": 0.7316,
      "step": 2035
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6233677268028259,
      "learning_rate": 0.00012184793070259866,
      "loss": 0.6792,
      "step": 2036
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.534206748008728,
      "learning_rate": 0.00012180943214629452,
      "loss": 0.7195,
      "step": 2037
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6175679564476013,
      "learning_rate": 0.00012177093358999038,
      "loss": 0.6622,
      "step": 2038
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4672880172729492,
      "learning_rate": 0.00012173243503368623,
      "loss": 0.7277,
      "step": 2039
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6855531930923462,
      "learning_rate": 0.00012169393647738209,
      "loss": 0.5424,
      "step": 2040
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5643823742866516,
      "learning_rate": 0.00012165543792107797,
      "loss": 0.7362,
      "step": 2041
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6620444655418396,
      "learning_rate": 0.00012161693936477383,
      "loss": 0.5227,
      "step": 2042
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5515279173851013,
      "learning_rate": 0.00012157844080846969,
      "loss": 0.6118,
      "step": 2043
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4979992210865021,
      "learning_rate": 0.00012153994225216554,
      "loss": 0.6957,
      "step": 2044
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5680111646652222,
      "learning_rate": 0.00012150144369586141,
      "loss": 0.6538,
      "step": 2045
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7590301632881165,
      "learning_rate": 0.00012146294513955727,
      "loss": 0.4548,
      "step": 2046
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7051795125007629,
      "learning_rate": 0.00012142444658325313,
      "loss": 0.5651,
      "step": 2047
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5354979038238525,
      "learning_rate": 0.00012138594802694901,
      "loss": 0.7414,
      "step": 2048
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.554533839225769,
      "learning_rate": 0.00012134744947064484,
      "loss": 0.7407,
      "step": 2049
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.595911979675293,
      "learning_rate": 0.00012130895091434072,
      "loss": 0.6258,
      "step": 2050
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6449824571609497,
      "learning_rate": 0.00012127045235803658,
      "loss": 0.5309,
      "step": 2051
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9058115482330322,
      "learning_rate": 0.00012123195380173245,
      "loss": 0.6768,
      "step": 2052
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.655267596244812,
      "learning_rate": 0.00012119345524542831,
      "loss": 0.4327,
      "step": 2053
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6320971250534058,
      "learning_rate": 0.00012115495668912416,
      "loss": 0.6738,
      "step": 2054
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4947320520877838,
      "learning_rate": 0.00012111645813282002,
      "loss": 0.7335,
      "step": 2055
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6001105308532715,
      "learning_rate": 0.00012107795957651588,
      "loss": 0.6487,
      "step": 2056
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5322490334510803,
      "learning_rate": 0.00012103946102021176,
      "loss": 0.7651,
      "step": 2057
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6607229113578796,
      "learning_rate": 0.00012100096246390762,
      "loss": 0.411,
      "step": 2058
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5707874894142151,
      "learning_rate": 0.00012096246390760347,
      "loss": 0.727,
      "step": 2059
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.568004310131073,
      "learning_rate": 0.00012092396535129933,
      "loss": 0.6798,
      "step": 2060
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5816327333450317,
      "learning_rate": 0.0001208854667949952,
      "loss": 0.6521,
      "step": 2061
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5993533134460449,
      "learning_rate": 0.00012084696823869106,
      "loss": 0.8757,
      "step": 2062
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6387884020805359,
      "learning_rate": 0.00012080846968238692,
      "loss": 0.7009,
      "step": 2063
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6644651889801025,
      "learning_rate": 0.00012076997112608277,
      "loss": 0.4073,
      "step": 2064
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5480085611343384,
      "learning_rate": 0.00012073147256977863,
      "loss": 0.7329,
      "step": 2065
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6623391509056091,
      "learning_rate": 0.0001206929740134745,
      "loss": 0.5597,
      "step": 2066
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6570023894309998,
      "learning_rate": 0.00012065447545717037,
      "loss": 0.6531,
      "step": 2067
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6952292323112488,
      "learning_rate": 0.00012061597690086624,
      "loss": 0.7013,
      "step": 2068
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7254212498664856,
      "learning_rate": 0.00012057747834456207,
      "loss": 0.5887,
      "step": 2069
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6655024886131287,
      "learning_rate": 0.00012053897978825795,
      "loss": 0.5579,
      "step": 2070
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.44187501072883606,
      "learning_rate": 0.00012050048123195381,
      "loss": 0.7466,
      "step": 2071
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8130383491516113,
      "learning_rate": 0.00012046198267564967,
      "loss": 0.4335,
      "step": 2072
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6431501507759094,
      "learning_rate": 0.00012042348411934552,
      "loss": 0.6142,
      "step": 2073
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.574508547782898,
      "learning_rate": 0.00012038498556304138,
      "loss": 0.8736,
      "step": 2074
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5852559804916382,
      "learning_rate": 0.00012034648700673725,
      "loss": 0.7536,
      "step": 2075
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.550538957118988,
      "learning_rate": 0.00012030798845043312,
      "loss": 0.5868,
      "step": 2076
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5034310221672058,
      "learning_rate": 0.00012026948989412899,
      "loss": 0.6918,
      "step": 2077
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8982884883880615,
      "learning_rate": 0.00012023099133782482,
      "loss": 0.5113,
      "step": 2078
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6706066131591797,
      "learning_rate": 0.0001201924927815207,
      "loss": 0.692,
      "step": 2079
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.824813723564148,
      "learning_rate": 0.00012015399422521656,
      "loss": 0.4706,
      "step": 2080
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6175369620323181,
      "learning_rate": 0.00012011549566891242,
      "loss": 0.5492,
      "step": 2081
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.49034130573272705,
      "learning_rate": 0.0001200769971126083,
      "loss": 0.6568,
      "step": 2082
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5926831364631653,
      "learning_rate": 0.00012003849855630414,
      "loss": 0.5553,
      "step": 2083
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5013852119445801,
      "learning_rate": 0.00012,
      "loss": 0.8324,
      "step": 2084
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6658658385276794,
      "learning_rate": 0.00011996150144369586,
      "loss": 0.5607,
      "step": 2085
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7712120413780212,
      "learning_rate": 0.00011992300288739174,
      "loss": 0.6683,
      "step": 2086
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5289482474327087,
      "learning_rate": 0.0001198845043310876,
      "loss": 0.7913,
      "step": 2087
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7652068138122559,
      "learning_rate": 0.00011984600577478345,
      "loss": 0.5788,
      "step": 2088
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.46042969822883606,
      "learning_rate": 0.00011980750721847931,
      "loss": 0.815,
      "step": 2089
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6515125632286072,
      "learning_rate": 0.00011976900866217517,
      "loss": 0.7823,
      "step": 2090
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6623435616493225,
      "learning_rate": 0.00011973051010587104,
      "loss": 0.3911,
      "step": 2091
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5617800354957581,
      "learning_rate": 0.0001196920115495669,
      "loss": 0.4476,
      "step": 2092
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6794402599334717,
      "learning_rate": 0.00011965351299326275,
      "loss": 0.4697,
      "step": 2093
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5526383519172668,
      "learning_rate": 0.00011961501443695861,
      "loss": 0.6398,
      "step": 2094
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5878256559371948,
      "learning_rate": 0.00011957651588065449,
      "loss": 0.7816,
      "step": 2095
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4738675057888031,
      "learning_rate": 0.00011953801732435035,
      "loss": 0.7966,
      "step": 2096
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6400088667869568,
      "learning_rate": 0.00011949951876804621,
      "loss": 0.7229,
      "step": 2097
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5514880418777466,
      "learning_rate": 0.00011946102021174206,
      "loss": 0.5918,
      "step": 2098
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5828971862792969,
      "learning_rate": 0.00011942252165543792,
      "loss": 0.4952,
      "step": 2099
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5938296318054199,
      "learning_rate": 0.00011938402309913379,
      "loss": 0.8417,
      "step": 2100
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5390080213546753,
      "learning_rate": 0.00011934552454282965,
      "loss": 0.9914,
      "step": 2101
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.583354115486145,
      "learning_rate": 0.0001193070259865255,
      "loss": 0.8638,
      "step": 2102
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5445369482040405,
      "learning_rate": 0.00011926852743022136,
      "loss": 0.4892,
      "step": 2103
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7171153426170349,
      "learning_rate": 0.00011923002887391724,
      "loss": 0.5524,
      "step": 2104
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6799771785736084,
      "learning_rate": 0.0001191915303176131,
      "loss": 0.7039,
      "step": 2105
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5320558547973633,
      "learning_rate": 0.00011915303176130896,
      "loss": 0.4239,
      "step": 2106
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7804939150810242,
      "learning_rate": 0.0001191145332050048,
      "loss": 0.6233,
      "step": 2107
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6643623113632202,
      "learning_rate": 0.00011907603464870068,
      "loss": 0.6786,
      "step": 2108
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7163774967193604,
      "learning_rate": 0.00011903753609239654,
      "loss": 0.7234,
      "step": 2109
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8227395415306091,
      "learning_rate": 0.0001189990375360924,
      "loss": 0.5033,
      "step": 2110
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5642378926277161,
      "learning_rate": 0.00011896053897978828,
      "loss": 0.6275,
      "step": 2111
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6193049550056458,
      "learning_rate": 0.00011892204042348411,
      "loss": 0.7913,
      "step": 2112
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7500722408294678,
      "learning_rate": 0.00011888354186717998,
      "loss": 0.5998,
      "step": 2113
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5645126700401306,
      "learning_rate": 0.00011884504331087585,
      "loss": 0.3791,
      "step": 2114
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5865591764450073,
      "learning_rate": 0.00011880654475457171,
      "loss": 0.5475,
      "step": 2115
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.650765597820282,
      "learning_rate": 0.00011876804619826758,
      "loss": 0.8374,
      "step": 2116
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5573832988739014,
      "learning_rate": 0.00011872954764196343,
      "loss": 0.8443,
      "step": 2117
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7106786370277405,
      "learning_rate": 0.00011869104908565929,
      "loss": 0.4377,
      "step": 2118
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7807832360267639,
      "learning_rate": 0.00011865255052935515,
      "loss": 0.6007,
      "step": 2119
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5899080038070679,
      "learning_rate": 0.00011861405197305103,
      "loss": 0.621,
      "step": 2120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4954891800880432,
      "learning_rate": 0.00011857555341674689,
      "loss": 0.8995,
      "step": 2121
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5917604565620422,
      "learning_rate": 0.00011853705486044273,
      "loss": 0.624,
      "step": 2122
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5892689228057861,
      "learning_rate": 0.0001184985563041386,
      "loss": 0.9006,
      "step": 2123
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6440193057060242,
      "learning_rate": 0.00011846005774783447,
      "loss": 0.8347,
      "step": 2124
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6211103796958923,
      "learning_rate": 0.00011842155919153033,
      "loss": 0.5322,
      "step": 2125
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5879185199737549,
      "learning_rate": 0.00011838306063522619,
      "loss": 0.7725,
      "step": 2126
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5037188529968262,
      "learning_rate": 0.00011834456207892204,
      "loss": 0.5247,
      "step": 2127
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4788191020488739,
      "learning_rate": 0.0001183060635226179,
      "loss": 0.7487,
      "step": 2128
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6044381260871887,
      "learning_rate": 0.00011826756496631377,
      "loss": 0.5606,
      "step": 2129
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5169891119003296,
      "learning_rate": 0.00011822906641000964,
      "loss": 0.4641,
      "step": 2130
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5143800973892212,
      "learning_rate": 0.0001181905678537055,
      "loss": 0.7336,
      "step": 2131
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5882507562637329,
      "learning_rate": 0.00011815206929740134,
      "loss": 0.5907,
      "step": 2132
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.48321595788002014,
      "learning_rate": 0.00011811357074109722,
      "loss": 0.6815,
      "step": 2133
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4281398057937622,
      "learning_rate": 0.00011807507218479308,
      "loss": 0.9419,
      "step": 2134
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8935244679450989,
      "learning_rate": 0.00011803657362848894,
      "loss": 0.4159,
      "step": 2135
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7395544648170471,
      "learning_rate": 0.00011799807507218479,
      "loss": 0.6938,
      "step": 2136
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.503156304359436,
      "learning_rate": 0.00011795957651588065,
      "loss": 0.6367,
      "step": 2137
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5178952813148499,
      "learning_rate": 0.00011792107795957652,
      "loss": 0.671,
      "step": 2138
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8096943497657776,
      "learning_rate": 0.00011788257940327238,
      "loss": 0.6575,
      "step": 2139
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7959922552108765,
      "learning_rate": 0.00011784408084696826,
      "loss": 0.5522,
      "step": 2140
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6590084433555603,
      "learning_rate": 0.00011780558229066409,
      "loss": 0.6489,
      "step": 2141
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6461594700813293,
      "learning_rate": 0.00011776708373435997,
      "loss": 0.7082,
      "step": 2142
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5847561955451965,
      "learning_rate": 0.00011772858517805583,
      "loss": 0.3918,
      "step": 2143
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6138674020767212,
      "learning_rate": 0.00011769008662175169,
      "loss": 0.5365,
      "step": 2144
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5810883641242981,
      "learning_rate": 0.00011765158806544756,
      "loss": 0.5433,
      "step": 2145
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6885060667991638,
      "learning_rate": 0.0001176130895091434,
      "loss": 0.8072,
      "step": 2146
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9186590313911438,
      "learning_rate": 0.00011757459095283927,
      "loss": 0.361,
      "step": 2147
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7279161810874939,
      "learning_rate": 0.00011753609239653513,
      "loss": 0.7716,
      "step": 2148
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5704081654548645,
      "learning_rate": 0.00011749759384023101,
      "loss": 0.6366,
      "step": 2149
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7019095420837402,
      "learning_rate": 0.00011745909528392687,
      "loss": 0.6288,
      "step": 2150
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5648744106292725,
      "learning_rate": 0.00011742059672762272,
      "loss": 0.6839,
      "step": 2151
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6193690299987793,
      "learning_rate": 0.00011738209817131858,
      "loss": 0.631,
      "step": 2152
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7051696181297302,
      "learning_rate": 0.00011734359961501444,
      "loss": 0.3447,
      "step": 2153
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.685695230960846,
      "learning_rate": 0.00011730510105871031,
      "loss": 0.5174,
      "step": 2154
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.874340832233429,
      "learning_rate": 0.00011726660250240617,
      "loss": 0.8013,
      "step": 2155
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2439762353897095,
      "learning_rate": 0.00011722810394610202,
      "loss": 0.8595,
      "step": 2156
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5617508292198181,
      "learning_rate": 0.00011718960538979788,
      "loss": 0.6931,
      "step": 2157
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5746146440505981,
      "learning_rate": 0.00011715110683349376,
      "loss": 0.4266,
      "step": 2158
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.567089855670929,
      "learning_rate": 0.00011711260827718962,
      "loss": 0.65,
      "step": 2159
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.500031590461731,
      "learning_rate": 0.00011707410972088548,
      "loss": 0.9683,
      "step": 2160
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4987984597682953,
      "learning_rate": 0.00011703561116458133,
      "loss": 0.742,
      "step": 2161
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5571105480194092,
      "learning_rate": 0.00011699711260827719,
      "loss": 0.9414,
      "step": 2162
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7136871218681335,
      "learning_rate": 0.00011695861405197306,
      "loss": 0.4841,
      "step": 2163
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5834577679634094,
      "learning_rate": 0.00011692011549566892,
      "loss": 0.7721,
      "step": 2164
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6263503432273865,
      "learning_rate": 0.00011688161693936477,
      "loss": 0.5729,
      "step": 2165
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5595878958702087,
      "learning_rate": 0.00011684311838306063,
      "loss": 0.6353,
      "step": 2166
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.49345487356185913,
      "learning_rate": 0.0001168046198267565,
      "loss": 0.6376,
      "step": 2167
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6539431214332581,
      "learning_rate": 0.00011676612127045237,
      "loss": 0.6264,
      "step": 2168
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4807756543159485,
      "learning_rate": 0.00011672762271414823,
      "loss": 0.7867,
      "step": 2169
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5664452910423279,
      "learning_rate": 0.00011668912415784407,
      "loss": 0.659,
      "step": 2170
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6780901551246643,
      "learning_rate": 0.00011665062560153995,
      "loss": 0.5829,
      "step": 2171
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7028161883354187,
      "learning_rate": 0.00011661212704523581,
      "loss": 0.6295,
      "step": 2172
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.46813783049583435,
      "learning_rate": 0.00011657362848893167,
      "loss": 0.6995,
      "step": 2173
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5163916349411011,
      "learning_rate": 0.00011653512993262755,
      "loss": 0.7202,
      "step": 2174
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7041745781898499,
      "learning_rate": 0.00011649663137632338,
      "loss": 0.6265,
      "step": 2175
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5713904500007629,
      "learning_rate": 0.00011645813282001925,
      "loss": 0.4395,
      "step": 2176
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6869379878044128,
      "learning_rate": 0.00011641963426371511,
      "loss": 0.5179,
      "step": 2177
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.608554482460022,
      "learning_rate": 0.00011638113570741098,
      "loss": 0.5769,
      "step": 2178
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6135281324386597,
      "learning_rate": 0.00011634263715110685,
      "loss": 0.5064,
      "step": 2179
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6391855478286743,
      "learning_rate": 0.0001163041385948027,
      "loss": 0.6775,
      "step": 2180
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5271572470664978,
      "learning_rate": 0.00011626564003849856,
      "loss": 0.8262,
      "step": 2181
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5059033036231995,
      "learning_rate": 0.00011622714148219442,
      "loss": 1.0141,
      "step": 2182
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5379052758216858,
      "learning_rate": 0.0001161886429258903,
      "loss": 0.8651,
      "step": 2183
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6424898505210876,
      "learning_rate": 0.00011615014436958616,
      "loss": 0.7297,
      "step": 2184
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6696630716323853,
      "learning_rate": 0.000116111645813282,
      "loss": 0.5548,
      "step": 2185
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6529718637466431,
      "learning_rate": 0.00011607314725697786,
      "loss": 0.6359,
      "step": 2186
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.725741982460022,
      "learning_rate": 0.00011603464870067374,
      "loss": 0.6182,
      "step": 2187
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7130367755889893,
      "learning_rate": 0.0001159961501443696,
      "loss": 0.6146,
      "step": 2188
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6904881596565247,
      "learning_rate": 0.00011595765158806546,
      "loss": 0.5565,
      "step": 2189
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6787330508232117,
      "learning_rate": 0.00011591915303176131,
      "loss": 0.2694,
      "step": 2190
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.590800404548645,
      "learning_rate": 0.00011588065447545717,
      "loss": 0.5456,
      "step": 2191
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.47185274958610535,
      "learning_rate": 0.00011584215591915304,
      "loss": 0.8895,
      "step": 2192
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7503556609153748,
      "learning_rate": 0.0001158036573628489,
      "loss": 0.8839,
      "step": 2193
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7427160143852234,
      "learning_rate": 0.00011576515880654476,
      "loss": 0.493,
      "step": 2194
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6228470802307129,
      "learning_rate": 0.00011572666025024061,
      "loss": 0.5607,
      "step": 2195
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5991917252540588,
      "learning_rate": 0.00011568816169393649,
      "loss": 0.6578,
      "step": 2196
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7216944694519043,
      "learning_rate": 0.00011564966313763235,
      "loss": 0.9188,
      "step": 2197
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.549109935760498,
      "learning_rate": 0.00011561116458132821,
      "loss": 0.6808,
      "step": 2198
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6940373778343201,
      "learning_rate": 0.00011557266602502406,
      "loss": 0.8251,
      "step": 2199
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6455672979354858,
      "learning_rate": 0.00011553416746871992,
      "loss": 0.6896,
      "step": 2200
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.457929402589798,
      "learning_rate": 0.00011549566891241579,
      "loss": 0.8922,
      "step": 2201
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6737395524978638,
      "learning_rate": 0.00011545717035611165,
      "loss": 0.3747,
      "step": 2202
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4292609691619873,
      "learning_rate": 0.00011541867179980753,
      "loss": 0.8245,
      "step": 2203
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6442922353744507,
      "learning_rate": 0.00011538017324350336,
      "loss": 0.6127,
      "step": 2204
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6429661512374878,
      "learning_rate": 0.00011534167468719924,
      "loss": 0.7688,
      "step": 2205
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7060120105743408,
      "learning_rate": 0.0001153031761308951,
      "loss": 0.9094,
      "step": 2206
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.743262767791748,
      "learning_rate": 0.00011526467757459096,
      "loss": 0.4111,
      "step": 2207
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8528344631195068,
      "learning_rate": 0.00011522617901828683,
      "loss": 0.6089,
      "step": 2208
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5591058731079102,
      "learning_rate": 0.00011518768046198267,
      "loss": 0.8611,
      "step": 2209
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7019994854927063,
      "learning_rate": 0.00011514918190567854,
      "loss": 0.4863,
      "step": 2210
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6200264692306519,
      "learning_rate": 0.0001151106833493744,
      "loss": 0.6192,
      "step": 2211
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.49797117710113525,
      "learning_rate": 0.00011507218479307028,
      "loss": 0.618,
      "step": 2212
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6254084706306458,
      "learning_rate": 0.00011503368623676614,
      "loss": 0.6072,
      "step": 2213
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.47666633129119873,
      "learning_rate": 0.00011499518768046198,
      "loss": 0.7221,
      "step": 2214
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5696667432785034,
      "learning_rate": 0.00011495668912415785,
      "loss": 1.0887,
      "step": 2215
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5984979867935181,
      "learning_rate": 0.0001149181905678537,
      "loss": 0.4331,
      "step": 2216
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.54532390832901,
      "learning_rate": 0.00011487969201154958,
      "loss": 0.6182,
      "step": 2217
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5971860885620117,
      "learning_rate": 0.00011484119345524544,
      "loss": 0.833,
      "step": 2218
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7710620164871216,
      "learning_rate": 0.00011480269489894129,
      "loss": 0.802,
      "step": 2219
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5828353762626648,
      "learning_rate": 0.00011476419634263715,
      "loss": 0.6738,
      "step": 2220
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5254765748977661,
      "learning_rate": 0.00011472569778633302,
      "loss": 0.8186,
      "step": 2221
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6174797415733337,
      "learning_rate": 0.00011468719923002889,
      "loss": 0.4859,
      "step": 2222
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5803366303443909,
      "learning_rate": 0.00011464870067372475,
      "loss": 0.57,
      "step": 2223
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.697977602481842,
      "learning_rate": 0.0001146102021174206,
      "loss": 0.4718,
      "step": 2224
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6823914051055908,
      "learning_rate": 0.00011457170356111646,
      "loss": 0.5995,
      "step": 2225
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6860018372535706,
      "learning_rate": 0.00011453320500481233,
      "loss": 0.521,
      "step": 2226
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6211827993392944,
      "learning_rate": 0.00011449470644850819,
      "loss": 0.6497,
      "step": 2227
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4325617551803589,
      "learning_rate": 0.00011445620789220404,
      "loss": 0.5368,
      "step": 2228
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.553538978099823,
      "learning_rate": 0.0001144177093358999,
      "loss": 0.5019,
      "step": 2229
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6231394410133362,
      "learning_rate": 0.00011437921077959577,
      "loss": 0.6276,
      "step": 2230
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.4787352979183197,
      "learning_rate": 0.00011434071222329163,
      "loss": 0.9011,
      "step": 2231
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6487831473350525,
      "learning_rate": 0.0001143022136669875,
      "loss": 0.8446,
      "step": 2232
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5703710913658142,
      "learning_rate": 0.00011426371511068334,
      "loss": 0.4362,
      "step": 2233
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.550408661365509,
      "learning_rate": 0.00011422521655437922,
      "loss": 0.5796,
      "step": 2234
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5896866917610168,
      "learning_rate": 0.00011418671799807508,
      "loss": 0.6205,
      "step": 2235
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8009530901908875,
      "learning_rate": 0.00011414821944177094,
      "loss": 0.4958,
      "step": 2236
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7270587682723999,
      "learning_rate": 0.00011410972088546681,
      "loss": 0.8423,
      "step": 2237
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5253137946128845,
      "learning_rate": 0.00011407122232916265,
      "loss": 0.7722,
      "step": 2238
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6021718978881836,
      "learning_rate": 0.00011403272377285852,
      "loss": 0.5754,
      "step": 2239
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.56671142578125,
      "learning_rate": 0.00011399422521655438,
      "loss": 0.7937,
      "step": 2240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5696572661399841,
      "learning_rate": 0.00011395572666025024,
      "loss": 0.6641,
      "step": 2241
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7219383120536804,
      "learning_rate": 0.00011391722810394612,
      "loss": 0.5678,
      "step": 2242
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8470805883407593,
      "learning_rate": 0.00011387872954764197,
      "loss": 0.3908,
      "step": 2243
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7121038436889648,
      "learning_rate": 0.00011384023099133783,
      "loss": 0.6903,
      "step": 2244
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7167257070541382,
      "learning_rate": 0.00011380173243503369,
      "loss": 0.8634,
      "step": 2245
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7132776975631714,
      "learning_rate": 0.00011376323387872956,
      "loss": 0.5844,
      "step": 2246
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6315654516220093,
      "learning_rate": 0.00011372473532242542,
      "loss": 0.3233,
      "step": 2247
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7520809173583984,
      "learning_rate": 0.00011368623676612127,
      "loss": 0.698,
      "step": 2248
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6073668003082275,
      "learning_rate": 0.00011364773820981713,
      "loss": 0.7751,
      "step": 2249
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6003475189208984,
      "learning_rate": 0.00011360923965351299,
      "loss": 0.5857,
      "step": 2250
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5550281405448914,
      "learning_rate": 0.00011357074109720887,
      "loss": 0.8528,
      "step": 2251
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6152428984642029,
      "learning_rate": 0.00011353224254090473,
      "loss": 0.5969,
      "step": 2252
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7365421056747437,
      "learning_rate": 0.00011349374398460058,
      "loss": 0.4776,
      "step": 2253
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6694262027740479,
      "learning_rate": 0.00011345524542829644,
      "loss": 0.6017,
      "step": 2254
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.693168580532074,
      "learning_rate": 0.00011341674687199231,
      "loss": 0.906,
      "step": 2255
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8672708868980408,
      "learning_rate": 0.00011337824831568817,
      "loss": 0.5497,
      "step": 2256
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.500724732875824,
      "learning_rate": 0.00011333974975938403,
      "loss": 0.6126,
      "step": 2257
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8613755106925964,
      "learning_rate": 0.00011330125120307988,
      "loss": 0.6407,
      "step": 2258
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.61661696434021,
      "learning_rate": 0.00011326275264677576,
      "loss": 0.6315,
      "step": 2259
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.766522228717804,
      "learning_rate": 0.00011322425409047162,
      "loss": 0.6871,
      "step": 2260
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5077000260353088,
      "learning_rate": 0.00011318575553416748,
      "loss": 0.6039,
      "step": 2261
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8590794205665588,
      "learning_rate": 0.00011314725697786332,
      "loss": 0.7787,
      "step": 2262
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.46298447251319885,
      "learning_rate": 0.00011310875842155919,
      "loss": 0.8708,
      "step": 2263
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7291937470436096,
      "learning_rate": 0.00011307025986525506,
      "loss": 0.5844,
      "step": 2264
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6488327383995056,
      "learning_rate": 0.00011303176130895092,
      "loss": 0.4542,
      "step": 2265
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6544030904769897,
      "learning_rate": 0.00011299326275264678,
      "loss": 0.5591,
      "step": 2266
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5832823514938354,
      "learning_rate": 0.00011295476419634263,
      "loss": 0.5209,
      "step": 2267
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6154413223266602,
      "learning_rate": 0.0001129162656400385,
      "loss": 0.555,
      "step": 2268
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4996202290058136,
      "learning_rate": 0.00011287776708373437,
      "loss": 0.8863,
      "step": 2269
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6415365934371948,
      "learning_rate": 0.00011283926852743023,
      "loss": 0.408,
      "step": 2270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5983700156211853,
      "learning_rate": 0.0001128007699711261,
      "loss": 0.528,
      "step": 2271
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8560895323753357,
      "learning_rate": 0.00011276227141482193,
      "loss": 0.5973,
      "step": 2272
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5147740840911865,
      "learning_rate": 0.00011272377285851781,
      "loss": 0.7432,
      "step": 2273
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.522030234336853,
      "learning_rate": 0.00011268527430221367,
      "loss": 0.7703,
      "step": 2274
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.514183759689331,
      "learning_rate": 0.00011264677574590954,
      "loss": 0.65,
      "step": 2275
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5255123376846313,
      "learning_rate": 0.0001126082771896054,
      "loss": 0.7474,
      "step": 2276
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6004142165184021,
      "learning_rate": 0.00011256977863330125,
      "loss": 0.4697,
      "step": 2277
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7292727828025818,
      "learning_rate": 0.00011253128007699711,
      "loss": 0.5602,
      "step": 2278
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6168885827064514,
      "learning_rate": 0.00011249278152069298,
      "loss": 0.6887,
      "step": 2279
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8337063789367676,
      "learning_rate": 0.00011245428296438885,
      "loss": 0.7438,
      "step": 2280
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9055806398391724,
      "learning_rate": 0.00011241578440808471,
      "loss": 0.7246,
      "step": 2281
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6013938784599304,
      "learning_rate": 0.00011237728585178056,
      "loss": 0.7013,
      "step": 2282
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5657368898391724,
      "learning_rate": 0.00011233878729547642,
      "loss": 0.7965,
      "step": 2283
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5872820019721985,
      "learning_rate": 0.0001123002887391723,
      "loss": 0.7738,
      "step": 2284
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5592882633209229,
      "learning_rate": 0.00011226179018286815,
      "loss": 0.6159,
      "step": 2285
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8404965996742249,
      "learning_rate": 0.00011222329162656402,
      "loss": 0.4629,
      "step": 2286
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.798347532749176,
      "learning_rate": 0.00011218479307025986,
      "loss": 0.7345,
      "step": 2287
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8209975957870483,
      "learning_rate": 0.00011214629451395572,
      "loss": 0.4734,
      "step": 2288
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6437084674835205,
      "learning_rate": 0.0001121077959576516,
      "loss": 0.7609,
      "step": 2289
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6067918539047241,
      "learning_rate": 0.00011206929740134746,
      "loss": 0.6657,
      "step": 2290
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5097646713256836,
      "learning_rate": 0.00011203079884504331,
      "loss": 0.6521,
      "step": 2291
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.481742799282074,
      "learning_rate": 0.00011199230028873917,
      "loss": 0.5296,
      "step": 2292
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7449878454208374,
      "learning_rate": 0.00011195380173243504,
      "loss": 0.5891,
      "step": 2293
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.725564181804657,
      "learning_rate": 0.0001119153031761309,
      "loss": 0.7566,
      "step": 2294
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6843059062957764,
      "learning_rate": 0.00011187680461982676,
      "loss": 0.5604,
      "step": 2295
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.77281254529953,
      "learning_rate": 0.00011183830606352261,
      "loss": 0.7217,
      "step": 2296
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6840528845787048,
      "learning_rate": 0.00011179980750721847,
      "loss": 0.6598,
      "step": 2297
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9290376305580139,
      "learning_rate": 0.00011176130895091435,
      "loss": 0.7598,
      "step": 2298
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5786566138267517,
      "learning_rate": 0.00011172281039461021,
      "loss": 0.5761,
      "step": 2299
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6518670320510864,
      "learning_rate": 0.00011168431183830608,
      "loss": 0.9558,
      "step": 2300
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6999177932739258,
      "learning_rate": 0.00011164581328200192,
      "loss": 0.5343,
      "step": 2301
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5437526106834412,
      "learning_rate": 0.00011160731472569779,
      "loss": 0.6758,
      "step": 2302
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4764953553676605,
      "learning_rate": 0.00011156881616939365,
      "loss": 0.6474,
      "step": 2303
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6072338223457336,
      "learning_rate": 0.00011153031761308951,
      "loss": 0.8931,
      "step": 2304
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6557515859603882,
      "learning_rate": 0.00011149181905678539,
      "loss": 0.3682,
      "step": 2305
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.516698956489563,
      "learning_rate": 0.00011145332050048124,
      "loss": 0.7231,
      "step": 2306
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4957563877105713,
      "learning_rate": 0.0001114148219441771,
      "loss": 0.5861,
      "step": 2307
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5460013151168823,
      "learning_rate": 0.00011137632338787296,
      "loss": 0.6982,
      "step": 2308
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5530625581741333,
      "learning_rate": 0.00011133782483156883,
      "loss": 0.6973,
      "step": 2309
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6084403395652771,
      "learning_rate": 0.00011129932627526469,
      "loss": 0.4507,
      "step": 2310
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4668910503387451,
      "learning_rate": 0.00011126082771896054,
      "loss": 0.8792,
      "step": 2311
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5357942581176758,
      "learning_rate": 0.0001112223291626564,
      "loss": 0.819,
      "step": 2312
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1227331161499023,
      "learning_rate": 0.00011118383060635226,
      "loss": 0.9551,
      "step": 2313
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.49297213554382324,
      "learning_rate": 0.00011114533205004814,
      "loss": 0.4669,
      "step": 2314
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8434656858444214,
      "learning_rate": 0.000111106833493744,
      "loss": 0.3265,
      "step": 2315
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.42332103848457336,
      "learning_rate": 0.00011106833493743984,
      "loss": 0.8231,
      "step": 2316
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9293109774589539,
      "learning_rate": 0.0001110298363811357,
      "loss": 0.8373,
      "step": 2317
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7838725447654724,
      "learning_rate": 0.00011099133782483158,
      "loss": 0.3492,
      "step": 2318
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.48446160554885864,
      "learning_rate": 0.00011095283926852744,
      "loss": 0.5783,
      "step": 2319
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5698411464691162,
      "learning_rate": 0.0001109143407122233,
      "loss": 0.5798,
      "step": 2320
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5171804428100586,
      "learning_rate": 0.00011087584215591915,
      "loss": 0.9317,
      "step": 2321
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6768290996551514,
      "learning_rate": 0.00011083734359961502,
      "loss": 0.6893,
      "step": 2322
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5097497701644897,
      "learning_rate": 0.00011079884504331089,
      "loss": 0.7586,
      "step": 2323
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6024848222732544,
      "learning_rate": 0.00011076034648700675,
      "loss": 0.5784,
      "step": 2324
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7117746472358704,
      "learning_rate": 0.0001107218479307026,
      "loss": 0.5814,
      "step": 2325
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5747885704040527,
      "learning_rate": 0.00011068334937439845,
      "loss": 0.7614,
      "step": 2326
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4392665922641754,
      "learning_rate": 0.00011064485081809433,
      "loss": 0.9398,
      "step": 2327
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6421635746955872,
      "learning_rate": 0.00011060635226179019,
      "loss": 0.4334,
      "step": 2328
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.641895055770874,
      "learning_rate": 0.00011056785370548605,
      "loss": 0.4295,
      "step": 2329
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5524030923843384,
      "learning_rate": 0.0001105293551491819,
      "loss": 0.5978,
      "step": 2330
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.726733386516571,
      "learning_rate": 0.00011049085659287777,
      "loss": 0.6556,
      "step": 2331
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6507512331008911,
      "learning_rate": 0.00011045235803657363,
      "loss": 0.5492,
      "step": 2332
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6734389066696167,
      "learning_rate": 0.0001104138594802695,
      "loss": 0.5563,
      "step": 2333
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4970758259296417,
      "learning_rate": 0.00011037536092396537,
      "loss": 0.7172,
      "step": 2334
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6021848917007446,
      "learning_rate": 0.0001103368623676612,
      "loss": 0.5739,
      "step": 2335
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5863089561462402,
      "learning_rate": 0.00011029836381135708,
      "loss": 0.6859,
      "step": 2336
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.787419319152832,
      "learning_rate": 0.00011025986525505294,
      "loss": 0.6643,
      "step": 2337
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6764302253723145,
      "learning_rate": 0.00011022136669874881,
      "loss": 0.7367,
      "step": 2338
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.530424177646637,
      "learning_rate": 0.00011018286814244467,
      "loss": 0.7659,
      "step": 2339
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6874826550483704,
      "learning_rate": 0.00011014436958614052,
      "loss": 0.594,
      "step": 2340
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.690697968006134,
      "learning_rate": 0.00011010587102983638,
      "loss": 0.7103,
      "step": 2341
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4918457269668579,
      "learning_rate": 0.00011006737247353224,
      "loss": 0.556,
      "step": 2342
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6396670937538147,
      "learning_rate": 0.00011002887391722812,
      "loss": 0.7443,
      "step": 2343
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7539977431297302,
      "learning_rate": 0.00010999037536092398,
      "loss": 0.7364,
      "step": 2344
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5150942206382751,
      "learning_rate": 0.00010995187680461983,
      "loss": 0.3423,
      "step": 2345
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5619184374809265,
      "learning_rate": 0.00010991337824831569,
      "loss": 0.9036,
      "step": 2346
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7347338199615479,
      "learning_rate": 0.00010987487969201156,
      "loss": 0.6531,
      "step": 2347
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6072944402694702,
      "learning_rate": 0.00010983638113570742,
      "loss": 0.6555,
      "step": 2348
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5773069858551025,
      "learning_rate": 0.00010979788257940328,
      "loss": 0.5721,
      "step": 2349
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5057227611541748,
      "learning_rate": 0.00010975938402309913,
      "loss": 0.7456,
      "step": 2350
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6793683767318726,
      "learning_rate": 0.00010972088546679499,
      "loss": 0.6733,
      "step": 2351
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5668054223060608,
      "learning_rate": 0.00010968238691049087,
      "loss": 0.5454,
      "step": 2352
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6874618530273438,
      "learning_rate": 0.00010964388835418673,
      "loss": 0.5465,
      "step": 2353
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6030134558677673,
      "learning_rate": 0.00010960538979788258,
      "loss": 0.506,
      "step": 2354
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7398611307144165,
      "learning_rate": 0.00010956689124157844,
      "loss": 0.5526,
      "step": 2355
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5788939595222473,
      "learning_rate": 0.00010952839268527431,
      "loss": 0.5426,
      "step": 2356
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5918261408805847,
      "learning_rate": 0.00010948989412897017,
      "loss": 0.6181,
      "step": 2357
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.568352997303009,
      "learning_rate": 0.00010945139557266603,
      "loss": 0.5232,
      "step": 2358
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6879154443740845,
      "learning_rate": 0.00010941289701636188,
      "loss": 0.6567,
      "step": 2359
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.47124022245407104,
      "learning_rate": 0.00010937439846005774,
      "loss": 0.8111,
      "step": 2360
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4961872696876526,
      "learning_rate": 0.00010933589990375362,
      "loss": 0.5006,
      "step": 2361
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6245496273040771,
      "learning_rate": 0.00010929740134744948,
      "loss": 0.5781,
      "step": 2362
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.672524631023407,
      "learning_rate": 0.00010925890279114535,
      "loss": 0.4719,
      "step": 2363
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6564081311225891,
      "learning_rate": 0.00010922040423484119,
      "loss": 0.8197,
      "step": 2364
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6002586483955383,
      "learning_rate": 0.00010918190567853706,
      "loss": 0.5214,
      "step": 2365
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5577394366264343,
      "learning_rate": 0.00010914340712223292,
      "loss": 0.8211,
      "step": 2366
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7031199336051941,
      "learning_rate": 0.00010910490856592878,
      "loss": 0.6537,
      "step": 2367
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7468215823173523,
      "learning_rate": 0.00010906641000962466,
      "loss": 0.5067,
      "step": 2368
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7384344935417175,
      "learning_rate": 0.0001090279114533205,
      "loss": 0.9173,
      "step": 2369
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5209723114967346,
      "learning_rate": 0.00010898941289701636,
      "loss": 0.742,
      "step": 2370
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7025666832923889,
      "learning_rate": 0.00010895091434071223,
      "loss": 0.6259,
      "step": 2371
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7046822905540466,
      "learning_rate": 0.0001089124157844081,
      "loss": 0.8306,
      "step": 2372
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6462429165840149,
      "learning_rate": 0.00010887391722810396,
      "loss": 0.6928,
      "step": 2373
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6312127709388733,
      "learning_rate": 0.00010883541867179981,
      "loss": 0.8823,
      "step": 2374
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.624917209148407,
      "learning_rate": 0.00010879692011549567,
      "loss": 0.7822,
      "step": 2375
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6737197637557983,
      "learning_rate": 0.00010875842155919153,
      "loss": 0.4273,
      "step": 2376
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.47186005115509033,
      "learning_rate": 0.0001087199230028874,
      "loss": 0.5918,
      "step": 2377
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7862766981124878,
      "learning_rate": 0.00010868142444658327,
      "loss": 0.5078,
      "step": 2378
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5870555639266968,
      "learning_rate": 0.00010864292589027911,
      "loss": 0.8902,
      "step": 2379
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7715224623680115,
      "learning_rate": 0.00010860442733397497,
      "loss": 0.8025,
      "step": 2380
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7582191228866577,
      "learning_rate": 0.00010856592877767085,
      "loss": 0.7567,
      "step": 2381
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6300626397132874,
      "learning_rate": 0.00010852743022136671,
      "loss": 0.501,
      "step": 2382
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7240617275238037,
      "learning_rate": 0.00010848893166506257,
      "loss": 0.6924,
      "step": 2383
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6462764143943787,
      "learning_rate": 0.00010845043310875842,
      "loss": 0.5735,
      "step": 2384
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5641697645187378,
      "learning_rate": 0.00010841193455245429,
      "loss": 0.7455,
      "step": 2385
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5762466192245483,
      "learning_rate": 0.00010837343599615015,
      "loss": 0.5666,
      "step": 2386
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7075461149215698,
      "learning_rate": 0.00010833493743984601,
      "loss": 0.8231,
      "step": 2387
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6770679950714111,
      "learning_rate": 0.00010829643888354186,
      "loss": 0.7102,
      "step": 2388
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0299475193023682,
      "learning_rate": 0.00010825794032723772,
      "loss": 0.7134,
      "step": 2389
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5599343180656433,
      "learning_rate": 0.0001082194417709336,
      "loss": 0.5312,
      "step": 2390
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5162670016288757,
      "learning_rate": 0.00010818094321462946,
      "loss": 0.5396,
      "step": 2391
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6758010387420654,
      "learning_rate": 0.00010814244465832532,
      "loss": 0.788,
      "step": 2392
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5408101677894592,
      "learning_rate": 0.00010810394610202117,
      "loss": 0.5841,
      "step": 2393
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6112580299377441,
      "learning_rate": 0.00010806544754571704,
      "loss": 0.4431,
      "step": 2394
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5565080046653748,
      "learning_rate": 0.0001080269489894129,
      "loss": 0.6868,
      "step": 2395
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5458228588104248,
      "learning_rate": 0.00010798845043310876,
      "loss": 0.6788,
      "step": 2396
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5980467200279236,
      "learning_rate": 0.00010794995187680464,
      "loss": 0.7285,
      "step": 2397
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5648931860923767,
      "learning_rate": 0.00010791145332050047,
      "loss": 0.8361,
      "step": 2398
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4743996262550354,
      "learning_rate": 0.00010787295476419635,
      "loss": 0.8938,
      "step": 2399
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6204242706298828,
      "learning_rate": 0.00010783445620789221,
      "loss": 0.4627,
      "step": 2400
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6413835287094116,
      "learning_rate": 0.00010779595765158807,
      "loss": 0.5293,
      "step": 2401
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8459625244140625,
      "learning_rate": 0.00010775745909528394,
      "loss": 0.4218,
      "step": 2402
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.645572304725647,
      "learning_rate": 0.00010771896053897979,
      "loss": 0.755,
      "step": 2403
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5045018196105957,
      "learning_rate": 0.00010768046198267565,
      "loss": 0.7937,
      "step": 2404
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.755817174911499,
      "learning_rate": 0.00010764196342637151,
      "loss": 0.5926,
      "step": 2405
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0004132986068726,
      "learning_rate": 0.00010760346487006739,
      "loss": 0.6572,
      "step": 2406
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6611197590827942,
      "learning_rate": 0.00010756496631376325,
      "loss": 0.7403,
      "step": 2407
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7182559967041016,
      "learning_rate": 0.0001075264677574591,
      "loss": 0.6192,
      "step": 2408
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7053318023681641,
      "learning_rate": 0.00010748796920115496,
      "loss": 0.4102,
      "step": 2409
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.47056084871292114,
      "learning_rate": 0.00010744947064485083,
      "loss": 0.878,
      "step": 2410
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8284932971000671,
      "learning_rate": 0.00010741097208854669,
      "loss": 0.3834,
      "step": 2411
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.56617271900177,
      "learning_rate": 0.00010737247353224255,
      "loss": 0.5205,
      "step": 2412
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.617781400680542,
      "learning_rate": 0.0001073339749759384,
      "loss": 0.521,
      "step": 2413
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6325260400772095,
      "learning_rate": 0.00010729547641963426,
      "loss": 0.5822,
      "step": 2414
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7801918983459473,
      "learning_rate": 0.00010725697786333014,
      "loss": 0.7517,
      "step": 2415
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7842265367507935,
      "learning_rate": 0.000107218479307026,
      "loss": 0.5116,
      "step": 2416
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5408447980880737,
      "learning_rate": 0.00010717998075072184,
      "loss": 0.6418,
      "step": 2417
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5727214813232422,
      "learning_rate": 0.0001071414821944177,
      "loss": 0.4455,
      "step": 2418
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5405592918395996,
      "learning_rate": 0.00010710298363811358,
      "loss": 0.6052,
      "step": 2419
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6457967758178711,
      "learning_rate": 0.00010706448508180944,
      "loss": 0.6029,
      "step": 2420
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4712563455104828,
      "learning_rate": 0.0001070259865255053,
      "loss": 0.8043,
      "step": 2421
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6867820620536804,
      "learning_rate": 0.00010698748796920115,
      "loss": 0.7154,
      "step": 2422
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5338007211685181,
      "learning_rate": 0.00010694898941289701,
      "loss": 0.7203,
      "step": 2423
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7303542494773865,
      "learning_rate": 0.00010691049085659288,
      "loss": 0.5527,
      "step": 2424
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5714064240455627,
      "learning_rate": 0.00010687199230028875,
      "loss": 0.7069,
      "step": 2425
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6119165420532227,
      "learning_rate": 0.00010683349374398462,
      "loss": 0.5979,
      "step": 2426
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5260111689567566,
      "learning_rate": 0.00010679499518768045,
      "loss": 0.4894,
      "step": 2427
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5942628979682922,
      "learning_rate": 0.00010675649663137633,
      "loss": 0.843,
      "step": 2428
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7258169651031494,
      "learning_rate": 0.00010671799807507219,
      "loss": 0.7663,
      "step": 2429
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5162966847419739,
      "learning_rate": 0.00010667949951876805,
      "loss": 0.802,
      "step": 2430
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5990315079689026,
      "learning_rate": 0.00010664100096246393,
      "loss": 0.5962,
      "step": 2431
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7176437377929688,
      "learning_rate": 0.00010660250240615976,
      "loss": 0.7522,
      "step": 2432
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7338178157806396,
      "learning_rate": 0.00010656400384985563,
      "loss": 0.7543,
      "step": 2433
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6391322016716003,
      "learning_rate": 0.0001065255052935515,
      "loss": 0.8067,
      "step": 2434
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6898947358131409,
      "learning_rate": 0.00010648700673724737,
      "loss": 0.64,
      "step": 2435
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5733233690261841,
      "learning_rate": 0.00010644850818094323,
      "loss": 0.5567,
      "step": 2436
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5939765572547913,
      "learning_rate": 0.00010641000962463908,
      "loss": 0.8713,
      "step": 2437
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6881442070007324,
      "learning_rate": 0.00010637151106833494,
      "loss": 0.5705,
      "step": 2438
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.508953869342804,
      "learning_rate": 0.0001063330125120308,
      "loss": 0.7177,
      "step": 2439
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6277223229408264,
      "learning_rate": 0.00010629451395572667,
      "loss": 0.5425,
      "step": 2440
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6475901007652283,
      "learning_rate": 0.00010625601539942253,
      "loss": 0.768,
      "step": 2441
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6488864421844482,
      "learning_rate": 0.00010621751684311838,
      "loss": 0.5591,
      "step": 2442
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.566101610660553,
      "learning_rate": 0.00010617901828681424,
      "loss": 0.4883,
      "step": 2443
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5399830937385559,
      "learning_rate": 0.00010614051973051012,
      "loss": 0.6798,
      "step": 2444
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8815752267837524,
      "learning_rate": 0.00010610202117420598,
      "loss": 0.6283,
      "step": 2445
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.574546217918396,
      "learning_rate": 0.00010606352261790184,
      "loss": 0.8487,
      "step": 2446
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5380874872207642,
      "learning_rate": 0.00010602502406159769,
      "loss": 0.8745,
      "step": 2447
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3217315673828125,
      "learning_rate": 0.00010598652550529355,
      "loss": 0.6706,
      "step": 2448
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5516969561576843,
      "learning_rate": 0.00010594802694898942,
      "loss": 0.8928,
      "step": 2449
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.46530207991600037,
      "learning_rate": 0.00010590952839268528,
      "loss": 0.7072,
      "step": 2450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.699347198009491,
      "learning_rate": 0.00010587102983638113,
      "loss": 0.5847,
      "step": 2451
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5455751419067383,
      "learning_rate": 0.00010583253128007699,
      "loss": 0.795,
      "step": 2452
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7034059762954712,
      "learning_rate": 0.00010579403272377287,
      "loss": 0.7429,
      "step": 2453
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8666707277297974,
      "learning_rate": 0.00010575553416746873,
      "loss": 0.9183,
      "step": 2454
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6532931327819824,
      "learning_rate": 0.00010571703561116459,
      "loss": 0.5494,
      "step": 2455
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6578937768936157,
      "learning_rate": 0.00010567853705486044,
      "loss": 0.638,
      "step": 2456
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.683727502822876,
      "learning_rate": 0.00010564003849855631,
      "loss": 0.6347,
      "step": 2457
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5599848628044128,
      "learning_rate": 0.00010560153994225217,
      "loss": 0.8029,
      "step": 2458
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5339811444282532,
      "learning_rate": 0.00010556304138594803,
      "loss": 0.7163,
      "step": 2459
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4861373007297516,
      "learning_rate": 0.00010552454282964391,
      "loss": 0.7937,
      "step": 2460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6430076360702515,
      "learning_rate": 0.00010548604427333974,
      "loss": 0.7049,
      "step": 2461
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5646589994430542,
      "learning_rate": 0.00010544754571703562,
      "loss": 0.4124,
      "step": 2462
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6990521550178528,
      "learning_rate": 0.00010540904716073148,
      "loss": 0.8338,
      "step": 2463
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5350193977355957,
      "learning_rate": 0.00010537054860442734,
      "loss": 0.6907,
      "step": 2464
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.576985776424408,
      "learning_rate": 0.00010533205004812321,
      "loss": 0.5987,
      "step": 2465
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5680385828018188,
      "learning_rate": 0.00010529355149181906,
      "loss": 0.7033,
      "step": 2466
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5476782917976379,
      "learning_rate": 0.00010525505293551492,
      "loss": 0.5488,
      "step": 2467
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6280765533447266,
      "learning_rate": 0.00010521655437921078,
      "loss": 0.6575,
      "step": 2468
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5606502890586853,
      "learning_rate": 0.00010517805582290666,
      "loss": 0.9506,
      "step": 2469
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5378345251083374,
      "learning_rate": 0.00010513955726660252,
      "loss": 0.4982,
      "step": 2470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5529789924621582,
      "learning_rate": 0.00010510105871029836,
      "loss": 0.4977,
      "step": 2471
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7480403184890747,
      "learning_rate": 0.00010506256015399423,
      "loss": 0.4475,
      "step": 2472
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6958354115486145,
      "learning_rate": 0.0001050240615976901,
      "loss": 0.3662,
      "step": 2473
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6022982597351074,
      "learning_rate": 0.00010498556304138596,
      "loss": 0.5895,
      "step": 2474
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6145215630531311,
      "learning_rate": 0.00010494706448508182,
      "loss": 0.8884,
      "step": 2475
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6113581657409668,
      "learning_rate": 0.00010490856592877767,
      "loss": 0.7632,
      "step": 2476
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5560540556907654,
      "learning_rate": 0.00010487006737247353,
      "loss": 0.7123,
      "step": 2477
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6848464608192444,
      "learning_rate": 0.0001048315688161694,
      "loss": 0.757,
      "step": 2478
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.521160900592804,
      "learning_rate": 0.00010479307025986527,
      "loss": 0.8531,
      "step": 2479
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6900349855422974,
      "learning_rate": 0.00010475457170356111,
      "loss": 0.6986,
      "step": 2480
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5871597528457642,
      "learning_rate": 0.00010471607314725697,
      "loss": 0.619,
      "step": 2481
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6829545497894287,
      "learning_rate": 0.00010467757459095285,
      "loss": 0.5885,
      "step": 2482
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5387759804725647,
      "learning_rate": 0.00010463907603464871,
      "loss": 0.5658,
      "step": 2483
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7444060444831848,
      "learning_rate": 0.00010460057747834457,
      "loss": 0.4319,
      "step": 2484
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.47473451495170593,
      "learning_rate": 0.00010456207892204042,
      "loss": 0.8294,
      "step": 2485
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6979472041130066,
      "learning_rate": 0.00010452358036573628,
      "loss": 0.6219,
      "step": 2486
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7242518067359924,
      "learning_rate": 0.00010448508180943215,
      "loss": 0.6032,
      "step": 2487
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6406856179237366,
      "learning_rate": 0.00010444658325312801,
      "loss": 0.6124,
      "step": 2488
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9175052046775818,
      "learning_rate": 0.00010440808469682389,
      "loss": 0.5714,
      "step": 2489
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5666040778160095,
      "learning_rate": 0.00010436958614051972,
      "loss": 0.4682,
      "step": 2490
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5076509714126587,
      "learning_rate": 0.0001043310875842156,
      "loss": 0.7166,
      "step": 2491
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7509636878967285,
      "learning_rate": 0.00010429258902791146,
      "loss": 0.6351,
      "step": 2492
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.521479606628418,
      "learning_rate": 0.00010425409047160732,
      "loss": 0.4993,
      "step": 2493
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.556110680103302,
      "learning_rate": 0.0001042155919153032,
      "loss": 0.7166,
      "step": 2494
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.508301854133606,
      "learning_rate": 0.00010417709335899903,
      "loss": 0.7371,
      "step": 2495
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6576254367828369,
      "learning_rate": 0.0001041385948026949,
      "loss": 0.5295,
      "step": 2496
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5219686031341553,
      "learning_rate": 0.00010410009624639076,
      "loss": 0.6615,
      "step": 2497
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5574052333831787,
      "learning_rate": 0.00010406159769008664,
      "loss": 0.8417,
      "step": 2498
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.47084876894950867,
      "learning_rate": 0.0001040230991337825,
      "loss": 0.771,
      "step": 2499
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6321773529052734,
      "learning_rate": 0.00010398460057747835,
      "loss": 0.6355,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6041848063468933,
      "learning_rate": 0.00010394610202117421,
      "loss": 0.5581,
      "step": 2501
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5564635992050171,
      "learning_rate": 0.00010390760346487007,
      "loss": 0.6923,
      "step": 2502
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5474562644958496,
      "learning_rate": 0.00010386910490856594,
      "loss": 0.7736,
      "step": 2503
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.45812225341796875,
      "learning_rate": 0.0001038306063522618,
      "loss": 0.843,
      "step": 2504
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6183377504348755,
      "learning_rate": 0.00010379210779595765,
      "loss": 0.6368,
      "step": 2505
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.46333712339401245,
      "learning_rate": 0.00010375360923965351,
      "loss": 0.6652,
      "step": 2506
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6475435495376587,
      "learning_rate": 0.00010371511068334939,
      "loss": 0.4939,
      "step": 2507
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6615743637084961,
      "learning_rate": 0.00010367661212704525,
      "loss": 0.619,
      "step": 2508
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5690407156944275,
      "learning_rate": 0.00010363811357074111,
      "loss": 0.839,
      "step": 2509
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5103554725646973,
      "learning_rate": 0.00010359961501443696,
      "loss": 0.6094,
      "step": 2510
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6871307492256165,
      "learning_rate": 0.00010356111645813282,
      "loss": 0.5991,
      "step": 2511
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6852967143058777,
      "learning_rate": 0.00010352261790182869,
      "loss": 1.0628,
      "step": 2512
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6728684306144714,
      "learning_rate": 0.00010348411934552455,
      "loss": 0.6766,
      "step": 2513
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4848467707633972,
      "learning_rate": 0.0001034456207892204,
      "loss": 0.5561,
      "step": 2514
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5512651205062866,
      "learning_rate": 0.00010340712223291626,
      "loss": 0.8076,
      "step": 2515
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6860362887382507,
      "learning_rate": 0.00010336862367661214,
      "loss": 0.8022,
      "step": 2516
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.493202805519104,
      "learning_rate": 0.000103330125120308,
      "loss": 0.557,
      "step": 2517
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9645848274230957,
      "learning_rate": 0.00010329162656400386,
      "loss": 0.7463,
      "step": 2518
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7432993650436401,
      "learning_rate": 0.0001032531280076997,
      "loss": 0.6608,
      "step": 2519
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6860565543174744,
      "learning_rate": 0.00010321462945139558,
      "loss": 0.6469,
      "step": 2520
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5568646192550659,
      "learning_rate": 0.00010317613089509144,
      "loss": 0.5838,
      "step": 2521
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7922033071517944,
      "learning_rate": 0.0001031376323387873,
      "loss": 0.7668,
      "step": 2522
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4828765392303467,
      "learning_rate": 0.00010309913378248318,
      "loss": 0.5596,
      "step": 2523
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7044193744659424,
      "learning_rate": 0.00010306063522617901,
      "loss": 0.6854,
      "step": 2524
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8513301610946655,
      "learning_rate": 0.00010302213666987488,
      "loss": 0.6375,
      "step": 2525
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5729102492332458,
      "learning_rate": 0.00010298363811357075,
      "loss": 0.627,
      "step": 2526
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7211494445800781,
      "learning_rate": 0.0001029451395572666,
      "loss": 0.3433,
      "step": 2527
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0624240636825562,
      "learning_rate": 0.00010290664100096248,
      "loss": 0.77,
      "step": 2528
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5437763929367065,
      "learning_rate": 0.00010286814244465833,
      "loss": 0.7136,
      "step": 2529
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8031578063964844,
      "learning_rate": 0.00010282964388835419,
      "loss": 0.5512,
      "step": 2530
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4996916353702545,
      "learning_rate": 0.00010279114533205005,
      "loss": 0.6205,
      "step": 2531
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6540822982788086,
      "learning_rate": 0.00010275264677574592,
      "loss": 0.7614,
      "step": 2532
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5712385177612305,
      "learning_rate": 0.00010271414821944179,
      "loss": 0.6834,
      "step": 2533
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5345030426979065,
      "learning_rate": 0.00010267564966313763,
      "loss": 0.5226,
      "step": 2534
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.47745510935783386,
      "learning_rate": 0.0001026371511068335,
      "loss": 0.7768,
      "step": 2535
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6670182347297668,
      "learning_rate": 0.00010259865255052935,
      "loss": 0.4202,
      "step": 2536
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5374890565872192,
      "learning_rate": 0.00010256015399422523,
      "loss": 0.7338,
      "step": 2537
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.49601858854293823,
      "learning_rate": 0.00010252165543792109,
      "loss": 0.7531,
      "step": 2538
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4918942451477051,
      "learning_rate": 0.00010248315688161694,
      "loss": 0.7574,
      "step": 2539
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6152672171592712,
      "learning_rate": 0.0001024446583253128,
      "loss": 0.6135,
      "step": 2540
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6863948702812195,
      "learning_rate": 0.00010240615976900867,
      "loss": 0.6563,
      "step": 2541
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.49117258191108704,
      "learning_rate": 0.00010236766121270453,
      "loss": 0.8074,
      "step": 2542
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5759852528572083,
      "learning_rate": 0.00010232916265640038,
      "loss": 0.5565,
      "step": 2543
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6346320509910583,
      "learning_rate": 0.00010229066410009624,
      "loss": 0.4743,
      "step": 2544
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.621955931186676,
      "learning_rate": 0.00010225216554379212,
      "loss": 0.5286,
      "step": 2545
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4432592988014221,
      "learning_rate": 0.00010221366698748798,
      "loss": 0.7481,
      "step": 2546
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.47051963210105896,
      "learning_rate": 0.00010217516843118384,
      "loss": 0.7535,
      "step": 2547
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6547646522521973,
      "learning_rate": 0.00010213666987487969,
      "loss": 0.8199,
      "step": 2548
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5860131978988647,
      "learning_rate": 0.00010209817131857555,
      "loss": 0.5895,
      "step": 2549
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7295166850090027,
      "learning_rate": 0.00010205967276227142,
      "loss": 0.5528,
      "step": 2550
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7320915460586548,
      "learning_rate": 0.00010202117420596728,
      "loss": 0.8173,
      "step": 2551
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5806019306182861,
      "learning_rate": 0.00010198267564966314,
      "loss": 0.5712,
      "step": 2552
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8375212550163269,
      "learning_rate": 0.00010194417709335899,
      "loss": 0.7521,
      "step": 2553
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7074230909347534,
      "learning_rate": 0.00010190567853705487,
      "loss": 0.7522,
      "step": 2554
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5736735463142395,
      "learning_rate": 0.00010186717998075073,
      "loss": 0.7104,
      "step": 2555
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6431143283843994,
      "learning_rate": 0.00010182868142444659,
      "loss": 0.4504,
      "step": 2556
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6240407228469849,
      "learning_rate": 0.00010179018286814246,
      "loss": 0.8398,
      "step": 2557
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6043626666069031,
      "learning_rate": 0.0001017516843118383,
      "loss": 0.7321,
      "step": 2558
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5457960367202759,
      "learning_rate": 0.00010171318575553417,
      "loss": 0.7472,
      "step": 2559
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6961458325386047,
      "learning_rate": 0.00010167468719923003,
      "loss": 0.6067,
      "step": 2560
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9097843766212463,
      "learning_rate": 0.0001016361886429259,
      "loss": 0.8134,
      "step": 2561
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6261298656463623,
      "learning_rate": 0.00010159769008662177,
      "loss": 0.4854,
      "step": 2562
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.49359840154647827,
      "learning_rate": 0.00010155919153031761,
      "loss": 1.0095,
      "step": 2563
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5776187181472778,
      "learning_rate": 0.00010152069297401348,
      "loss": 0.6691,
      "step": 2564
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5989841818809509,
      "learning_rate": 0.00010148219441770934,
      "loss": 0.5963,
      "step": 2565
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7487188577651978,
      "learning_rate": 0.00010144369586140521,
      "loss": 0.4332,
      "step": 2566
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6390175819396973,
      "learning_rate": 0.00010140519730510107,
      "loss": 0.6453,
      "step": 2567
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6751930117607117,
      "learning_rate": 0.00010136669874879692,
      "loss": 0.826,
      "step": 2568
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5195732116699219,
      "learning_rate": 0.00010132820019249278,
      "loss": 0.6251,
      "step": 2569
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7997875809669495,
      "learning_rate": 0.00010128970163618866,
      "loss": 0.3902,
      "step": 2570
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8052754998207092,
      "learning_rate": 0.00010125120307988452,
      "loss": 0.8308,
      "step": 2571
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7402248382568359,
      "learning_rate": 0.00010121270452358038,
      "loss": 0.5627,
      "step": 2572
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5771600008010864,
      "learning_rate": 0.00010117420596727622,
      "loss": 0.6043,
      "step": 2573
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7999167442321777,
      "learning_rate": 0.00010113570741097209,
      "loss": 0.6394,
      "step": 2574
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.654683530330658,
      "learning_rate": 0.00010109720885466796,
      "loss": 0.6575,
      "step": 2575
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5870057940483093,
      "learning_rate": 0.00010105871029836382,
      "loss": 0.7093,
      "step": 2576
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8088281154632568,
      "learning_rate": 0.00010102021174205967,
      "loss": 0.6823,
      "step": 2577
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5403174757957458,
      "learning_rate": 0.00010098171318575553,
      "loss": 0.7624,
      "step": 2578
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7076311707496643,
      "learning_rate": 0.0001009432146294514,
      "loss": 0.5162,
      "step": 2579
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.553042471408844,
      "learning_rate": 0.00010090471607314727,
      "loss": 0.8323,
      "step": 2580
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6021670699119568,
      "learning_rate": 0.00010086621751684313,
      "loss": 0.8226,
      "step": 2581
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4759165644645691,
      "learning_rate": 0.00010082771896053897,
      "loss": 0.8014,
      "step": 2582
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6213688254356384,
      "learning_rate": 0.00010078922040423483,
      "loss": 0.6929,
      "step": 2583
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.620686948299408,
      "learning_rate": 0.00010075072184793071,
      "loss": 0.6046,
      "step": 2584
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6553773283958435,
      "learning_rate": 0.00010071222329162657,
      "loss": 0.9789,
      "step": 2585
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7080220580101013,
      "learning_rate": 0.00010067372473532244,
      "loss": 0.5762,
      "step": 2586
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5719016194343567,
      "learning_rate": 0.00010063522617901828,
      "loss": 0.497,
      "step": 2587
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6240701079368591,
      "learning_rate": 0.00010059672762271415,
      "loss": 0.5971,
      "step": 2588
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6417034864425659,
      "learning_rate": 0.00010055822906641001,
      "loss": 0.6125,
      "step": 2589
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3864092230796814,
      "learning_rate": 0.00010051973051010587,
      "loss": 0.8757,
      "step": 2590
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6683790683746338,
      "learning_rate": 0.00010048123195380175,
      "loss": 0.6222,
      "step": 2591
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5993905663490295,
      "learning_rate": 0.0001004427333974976,
      "loss": 0.4285,
      "step": 2592
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5817583799362183,
      "learning_rate": 0.00010040423484119346,
      "loss": 0.4347,
      "step": 2593
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7257253527641296,
      "learning_rate": 0.00010036573628488932,
      "loss": 0.6849,
      "step": 2594
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.656542956829071,
      "learning_rate": 0.0001003272377285852,
      "loss": 0.6517,
      "step": 2595
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5667185187339783,
      "learning_rate": 0.00010028873917228105,
      "loss": 0.5602,
      "step": 2596
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6822704672813416,
      "learning_rate": 0.0001002502406159769,
      "loss": 0.4386,
      "step": 2597
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5801700353622437,
      "learning_rate": 0.00010021174205967276,
      "loss": 0.8588,
      "step": 2598
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5276011228561401,
      "learning_rate": 0.00010017324350336862,
      "loss": 0.7256,
      "step": 2599
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6367591023445129,
      "learning_rate": 0.0001001347449470645,
      "loss": 0.3772,
      "step": 2600
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6010964512825012,
      "learning_rate": 0.00010009624639076036,
      "loss": 0.5527,
      "step": 2601
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6148302555084229,
      "learning_rate": 0.0001000577478344562,
      "loss": 0.3793,
      "step": 2602
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5929328203201294,
      "learning_rate": 0.00010001924927815207,
      "loss": 0.5713,
      "step": 2603
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6889114379882812,
      "learning_rate": 9.998075072184794e-05,
      "loss": 0.7835,
      "step": 2604
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6179149746894836,
      "learning_rate": 9.994225216554379e-05,
      "loss": 0.6926,
      "step": 2605
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.49109408259391785,
      "learning_rate": 9.990375360923966e-05,
      "loss": 0.7652,
      "step": 2606
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5674355626106262,
      "learning_rate": 9.986525505293552e-05,
      "loss": 0.6999,
      "step": 2607
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.519757091999054,
      "learning_rate": 9.982675649663139e-05,
      "loss": 0.5823,
      "step": 2608
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5960505604743958,
      "learning_rate": 9.978825794032725e-05,
      "loss": 0.5346,
      "step": 2609
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6081132292747498,
      "learning_rate": 9.97497593840231e-05,
      "loss": 0.6838,
      "step": 2610
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6315455436706543,
      "learning_rate": 9.971126082771897e-05,
      "loss": 0.7747,
      "step": 2611
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6558219194412231,
      "learning_rate": 9.967276227141482e-05,
      "loss": 0.5299,
      "step": 2612
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6370853781700134,
      "learning_rate": 9.963426371511069e-05,
      "loss": 0.5898,
      "step": 2613
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5652143359184265,
      "learning_rate": 9.959576515880655e-05,
      "loss": 0.6125,
      "step": 2614
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5243841409683228,
      "learning_rate": 9.955726660250241e-05,
      "loss": 0.532,
      "step": 2615
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6444534063339233,
      "learning_rate": 9.951876804619827e-05,
      "loss": 0.4584,
      "step": 2616
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6261962652206421,
      "learning_rate": 9.948026948989413e-05,
      "loss": 0.6145,
      "step": 2617
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7233673334121704,
      "learning_rate": 9.944177093359e-05,
      "loss": 0.8166,
      "step": 2618
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5000271201133728,
      "learning_rate": 9.940327237728586e-05,
      "loss": 0.8119,
      "step": 2619
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5322843194007874,
      "learning_rate": 9.936477382098172e-05,
      "loss": 0.6858,
      "step": 2620
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5797109007835388,
      "learning_rate": 9.932627526467758e-05,
      "loss": 0.5631,
      "step": 2621
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7062681317329407,
      "learning_rate": 9.928777670837344e-05,
      "loss": 0.6326,
      "step": 2622
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.48245173692703247,
      "learning_rate": 9.92492781520693e-05,
      "loss": 0.8157,
      "step": 2623
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5673313736915588,
      "learning_rate": 9.921077959576518e-05,
      "loss": 0.4788,
      "step": 2624
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.46581947803497314,
      "learning_rate": 9.917228103946102e-05,
      "loss": 0.4734,
      "step": 2625
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6671740412712097,
      "learning_rate": 9.913378248315688e-05,
      "loss": 0.5459,
      "step": 2626
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.752738893032074,
      "learning_rate": 9.909528392685274e-05,
      "loss": 0.5157,
      "step": 2627
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6750048398971558,
      "learning_rate": 9.90567853705486e-05,
      "loss": 0.6146,
      "step": 2628
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5005720853805542,
      "learning_rate": 9.901828681424447e-05,
      "loss": 0.9228,
      "step": 2629
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5259250998497009,
      "learning_rate": 9.897978825794033e-05,
      "loss": 0.9545,
      "step": 2630
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.608088493347168,
      "learning_rate": 9.89412897016362e-05,
      "loss": 0.449,
      "step": 2631
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5051705837249756,
      "learning_rate": 9.890279114533205e-05,
      "loss": 0.9396,
      "step": 2632
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5896523594856262,
      "learning_rate": 9.886429258902792e-05,
      "loss": 0.7646,
      "step": 2633
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5674850940704346,
      "learning_rate": 9.882579403272377e-05,
      "loss": 0.7891,
      "step": 2634
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5561779737472534,
      "learning_rate": 9.878729547641963e-05,
      "loss": 0.5998,
      "step": 2635
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6635401844978333,
      "learning_rate": 9.874879692011551e-05,
      "loss": 0.6865,
      "step": 2636
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6808783411979675,
      "learning_rate": 9.871029836381135e-05,
      "loss": 0.5037,
      "step": 2637
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4825012683868408,
      "learning_rate": 9.867179980750723e-05,
      "loss": 0.7618,
      "step": 2638
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5769425630569458,
      "learning_rate": 9.863330125120308e-05,
      "loss": 0.8025,
      "step": 2639
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5625503063201904,
      "learning_rate": 9.859480269489895e-05,
      "loss": 0.7333,
      "step": 2640
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6145923137664795,
      "learning_rate": 9.855630413859481e-05,
      "loss": 0.3471,
      "step": 2641
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7239027619361877,
      "learning_rate": 9.851780558229067e-05,
      "loss": 0.6425,
      "step": 2642
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4895348846912384,
      "learning_rate": 9.847930702598653e-05,
      "loss": 0.58,
      "step": 2643
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5728447437286377,
      "learning_rate": 9.84408084696824e-05,
      "loss": 0.3842,
      "step": 2644
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6177746653556824,
      "learning_rate": 9.840230991337826e-05,
      "loss": 0.6249,
      "step": 2645
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5636466145515442,
      "learning_rate": 9.83638113570741e-05,
      "loss": 0.6374,
      "step": 2646
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6527650356292725,
      "learning_rate": 9.832531280076998e-05,
      "loss": 0.5544,
      "step": 2647
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5085991621017456,
      "learning_rate": 9.828681424446584e-05,
      "loss": 0.5561,
      "step": 2648
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8704091906547546,
      "learning_rate": 9.82483156881617e-05,
      "loss": 0.4216,
      "step": 2649
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5611402988433838,
      "learning_rate": 9.820981713185756e-05,
      "loss": 0.3922,
      "step": 2650
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6456888318061829,
      "learning_rate": 9.817131857555342e-05,
      "loss": 0.9334,
      "step": 2651
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6705992221832275,
      "learning_rate": 9.813282001924928e-05,
      "loss": 0.5015,
      "step": 2652
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5254772901535034,
      "learning_rate": 9.809432146294514e-05,
      "loss": 0.9007,
      "step": 2653
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6755345463752747,
      "learning_rate": 9.8055822906641e-05,
      "loss": 0.4707,
      "step": 2654
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5490778684616089,
      "learning_rate": 9.801732435033687e-05,
      "loss": 0.5386,
      "step": 2655
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6358391642570496,
      "learning_rate": 9.797882579403273e-05,
      "loss": 0.7294,
      "step": 2656
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5438187718391418,
      "learning_rate": 9.794032723772859e-05,
      "loss": 0.6512,
      "step": 2657
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5474260449409485,
      "learning_rate": 9.790182868142446e-05,
      "loss": 0.7045,
      "step": 2658
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.671258807182312,
      "learning_rate": 9.786333012512031e-05,
      "loss": 0.5818,
      "step": 2659
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.44755297899246216,
      "learning_rate": 9.782483156881618e-05,
      "loss": 0.8366,
      "step": 2660
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5369211435317993,
      "learning_rate": 9.778633301251203e-05,
      "loss": 0.6874,
      "step": 2661
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5922843217849731,
      "learning_rate": 9.774783445620789e-05,
      "loss": 0.887,
      "step": 2662
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6526399254798889,
      "learning_rate": 9.770933589990375e-05,
      "loss": 0.6583,
      "step": 2663
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5286775231361389,
      "learning_rate": 9.767083734359961e-05,
      "loss": 0.6982,
      "step": 2664
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.613075852394104,
      "learning_rate": 9.763233878729549e-05,
      "loss": 0.5061,
      "step": 2665
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5064207911491394,
      "learning_rate": 9.759384023099134e-05,
      "loss": 0.8187,
      "step": 2666
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7072269320487976,
      "learning_rate": 9.755534167468721e-05,
      "loss": 0.8599,
      "step": 2667
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6143394112586975,
      "learning_rate": 9.751684311838306e-05,
      "loss": 0.5333,
      "step": 2668
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5485984086990356,
      "learning_rate": 9.747834456207893e-05,
      "loss": 0.6168,
      "step": 2669
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6098638772964478,
      "learning_rate": 9.74398460057748e-05,
      "loss": 0.4417,
      "step": 2670
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8466745018959045,
      "learning_rate": 9.740134744947065e-05,
      "loss": 0.5989,
      "step": 2671
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.586601734161377,
      "learning_rate": 9.736284889316652e-05,
      "loss": 0.5836,
      "step": 2672
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.47113892436027527,
      "learning_rate": 9.732435033686236e-05,
      "loss": 0.7199,
      "step": 2673
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5458950400352478,
      "learning_rate": 9.728585178055824e-05,
      "loss": 0.5089,
      "step": 2674
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5320448875427246,
      "learning_rate": 9.724735322425409e-05,
      "loss": 0.7311,
      "step": 2675
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5940539836883545,
      "learning_rate": 9.720885466794996e-05,
      "loss": 0.8321,
      "step": 2676
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4522356688976288,
      "learning_rate": 9.717035611164582e-05,
      "loss": 0.6502,
      "step": 2677
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5801218152046204,
      "learning_rate": 9.713185755534168e-05,
      "loss": 0.7303,
      "step": 2678
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5195162892341614,
      "learning_rate": 9.709335899903754e-05,
      "loss": 0.6674,
      "step": 2679
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5036740899085999,
      "learning_rate": 9.70548604427334e-05,
      "loss": 0.9036,
      "step": 2680
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6478328108787537,
      "learning_rate": 9.701636188642926e-05,
      "loss": 0.6612,
      "step": 2681
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6744868755340576,
      "learning_rate": 9.697786333012513e-05,
      "loss": 0.6348,
      "step": 2682
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6545068025588989,
      "learning_rate": 9.693936477382099e-05,
      "loss": 0.5661,
      "step": 2683
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8944377303123474,
      "learning_rate": 9.690086621751685e-05,
      "loss": 0.5644,
      "step": 2684
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6213851571083069,
      "learning_rate": 9.686236766121271e-05,
      "loss": 0.5083,
      "step": 2685
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5510855317115784,
      "learning_rate": 9.682386910490857e-05,
      "loss": 0.8421,
      "step": 2686
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5478624105453491,
      "learning_rate": 9.678537054860443e-05,
      "loss": 0.6149,
      "step": 2687
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5957368016242981,
      "learning_rate": 9.674687199230029e-05,
      "loss": 0.7006,
      "step": 2688
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7995091676712036,
      "learning_rate": 9.670837343599615e-05,
      "loss": 0.895,
      "step": 2689
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5760043263435364,
      "learning_rate": 9.666987487969201e-05,
      "loss": 0.5789,
      "step": 2690
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7454721331596375,
      "learning_rate": 9.663137632338787e-05,
      "loss": 0.6458,
      "step": 2691
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5717118978500366,
      "learning_rate": 9.659287776708374e-05,
      "loss": 0.509,
      "step": 2692
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6054398417472839,
      "learning_rate": 9.65543792107796e-05,
      "loss": 0.4178,
      "step": 2693
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7117345333099365,
      "learning_rate": 9.651588065447547e-05,
      "loss": 0.4533,
      "step": 2694
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6204318404197693,
      "learning_rate": 9.647738209817132e-05,
      "loss": 0.7774,
      "step": 2695
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5372308492660522,
      "learning_rate": 9.643888354186719e-05,
      "loss": 0.7274,
      "step": 2696
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7027552723884583,
      "learning_rate": 9.640038498556304e-05,
      "loss": 0.5562,
      "step": 2697
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5524712204933167,
      "learning_rate": 9.63618864292589e-05,
      "loss": 0.7045,
      "step": 2698
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6568295955657959,
      "learning_rate": 9.632338787295478e-05,
      "loss": 0.3855,
      "step": 2699
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6969993114471436,
      "learning_rate": 9.628488931665062e-05,
      "loss": 0.4394,
      "step": 2700
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7804660797119141,
      "learning_rate": 9.62463907603465e-05,
      "loss": 0.5863,
      "step": 2701
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6103712320327759,
      "learning_rate": 9.620789220404235e-05,
      "loss": 0.3056,
      "step": 2702
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.584962785243988,
      "learning_rate": 9.616939364773822e-05,
      "loss": 0.5273,
      "step": 2703
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0614138841629028,
      "learning_rate": 9.613089509143408e-05,
      "loss": 0.4851,
      "step": 2704
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6809135675430298,
      "learning_rate": 9.609239653512994e-05,
      "loss": 0.4362,
      "step": 2705
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5923634171485901,
      "learning_rate": 9.60538979788258e-05,
      "loss": 0.5958,
      "step": 2706
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.47916507720947266,
      "learning_rate": 9.601539942252166e-05,
      "loss": 0.6421,
      "step": 2707
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6306365132331848,
      "learning_rate": 9.597690086621752e-05,
      "loss": 0.594,
      "step": 2708
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6744241118431091,
      "learning_rate": 9.593840230991337e-05,
      "loss": 0.5518,
      "step": 2709
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6481714248657227,
      "learning_rate": 9.589990375360925e-05,
      "loss": 0.511,
      "step": 2710
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.42751964926719666,
      "learning_rate": 9.586140519730511e-05,
      "loss": 0.8978,
      "step": 2711
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8755199909210205,
      "learning_rate": 9.582290664100097e-05,
      "loss": 0.3177,
      "step": 2712
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5334110260009766,
      "learning_rate": 9.578440808469683e-05,
      "loss": 0.842,
      "step": 2713
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6455775499343872,
      "learning_rate": 9.574590952839269e-05,
      "loss": 0.5128,
      "step": 2714
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.689697265625,
      "learning_rate": 9.570741097208855e-05,
      "loss": 0.5606,
      "step": 2715
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7956871390342712,
      "learning_rate": 9.566891241578441e-05,
      "loss": 0.6081,
      "step": 2716
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5931480526924133,
      "learning_rate": 9.563041385948027e-05,
      "loss": 0.7861,
      "step": 2717
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.551981508731842,
      "learning_rate": 9.559191530317613e-05,
      "loss": 0.5045,
      "step": 2718
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5010456442832947,
      "learning_rate": 9.5553416746872e-05,
      "loss": 0.9116,
      "step": 2719
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8273999094963074,
      "learning_rate": 9.551491819056786e-05,
      "loss": 0.9517,
      "step": 2720
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.47467005252838135,
      "learning_rate": 9.547641963426373e-05,
      "loss": 0.6431,
      "step": 2721
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.717208981513977,
      "learning_rate": 9.543792107795958e-05,
      "loss": 0.4436,
      "step": 2722
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6763932704925537,
      "learning_rate": 9.539942252165545e-05,
      "loss": 0.5314,
      "step": 2723
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5289153456687927,
      "learning_rate": 9.53609239653513e-05,
      "loss": 0.9942,
      "step": 2724
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4916934370994568,
      "learning_rate": 9.532242540904716e-05,
      "loss": 0.7917,
      "step": 2725
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7467163801193237,
      "learning_rate": 9.528392685274302e-05,
      "loss": 0.5661,
      "step": 2726
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6042643189430237,
      "learning_rate": 9.524542829643888e-05,
      "loss": 0.4258,
      "step": 2727
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.40945175290107727,
      "learning_rate": 9.520692974013476e-05,
      "loss": 0.7547,
      "step": 2728
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6705679297447205,
      "learning_rate": 9.51684311838306e-05,
      "loss": 0.4874,
      "step": 2729
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6766210794448853,
      "learning_rate": 9.512993262752648e-05,
      "loss": 0.5,
      "step": 2730
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5228131413459778,
      "learning_rate": 9.509143407122233e-05,
      "loss": 0.6864,
      "step": 2731
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5922039747238159,
      "learning_rate": 9.50529355149182e-05,
      "loss": 0.7537,
      "step": 2732
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5801718831062317,
      "learning_rate": 9.501443695861406e-05,
      "loss": 0.4168,
      "step": 2733
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6579384207725525,
      "learning_rate": 9.497593840230991e-05,
      "loss": 0.7388,
      "step": 2734
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4830470383167267,
      "learning_rate": 9.493743984600578e-05,
      "loss": 0.6702,
      "step": 2735
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5736512541770935,
      "learning_rate": 9.489894128970163e-05,
      "loss": 0.7913,
      "step": 2736
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6271511316299438,
      "learning_rate": 9.48604427333975e-05,
      "loss": 0.4145,
      "step": 2737
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6831672787666321,
      "learning_rate": 9.482194417709335e-05,
      "loss": 0.6177,
      "step": 2738
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8196303844451904,
      "learning_rate": 9.478344562078923e-05,
      "loss": 0.7959,
      "step": 2739
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6182034015655518,
      "learning_rate": 9.474494706448509e-05,
      "loss": 0.6271,
      "step": 2740
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.46808430552482605,
      "learning_rate": 9.470644850818095e-05,
      "loss": 0.6691,
      "step": 2741
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4342450797557831,
      "learning_rate": 9.466794995187681e-05,
      "loss": 0.6424,
      "step": 2742
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7216116189956665,
      "learning_rate": 9.462945139557267e-05,
      "loss": 0.4645,
      "step": 2743
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5111357569694519,
      "learning_rate": 9.459095283926853e-05,
      "loss": 0.4521,
      "step": 2744
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5787410140037537,
      "learning_rate": 9.45524542829644e-05,
      "loss": 0.4919,
      "step": 2745
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5549808144569397,
      "learning_rate": 9.451395572666026e-05,
      "loss": 0.7424,
      "step": 2746
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5363532304763794,
      "learning_rate": 9.447545717035612e-05,
      "loss": 0.7204,
      "step": 2747
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7346624732017517,
      "learning_rate": 9.443695861405198e-05,
      "loss": 0.6889,
      "step": 2748
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6095187664031982,
      "learning_rate": 9.439846005774784e-05,
      "loss": 0.7335,
      "step": 2749
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6723291873931885,
      "learning_rate": 9.43599615014437e-05,
      "loss": 0.7695,
      "step": 2750
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5892725586891174,
      "learning_rate": 9.432146294513956e-05,
      "loss": 0.6463,
      "step": 2751
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.685546338558197,
      "learning_rate": 9.428296438883542e-05,
      "loss": 0.7325,
      "step": 2752
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.47376441955566406,
      "learning_rate": 9.424446583253128e-05,
      "loss": 0.4876,
      "step": 2753
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5826228857040405,
      "learning_rate": 9.420596727622714e-05,
      "loss": 0.6874,
      "step": 2754
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.59764164686203,
      "learning_rate": 9.4167468719923e-05,
      "loss": 0.9669,
      "step": 2755
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.49194440245628357,
      "learning_rate": 9.412897016361886e-05,
      "loss": 0.8271,
      "step": 2756
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6601529121398926,
      "learning_rate": 9.409047160731474e-05,
      "loss": 0.4997,
      "step": 2757
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.43876174092292786,
      "learning_rate": 9.405197305101059e-05,
      "loss": 0.9197,
      "step": 2758
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5091859102249146,
      "learning_rate": 9.401347449470646e-05,
      "loss": 0.9206,
      "step": 2759
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5615870356559753,
      "learning_rate": 9.397497593840231e-05,
      "loss": 0.6467,
      "step": 2760
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5087628364562988,
      "learning_rate": 9.393647738209817e-05,
      "loss": 0.4239,
      "step": 2761
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6553736925125122,
      "learning_rate": 9.389797882579404e-05,
      "loss": 0.5588,
      "step": 2762
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5565497875213623,
      "learning_rate": 9.385948026948989e-05,
      "loss": 0.543,
      "step": 2763
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.602509617805481,
      "learning_rate": 9.382098171318577e-05,
      "loss": 0.539,
      "step": 2764
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6029108762741089,
      "learning_rate": 9.378248315688161e-05,
      "loss": 0.6928,
      "step": 2765
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5621103644371033,
      "learning_rate": 9.374398460057749e-05,
      "loss": 0.4613,
      "step": 2766
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4673151671886444,
      "learning_rate": 9.370548604427335e-05,
      "loss": 0.5961,
      "step": 2767
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6520093679428101,
      "learning_rate": 9.366698748796921e-05,
      "loss": 0.5118,
      "step": 2768
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6209667921066284,
      "learning_rate": 9.362848893166507e-05,
      "loss": 0.4582,
      "step": 2769
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8706281185150146,
      "learning_rate": 9.358999037536092e-05,
      "loss": 0.7008,
      "step": 2770
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6461219191551208,
      "learning_rate": 9.355149181905679e-05,
      "loss": 0.4307,
      "step": 2771
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7742838263511658,
      "learning_rate": 9.351299326275264e-05,
      "loss": 0.4422,
      "step": 2772
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5518825650215149,
      "learning_rate": 9.347449470644852e-05,
      "loss": 0.6155,
      "step": 2773
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6342319846153259,
      "learning_rate": 9.343599615014438e-05,
      "loss": 0.6035,
      "step": 2774
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5874330997467041,
      "learning_rate": 9.339749759384024e-05,
      "loss": 0.4288,
      "step": 2775
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6570035815238953,
      "learning_rate": 9.33589990375361e-05,
      "loss": 0.4231,
      "step": 2776
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.47091567516326904,
      "learning_rate": 9.332050048123196e-05,
      "loss": 0.8614,
      "step": 2777
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.49482572078704834,
      "learning_rate": 9.328200192492782e-05,
      "loss": 0.7033,
      "step": 2778
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6623446345329285,
      "learning_rate": 9.324350336862368e-05,
      "loss": 0.9393,
      "step": 2779
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.512995183467865,
      "learning_rate": 9.320500481231954e-05,
      "loss": 0.4771,
      "step": 2780
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6453258395195007,
      "learning_rate": 9.31665062560154e-05,
      "loss": 0.9182,
      "step": 2781
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6221798658370972,
      "learning_rate": 9.312800769971126e-05,
      "loss": 0.7941,
      "step": 2782
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5856285095214844,
      "learning_rate": 9.308950914340712e-05,
      "loss": 0.8068,
      "step": 2783
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8950482606887817,
      "learning_rate": 9.3051010587103e-05,
      "loss": 0.2982,
      "step": 2784
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6401569247245789,
      "learning_rate": 9.301251203079885e-05,
      "loss": 0.5439,
      "step": 2785
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5935566425323486,
      "learning_rate": 9.297401347449471e-05,
      "loss": 0.8041,
      "step": 2786
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.636520266532898,
      "learning_rate": 9.293551491819057e-05,
      "loss": 0.8603,
      "step": 2787
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.44568178057670593,
      "learning_rate": 9.289701636188643e-05,
      "loss": 1.044,
      "step": 2788
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5590224862098694,
      "learning_rate": 9.285851780558229e-05,
      "loss": 0.8089,
      "step": 2789
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6031217575073242,
      "learning_rate": 9.282001924927815e-05,
      "loss": 0.6483,
      "step": 2790
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6149701476097107,
      "learning_rate": 9.278152069297403e-05,
      "loss": 0.589,
      "step": 2791
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.640972375869751,
      "learning_rate": 9.274302213666987e-05,
      "loss": 0.6489,
      "step": 2792
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6233463287353516,
      "learning_rate": 9.270452358036575e-05,
      "loss": 0.6284,
      "step": 2793
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4399469792842865,
      "learning_rate": 9.26660250240616e-05,
      "loss": 0.914,
      "step": 2794
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6972444653511047,
      "learning_rate": 9.262752646775747e-05,
      "loss": 0.3959,
      "step": 2795
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4695816934108734,
      "learning_rate": 9.258902791145333e-05,
      "loss": 0.7717,
      "step": 2796
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.61039799451828,
      "learning_rate": 9.255052935514918e-05,
      "loss": 0.6548,
      "step": 2797
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.49447765946388245,
      "learning_rate": 9.251203079884505e-05,
      "loss": 0.5205,
      "step": 2798
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5861296057701111,
      "learning_rate": 9.24735322425409e-05,
      "loss": 0.5552,
      "step": 2799
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8972660303115845,
      "learning_rate": 9.243503368623678e-05,
      "loss": 0.6914,
      "step": 2800
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6672868728637695,
      "learning_rate": 9.239653512993262e-05,
      "loss": 0.4692,
      "step": 2801
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5642586946487427,
      "learning_rate": 9.23580365736285e-05,
      "loss": 0.6217,
      "step": 2802
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3957251012325287,
      "learning_rate": 9.231953801732436e-05,
      "loss": 0.8174,
      "step": 2803
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7869336605072021,
      "learning_rate": 9.228103946102022e-05,
      "loss": 0.4978,
      "step": 2804
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4911160469055176,
      "learning_rate": 9.224254090471608e-05,
      "loss": 0.6232,
      "step": 2805
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5812824964523315,
      "learning_rate": 9.220404234841194e-05,
      "loss": 0.7105,
      "step": 2806
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6181018352508545,
      "learning_rate": 9.21655437921078e-05,
      "loss": 0.7683,
      "step": 2807
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5538690686225891,
      "learning_rate": 9.212704523580366e-05,
      "loss": 0.7394,
      "step": 2808
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5907868146896362,
      "learning_rate": 9.208854667949952e-05,
      "loss": 0.6366,
      "step": 2809
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9914849996566772,
      "learning_rate": 9.205004812319538e-05,
      "loss": 0.3229,
      "step": 2810
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5845313668251038,
      "learning_rate": 9.201154956689125e-05,
      "loss": 0.512,
      "step": 2811
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6787486672401428,
      "learning_rate": 9.197305101058711e-05,
      "loss": 0.7065,
      "step": 2812
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.506846010684967,
      "learning_rate": 9.193455245428297e-05,
      "loss": 0.5918,
      "step": 2813
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8551016449928284,
      "learning_rate": 9.189605389797883e-05,
      "loss": 0.7092,
      "step": 2814
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8242312669754028,
      "learning_rate": 9.185755534167469e-05,
      "loss": 0.424,
      "step": 2815
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6553502678871155,
      "learning_rate": 9.181905678537055e-05,
      "loss": 0.711,
      "step": 2816
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6531500220298767,
      "learning_rate": 9.178055822906641e-05,
      "loss": 0.8223,
      "step": 2817
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7574584484100342,
      "learning_rate": 9.174205967276227e-05,
      "loss": 0.724,
      "step": 2818
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6738603115081787,
      "learning_rate": 9.170356111645813e-05,
      "loss": 0.5625,
      "step": 2819
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.51288902759552,
      "learning_rate": 9.166506256015401e-05,
      "loss": 0.7997,
      "step": 2820
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8553451895713806,
      "learning_rate": 9.162656400384986e-05,
      "loss": 0.4828,
      "step": 2821
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7318819761276245,
      "learning_rate": 9.158806544754572e-05,
      "loss": 0.5602,
      "step": 2822
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5325825810432434,
      "learning_rate": 9.154956689124158e-05,
      "loss": 0.5779,
      "step": 2823
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5067152976989746,
      "learning_rate": 9.151106833493744e-05,
      "loss": 0.9114,
      "step": 2824
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5672284364700317,
      "learning_rate": 9.147256977863331e-05,
      "loss": 0.8264,
      "step": 2825
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6035405993461609,
      "learning_rate": 9.143407122232916e-05,
      "loss": 0.5936,
      "step": 2826
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5714378952980042,
      "learning_rate": 9.139557266602504e-05,
      "loss": 0.7522,
      "step": 2827
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5318989157676697,
      "learning_rate": 9.135707410972088e-05,
      "loss": 0.7198,
      "step": 2828
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6702309250831604,
      "learning_rate": 9.131857555341676e-05,
      "loss": 0.4992,
      "step": 2829
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.494232714176178,
      "learning_rate": 9.128007699711262e-05,
      "loss": 0.7687,
      "step": 2830
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7094332575798035,
      "learning_rate": 9.124157844080848e-05,
      "loss": 0.5194,
      "step": 2831
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5567296743392944,
      "learning_rate": 9.120307988450434e-05,
      "loss": 0.5903,
      "step": 2832
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7699905633926392,
      "learning_rate": 9.116458132820019e-05,
      "loss": 0.6974,
      "step": 2833
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6439357399940491,
      "learning_rate": 9.112608277189606e-05,
      "loss": 0.4779,
      "step": 2834
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6352108120918274,
      "learning_rate": 9.108758421559191e-05,
      "loss": 0.6292,
      "step": 2835
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5221238136291504,
      "learning_rate": 9.104908565928778e-05,
      "loss": 0.7552,
      "step": 2836
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5646518468856812,
      "learning_rate": 9.101058710298364e-05,
      "loss": 0.8503,
      "step": 2837
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7049456834793091,
      "learning_rate": 9.09720885466795e-05,
      "loss": 0.6456,
      "step": 2838
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5067062973976135,
      "learning_rate": 9.093358999037537e-05,
      "loss": 0.8286,
      "step": 2839
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5585299730300903,
      "learning_rate": 9.089509143407123e-05,
      "loss": 0.7843,
      "step": 2840
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7015340328216553,
      "learning_rate": 9.085659287776709e-05,
      "loss": 0.6442,
      "step": 2841
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7426957488059998,
      "learning_rate": 9.081809432146295e-05,
      "loss": 0.9616,
      "step": 2842
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5431903004646301,
      "learning_rate": 9.077959576515881e-05,
      "loss": 0.458,
      "step": 2843
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.608831524848938,
      "learning_rate": 9.074109720885467e-05,
      "loss": 0.617,
      "step": 2844
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5410026907920837,
      "learning_rate": 9.070259865255053e-05,
      "loss": 0.8569,
      "step": 2845
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5878278017044067,
      "learning_rate": 9.06641000962464e-05,
      "loss": 0.7457,
      "step": 2846
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.777372419834137,
      "learning_rate": 9.062560153994227e-05,
      "loss": 0.6258,
      "step": 2847
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5334228873252869,
      "learning_rate": 9.058710298363812e-05,
      "loss": 0.4407,
      "step": 2848
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5936456918716431,
      "learning_rate": 9.054860442733398e-05,
      "loss": 0.7731,
      "step": 2849
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9793249368667603,
      "learning_rate": 9.051010587102984e-05,
      "loss": 1.0252,
      "step": 2850
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7253830432891846,
      "learning_rate": 9.04716073147257e-05,
      "loss": 0.7539,
      "step": 2851
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8065146207809448,
      "learning_rate": 9.043310875842156e-05,
      "loss": 0.5234,
      "step": 2852
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6189261674880981,
      "learning_rate": 9.039461020211742e-05,
      "loss": 0.6423,
      "step": 2853
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5860618948936462,
      "learning_rate": 9.03561116458133e-05,
      "loss": 0.9278,
      "step": 2854
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.47215256094932556,
      "learning_rate": 9.031761308950914e-05,
      "loss": 0.7669,
      "step": 2855
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5488216876983643,
      "learning_rate": 9.027911453320502e-05,
      "loss": 0.8839,
      "step": 2856
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6094645857810974,
      "learning_rate": 9.024061597690086e-05,
      "loss": 0.421,
      "step": 2857
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7401220202445984,
      "learning_rate": 9.020211742059674e-05,
      "loss": 0.4814,
      "step": 2858
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4684085249900818,
      "learning_rate": 9.01636188642926e-05,
      "loss": 0.9597,
      "step": 2859
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6075493097305298,
      "learning_rate": 9.012512030798845e-05,
      "loss": 0.719,
      "step": 2860
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.48848214745521545,
      "learning_rate": 9.008662175168432e-05,
      "loss": 1.0273,
      "step": 2861
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6113967895507812,
      "learning_rate": 9.004812319538017e-05,
      "loss": 0.6322,
      "step": 2862
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4672994315624237,
      "learning_rate": 9.000962463907604e-05,
      "loss": 0.3734,
      "step": 2863
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5625998973846436,
      "learning_rate": 8.997112608277189e-05,
      "loss": 0.986,
      "step": 2864
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5162373781204224,
      "learning_rate": 8.993262752646777e-05,
      "loss": 0.8867,
      "step": 2865
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5296968817710876,
      "learning_rate": 8.989412897016363e-05,
      "loss": 0.4653,
      "step": 2866
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5351810455322266,
      "learning_rate": 8.985563041385949e-05,
      "loss": 0.4884,
      "step": 2867
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.650574803352356,
      "learning_rate": 8.981713185755535e-05,
      "loss": 0.672,
      "step": 2868
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4778006672859192,
      "learning_rate": 8.97786333012512e-05,
      "loss": 0.7529,
      "step": 2869
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5708793997764587,
      "learning_rate": 8.974013474494707e-05,
      "loss": 0.5999,
      "step": 2870
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5277342200279236,
      "learning_rate": 8.970163618864293e-05,
      "loss": 0.7976,
      "step": 2871
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5461068153381348,
      "learning_rate": 8.966313763233879e-05,
      "loss": 0.5519,
      "step": 2872
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6753972172737122,
      "learning_rate": 8.962463907603465e-05,
      "loss": 0.2754,
      "step": 2873
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5929183959960938,
      "learning_rate": 8.958614051973051e-05,
      "loss": 1.0612,
      "step": 2874
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.717923641204834,
      "learning_rate": 8.954764196342638e-05,
      "loss": 0.3868,
      "step": 2875
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5092942714691162,
      "learning_rate": 8.950914340712224e-05,
      "loss": 0.5136,
      "step": 2876
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5940436720848083,
      "learning_rate": 8.94706448508181e-05,
      "loss": 0.6696,
      "step": 2877
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6396057605743408,
      "learning_rate": 8.943214629451396e-05,
      "loss": 0.6647,
      "step": 2878
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5385118126869202,
      "learning_rate": 8.939364773820982e-05,
      "loss": 0.8742,
      "step": 2879
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5367113351821899,
      "learning_rate": 8.935514918190568e-05,
      "loss": 0.5958,
      "step": 2880
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5856937766075134,
      "learning_rate": 8.931665062560154e-05,
      "loss": 0.6223,
      "step": 2881
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5360838174819946,
      "learning_rate": 8.92781520692974e-05,
      "loss": 0.9641,
      "step": 2882
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.49779653549194336,
      "learning_rate": 8.923965351299328e-05,
      "loss": 0.7636,
      "step": 2883
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6212396025657654,
      "learning_rate": 8.920115495668912e-05,
      "loss": 0.5081,
      "step": 2884
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4749324321746826,
      "learning_rate": 8.916265640038499e-05,
      "loss": 0.6498,
      "step": 2885
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8425650000572205,
      "learning_rate": 8.912415784408085e-05,
      "loss": 0.7327,
      "step": 2886
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7816417217254639,
      "learning_rate": 8.908565928777671e-05,
      "loss": 0.7342,
      "step": 2887
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5183226466178894,
      "learning_rate": 8.904716073147258e-05,
      "loss": 0.6083,
      "step": 2888
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5311650633811951,
      "learning_rate": 8.900866217516843e-05,
      "loss": 0.5115,
      "step": 2889
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6845933794975281,
      "learning_rate": 8.89701636188643e-05,
      "loss": 0.5504,
      "step": 2890
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4283297061920166,
      "learning_rate": 8.893166506256015e-05,
      "loss": 0.2859,
      "step": 2891
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5705369710922241,
      "learning_rate": 8.889316650625603e-05,
      "loss": 0.7437,
      "step": 2892
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8909246921539307,
      "learning_rate": 8.885466794995189e-05,
      "loss": 0.5459,
      "step": 2893
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4669990539550781,
      "learning_rate": 8.881616939364775e-05,
      "loss": 0.8742,
      "step": 2894
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5581843852996826,
      "learning_rate": 8.877767083734361e-05,
      "loss": 0.6261,
      "step": 2895
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.64890056848526,
      "learning_rate": 8.873917228103946e-05,
      "loss": 0.5157,
      "step": 2896
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7049034833908081,
      "learning_rate": 8.870067372473533e-05,
      "loss": 0.7114,
      "step": 2897
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6636794209480286,
      "learning_rate": 8.866217516843118e-05,
      "loss": 0.6828,
      "step": 2898
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6027365326881409,
      "learning_rate": 8.862367661212705e-05,
      "loss": 0.5838,
      "step": 2899
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7302346229553223,
      "learning_rate": 8.858517805582291e-05,
      "loss": 0.5031,
      "step": 2900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6382576823234558,
      "learning_rate": 8.854667949951877e-05,
      "loss": 0.5568,
      "step": 2901
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6496707201004028,
      "learning_rate": 8.850818094321464e-05,
      "loss": 0.6129,
      "step": 2902
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6381235122680664,
      "learning_rate": 8.84696823869105e-05,
      "loss": 0.594,
      "step": 2903
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6550209522247314,
      "learning_rate": 8.843118383060636e-05,
      "loss": 0.4126,
      "step": 2904
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7210118174552917,
      "learning_rate": 8.839268527430222e-05,
      "loss": 0.5425,
      "step": 2905
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5345757007598877,
      "learning_rate": 8.835418671799808e-05,
      "loss": 0.7838,
      "step": 2906
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.45115405321121216,
      "learning_rate": 8.831568816169394e-05,
      "loss": 0.4659,
      "step": 2907
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5999240875244141,
      "learning_rate": 8.82771896053898e-05,
      "loss": 0.7291,
      "step": 2908
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.546909511089325,
      "learning_rate": 8.823869104908566e-05,
      "loss": 0.5442,
      "step": 2909
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5917428135871887,
      "learning_rate": 8.820019249278154e-05,
      "loss": 0.5998,
      "step": 2910
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5991014242172241,
      "learning_rate": 8.816169393647738e-05,
      "loss": 0.4628,
      "step": 2911
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.534766674041748,
      "learning_rate": 8.812319538017325e-05,
      "loss": 0.7878,
      "step": 2912
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7192839980125427,
      "learning_rate": 8.80846968238691e-05,
      "loss": 0.6185,
      "step": 2913
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5022011995315552,
      "learning_rate": 8.804619826756497e-05,
      "loss": 0.7657,
      "step": 2914
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5534327030181885,
      "learning_rate": 8.800769971126083e-05,
      "loss": 0.805,
      "step": 2915
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.643775463104248,
      "learning_rate": 8.796920115495669e-05,
      "loss": 0.5696,
      "step": 2916
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5517790913581848,
      "learning_rate": 8.793070259865256e-05,
      "loss": 0.9423,
      "step": 2917
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.659214437007904,
      "learning_rate": 8.789220404234841e-05,
      "loss": 0.3591,
      "step": 2918
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7573196291923523,
      "learning_rate": 8.785370548604429e-05,
      "loss": 0.5263,
      "step": 2919
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6387990117073059,
      "learning_rate": 8.781520692974013e-05,
      "loss": 0.8753,
      "step": 2920
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6667509078979492,
      "learning_rate": 8.7776708373436e-05,
      "loss": 0.6944,
      "step": 2921
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5561687350273132,
      "learning_rate": 8.773820981713187e-05,
      "loss": 0.7129,
      "step": 2922
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5516160130500793,
      "learning_rate": 8.769971126082772e-05,
      "loss": 0.5788,
      "step": 2923
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5253273248672485,
      "learning_rate": 8.766121270452359e-05,
      "loss": 0.5819,
      "step": 2924
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6055787801742554,
      "learning_rate": 8.762271414821944e-05,
      "loss": 0.6783,
      "step": 2925
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.538567304611206,
      "learning_rate": 8.758421559191531e-05,
      "loss": 0.514,
      "step": 2926
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5788332223892212,
      "learning_rate": 8.754571703561116e-05,
      "loss": 0.6559,
      "step": 2927
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5554453134536743,
      "learning_rate": 8.750721847930703e-05,
      "loss": 0.4365,
      "step": 2928
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6046895980834961,
      "learning_rate": 8.74687199230029e-05,
      "loss": 1.0599,
      "step": 2929
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4972183108329773,
      "learning_rate": 8.743022136669876e-05,
      "loss": 0.8987,
      "step": 2930
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4338659942150116,
      "learning_rate": 8.739172281039462e-05,
      "loss": 0.8139,
      "step": 2931
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4900702238082886,
      "learning_rate": 8.735322425409046e-05,
      "loss": 0.8781,
      "step": 2932
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6908307671546936,
      "learning_rate": 8.731472569778634e-05,
      "loss": 0.5639,
      "step": 2933
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5233795642852783,
      "learning_rate": 8.72762271414822e-05,
      "loss": 0.8048,
      "step": 2934
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7704653143882751,
      "learning_rate": 8.723772858517806e-05,
      "loss": 0.6069,
      "step": 2935
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7124736309051514,
      "learning_rate": 8.719923002887392e-05,
      "loss": 0.8407,
      "step": 2936
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5222436189651489,
      "learning_rate": 8.716073147256978e-05,
      "loss": 0.7593,
      "step": 2937
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6399132013320923,
      "learning_rate": 8.712223291626564e-05,
      "loss": 0.5914,
      "step": 2938
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6350351572036743,
      "learning_rate": 8.70837343599615e-05,
      "loss": 0.6851,
      "step": 2939
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7199227809906006,
      "learning_rate": 8.704523580365737e-05,
      "loss": 0.4707,
      "step": 2940
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5384609699249268,
      "learning_rate": 8.700673724735323e-05,
      "loss": 0.8582,
      "step": 2941
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6200560927391052,
      "learning_rate": 8.696823869104909e-05,
      "loss": 0.7949,
      "step": 2942
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6084560751914978,
      "learning_rate": 8.692974013474495e-05,
      "loss": 0.5387,
      "step": 2943
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5350247025489807,
      "learning_rate": 8.689124157844081e-05,
      "loss": 0.5192,
      "step": 2944
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.576543390750885,
      "learning_rate": 8.685274302213667e-05,
      "loss": 0.6806,
      "step": 2945
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5069077014923096,
      "learning_rate": 8.681424446583255e-05,
      "loss": 0.5893,
      "step": 2946
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5287004709243774,
      "learning_rate": 8.677574590952839e-05,
      "loss": 0.7268,
      "step": 2947
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4840850830078125,
      "learning_rate": 8.673724735322425e-05,
      "loss": 0.8797,
      "step": 2948
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.540693998336792,
      "learning_rate": 8.669874879692012e-05,
      "loss": 0.9279,
      "step": 2949
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.49714136123657227,
      "learning_rate": 8.666025024061598e-05,
      "loss": 0.8135,
      "step": 2950
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6691241264343262,
      "learning_rate": 8.662175168431185e-05,
      "loss": 0.4337,
      "step": 2951
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.39027783274650574,
      "learning_rate": 8.65832531280077e-05,
      "loss": 0.581,
      "step": 2952
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5557922124862671,
      "learning_rate": 8.654475457170357e-05,
      "loss": 0.8531,
      "step": 2953
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5431107878684998,
      "learning_rate": 8.650625601539942e-05,
      "loss": 0.6283,
      "step": 2954
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5580481290817261,
      "learning_rate": 8.64677574590953e-05,
      "loss": 0.752,
      "step": 2955
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6654855608940125,
      "learning_rate": 8.642925890279116e-05,
      "loss": 0.4706,
      "step": 2956
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5359135270118713,
      "learning_rate": 8.639076034648702e-05,
      "loss": 0.7286,
      "step": 2957
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.47778090834617615,
      "learning_rate": 8.635226179018288e-05,
      "loss": 0.6301,
      "step": 2958
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.49959737062454224,
      "learning_rate": 8.631376323387872e-05,
      "loss": 0.674,
      "step": 2959
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6069414615631104,
      "learning_rate": 8.62752646775746e-05,
      "loss": 0.5771,
      "step": 2960
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5897968411445618,
      "learning_rate": 8.623676612127045e-05,
      "loss": 0.6952,
      "step": 2961
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5813722610473633,
      "learning_rate": 8.619826756496632e-05,
      "loss": 0.5198,
      "step": 2962
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6508141160011292,
      "learning_rate": 8.615976900866218e-05,
      "loss": 0.421,
      "step": 2963
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8826882839202881,
      "learning_rate": 8.612127045235804e-05,
      "loss": 0.8578,
      "step": 2964
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5602049827575684,
      "learning_rate": 8.60827718960539e-05,
      "loss": 0.8421,
      "step": 2965
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.694659411907196,
      "learning_rate": 8.604427333974977e-05,
      "loss": 0.6574,
      "step": 2966
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6783688068389893,
      "learning_rate": 8.600577478344563e-05,
      "loss": 0.6422,
      "step": 2967
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5844067931175232,
      "learning_rate": 8.596727622714149e-05,
      "loss": 0.6271,
      "step": 2968
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5993360877037048,
      "learning_rate": 8.592877767083735e-05,
      "loss": 0.5817,
      "step": 2969
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.508762776851654,
      "learning_rate": 8.589027911453321e-05,
      "loss": 0.8519,
      "step": 2970
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5564888715744019,
      "learning_rate": 8.585178055822907e-05,
      "loss": 0.4546,
      "step": 2971
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.029579997062683,
      "learning_rate": 8.581328200192493e-05,
      "loss": 0.3593,
      "step": 2972
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.49917370080947876,
      "learning_rate": 8.577478344562079e-05,
      "loss": 0.5581,
      "step": 2973
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5182873010635376,
      "learning_rate": 8.573628488931665e-05,
      "loss": 0.5509,
      "step": 2974
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5333377718925476,
      "learning_rate": 8.569778633301251e-05,
      "loss": 0.7454,
      "step": 2975
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6067705154418945,
      "learning_rate": 8.565928777670837e-05,
      "loss": 0.7187,
      "step": 2976
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6479368209838867,
      "learning_rate": 8.562078922040424e-05,
      "loss": 0.6922,
      "step": 2977
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5420318841934204,
      "learning_rate": 8.55822906641001e-05,
      "loss": 0.8745,
      "step": 2978
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6082957983016968,
      "learning_rate": 8.554379210779596e-05,
      "loss": 0.767,
      "step": 2979
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6222394108772278,
      "learning_rate": 8.550529355149183e-05,
      "loss": 0.6138,
      "step": 2980
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5735543370246887,
      "learning_rate": 8.546679499518768e-05,
      "loss": 0.8007,
      "step": 2981
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6498647928237915,
      "learning_rate": 8.542829643888355e-05,
      "loss": 0.8904,
      "step": 2982
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6392995119094849,
      "learning_rate": 8.53897978825794e-05,
      "loss": 0.6436,
      "step": 2983
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8718652725219727,
      "learning_rate": 8.535129932627526e-05,
      "loss": 0.7474,
      "step": 2984
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4471295177936554,
      "learning_rate": 8.531280076997114e-05,
      "loss": 0.5434,
      "step": 2985
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6574384570121765,
      "learning_rate": 8.527430221366698e-05,
      "loss": 0.701,
      "step": 2986
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5096270442008972,
      "learning_rate": 8.523580365736286e-05,
      "loss": 0.7724,
      "step": 2987
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5777497291564941,
      "learning_rate": 8.51973051010587e-05,
      "loss": 0.5391,
      "step": 2988
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5087798833847046,
      "learning_rate": 8.515880654475458e-05,
      "loss": 0.6413,
      "step": 2989
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6643353700637817,
      "learning_rate": 8.512030798845043e-05,
      "loss": 0.4537,
      "step": 2990
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7254756689071655,
      "learning_rate": 8.50818094321463e-05,
      "loss": 0.8653,
      "step": 2991
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7760726809501648,
      "learning_rate": 8.504331087584216e-05,
      "loss": 0.571,
      "step": 2992
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7527886033058167,
      "learning_rate": 8.500481231953803e-05,
      "loss": 0.5022,
      "step": 2993
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.662128746509552,
      "learning_rate": 8.496631376323389e-05,
      "loss": 0.4345,
      "step": 2994
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5351866483688354,
      "learning_rate": 8.492781520692973e-05,
      "loss": 0.4811,
      "step": 2995
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6541645526885986,
      "learning_rate": 8.488931665062561e-05,
      "loss": 0.6632,
      "step": 2996
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7386701107025146,
      "learning_rate": 8.485081809432147e-05,
      "loss": 0.8915,
      "step": 2997
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4988487958908081,
      "learning_rate": 8.481231953801733e-05,
      "loss": 0.5798,
      "step": 2998
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6007112860679626,
      "learning_rate": 8.477382098171319e-05,
      "loss": 0.7908,
      "step": 2999
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.619147539138794,
      "learning_rate": 8.473532242540905e-05,
      "loss": 0.6411,
      "step": 3000
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.53346848487854,
      "learning_rate": 8.469682386910491e-05,
      "loss": 0.5326,
      "step": 3001
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6643557548522949,
      "learning_rate": 8.465832531280077e-05,
      "loss": 1.002,
      "step": 3002
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6752854585647583,
      "learning_rate": 8.461982675649663e-05,
      "loss": 0.5255,
      "step": 3003
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.45869380235671997,
      "learning_rate": 8.45813282001925e-05,
      "loss": 0.6802,
      "step": 3004
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6049326062202454,
      "learning_rate": 8.454282964388836e-05,
      "loss": 0.6301,
      "step": 3005
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5987918972969055,
      "learning_rate": 8.450433108758422e-05,
      "loss": 0.5691,
      "step": 3006
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5709619522094727,
      "learning_rate": 8.446583253128008e-05,
      "loss": 0.6601,
      "step": 3007
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6526986956596375,
      "learning_rate": 8.442733397497594e-05,
      "loss": 0.5195,
      "step": 3008
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6139487028121948,
      "learning_rate": 8.438883541867181e-05,
      "loss": 0.8275,
      "step": 3009
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6122934818267822,
      "learning_rate": 8.435033686236766e-05,
      "loss": 0.9658,
      "step": 3010
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6420741677284241,
      "learning_rate": 8.431183830606352e-05,
      "loss": 0.5784,
      "step": 3011
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.51669842004776,
      "learning_rate": 8.427333974975938e-05,
      "loss": 0.9533,
      "step": 3012
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6149280071258545,
      "learning_rate": 8.423484119345524e-05,
      "loss": 0.6829,
      "step": 3013
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5209029316902161,
      "learning_rate": 8.419634263715112e-05,
      "loss": 0.7337,
      "step": 3014
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6215808391571045,
      "learning_rate": 8.415784408084697e-05,
      "loss": 0.6047,
      "step": 3015
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.46595317125320435,
      "learning_rate": 8.411934552454284e-05,
      "loss": 0.9065,
      "step": 3016
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6627228260040283,
      "learning_rate": 8.408084696823869e-05,
      "loss": 0.5276,
      "step": 3017
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5869214534759521,
      "learning_rate": 8.404234841193456e-05,
      "loss": 0.5987,
      "step": 3018
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6587797999382019,
      "learning_rate": 8.400384985563042e-05,
      "loss": 0.5113,
      "step": 3019
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6666989922523499,
      "learning_rate": 8.396535129932627e-05,
      "loss": 0.4716,
      "step": 3020
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6747462153434753,
      "learning_rate": 8.392685274302215e-05,
      "loss": 0.5081,
      "step": 3021
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.44868865609169006,
      "learning_rate": 8.3888354186718e-05,
      "loss": 0.6426,
      "step": 3022
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6451286673545837,
      "learning_rate": 8.384985563041387e-05,
      "loss": 0.5333,
      "step": 3023
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5132895708084106,
      "learning_rate": 8.381135707410972e-05,
      "loss": 0.374,
      "step": 3024
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5640871524810791,
      "learning_rate": 8.377285851780559e-05,
      "loss": 0.6192,
      "step": 3025
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6493111252784729,
      "learning_rate": 8.373435996150145e-05,
      "loss": 0.7511,
      "step": 3026
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5163981318473816,
      "learning_rate": 8.369586140519731e-05,
      "loss": 0.922,
      "step": 3027
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7232876420021057,
      "learning_rate": 8.365736284889317e-05,
      "loss": 0.6131,
      "step": 3028
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4874882102012634,
      "learning_rate": 8.361886429258903e-05,
      "loss": 0.7446,
      "step": 3029
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.662792444229126,
      "learning_rate": 8.35803657362849e-05,
      "loss": 0.6571,
      "step": 3030
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6213631629943848,
      "learning_rate": 8.354186717998076e-05,
      "loss": 0.8621,
      "step": 3031
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6555597186088562,
      "learning_rate": 8.350336862367662e-05,
      "loss": 0.6517,
      "step": 3032
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.730358362197876,
      "learning_rate": 8.346487006737248e-05,
      "loss": 0.9957,
      "step": 3033
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6166965365409851,
      "learning_rate": 8.342637151106834e-05,
      "loss": 0.6342,
      "step": 3034
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7342044115066528,
      "learning_rate": 8.33878729547642e-05,
      "loss": 0.4446,
      "step": 3035
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5543916821479797,
      "learning_rate": 8.334937439846006e-05,
      "loss": 0.7515,
      "step": 3036
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5902413725852966,
      "learning_rate": 8.331087584215592e-05,
      "loss": 0.6362,
      "step": 3037
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5347285270690918,
      "learning_rate": 8.327237728585178e-05,
      "loss": 0.6099,
      "step": 3038
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7276169657707214,
      "learning_rate": 8.323387872954764e-05,
      "loss": 0.7405,
      "step": 3039
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6509950757026672,
      "learning_rate": 8.31953801732435e-05,
      "loss": 0.7198,
      "step": 3040
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.46645501255989075,
      "learning_rate": 8.315688161693937e-05,
      "loss": 0.4961,
      "step": 3041
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5285349488258362,
      "learning_rate": 8.311838306063523e-05,
      "loss": 0.7139,
      "step": 3042
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4609602391719818,
      "learning_rate": 8.30798845043311e-05,
      "loss": 0.6819,
      "step": 3043
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5857248306274414,
      "learning_rate": 8.304138594802695e-05,
      "loss": 0.6455,
      "step": 3044
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4846096336841583,
      "learning_rate": 8.300288739172282e-05,
      "loss": 0.5628,
      "step": 3045
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5879151821136475,
      "learning_rate": 8.296438883541867e-05,
      "loss": 0.6267,
      "step": 3046
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5174413323402405,
      "learning_rate": 8.292589027911453e-05,
      "loss": 0.6602,
      "step": 3047
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6451712250709534,
      "learning_rate": 8.28873917228104e-05,
      "loss": 0.3835,
      "step": 3048
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6931876540184021,
      "learning_rate": 8.284889316650625e-05,
      "loss": 0.8298,
      "step": 3049
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5679410696029663,
      "learning_rate": 8.281039461020213e-05,
      "loss": 0.7997,
      "step": 3050
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6395130157470703,
      "learning_rate": 8.277189605389798e-05,
      "loss": 0.6793,
      "step": 3051
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8673911094665527,
      "learning_rate": 8.273339749759385e-05,
      "loss": 0.5112,
      "step": 3052
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5230692028999329,
      "learning_rate": 8.26948989412897e-05,
      "loss": 0.6749,
      "step": 3053
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5250663161277771,
      "learning_rate": 8.265640038498557e-05,
      "loss": 0.556,
      "step": 3054
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7511320114135742,
      "learning_rate": 8.261790182868143e-05,
      "loss": 0.5997,
      "step": 3055
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5149022936820984,
      "learning_rate": 8.257940327237728e-05,
      "loss": 0.7789,
      "step": 3056
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6155040264129639,
      "learning_rate": 8.254090471607315e-05,
      "loss": 0.8441,
      "step": 3057
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5733828544616699,
      "learning_rate": 8.2502406159769e-05,
      "loss": 0.6004,
      "step": 3058
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7648042440414429,
      "learning_rate": 8.246390760346488e-05,
      "loss": 0.4005,
      "step": 3059
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.49478161334991455,
      "learning_rate": 8.242540904716074e-05,
      "loss": 0.4604,
      "step": 3060
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5439568758010864,
      "learning_rate": 8.23869104908566e-05,
      "loss": 0.7098,
      "step": 3061
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5120150446891785,
      "learning_rate": 8.234841193455246e-05,
      "loss": 0.804,
      "step": 3062
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9013311862945557,
      "learning_rate": 8.230991337824832e-05,
      "loss": 0.7552,
      "step": 3063
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.767408549785614,
      "learning_rate": 8.227141482194418e-05,
      "loss": 0.588,
      "step": 3064
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5926640033721924,
      "learning_rate": 8.223291626564004e-05,
      "loss": 0.4229,
      "step": 3065
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7767144441604614,
      "learning_rate": 8.21944177093359e-05,
      "loss": 0.5708,
      "step": 3066
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4652583599090576,
      "learning_rate": 8.215591915303176e-05,
      "loss": 0.8398,
      "step": 3067
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7343325614929199,
      "learning_rate": 8.211742059672763e-05,
      "loss": 0.6251,
      "step": 3068
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4060419499874115,
      "learning_rate": 8.207892204042349e-05,
      "loss": 0.57,
      "step": 3069
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6941137313842773,
      "learning_rate": 8.204042348411935e-05,
      "loss": 0.4873,
      "step": 3070
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6709753274917603,
      "learning_rate": 8.200192492781521e-05,
      "loss": 0.4994,
      "step": 3071
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5643481016159058,
      "learning_rate": 8.196342637151107e-05,
      "loss": 0.624,
      "step": 3072
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5883188843727112,
      "learning_rate": 8.192492781520693e-05,
      "loss": 0.7132,
      "step": 3073
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5778456330299377,
      "learning_rate": 8.188642925890279e-05,
      "loss": 0.5018,
      "step": 3074
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5068455338478088,
      "learning_rate": 8.184793070259865e-05,
      "loss": 0.6762,
      "step": 3075
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4827568233013153,
      "learning_rate": 8.180943214629451e-05,
      "loss": 0.9126,
      "step": 3076
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5327210426330566,
      "learning_rate": 8.177093358999039e-05,
      "loss": 0.7271,
      "step": 3077
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7368320226669312,
      "learning_rate": 8.173243503368624e-05,
      "loss": 0.87,
      "step": 3078
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6715800762176514,
      "learning_rate": 8.169393647738211e-05,
      "loss": 0.517,
      "step": 3079
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5304865837097168,
      "learning_rate": 8.165543792107796e-05,
      "loss": 0.4967,
      "step": 3080
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5103051066398621,
      "learning_rate": 8.161693936477383e-05,
      "loss": 0.8172,
      "step": 3081
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4749707579612732,
      "learning_rate": 8.157844080846969e-05,
      "loss": 0.7605,
      "step": 3082
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7769431471824646,
      "learning_rate": 8.153994225216554e-05,
      "loss": 0.3667,
      "step": 3083
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6220328211784363,
      "learning_rate": 8.150144369586141e-05,
      "loss": 0.8451,
      "step": 3084
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5027702450752258,
      "learning_rate": 8.146294513955726e-05,
      "loss": 0.4927,
      "step": 3085
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5264575481414795,
      "learning_rate": 8.142444658325314e-05,
      "loss": 0.6541,
      "step": 3086
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4826143980026245,
      "learning_rate": 8.138594802694898e-05,
      "loss": 0.6184,
      "step": 3087
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4448401927947998,
      "learning_rate": 8.134744947064486e-05,
      "loss": 1.0688,
      "step": 3088
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5735114812850952,
      "learning_rate": 8.130895091434072e-05,
      "loss": 0.6233,
      "step": 3089
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.586708128452301,
      "learning_rate": 8.127045235803658e-05,
      "loss": 0.5169,
      "step": 3090
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4474826455116272,
      "learning_rate": 8.123195380173244e-05,
      "loss": 0.6885,
      "step": 3091
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6595907807350159,
      "learning_rate": 8.11934552454283e-05,
      "loss": 0.7439,
      "step": 3092
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5129302740097046,
      "learning_rate": 8.115495668912416e-05,
      "loss": 0.7797,
      "step": 3093
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5517082214355469,
      "learning_rate": 8.111645813282002e-05,
      "loss": 0.7848,
      "step": 3094
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5734771490097046,
      "learning_rate": 8.107795957651589e-05,
      "loss": 0.7424,
      "step": 3095
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8959488868713379,
      "learning_rate": 8.103946102021175e-05,
      "loss": 0.4859,
      "step": 3096
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5832574367523193,
      "learning_rate": 8.100096246390761e-05,
      "loss": 0.6545,
      "step": 3097
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7260463833808899,
      "learning_rate": 8.096246390760347e-05,
      "loss": 0.5889,
      "step": 3098
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6336350440979004,
      "learning_rate": 8.092396535129933e-05,
      "loss": 0.7574,
      "step": 3099
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6164264678955078,
      "learning_rate": 8.088546679499519e-05,
      "loss": 0.7963,
      "step": 3100
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.49990564584732056,
      "learning_rate": 8.084696823869105e-05,
      "loss": 0.592,
      "step": 3101
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6449159979820251,
      "learning_rate": 8.080846968238691e-05,
      "loss": 0.2674,
      "step": 3102
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5115610361099243,
      "learning_rate": 8.076997112608277e-05,
      "loss": 0.4885,
      "step": 3103
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.48942336440086365,
      "learning_rate": 8.073147256977863e-05,
      "loss": 0.7468,
      "step": 3104
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6791175603866577,
      "learning_rate": 8.06929740134745e-05,
      "loss": 0.7419,
      "step": 3105
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5783547759056091,
      "learning_rate": 8.065447545717037e-05,
      "loss": 0.5228,
      "step": 3106
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7321954369544983,
      "learning_rate": 8.061597690086622e-05,
      "loss": 0.7138,
      "step": 3107
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5878262519836426,
      "learning_rate": 8.057747834456209e-05,
      "loss": 0.5935,
      "step": 3108
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5588389039039612,
      "learning_rate": 8.053897978825794e-05,
      "loss": 0.7428,
      "step": 3109
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6134451627731323,
      "learning_rate": 8.05004812319538e-05,
      "loss": 0.535,
      "step": 3110
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6135885119438171,
      "learning_rate": 8.046198267564967e-05,
      "loss": 0.6048,
      "step": 3111
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5421188473701477,
      "learning_rate": 8.042348411934552e-05,
      "loss": 0.6318,
      "step": 3112
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.628250002861023,
      "learning_rate": 8.03849855630414e-05,
      "loss": 0.6519,
      "step": 3113
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5129433870315552,
      "learning_rate": 8.034648700673724e-05,
      "loss": 0.5208,
      "step": 3114
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5476192831993103,
      "learning_rate": 8.030798845043312e-05,
      "loss": 0.7777,
      "step": 3115
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6176209449768066,
      "learning_rate": 8.026948989412897e-05,
      "loss": 0.446,
      "step": 3116
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6499560475349426,
      "learning_rate": 8.023099133782484e-05,
      "loss": 0.5242,
      "step": 3117
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5495684146881104,
      "learning_rate": 8.01924927815207e-05,
      "loss": 0.7797,
      "step": 3118
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5671772956848145,
      "learning_rate": 8.015399422521655e-05,
      "loss": 0.6175,
      "step": 3119
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7040782570838928,
      "learning_rate": 8.011549566891242e-05,
      "loss": 0.7081,
      "step": 3120
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7409878969192505,
      "learning_rate": 8.007699711260827e-05,
      "loss": 0.5322,
      "step": 3121
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5647016167640686,
      "learning_rate": 8.003849855630415e-05,
      "loss": 0.8271,
      "step": 3122
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.616721510887146,
      "learning_rate": 8e-05,
      "loss": 0.8037,
      "step": 3123
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.82240229845047,
      "learning_rate": 7.996150144369587e-05,
      "loss": 0.5914,
      "step": 3124
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5137932300567627,
      "learning_rate": 7.992300288739173e-05,
      "loss": 0.8361,
      "step": 3125
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.648531436920166,
      "learning_rate": 7.988450433108759e-05,
      "loss": 0.8877,
      "step": 3126
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.166967749595642,
      "learning_rate": 7.984600577478345e-05,
      "loss": 0.9529,
      "step": 3127
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.49377885460853577,
      "learning_rate": 7.980750721847931e-05,
      "loss": 0.7722,
      "step": 3128
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5181968808174133,
      "learning_rate": 7.976900866217517e-05,
      "loss": 0.8714,
      "step": 3129
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.520183265209198,
      "learning_rate": 7.973051010587103e-05,
      "loss": 0.9727,
      "step": 3130
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7810470461845398,
      "learning_rate": 7.96920115495669e-05,
      "loss": 0.7238,
      "step": 3131
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5242288708686829,
      "learning_rate": 7.965351299326276e-05,
      "loss": 0.8638,
      "step": 3132
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6001251339912415,
      "learning_rate": 7.961501443695862e-05,
      "loss": 0.5796,
      "step": 3133
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5062482357025146,
      "learning_rate": 7.957651588065448e-05,
      "loss": 0.5203,
      "step": 3134
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5861556529998779,
      "learning_rate": 7.953801732435034e-05,
      "loss": 0.7203,
      "step": 3135
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5351290702819824,
      "learning_rate": 7.94995187680462e-05,
      "loss": 0.9339,
      "step": 3136
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6303215026855469,
      "learning_rate": 7.946102021174206e-05,
      "loss": 0.6699,
      "step": 3137
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.780354917049408,
      "learning_rate": 7.942252165543792e-05,
      "loss": 0.3813,
      "step": 3138
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5691993832588196,
      "learning_rate": 7.938402309913378e-05,
      "loss": 0.6154,
      "step": 3139
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4892597794532776,
      "learning_rate": 7.934552454282966e-05,
      "loss": 0.6164,
      "step": 3140
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6386151313781738,
      "learning_rate": 7.93070259865255e-05,
      "loss": 0.4718,
      "step": 3141
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4321484863758087,
      "learning_rate": 7.926852743022138e-05,
      "loss": 0.6213,
      "step": 3142
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5894069671630859,
      "learning_rate": 7.923002887391723e-05,
      "loss": 0.3072,
      "step": 3143
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7499212622642517,
      "learning_rate": 7.91915303176131e-05,
      "loss": 0.487,
      "step": 3144
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4996177554130554,
      "learning_rate": 7.915303176130896e-05,
      "loss": 0.7169,
      "step": 3145
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.47082048654556274,
      "learning_rate": 7.911453320500481e-05,
      "loss": 0.8749,
      "step": 3146
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5365607738494873,
      "learning_rate": 7.907603464870068e-05,
      "loss": 0.6294,
      "step": 3147
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6339857578277588,
      "learning_rate": 7.903753609239653e-05,
      "loss": 0.6188,
      "step": 3148
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4479904770851135,
      "learning_rate": 7.89990375360924e-05,
      "loss": 0.6219,
      "step": 3149
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7208887338638306,
      "learning_rate": 7.896053897978825e-05,
      "loss": 0.6552,
      "step": 3150
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5640572905540466,
      "learning_rate": 7.892204042348413e-05,
      "loss": 0.62,
      "step": 3151
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6347392797470093,
      "learning_rate": 7.888354186717999e-05,
      "loss": 0.727,
      "step": 3152
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.49805477261543274,
      "learning_rate": 7.884504331087585e-05,
      "loss": 0.523,
      "step": 3153
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5678948163986206,
      "learning_rate": 7.880654475457171e-05,
      "loss": 0.7077,
      "step": 3154
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5593597888946533,
      "learning_rate": 7.876804619826756e-05,
      "loss": 0.4988,
      "step": 3155
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5189074873924255,
      "learning_rate": 7.872954764196343e-05,
      "loss": 0.753,
      "step": 3156
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5621452927589417,
      "learning_rate": 7.86910490856593e-05,
      "loss": 0.4761,
      "step": 3157
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5230786800384521,
      "learning_rate": 7.865255052935515e-05,
      "loss": 0.7306,
      "step": 3158
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.535437822341919,
      "learning_rate": 7.861405197305102e-05,
      "loss": 0.6332,
      "step": 3159
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8031255006790161,
      "learning_rate": 7.857555341674688e-05,
      "loss": 0.5774,
      "step": 3160
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5225934386253357,
      "learning_rate": 7.853705486044274e-05,
      "loss": 0.7961,
      "step": 3161
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.473766952753067,
      "learning_rate": 7.84985563041386e-05,
      "loss": 0.6756,
      "step": 3162
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0560593605041504,
      "learning_rate": 7.846005774783446e-05,
      "loss": 0.5771,
      "step": 3163
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.43392953276634216,
      "learning_rate": 7.842155919153032e-05,
      "loss": 0.7622,
      "step": 3164
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8524100184440613,
      "learning_rate": 7.838306063522618e-05,
      "loss": 0.4233,
      "step": 3165
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9464726448059082,
      "learning_rate": 7.834456207892204e-05,
      "loss": 0.7239,
      "step": 3166
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5908270478248596,
      "learning_rate": 7.83060635226179e-05,
      "loss": 1.0033,
      "step": 3167
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7000332474708557,
      "learning_rate": 7.826756496631376e-05,
      "loss": 0.4254,
      "step": 3168
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6092998385429382,
      "learning_rate": 7.822906641000964e-05,
      "loss": 0.7911,
      "step": 3169
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5283005833625793,
      "learning_rate": 7.819056785370549e-05,
      "loss": 0.8958,
      "step": 3170
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5042657256126404,
      "learning_rate": 7.815206929740135e-05,
      "loss": 0.7472,
      "step": 3171
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5182255506515503,
      "learning_rate": 7.811357074109721e-05,
      "loss": 0.8983,
      "step": 3172
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6121584177017212,
      "learning_rate": 7.807507218479307e-05,
      "loss": 0.5732,
      "step": 3173
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6150258183479309,
      "learning_rate": 7.803657362848894e-05,
      "loss": 0.6719,
      "step": 3174
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5150590538978577,
      "learning_rate": 7.799807507218479e-05,
      "loss": 0.5516,
      "step": 3175
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5262035727500916,
      "learning_rate": 7.795957651588067e-05,
      "loss": 0.9923,
      "step": 3176
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7638717889785767,
      "learning_rate": 7.792107795957651e-05,
      "loss": 0.4868,
      "step": 3177
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5304864048957825,
      "learning_rate": 7.788257940327239e-05,
      "loss": 0.6302,
      "step": 3178
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2983176708221436,
      "learning_rate": 7.784408084696823e-05,
      "loss": 1.0097,
      "step": 3179
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7126185297966003,
      "learning_rate": 7.780558229066411e-05,
      "loss": 0.415,
      "step": 3180
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5689801573753357,
      "learning_rate": 7.776708373435997e-05,
      "loss": 0.8564,
      "step": 3181
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6181755661964417,
      "learning_rate": 7.772858517805582e-05,
      "loss": 0.5565,
      "step": 3182
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.581092357635498,
      "learning_rate": 7.769008662175169e-05,
      "loss": 0.6011,
      "step": 3183
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4957127273082733,
      "learning_rate": 7.765158806544754e-05,
      "loss": 0.6406,
      "step": 3184
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.47399577498435974,
      "learning_rate": 7.761308950914341e-05,
      "loss": 0.89,
      "step": 3185
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6532487273216248,
      "learning_rate": 7.757459095283928e-05,
      "loss": 0.7473,
      "step": 3186
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6119555234909058,
      "learning_rate": 7.753609239653514e-05,
      "loss": 0.6267,
      "step": 3187
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4711967706680298,
      "learning_rate": 7.7497593840231e-05,
      "loss": 0.7802,
      "step": 3188
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5276861786842346,
      "learning_rate": 7.745909528392686e-05,
      "loss": 0.7758,
      "step": 3189
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5031951665878296,
      "learning_rate": 7.742059672762272e-05,
      "loss": 0.5757,
      "step": 3190
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.46566447615623474,
      "learning_rate": 7.738209817131858e-05,
      "loss": 0.8422,
      "step": 3191
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6212090253829956,
      "learning_rate": 7.734359961501444e-05,
      "loss": 0.5749,
      "step": 3192
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5675336718559265,
      "learning_rate": 7.73051010587103e-05,
      "loss": 0.7299,
      "step": 3193
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7848361134529114,
      "learning_rate": 7.726660250240616e-05,
      "loss": 0.4857,
      "step": 3194
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6383767127990723,
      "learning_rate": 7.722810394610202e-05,
      "loss": 0.6639,
      "step": 3195
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6745420098304749,
      "learning_rate": 7.718960538979789e-05,
      "loss": 0.5815,
      "step": 3196
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4846532642841339,
      "learning_rate": 7.715110683349375e-05,
      "loss": 0.6477,
      "step": 3197
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.44336938858032227,
      "learning_rate": 7.711260827718961e-05,
      "loss": 0.8122,
      "step": 3198
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.168865919113159,
      "learning_rate": 7.707410972088547e-05,
      "loss": 0.651,
      "step": 3199
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6087213754653931,
      "learning_rate": 7.703561116458133e-05,
      "loss": 0.5615,
      "step": 3200
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5233312249183655,
      "learning_rate": 7.699711260827719e-05,
      "loss": 0.7371,
      "step": 3201
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5166227221488953,
      "learning_rate": 7.695861405197305e-05,
      "loss": 0.6742,
      "step": 3202
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.716546356678009,
      "learning_rate": 7.692011549566893e-05,
      "loss": 0.7213,
      "step": 3203
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6367550492286682,
      "learning_rate": 7.688161693936477e-05,
      "loss": 0.701,
      "step": 3204
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6124588847160339,
      "learning_rate": 7.684311838306065e-05,
      "loss": 0.7479,
      "step": 3205
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6369837522506714,
      "learning_rate": 7.68046198267565e-05,
      "loss": 0.6296,
      "step": 3206
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.43357372283935547,
      "learning_rate": 7.676612127045236e-05,
      "loss": 0.8795,
      "step": 3207
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6564217209815979,
      "learning_rate": 7.672762271414823e-05,
      "loss": 0.6107,
      "step": 3208
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5782095789909363,
      "learning_rate": 7.668912415784408e-05,
      "loss": 0.6489,
      "step": 3209
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.618081271648407,
      "learning_rate": 7.665062560153995e-05,
      "loss": 0.3689,
      "step": 3210
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6739771962165833,
      "learning_rate": 7.66121270452358e-05,
      "loss": 0.478,
      "step": 3211
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6414416432380676,
      "learning_rate": 7.657362848893167e-05,
      "loss": 0.6556,
      "step": 3212
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5676552653312683,
      "learning_rate": 7.653512993262752e-05,
      "loss": 0.7265,
      "step": 3213
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.554624080657959,
      "learning_rate": 7.64966313763234e-05,
      "loss": 0.9609,
      "step": 3214
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.49769341945648193,
      "learning_rate": 7.645813282001926e-05,
      "loss": 0.6974,
      "step": 3215
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5083463191986084,
      "learning_rate": 7.641963426371512e-05,
      "loss": 0.7347,
      "step": 3216
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5909741520881653,
      "learning_rate": 7.638113570741098e-05,
      "loss": 0.5845,
      "step": 3217
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5735964179039001,
      "learning_rate": 7.634263715110683e-05,
      "loss": 0.3275,
      "step": 3218
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5949086546897888,
      "learning_rate": 7.63041385948027e-05,
      "loss": 0.926,
      "step": 3219
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.675482988357544,
      "learning_rate": 7.626564003849856e-05,
      "loss": 0.4108,
      "step": 3220
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7420614957809448,
      "learning_rate": 7.622714148219442e-05,
      "loss": 0.4898,
      "step": 3221
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.566791296005249,
      "learning_rate": 7.618864292589028e-05,
      "loss": 0.6069,
      "step": 3222
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5675615668296814,
      "learning_rate": 7.615014436958615e-05,
      "loss": 0.85,
      "step": 3223
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5648126602172852,
      "learning_rate": 7.6111645813282e-05,
      "loss": 0.8236,
      "step": 3224
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6011543869972229,
      "learning_rate": 7.607314725697787e-05,
      "loss": 0.7673,
      "step": 3225
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5500502586364746,
      "learning_rate": 7.603464870067373e-05,
      "loss": 0.8862,
      "step": 3226
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5084953308105469,
      "learning_rate": 7.599615014436959e-05,
      "loss": 0.6237,
      "step": 3227
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5961072444915771,
      "learning_rate": 7.595765158806545e-05,
      "loss": 0.5272,
      "step": 3228
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5441976189613342,
      "learning_rate": 7.591915303176131e-05,
      "loss": 0.4512,
      "step": 3229
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4944899380207062,
      "learning_rate": 7.588065447545717e-05,
      "loss": 0.6895,
      "step": 3230
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5807552933692932,
      "learning_rate": 7.584215591915303e-05,
      "loss": 0.64,
      "step": 3231
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.479012131690979,
      "learning_rate": 7.580365736284891e-05,
      "loss": 0.5588,
      "step": 3232
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5161168575286865,
      "learning_rate": 7.576515880654475e-05,
      "loss": 0.6352,
      "step": 3233
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5961063504219055,
      "learning_rate": 7.572666025024062e-05,
      "loss": 0.6853,
      "step": 3234
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5006608366966248,
      "learning_rate": 7.568816169393648e-05,
      "loss": 0.8424,
      "step": 3235
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.65360027551651,
      "learning_rate": 7.564966313763234e-05,
      "loss": 0.3965,
      "step": 3236
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4528270363807678,
      "learning_rate": 7.561116458132821e-05,
      "loss": 0.6721,
      "step": 3237
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5389271974563599,
      "learning_rate": 7.557266602502406e-05,
      "loss": 0.8916,
      "step": 3238
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5385229587554932,
      "learning_rate": 7.553416746871993e-05,
      "loss": 0.8016,
      "step": 3239
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6341633796691895,
      "learning_rate": 7.549566891241578e-05,
      "loss": 0.5959,
      "step": 3240
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5154868960380554,
      "learning_rate": 7.545717035611166e-05,
      "loss": 0.7841,
      "step": 3241
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7202576994895935,
      "learning_rate": 7.54186717998075e-05,
      "loss": 0.766,
      "step": 3242
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5075547695159912,
      "learning_rate": 7.538017324350338e-05,
      "loss": 0.6735,
      "step": 3243
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5900738835334778,
      "learning_rate": 7.534167468719924e-05,
      "loss": 0.6338,
      "step": 3244
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5418612957000732,
      "learning_rate": 7.530317613089509e-05,
      "loss": 0.6386,
      "step": 3245
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6499151587486267,
      "learning_rate": 7.526467757459096e-05,
      "loss": 0.475,
      "step": 3246
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6458569169044495,
      "learning_rate": 7.522617901828681e-05,
      "loss": 0.5483,
      "step": 3247
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6315385103225708,
      "learning_rate": 7.518768046198268e-05,
      "loss": 0.6832,
      "step": 3248
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5534324645996094,
      "learning_rate": 7.514918190567854e-05,
      "loss": 0.6176,
      "step": 3249
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5490148067474365,
      "learning_rate": 7.51106833493744e-05,
      "loss": 0.7562,
      "step": 3250
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4737747013568878,
      "learning_rate": 7.507218479307027e-05,
      "loss": 0.7818,
      "step": 3251
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5897590517997742,
      "learning_rate": 7.503368623676613e-05,
      "loss": 0.7046,
      "step": 3252
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6074649095535278,
      "learning_rate": 7.499518768046199e-05,
      "loss": 0.6451,
      "step": 3253
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.807470977306366,
      "learning_rate": 7.495668912415785e-05,
      "loss": 0.8251,
      "step": 3254
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.44897058606147766,
      "learning_rate": 7.491819056785371e-05,
      "loss": 0.9222,
      "step": 3255
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5103428959846497,
      "learning_rate": 7.487969201154957e-05,
      "loss": 0.6246,
      "step": 3256
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7554305195808411,
      "learning_rate": 7.484119345524543e-05,
      "loss": 0.7812,
      "step": 3257
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6875192523002625,
      "learning_rate": 7.480269489894129e-05,
      "loss": 0.58,
      "step": 3258
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5279911756515503,
      "learning_rate": 7.476419634263715e-05,
      "loss": 0.7703,
      "step": 3259
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5130933523178101,
      "learning_rate": 7.472569778633301e-05,
      "loss": 0.6315,
      "step": 3260
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6171624064445496,
      "learning_rate": 7.468719923002888e-05,
      "loss": 0.7103,
      "step": 3261
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5141058564186096,
      "learning_rate": 7.464870067372474e-05,
      "loss": 0.8383,
      "step": 3262
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5969873070716858,
      "learning_rate": 7.46102021174206e-05,
      "loss": 0.5195,
      "step": 3263
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4117981493473053,
      "learning_rate": 7.457170356111646e-05,
      "loss": 0.7568,
      "step": 3264
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4838251769542694,
      "learning_rate": 7.453320500481232e-05,
      "loss": 0.8537,
      "step": 3265
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.45225223898887634,
      "learning_rate": 7.44947064485082e-05,
      "loss": 0.6787,
      "step": 3266
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5406246185302734,
      "learning_rate": 7.445620789220404e-05,
      "loss": 0.4686,
      "step": 3267
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6220400333404541,
      "learning_rate": 7.441770933589992e-05,
      "loss": 0.6001,
      "step": 3268
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.48554325103759766,
      "learning_rate": 7.437921077959576e-05,
      "loss": 0.6129,
      "step": 3269
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5642387866973877,
      "learning_rate": 7.434071222329162e-05,
      "loss": 0.4855,
      "step": 3270
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5415917634963989,
      "learning_rate": 7.43022136669875e-05,
      "loss": 0.7048,
      "step": 3271
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6285754442214966,
      "learning_rate": 7.426371511068335e-05,
      "loss": 0.7049,
      "step": 3272
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.588184118270874,
      "learning_rate": 7.422521655437922e-05,
      "loss": 0.4464,
      "step": 3273
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5651788711547852,
      "learning_rate": 7.418671799807507e-05,
      "loss": 0.6507,
      "step": 3274
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6517391800880432,
      "learning_rate": 7.414821944177094e-05,
      "loss": 0.4742,
      "step": 3275
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.635270893573761,
      "learning_rate": 7.410972088546679e-05,
      "loss": 0.58,
      "step": 3276
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5987905263900757,
      "learning_rate": 7.407122232916266e-05,
      "loss": 0.6777,
      "step": 3277
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.46831920742988586,
      "learning_rate": 7.403272377285853e-05,
      "loss": 0.7051,
      "step": 3278
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6669482588768005,
      "learning_rate": 7.399422521655439e-05,
      "loss": 0.699,
      "step": 3279
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6707508563995361,
      "learning_rate": 7.395572666025025e-05,
      "loss": 0.6539,
      "step": 3280
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5891085863113403,
      "learning_rate": 7.39172281039461e-05,
      "loss": 0.7488,
      "step": 3281
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.539867639541626,
      "learning_rate": 7.387872954764197e-05,
      "loss": 0.9023,
      "step": 3282
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6416000127792358,
      "learning_rate": 7.384023099133783e-05,
      "loss": 0.5051,
      "step": 3283
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6462294459342957,
      "learning_rate": 7.380173243503369e-05,
      "loss": 0.5074,
      "step": 3284
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5641290545463562,
      "learning_rate": 7.376323387872955e-05,
      "loss": 0.6742,
      "step": 3285
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5477766990661621,
      "learning_rate": 7.372473532242541e-05,
      "loss": 0.7045,
      "step": 3286
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6891918182373047,
      "learning_rate": 7.368623676612127e-05,
      "loss": 0.7816,
      "step": 3287
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.581771194934845,
      "learning_rate": 7.364773820981714e-05,
      "loss": 0.5779,
      "step": 3288
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5366312861442566,
      "learning_rate": 7.3609239653513e-05,
      "loss": 0.6787,
      "step": 3289
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.133137583732605,
      "learning_rate": 7.357074109720886e-05,
      "loss": 0.6993,
      "step": 3290
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5802149772644043,
      "learning_rate": 7.353224254090472e-05,
      "loss": 0.7241,
      "step": 3291
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8559004068374634,
      "learning_rate": 7.349374398460058e-05,
      "loss": 0.3467,
      "step": 3292
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6066559553146362,
      "learning_rate": 7.345524542829644e-05,
      "loss": 0.5845,
      "step": 3293
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5980022549629211,
      "learning_rate": 7.34167468719923e-05,
      "loss": 0.51,
      "step": 3294
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5846585631370544,
      "learning_rate": 7.337824831568818e-05,
      "loss": 0.5484,
      "step": 3295
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5635424256324768,
      "learning_rate": 7.333974975938402e-05,
      "loss": 0.616,
      "step": 3296
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6053573489189148,
      "learning_rate": 7.330125120307988e-05,
      "loss": 0.6131,
      "step": 3297
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6119810938835144,
      "learning_rate": 7.326275264677575e-05,
      "loss": 0.5792,
      "step": 3298
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5041476488113403,
      "learning_rate": 7.32242540904716e-05,
      "loss": 0.6882,
      "step": 3299
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6258525848388672,
      "learning_rate": 7.318575553416748e-05,
      "loss": 0.3641,
      "step": 3300
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5574802756309509,
      "learning_rate": 7.314725697786333e-05,
      "loss": 0.5834,
      "step": 3301
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5462488532066345,
      "learning_rate": 7.31087584215592e-05,
      "loss": 0.4992,
      "step": 3302
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6177618503570557,
      "learning_rate": 7.307025986525505e-05,
      "loss": 0.7791,
      "step": 3303
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8875640034675598,
      "learning_rate": 7.303176130895092e-05,
      "loss": 0.7213,
      "step": 3304
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4989127814769745,
      "learning_rate": 7.299326275264677e-05,
      "loss": 0.3334,
      "step": 3305
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6858596801757812,
      "learning_rate": 7.295476419634263e-05,
      "loss": 0.4783,
      "step": 3306
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9871046543121338,
      "learning_rate": 7.291626564003851e-05,
      "loss": 0.5209,
      "step": 3307
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5193162560462952,
      "learning_rate": 7.287776708373436e-05,
      "loss": 0.7016,
      "step": 3308
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7907700538635254,
      "learning_rate": 7.283926852743023e-05,
      "loss": 0.73,
      "step": 3309
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5631684064865112,
      "learning_rate": 7.280076997112608e-05,
      "loss": 0.3741,
      "step": 3310
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0970340967178345,
      "learning_rate": 7.276227141482195e-05,
      "loss": 0.9409,
      "step": 3311
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5758060216903687,
      "learning_rate": 7.272377285851781e-05,
      "loss": 0.7748,
      "step": 3312
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7697036266326904,
      "learning_rate": 7.268527430221367e-05,
      "loss": 0.5926,
      "step": 3313
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4642500877380371,
      "learning_rate": 7.264677574590953e-05,
      "loss": 0.811,
      "step": 3314
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6188255548477173,
      "learning_rate": 7.26082771896054e-05,
      "loss": 0.6176,
      "step": 3315
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5102343559265137,
      "learning_rate": 7.256977863330126e-05,
      "loss": 0.8624,
      "step": 3316
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5479130744934082,
      "learning_rate": 7.253128007699712e-05,
      "loss": 0.5563,
      "step": 3317
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6265864372253418,
      "learning_rate": 7.249278152069298e-05,
      "loss": 0.6422,
      "step": 3318
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6214033365249634,
      "learning_rate": 7.245428296438884e-05,
      "loss": 0.6022,
      "step": 3319
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.645011842250824,
      "learning_rate": 7.24157844080847e-05,
      "loss": 0.4859,
      "step": 3320
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6212761998176575,
      "learning_rate": 7.237728585178056e-05,
      "loss": 0.2956,
      "step": 3321
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9617182016372681,
      "learning_rate": 7.233878729547642e-05,
      "loss": 0.4428,
      "step": 3322
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6093331575393677,
      "learning_rate": 7.230028873917228e-05,
      "loss": 0.671,
      "step": 3323
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6699903607368469,
      "learning_rate": 7.226179018286814e-05,
      "loss": 0.3796,
      "step": 3324
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4981521666049957,
      "learning_rate": 7.2223291626564e-05,
      "loss": 0.9206,
      "step": 3325
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5147204995155334,
      "learning_rate": 7.218479307025987e-05,
      "loss": 0.8281,
      "step": 3326
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5150941610336304,
      "learning_rate": 7.214629451395573e-05,
      "loss": 0.7436,
      "step": 3327
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7341964244842529,
      "learning_rate": 7.210779595765159e-05,
      "loss": 0.5273,
      "step": 3328
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5858457088470459,
      "learning_rate": 7.206929740134746e-05,
      "loss": 0.8847,
      "step": 3329
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5992617011070251,
      "learning_rate": 7.203079884504331e-05,
      "loss": 0.6543,
      "step": 3330
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5134909749031067,
      "learning_rate": 7.199230028873918e-05,
      "loss": 0.8733,
      "step": 3331
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.771073579788208,
      "learning_rate": 7.195380173243503e-05,
      "loss": 0.6918,
      "step": 3332
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5384448766708374,
      "learning_rate": 7.19153031761309e-05,
      "loss": 0.4835,
      "step": 3333
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5761873126029968,
      "learning_rate": 7.187680461982677e-05,
      "loss": 0.5761,
      "step": 3334
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8062142729759216,
      "learning_rate": 7.183830606352262e-05,
      "loss": 0.5755,
      "step": 3335
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6920562982559204,
      "learning_rate": 7.179980750721849e-05,
      "loss": 0.5812,
      "step": 3336
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6722986102104187,
      "learning_rate": 7.176130895091434e-05,
      "loss": 0.4889,
      "step": 3337
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6287564635276794,
      "learning_rate": 7.172281039461021e-05,
      "loss": 0.93,
      "step": 3338
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5781503915786743,
      "learning_rate": 7.168431183830606e-05,
      "loss": 0.7329,
      "step": 3339
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5944199562072754,
      "learning_rate": 7.164581328200193e-05,
      "loss": 0.4898,
      "step": 3340
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6255539059638977,
      "learning_rate": 7.16073147256978e-05,
      "loss": 0.7712,
      "step": 3341
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5403274893760681,
      "learning_rate": 7.156881616939364e-05,
      "loss": 0.7715,
      "step": 3342
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5489911437034607,
      "learning_rate": 7.153031761308952e-05,
      "loss": 0.739,
      "step": 3343
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5217779278755188,
      "learning_rate": 7.149181905678536e-05,
      "loss": 0.704,
      "step": 3344
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6445834040641785,
      "learning_rate": 7.145332050048124e-05,
      "loss": 0.3571,
      "step": 3345
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.552844762802124,
      "learning_rate": 7.14148219441771e-05,
      "loss": 0.8675,
      "step": 3346
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9464280009269714,
      "learning_rate": 7.137632338787296e-05,
      "loss": 0.5823,
      "step": 3347
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5761274099349976,
      "learning_rate": 7.133782483156882e-05,
      "loss": 0.5385,
      "step": 3348
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5445232391357422,
      "learning_rate": 7.129932627526468e-05,
      "loss": 0.5259,
      "step": 3349
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.49879732728004456,
      "learning_rate": 7.126082771896054e-05,
      "loss": 0.5552,
      "step": 3350
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5712737441062927,
      "learning_rate": 7.12223291626564e-05,
      "loss": 0.5082,
      "step": 3351
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5487467646598816,
      "learning_rate": 7.118383060635227e-05,
      "loss": 0.6928,
      "step": 3352
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5144301056861877,
      "learning_rate": 7.114533205004813e-05,
      "loss": 0.8639,
      "step": 3353
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0859125852584839,
      "learning_rate": 7.110683349374399e-05,
      "loss": 0.6003,
      "step": 3354
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6507037281990051,
      "learning_rate": 7.106833493743985e-05,
      "loss": 0.7665,
      "step": 3355
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5231063365936279,
      "learning_rate": 7.102983638113571e-05,
      "loss": 0.4632,
      "step": 3356
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7298325896263123,
      "learning_rate": 7.099133782483157e-05,
      "loss": 0.7482,
      "step": 3357
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.597316563129425,
      "learning_rate": 7.095283926852743e-05,
      "loss": 0.2747,
      "step": 3358
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6408125758171082,
      "learning_rate": 7.091434071222329e-05,
      "loss": 0.7141,
      "step": 3359
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5271499156951904,
      "learning_rate": 7.087584215591915e-05,
      "loss": 0.6861,
      "step": 3360
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6315893530845642,
      "learning_rate": 7.083734359961501e-05,
      "loss": 0.8064,
      "step": 3361
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5031954646110535,
      "learning_rate": 7.079884504331088e-05,
      "loss": 0.6672,
      "step": 3362
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6505734324455261,
      "learning_rate": 7.076034648700675e-05,
      "loss": 0.5942,
      "step": 3363
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7176305055618286,
      "learning_rate": 7.07218479307026e-05,
      "loss": 0.4287,
      "step": 3364
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5539989471435547,
      "learning_rate": 7.068334937439847e-05,
      "loss": 0.883,
      "step": 3365
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5525774955749512,
      "learning_rate": 7.064485081809432e-05,
      "loss": 0.425,
      "step": 3366
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5351623892784119,
      "learning_rate": 7.06063522617902e-05,
      "loss": 0.7077,
      "step": 3367
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5857645273208618,
      "learning_rate": 7.056785370548604e-05,
      "loss": 0.82,
      "step": 3368
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5821256041526794,
      "learning_rate": 7.05293551491819e-05,
      "loss": 0.629,
      "step": 3369
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.461153507232666,
      "learning_rate": 7.049085659287778e-05,
      "loss": 0.6297,
      "step": 3370
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6136695742607117,
      "learning_rate": 7.045235803657362e-05,
      "loss": 0.775,
      "step": 3371
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5707822442054749,
      "learning_rate": 7.04138594802695e-05,
      "loss": 0.7982,
      "step": 3372
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6784573197364807,
      "learning_rate": 7.037536092396535e-05,
      "loss": 0.6009,
      "step": 3373
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6295205354690552,
      "learning_rate": 7.033686236766122e-05,
      "loss": 0.557,
      "step": 3374
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4976131319999695,
      "learning_rate": 7.029836381135708e-05,
      "loss": 0.4396,
      "step": 3375
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6163244843482971,
      "learning_rate": 7.025986525505294e-05,
      "loss": 0.8515,
      "step": 3376
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5373585224151611,
      "learning_rate": 7.02213666987488e-05,
      "loss": 0.6286,
      "step": 3377
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7741310000419617,
      "learning_rate": 7.018286814244466e-05,
      "loss": 0.8333,
      "step": 3378
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6958571672439575,
      "learning_rate": 7.014436958614053e-05,
      "loss": 0.4312,
      "step": 3379
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.631676435470581,
      "learning_rate": 7.010587102983639e-05,
      "loss": 0.6152,
      "step": 3380
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7370767593383789,
      "learning_rate": 7.006737247353225e-05,
      "loss": 1.1704,
      "step": 3381
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6656820178031921,
      "learning_rate": 7.002887391722811e-05,
      "loss": 0.3336,
      "step": 3382
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5411056876182556,
      "learning_rate": 6.999037536092397e-05,
      "loss": 0.7905,
      "step": 3383
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5146618485450745,
      "learning_rate": 6.995187680461983e-05,
      "loss": 0.8785,
      "step": 3384
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.658340573310852,
      "learning_rate": 6.991337824831569e-05,
      "loss": 0.6071,
      "step": 3385
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5567183494567871,
      "learning_rate": 6.987487969201155e-05,
      "loss": 0.7384,
      "step": 3386
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5178961753845215,
      "learning_rate": 6.983638113570741e-05,
      "loss": 0.7084,
      "step": 3387
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6337137222290039,
      "learning_rate": 6.979788257940327e-05,
      "loss": 0.4885,
      "step": 3388
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6721010208129883,
      "learning_rate": 6.975938402309914e-05,
      "loss": 0.4807,
      "step": 3389
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5528951287269592,
      "learning_rate": 6.9720885466795e-05,
      "loss": 0.9944,
      "step": 3390
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6014074087142944,
      "learning_rate": 6.968238691049086e-05,
      "loss": 0.6007,
      "step": 3391
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5742154121398926,
      "learning_rate": 6.964388835418673e-05,
      "loss": 0.9766,
      "step": 3392
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.559101402759552,
      "learning_rate": 6.960538979788258e-05,
      "loss": 0.5789,
      "step": 3393
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5555206537246704,
      "learning_rate": 6.956689124157845e-05,
      "loss": 0.7723,
      "step": 3394
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5650765299797058,
      "learning_rate": 6.95283926852743e-05,
      "loss": 0.5371,
      "step": 3395
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5939083099365234,
      "learning_rate": 6.948989412897016e-05,
      "loss": 0.6479,
      "step": 3396
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6250513195991516,
      "learning_rate": 6.945139557266604e-05,
      "loss": 0.6322,
      "step": 3397
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.48015573620796204,
      "learning_rate": 6.941289701636188e-05,
      "loss": 0.7381,
      "step": 3398
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.553472638130188,
      "learning_rate": 6.937439846005776e-05,
      "loss": 0.6419,
      "step": 3399
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4329177141189575,
      "learning_rate": 6.93358999037536e-05,
      "loss": 0.6471,
      "step": 3400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6380890011787415,
      "learning_rate": 6.929740134744948e-05,
      "loss": 0.6748,
      "step": 3401
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.42811545729637146,
      "learning_rate": 6.925890279114533e-05,
      "loss": 0.8474,
      "step": 3402
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5098042488098145,
      "learning_rate": 6.92204042348412e-05,
      "loss": 0.6419,
      "step": 3403
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5540610551834106,
      "learning_rate": 6.918190567853706e-05,
      "loss": 0.6363,
      "step": 3404
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.551047682762146,
      "learning_rate": 6.914340712223291e-05,
      "loss": 0.7031,
      "step": 3405
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5402334332466125,
      "learning_rate": 6.910490856592879e-05,
      "loss": 0.7315,
      "step": 3406
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.493857204914093,
      "learning_rate": 6.906641000962463e-05,
      "loss": 1.0436,
      "step": 3407
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.47325408458709717,
      "learning_rate": 6.902791145332051e-05,
      "loss": 0.7658,
      "step": 3408
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5121584534645081,
      "learning_rate": 6.898941289701637e-05,
      "loss": 0.4903,
      "step": 3409
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.680051863193512,
      "learning_rate": 6.895091434071223e-05,
      "loss": 0.4198,
      "step": 3410
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5538654923439026,
      "learning_rate": 6.891241578440809e-05,
      "loss": 0.8081,
      "step": 3411
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5458298325538635,
      "learning_rate": 6.887391722810395e-05,
      "loss": 0.6231,
      "step": 3412
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6196423768997192,
      "learning_rate": 6.883541867179981e-05,
      "loss": 0.5123,
      "step": 3413
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.514525294303894,
      "learning_rate": 6.879692011549567e-05,
      "loss": 0.6721,
      "step": 3414
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6506207585334778,
      "learning_rate": 6.875842155919153e-05,
      "loss": 0.7817,
      "step": 3415
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4726092517375946,
      "learning_rate": 6.87199230028874e-05,
      "loss": 0.9503,
      "step": 3416
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5573468208312988,
      "learning_rate": 6.868142444658326e-05,
      "loss": 0.7596,
      "step": 3417
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5519214272499084,
      "learning_rate": 6.864292589027912e-05,
      "loss": 0.6083,
      "step": 3418
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6878630518913269,
      "learning_rate": 6.860442733397498e-05,
      "loss": 0.8496,
      "step": 3419
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5821549296379089,
      "learning_rate": 6.856592877767084e-05,
      "loss": 0.4978,
      "step": 3420
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6937140822410583,
      "learning_rate": 6.85274302213667e-05,
      "loss": 0.5625,
      "step": 3421
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6863394975662231,
      "learning_rate": 6.848893166506256e-05,
      "loss": 0.5844,
      "step": 3422
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6808015704154968,
      "learning_rate": 6.845043310875842e-05,
      "loss": 0.6506,
      "step": 3423
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6108471155166626,
      "learning_rate": 6.841193455245428e-05,
      "loss": 0.7431,
      "step": 3424
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4947998821735382,
      "learning_rate": 6.837343599615014e-05,
      "loss": 0.6144,
      "step": 3425
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5460892915725708,
      "learning_rate": 6.833493743984602e-05,
      "loss": 0.747,
      "step": 3426
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5458992123603821,
      "learning_rate": 6.829643888354187e-05,
      "loss": 0.8087,
      "step": 3427
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.529608964920044,
      "learning_rate": 6.825794032723774e-05,
      "loss": 0.8553,
      "step": 3428
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5048443675041199,
      "learning_rate": 6.821944177093359e-05,
      "loss": 0.7603,
      "step": 3429
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7239419221878052,
      "learning_rate": 6.818094321462946e-05,
      "loss": 0.7358,
      "step": 3430
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6782866716384888,
      "learning_rate": 6.814244465832531e-05,
      "loss": 0.5365,
      "step": 3431
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.570254921913147,
      "learning_rate": 6.810394610202117e-05,
      "loss": 0.7597,
      "step": 3432
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6675590872764587,
      "learning_rate": 6.806544754571705e-05,
      "loss": 0.6134,
      "step": 3433
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.43407386541366577,
      "learning_rate": 6.802694898941289e-05,
      "loss": 0.6091,
      "step": 3434
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.590707540512085,
      "learning_rate": 6.798845043310877e-05,
      "loss": 0.5501,
      "step": 3435
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5670932531356812,
      "learning_rate": 6.794995187680461e-05,
      "loss": 0.6147,
      "step": 3436
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6254976391792297,
      "learning_rate": 6.791145332050049e-05,
      "loss": 0.7657,
      "step": 3437
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7446479797363281,
      "learning_rate": 6.787295476419635e-05,
      "loss": 0.5679,
      "step": 3438
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.703597903251648,
      "learning_rate": 6.783445620789221e-05,
      "loss": 0.3716,
      "step": 3439
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8644564151763916,
      "learning_rate": 6.779595765158807e-05,
      "loss": 0.3542,
      "step": 3440
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6656836271286011,
      "learning_rate": 6.775745909528392e-05,
      "loss": 0.4137,
      "step": 3441
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7699958682060242,
      "learning_rate": 6.77189605389798e-05,
      "loss": 0.563,
      "step": 3442
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.49496039748191833,
      "learning_rate": 6.768046198267566e-05,
      "loss": 0.4712,
      "step": 3443
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5643541812896729,
      "learning_rate": 6.764196342637152e-05,
      "loss": 0.6268,
      "step": 3444
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5167645215988159,
      "learning_rate": 6.760346487006738e-05,
      "loss": 0.8991,
      "step": 3445
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7291492223739624,
      "learning_rate": 6.756496631376324e-05,
      "loss": 0.4066,
      "step": 3446
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6435070633888245,
      "learning_rate": 6.75264677574591e-05,
      "loss": 0.4209,
      "step": 3447
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6325743794441223,
      "learning_rate": 6.748796920115496e-05,
      "loss": 0.8226,
      "step": 3448
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5412110686302185,
      "learning_rate": 6.744947064485082e-05,
      "loss": 0.5171,
      "step": 3449
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7694794535636902,
      "learning_rate": 6.741097208854668e-05,
      "loss": 0.8086,
      "step": 3450
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.47316399216651917,
      "learning_rate": 6.737247353224254e-05,
      "loss": 0.7497,
      "step": 3451
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5019818544387817,
      "learning_rate": 6.73339749759384e-05,
      "loss": 0.723,
      "step": 3452
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5930013656616211,
      "learning_rate": 6.729547641963426e-05,
      "loss": 0.6968,
      "step": 3453
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.49925753474235535,
      "learning_rate": 6.725697786333013e-05,
      "loss": 0.721,
      "step": 3454
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5315852761268616,
      "learning_rate": 6.7218479307026e-05,
      "loss": 0.7223,
      "step": 3455
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.46330007910728455,
      "learning_rate": 6.717998075072185e-05,
      "loss": 0.7234,
      "step": 3456
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6132866144180298,
      "learning_rate": 6.714148219441771e-05,
      "loss": 0.5916,
      "step": 3457
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5710331797599792,
      "learning_rate": 6.710298363811357e-05,
      "loss": 0.8718,
      "step": 3458
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5491119027137756,
      "learning_rate": 6.706448508180943e-05,
      "loss": 0.6773,
      "step": 3459
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6165672540664673,
      "learning_rate": 6.70259865255053e-05,
      "loss": 0.6848,
      "step": 3460
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5764372944831848,
      "learning_rate": 6.698748796920115e-05,
      "loss": 0.5696,
      "step": 3461
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5313699245452881,
      "learning_rate": 6.694898941289703e-05,
      "loss": 0.7841,
      "step": 3462
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7637684345245361,
      "learning_rate": 6.691049085659287e-05,
      "loss": 0.8394,
      "step": 3463
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5181105136871338,
      "learning_rate": 6.687199230028875e-05,
      "loss": 0.9017,
      "step": 3464
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7713474035263062,
      "learning_rate": 6.68334937439846e-05,
      "loss": 0.514,
      "step": 3465
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5920826196670532,
      "learning_rate": 6.679499518768047e-05,
      "loss": 0.5512,
      "step": 3466
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5476763844490051,
      "learning_rate": 6.675649663137633e-05,
      "loss": 0.5806,
      "step": 3467
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5787104368209839,
      "learning_rate": 6.671799807507218e-05,
      "loss": 0.6734,
      "step": 3468
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6405604481697083,
      "learning_rate": 6.667949951876805e-05,
      "loss": 0.7224,
      "step": 3469
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.517577052116394,
      "learning_rate": 6.66410009624639e-05,
      "loss": 0.7557,
      "step": 3470
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5998243689537048,
      "learning_rate": 6.660250240615978e-05,
      "loss": 0.8231,
      "step": 3471
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5251399874687195,
      "learning_rate": 6.656400384985564e-05,
      "loss": 0.5646,
      "step": 3472
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.616478681564331,
      "learning_rate": 6.65255052935515e-05,
      "loss": 0.6747,
      "step": 3473
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5371041297912598,
      "learning_rate": 6.648700673724736e-05,
      "loss": 0.8626,
      "step": 3474
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4581124484539032,
      "learning_rate": 6.644850818094322e-05,
      "loss": 0.6681,
      "step": 3475
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5823534727096558,
      "learning_rate": 6.641000962463908e-05,
      "loss": 0.6337,
      "step": 3476
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.49241435527801514,
      "learning_rate": 6.637151106833494e-05,
      "loss": 0.4459,
      "step": 3477
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4981359839439392,
      "learning_rate": 6.63330125120308e-05,
      "loss": 0.8287,
      "step": 3478
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6624318361282349,
      "learning_rate": 6.629451395572666e-05,
      "loss": 0.7733,
      "step": 3479
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.47130054235458374,
      "learning_rate": 6.625601539942252e-05,
      "loss": 0.6599,
      "step": 3480
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5290369987487793,
      "learning_rate": 6.621751684311839e-05,
      "loss": 0.6245,
      "step": 3481
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7540886998176575,
      "learning_rate": 6.617901828681425e-05,
      "loss": 0.5366,
      "step": 3482
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8937469720840454,
      "learning_rate": 6.614051973051011e-05,
      "loss": 0.276,
      "step": 3483
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6538272500038147,
      "learning_rate": 6.610202117420597e-05,
      "loss": 0.7982,
      "step": 3484
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5314669013023376,
      "learning_rate": 6.606352261790183e-05,
      "loss": 0.6405,
      "step": 3485
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5320478081703186,
      "learning_rate": 6.602502406159769e-05,
      "loss": 0.7729,
      "step": 3486
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7367421984672546,
      "learning_rate": 6.598652550529355e-05,
      "loss": 0.3994,
      "step": 3487
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6016281843185425,
      "learning_rate": 6.594802694898941e-05,
      "loss": 0.597,
      "step": 3488
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5410623550415039,
      "learning_rate": 6.590952839268529e-05,
      "loss": 0.4458,
      "step": 3489
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5450332164764404,
      "learning_rate": 6.587102983638113e-05,
      "loss": 0.6461,
      "step": 3490
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6848475933074951,
      "learning_rate": 6.583253128007701e-05,
      "loss": 0.5041,
      "step": 3491
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.45103874802589417,
      "learning_rate": 6.579403272377286e-05,
      "loss": 0.9398,
      "step": 3492
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7559641599655151,
      "learning_rate": 6.575553416746872e-05,
      "loss": 0.8179,
      "step": 3493
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5186185836791992,
      "learning_rate": 6.571703561116458e-05,
      "loss": 0.7776,
      "step": 3494
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5917221307754517,
      "learning_rate": 6.567853705486044e-05,
      "loss": 0.5791,
      "step": 3495
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5531963109970093,
      "learning_rate": 6.564003849855631e-05,
      "loss": 0.5582,
      "step": 3496
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6630461812019348,
      "learning_rate": 6.560153994225216e-05,
      "loss": 0.63,
      "step": 3497
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5717048645019531,
      "learning_rate": 6.556304138594804e-05,
      "loss": 0.7726,
      "step": 3498
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.797838568687439,
      "learning_rate": 6.552454282964388e-05,
      "loss": 0.3715,
      "step": 3499
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.508686900138855,
      "learning_rate": 6.548604427333976e-05,
      "loss": 0.6987,
      "step": 3500
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 6.620109114802176e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

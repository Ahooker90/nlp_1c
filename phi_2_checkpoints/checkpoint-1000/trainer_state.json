{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.19229844719003894,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.9766390323638916,
      "learning_rate": 4e-05,
      "loss": 1.7634,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.435124397277832,
      "learning_rate": 8e-05,
      "loss": 1.6829,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.5236518383026123,
      "learning_rate": 0.00012,
      "loss": 1.6805,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1257619857788086,
      "learning_rate": 0.00016,
      "loss": 1.7545,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.0642006397247314,
      "learning_rate": 0.0002,
      "loss": 1.6766,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.411266565322876,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.5088,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.639124631881714,
      "learning_rate": 0.00019992300288739173,
      "loss": 1.2468,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2554538249969482,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.0573,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1159424781799316,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.182,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9325945377349854,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.0295,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.9144940376281738,
      "learning_rate": 0.00019976900866217518,
      "loss": 0.8971,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.706571340560913,
      "learning_rate": 0.00019973051010587105,
      "loss": 0.7713,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.6338694095611572,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.0035,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.232801079750061,
      "learning_rate": 0.00019965351299326277,
      "loss": 0.8582,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3732980489730835,
      "learning_rate": 0.00019961501443695862,
      "loss": 0.6596,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1462560892105103,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9916,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0849612951278687,
      "learning_rate": 0.00019953801732435037,
      "loss": 0.8837,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2592130899429321,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.9541,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2652932405471802,
      "learning_rate": 0.00019946102021174206,
      "loss": 0.9224,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3635163307189941,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.7145,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.273509979248047,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9682,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0948615074157715,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.6891,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.515223979949951,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.7041,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4680339097976685,
      "learning_rate": 0.00019926852743022138,
      "loss": 0.83,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2920639514923096,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.7418,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4675650596618652,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8998,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.405659794807434,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.5813,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2196124792099,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.7399,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.995840072631836,
      "learning_rate": 0.00019907603464870067,
      "loss": 1.1377,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8859715461730957,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.6972,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2927278280258179,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7877,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2092667818069458,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.924,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0641872882843018,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.844,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2754861116409302,
      "learning_rate": 0.00019888354186718,
      "loss": 0.833,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4720009565353394,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.6683,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1312196254730225,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7498,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4843389987945557,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.6933,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.737054467201233,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.8828,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.621341347694397,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.9389,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.10187566280365,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.6188,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1402729749679565,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.705,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.300221562385559,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.7825,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.351014494895935,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.691,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.7262177467346191,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.7756,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4864147901535034,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7574,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5389310121536255,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.7553,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6697019338607788,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.4816,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8021868467330933,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.5162,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5151989459991455,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.8018,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4660720825195312,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7437,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4324597120285034,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7255,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3882066011428833,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.7743,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1289256811141968,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.5449,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6433510780334473,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.615,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0964218378067017,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.9441,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0598076581954956,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.599,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1570210456848145,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.9157,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3224908113479614,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.757,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.027965545654297,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.9405,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0639221668243408,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8265,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3123269081115723,
      "learning_rate": 0.00019784408084696825,
      "loss": 1.1054,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0593514442443848,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.6289,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.927435576915741,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.8563,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.122362732887268,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.7896,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4112809896469116,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.6135,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1536827087402344,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7691,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2973562479019165,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.662,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1758365631103516,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.5567,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4415098428726196,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.6663,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4505945444107056,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.83,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0297611951828003,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.9364,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3291810750961304,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.5379,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4843671321868896,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.6709,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2337127923965454,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.4647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9915568828582764,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.6439,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1892094612121582,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7327,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4218144416809082,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.7468,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8900254964828491,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.5615,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2152378559112549,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.5918,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1518409252166748,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.7118,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9143003225326538,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.8193,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0710068941116333,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.5147,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.87776780128479,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.8635,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2822787761688232,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.6298,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.026825189590454,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.9106,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1366348266601562,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.9373,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3177250623703003,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.7351,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2249926328659058,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.5835,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.808040738105774,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.6813,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.277226209640503,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.5897,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3442306518554688,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7905,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1461127996444702,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.8015,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9360058903694153,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.8105,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2209837436676025,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7686,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0291593074798584,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.9542,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8803523182868958,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9003,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8462835550308228,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.6453,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.5406043529510498,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7514,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.086790084838867,
      "learning_rate": 0.000196381135707411,
      "loss": 0.6565,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8038688898086548,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8815,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7158440351486206,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.7875,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2155958414077759,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7357,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.961394727230072,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.8628,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.96473228931427,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.6931,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9059011340141296,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.7431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.253554344177246,
      "learning_rate": 0.000196111645813282,
      "loss": 0.716,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8613760471343994,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.9859,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2081166505813599,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.6575,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0867011547088623,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.7505,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1116654872894287,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.492,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4465603828430176,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.7577,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.988479733467102,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.6687,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8707459568977356,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8801,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4584712982177734,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.7284,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1217535734176636,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.6554,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6862573623657227,
      "learning_rate": 0.00019572666025024062,
      "loss": 0.7971,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4024852514266968,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.395,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3252756595611572,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.6865,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.124302864074707,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.4668,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1343193054199219,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.5322,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6102299690246582,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.575,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9591246843338013,
      "learning_rate": 0.00019549566891241578,
      "loss": 1.023,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0329092741012573,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.8113,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0736831426620483,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.4766,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9227723479270935,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.5173,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8723241090774536,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.8905,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6511275768280029,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.7647,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.005831003189087,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.7374,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8661340475082397,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.669,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7919161915779114,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7387,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0209808349609375,
      "learning_rate": 0.00019514918190567855,
      "loss": 1.0741,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.164157748222351,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.7856,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9031721949577332,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.6197,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9569196105003357,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.8645,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0174713134765625,
      "learning_rate": 0.000194995187680462,
      "loss": 0.793,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0296181440353394,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.7721,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8890597820281982,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.5771,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8176144957542419,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.9459,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8257383704185486,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.6564,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7403143644332886,
      "learning_rate": 0.0001948026948989413,
      "loss": 1.0655,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0076433420181274,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.517,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8821527361869812,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.7529,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": Infinity,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.9055,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.923977255821228,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5808,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8217901587486267,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7364,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9798531532287598,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.6119,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6735888719558716,
      "learning_rate": 0.00019457170356111648,
      "loss": 1.0526,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7803233861923218,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.8075,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1770597696304321,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.8079,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0164283514022827,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.4754,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9601749777793884,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.6892,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8489695191383362,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.5216,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7636417746543884,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.6582,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1955299377441406,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.4717,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8320456147193909,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.7358,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0133183002471924,
      "learning_rate": 0.0001942252165543792,
      "loss": 1.0343,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0720036029815674,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.5315,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0775949954986572,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6193,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7920546531677246,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.7595,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3015785217285156,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.9733,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8165020942687988,
      "learning_rate": 0.00019403272377285853,
      "loss": 0.7597,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4158751964569092,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.568,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.2686575651168823,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.6968,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3919662237167358,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8041,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9166744351387024,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.6156,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.136273741722107,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7026,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8245551586151123,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.8833,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9562796950340271,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.7529,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9529739022254944,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.8045,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4480829238891602,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.6155,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0233687162399292,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.6041,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7334891557693481,
      "learning_rate": 0.000193609239653513,
      "loss": 0.9663,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7895396947860718,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8324,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7623308300971985,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.8914,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8783438205718994,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.5553,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8427506685256958,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.5809,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.565274715423584,
      "learning_rate": 0.0001934167468719923,
      "loss": 1.1704,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8487130403518677,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.8637,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7599690556526184,
      "learning_rate": 0.00019333974975938403,
      "loss": 1.0428,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6733267307281494,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8145,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8760805130004883,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6674,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7678978443145752,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.6376,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7904714941978455,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6513,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7921337485313416,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.5813,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9006468057632446,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.8312,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9150775671005249,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.5722,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9657385349273682,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.7529,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.839449405670166,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.6083,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1582216024398804,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7123,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.140467882156372,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7309,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9428714513778687,
      "learning_rate": 0.00019287776708373439,
      "loss": 0.6775,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1014231443405151,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.4118,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0334292650222778,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.65,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1933209896087646,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6013,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8265478610992432,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7071,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8585402369499207,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.5727,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.787067711353302,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.7735,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1874279975891113,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.7179,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.971271276473999,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.6993,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.236193895339966,
      "learning_rate": 0.00019253128007699712,
      "loss": 1.0061,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9123310446739197,
      "learning_rate": 0.000192492781520693,
      "loss": 0.8033,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6489309072494507,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.7415,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0011146068572998,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.5747,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8328598737716675,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.5537,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.791504442691803,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7737,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7130611538887024,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.6439,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7929614186286926,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.755,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8132526278495789,
      "learning_rate": 0.000192223291626564,
      "loss": 0.6144,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9258521795272827,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7335,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9880536794662476,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.5069,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8288092613220215,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.7903,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9645191431045532,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.5626,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.09334397315979,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.5528,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7808449268341064,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.6246,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9576950073242188,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.552,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8885469436645508,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.6746,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9373623728752136,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7364,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6853724122047424,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.8125,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9469802975654602,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.6254,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0501898527145386,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.6862,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8763583302497864,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.8578,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.920737087726593,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.8214,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6409149765968323,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.6631,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8207921385765076,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.6582,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0325123071670532,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.5805,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9549276828765869,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.5267,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2399728298187256,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.7764,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7685335874557495,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.7752,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9186263680458069,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.6403,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1575677394866943,
      "learning_rate": 0.00019137632338787298,
      "loss": 1.0128,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6230560541152954,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.8143,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6135293841362,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.9284,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9068969488143921,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.7929,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0303515195846558,
      "learning_rate": 0.00019122232916265642,
      "loss": 1.0166,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8789127469062805,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.828,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.932952880859375,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.7154,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3748090267181396,
      "learning_rate": 0.000191106833493744,
      "loss": 0.4858,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7238903641700745,
      "learning_rate": 0.00019106833493743986,
      "loss": 1.0197,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8612135052680969,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.6402,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0058850049972534,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.5625,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7587082982063293,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.7146,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8537068963050842,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.6575,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8969892263412476,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.6438,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6655741333961487,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7692,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6944710612297058,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.8478,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8596721887588501,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.5002,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.586476445198059,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.5461,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0440481901168823,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.6742,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8207206726074219,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.6833,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0530555248260498,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.5616,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7683369517326355,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.5294,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0457940101623535,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.6963,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6145095825195312,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8594,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8121146559715271,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.6559,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.220907211303711,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.5442,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7089275121688843,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.7317,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9419508576393127,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.8281,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.628293514251709,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7145,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7072062492370605,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.683,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7283824682235718,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.8467,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1346855163574219,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.6207,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7329082489013672,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.6492,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7539021372795105,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.5169,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6919435262680054,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7795,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9497821927070618,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7684,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7363495230674744,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.7672,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7237761616706848,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.6591,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6229631304740906,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.8745,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.452817440032959,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.6145,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6157515048980713,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.744,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9306153059005737,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.4724,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1150598526000977,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.9032,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8624481558799744,
      "learning_rate": 0.000189720885466795,
      "loss": 0.7131,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7226539850234985,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.8181,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7369751930236816,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.7088,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8418794274330139,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7236,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.08870530128479,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.5989,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7107866406440735,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.6236,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9303227066993713,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5213,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6057505011558533,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9274,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7860249876976013,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.5527,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8407137393951416,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.438,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.788601279258728,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.5906,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7538231015205383,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.4701,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7311952710151672,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.6179,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0561766624450684,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.4345,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6438183188438416,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.8134,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.743452250957489,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.536,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5953269600868225,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.7504,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6800954341888428,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.5422,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7698876857757568,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.4952,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7443271279335022,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.8343,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2300752401351929,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.6186,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8002804517745972,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.5712,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0497325658798218,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.845,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6107672452926636,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8377,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7461987137794495,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.8034,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7233768105506897,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8044,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9682684540748596,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.8155,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0884222984313965,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.8066,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8505268692970276,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.4212,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8903761506080627,
      "learning_rate": 0.000188604427333975,
      "loss": 0.4617,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8329160213470459,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.646,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7580491900444031,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.6545,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5973345041275024,
      "learning_rate": 0.00018848893166506256,
      "loss": 1.0677,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7318881750106812,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.6773,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7885010838508606,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.7792,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8507166504859924,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.9515,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6224185824394226,
      "learning_rate": 0.000188334937439846,
      "loss": 0.793,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.718784511089325,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6929,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8589291572570801,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.8126,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8662039637565613,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.4193,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5792511701583862,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.5858,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8806815147399902,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.5773,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8599536418914795,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.6636,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5740275979042053,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.9467,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6886740326881409,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.8395,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9049243330955505,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.6245,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7558502554893494,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.688,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8135894536972046,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6968,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8597134947776794,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.5344,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6497805714607239,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.7432,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.624045193195343,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.5921,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7488207817077637,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.9047,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2660577297210693,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.5851,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1815978288650513,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.5468,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6585094928741455,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.5055,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6599869728088379,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.8755,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8747279644012451,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.9256,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0177969932556152,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.2889,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8498440980911255,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7156,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6891127228736877,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.7287,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7740240693092346,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.8368,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7449020743370056,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.4807,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4376306533813477,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.9404,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.736077070236206,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8668,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6683731079101562,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.6029,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7797954082489014,
      "learning_rate": 0.000187218479307026,
      "loss": 0.5901,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5687959790229797,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8516,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6512517333030701,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7347,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.565966010093689,
      "learning_rate": 0.00018710298363811359,
      "loss": 1.0649,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9909862279891968,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.4288,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7884112596511841,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.6397,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7323040962219238,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7309,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7657570242881775,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.8031,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8743228316307068,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6299,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9807490110397339,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6752,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7816490530967712,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.7282,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6959101557731628,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.6651,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7261993288993835,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8877,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6144199371337891,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.8319,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6571177244186401,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.7135,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0807875394821167,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7566,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8185086846351624,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.5601,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6865718960762024,
      "learning_rate": 0.00018656400384985564,
      "loss": 1.1941,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7527123689651489,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.6283,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.633386492729187,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.7949,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7434275150299072,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.749,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3395079374313354,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.9689,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6887421011924744,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.7547,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5965858697891235,
      "learning_rate": 0.0001863330125120308,
      "loss": 1.0431,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9297249913215637,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.809,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5710415244102478,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6837,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.623849093914032,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.7247,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9221763014793396,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.518,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.48956894874572754,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.8311,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5858659744262695,
      "learning_rate": 0.000186102021174206,
      "loss": 0.7148,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9408402442932129,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.6661,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8599625825881958,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.4558,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6531791090965271,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.7232,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7258799076080322,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.6838,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7172141671180725,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.6849,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5655890107154846,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.8398,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5579836964607239,
      "learning_rate": 0.000185832531280077,
      "loss": 0.8208,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8500748872756958,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.7686,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7076826095581055,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.646,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.750829815864563,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.5834,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7004405856132507,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.6413,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6903966665267944,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.6479,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.628515362739563,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7402,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.009565830230713,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.5636,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.736901044845581,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.6898,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8011174201965332,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.9058,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5748683214187622,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.684,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6112973093986511,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.6892,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8286272883415222,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7102,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.933481752872467,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.4317,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7664060592651367,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8973,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.57676100730896,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7021,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7917118668556213,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7848,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9117770791053772,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.456,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8564830422401428,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.3618,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9490712285041809,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.5153,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7518885731697083,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.7539,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7193209528923035,
      "learning_rate": 0.0001850240615976901,
      "loss": 1.0002,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7111209034919739,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7467,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9438728094100952,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6184,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8447867631912231,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.9111,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5188901424407959,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.6593,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7598814368247986,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.881,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5978820323944092,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.6949,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7871193885803223,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.5207,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7425273060798645,
      "learning_rate": 0.000184716073147257,
      "loss": 0.8033,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5325318574905396,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7403,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6582126021385193,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.6868,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5985537767410278,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.704,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8908801674842834,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.719,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7575201392173767,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.7543,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8175365328788757,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.6602,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6037975549697876,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8361,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5509572625160217,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.4216,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7482405304908752,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.3945,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8625118136405945,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.7002,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7192174792289734,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6841,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7142515182495117,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.6865,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7495271563529968,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.7471,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7775553464889526,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.6908,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5583651065826416,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.5281,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7792724370956421,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6543,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6158411502838135,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7052,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7116422653198242,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.8469,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2091479301452637,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.687,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8763923048973083,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.701,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7194721102714539,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5902,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.622972846031189,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.7281,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8785674571990967,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.7788,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.561694860458374,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.7398,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5931367874145508,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.9208,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8336869478225708,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.4492,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7663393616676331,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6691,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6989089846611023,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.8855,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5969981551170349,
      "learning_rate": 0.00018359961501443698,
      "loss": 0.8035,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.556025505065918,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.9405,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5868527293205261,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.927,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.747269332408905,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7711,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5778203010559082,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.5097,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7665207982063293,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7753,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6795540452003479,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.6638,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7306339144706726,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.4294,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.641844630241394,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.6496,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.660853385925293,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.5296,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7177244424819946,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.4683,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2018318176269531,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.9297,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8318695425987244,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.6177,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5980833172798157,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.5037,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7439042329788208,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7146,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8085542917251587,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.6122,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6640565395355225,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.5139,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0524460077285767,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.7783,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.617692232131958,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.9802,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.122811198234558,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.6802,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8143771290779114,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.6618,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6935192346572876,
      "learning_rate": 0.00018279114533205007,
      "loss": 1.1362,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7444424033164978,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8607,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5704548358917236,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5804,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5939321517944336,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.7454,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.974220335483551,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.5903,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.843052864074707,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.6173,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6161561012268066,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.5802,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8895635008811951,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.3974,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5754928588867188,
      "learning_rate": 0.00018248315688161696,
      "loss": 0.7096,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7855966091156006,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7746,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6445358395576477,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7296,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5740096569061279,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8779,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7613345384597778,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.5638,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7333557605743408,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.5855,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7124179005622864,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.7167,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.638280987739563,
      "learning_rate": 0.000182213666987488,
      "loss": 0.9548,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9654234051704407,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.7242,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7197368144989014,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.6723,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5494047999382019,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8031,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5353728532791138,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.8029,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6315490007400513,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.5837,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7555389404296875,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7125,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8384435772895813,
      "learning_rate": 0.000181944177093359,
      "loss": 0.5034,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5619967579841614,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8396,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7444220185279846,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.8219,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5551384091377258,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.7687,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7309958338737488,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.6539,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.614891767501831,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.5977,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7716305255889893,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7605,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7078102827072144,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8178,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7726227641105652,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.7639,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.777751624584198,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.6402,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9366869926452637,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.8419,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7884979248046875,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.4486,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8710904121398926,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.5999,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6384978294372559,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7706,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7797781825065613,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.5892,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6219421029090881,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.6704,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9979626536369324,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.4893,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6125726699829102,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.5604,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6936690807342529,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.6456,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6553232073783875,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.8872,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7319735288619995,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.5098,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6700308918952942,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8333,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8183261156082153,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6948,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9010966420173645,
      "learning_rate": 0.0001810587102983638,
      "loss": 0.3522,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9813642501831055,
      "learning_rate": 0.00018102021174205968,
      "loss": 0.5139,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.735927939414978,
      "learning_rate": 0.00018098171318575555,
      "loss": 0.9666,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7688445448875427,
      "learning_rate": 0.0001809432146294514,
      "loss": 0.654,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7212250232696533,
      "learning_rate": 0.00018090471607314727,
      "loss": 0.4753,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6220759153366089,
      "learning_rate": 0.00018086621751684312,
      "loss": 0.6951,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.552781879901886,
      "learning_rate": 0.000180827718960539,
      "loss": 0.8248,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7625164985656738,
      "learning_rate": 0.00018078922040423484,
      "loss": 0.4531,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5779299139976501,
      "learning_rate": 0.00018075072184793072,
      "loss": 0.7087,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5191786289215088,
      "learning_rate": 0.0001807122232916266,
      "loss": 0.9063,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6027359962463379,
      "learning_rate": 0.00018067372473532244,
      "loss": 0.8213,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7313194274902344,
      "learning_rate": 0.00018063522617901828,
      "loss": 0.516,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5989764928817749,
      "learning_rate": 0.00018059672762271416,
      "loss": 1.0973,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7442408800125122,
      "learning_rate": 0.00018055822906641003,
      "loss": 0.5786,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6334717273712158,
      "learning_rate": 0.00018051973051010588,
      "loss": 0.4938,
      "step": 512
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5559924244880676,
      "learning_rate": 0.00018048123195380173,
      "loss": 0.8648,
      "step": 513
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5963814854621887,
      "learning_rate": 0.0001804427333974976,
      "loss": 0.5543,
      "step": 514
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8214461207389832,
      "learning_rate": 0.00018040423484119348,
      "loss": 0.7705,
      "step": 515
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8785788416862488,
      "learning_rate": 0.00018036573628488933,
      "loss": 0.4427,
      "step": 516
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7951868176460266,
      "learning_rate": 0.0001803272377285852,
      "loss": 0.5326,
      "step": 517
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6466233730316162,
      "learning_rate": 0.00018028873917228105,
      "loss": 0.6987,
      "step": 518
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7211444973945618,
      "learning_rate": 0.0001802502406159769,
      "loss": 0.7709,
      "step": 519
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.931510329246521,
      "learning_rate": 0.00018021174205967277,
      "loss": 0.5353,
      "step": 520
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.726398766040802,
      "learning_rate": 0.00018017324350336864,
      "loss": 0.4566,
      "step": 521
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9202558994293213,
      "learning_rate": 0.0001801347449470645,
      "loss": 0.8507,
      "step": 522
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6638332605361938,
      "learning_rate": 0.00018009624639076034,
      "loss": 0.7436,
      "step": 523
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.832954466342926,
      "learning_rate": 0.0001800577478344562,
      "loss": 0.5198,
      "step": 524
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8316726088523865,
      "learning_rate": 0.0001800192492781521,
      "loss": 0.5822,
      "step": 525
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6892343759536743,
      "learning_rate": 0.00017998075072184794,
      "loss": 0.769,
      "step": 526
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7093865275382996,
      "learning_rate": 0.00017994225216554378,
      "loss": 0.9413,
      "step": 527
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6044589281082153,
      "learning_rate": 0.00017990375360923966,
      "loss": 0.6977,
      "step": 528
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7711941599845886,
      "learning_rate": 0.00017986525505293553,
      "loss": 0.9329,
      "step": 529
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8691420555114746,
      "learning_rate": 0.00017982675649663138,
      "loss": 0.5256,
      "step": 530
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5082821846008301,
      "learning_rate": 0.00017978825794032725,
      "loss": 0.7816,
      "step": 531
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.570527195930481,
      "learning_rate": 0.0001797497593840231,
      "loss": 0.6493,
      "step": 532
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6981233358383179,
      "learning_rate": 0.00017971126082771898,
      "loss": 0.9473,
      "step": 533
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6987241506576538,
      "learning_rate": 0.00017967276227141482,
      "loss": 0.7451,
      "step": 534
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5137880444526672,
      "learning_rate": 0.0001796342637151107,
      "loss": 0.8249,
      "step": 535
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9250155687332153,
      "learning_rate": 0.00017959576515880657,
      "loss": 0.6099,
      "step": 536
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6776856184005737,
      "learning_rate": 0.0001795572666025024,
      "loss": 0.6047,
      "step": 537
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6719252467155457,
      "learning_rate": 0.00017951876804619827,
      "loss": 0.7126,
      "step": 538
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.590328574180603,
      "learning_rate": 0.00017948026948989414,
      "loss": 1.0215,
      "step": 539
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6601207852363586,
      "learning_rate": 0.00017944177093359002,
      "loss": 0.5115,
      "step": 540
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6893088817596436,
      "learning_rate": 0.00017940327237728586,
      "loss": 0.7127,
      "step": 541
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.621976375579834,
      "learning_rate": 0.0001793647738209817,
      "loss": 0.6285,
      "step": 542
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7940705418586731,
      "learning_rate": 0.00017932627526467759,
      "loss": 0.5925,
      "step": 543
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6036211848258972,
      "learning_rate": 0.00017928777670837343,
      "loss": 0.4134,
      "step": 544
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.587741494178772,
      "learning_rate": 0.0001792492781520693,
      "loss": 0.5489,
      "step": 545
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6074514985084534,
      "learning_rate": 0.00017921077959576518,
      "loss": 0.7261,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.035722255706787,
      "learning_rate": 0.00017917228103946103,
      "loss": 0.6641,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9030612707138062,
      "learning_rate": 0.00017913378248315688,
      "loss": 0.865,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5708800554275513,
      "learning_rate": 0.00017909528392685275,
      "loss": 0.6536,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7275450825691223,
      "learning_rate": 0.00017905678537054863,
      "loss": 0.4152,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5675240159034729,
      "learning_rate": 0.00017901828681424447,
      "loss": 0.5793,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6410626173019409,
      "learning_rate": 0.00017897978825794032,
      "loss": 0.6824,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7726817727088928,
      "learning_rate": 0.0001789412897016362,
      "loss": 0.7125,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8998408913612366,
      "learning_rate": 0.00017890279114533207,
      "loss": 0.3345,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6513839364051819,
      "learning_rate": 0.00017886429258902792,
      "loss": 0.5045,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.727322518825531,
      "learning_rate": 0.0001788257940327238,
      "loss": 0.7322,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6974987983703613,
      "learning_rate": 0.00017878729547641964,
      "loss": 0.6009,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7905023694038391,
      "learning_rate": 0.0001787487969201155,
      "loss": 0.6988,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9839308857917786,
      "learning_rate": 0.00017871029836381136,
      "loss": 0.6749,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7490098476409912,
      "learning_rate": 0.00017867179980750724,
      "loss": 0.6961,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0670418739318848,
      "learning_rate": 0.00017863330125120308,
      "loss": 0.5953,
      "step": 561
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.593356192111969,
      "learning_rate": 0.00017859480269489896,
      "loss": 0.7749,
      "step": 562
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7387890815734863,
      "learning_rate": 0.0001785563041385948,
      "loss": 0.5965,
      "step": 563
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6877281069755554,
      "learning_rate": 0.00017851780558229068,
      "loss": 0.6064,
      "step": 564
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5250972509384155,
      "learning_rate": 0.00017847930702598655,
      "loss": 0.7343,
      "step": 565
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6507566571235657,
      "learning_rate": 0.00017844080846968237,
      "loss": 0.7547,
      "step": 566
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6374786496162415,
      "learning_rate": 0.00017840230991337825,
      "loss": 0.7447,
      "step": 567
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5923673510551453,
      "learning_rate": 0.00017836381135707412,
      "loss": 0.6631,
      "step": 568
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5488978028297424,
      "learning_rate": 0.00017832531280076997,
      "loss": 0.6709,
      "step": 569
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0043591260910034,
      "learning_rate": 0.00017828681424446585,
      "loss": 0.6065,
      "step": 570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7207235097885132,
      "learning_rate": 0.0001782483156881617,
      "loss": 0.6428,
      "step": 571
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6688354015350342,
      "learning_rate": 0.00017820981713185757,
      "loss": 0.7885,
      "step": 572
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7515926361083984,
      "learning_rate": 0.00017817131857555341,
      "loss": 0.5332,
      "step": 573
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0833226442337036,
      "learning_rate": 0.0001781328200192493,
      "loss": 0.7669,
      "step": 574
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8054810166358948,
      "learning_rate": 0.00017809432146294516,
      "loss": 0.6776,
      "step": 575
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6206085681915283,
      "learning_rate": 0.000178055822906641,
      "loss": 0.559,
      "step": 576
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7385501861572266,
      "learning_rate": 0.00017801732435033686,
      "loss": 0.7062,
      "step": 577
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8732308745384216,
      "learning_rate": 0.00017797882579403273,
      "loss": 0.5078,
      "step": 578
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6646142601966858,
      "learning_rate": 0.0001779403272377286,
      "loss": 0.6726,
      "step": 579
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5578314065933228,
      "learning_rate": 0.00017790182868142445,
      "loss": 1.0685,
      "step": 580
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7208375334739685,
      "learning_rate": 0.0001778633301251203,
      "loss": 0.692,
      "step": 581
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9988183975219727,
      "learning_rate": 0.00017782483156881618,
      "loss": 0.758,
      "step": 582
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7599869966506958,
      "learning_rate": 0.00017778633301251205,
      "loss": 0.4665,
      "step": 583
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8353445529937744,
      "learning_rate": 0.0001777478344562079,
      "loss": 0.4908,
      "step": 584
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7772532105445862,
      "learning_rate": 0.00017770933589990377,
      "loss": 0.5119,
      "step": 585
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7856645584106445,
      "learning_rate": 0.00017767083734359962,
      "loss": 0.6478,
      "step": 586
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7736432552337646,
      "learning_rate": 0.0001776323387872955,
      "loss": 0.6798,
      "step": 587
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.662562370300293,
      "learning_rate": 0.00017759384023099134,
      "loss": 0.5114,
      "step": 588
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.737090528011322,
      "learning_rate": 0.00017755534167468722,
      "loss": 0.7474,
      "step": 589
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6457744240760803,
      "learning_rate": 0.00017751684311838306,
      "loss": 0.5693,
      "step": 590
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9803255796432495,
      "learning_rate": 0.0001774783445620789,
      "loss": 0.7573,
      "step": 591
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.612112283706665,
      "learning_rate": 0.0001774398460057748,
      "loss": 0.7371,
      "step": 592
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9148984551429749,
      "learning_rate": 0.00017740134744947066,
      "loss": 0.724,
      "step": 593
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6975201964378357,
      "learning_rate": 0.0001773628488931665,
      "loss": 0.7316,
      "step": 594
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5441070795059204,
      "learning_rate": 0.00017732435033686236,
      "loss": 0.9123,
      "step": 595
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6095752120018005,
      "learning_rate": 0.00017728585178055823,
      "loss": 0.7638,
      "step": 596
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6558985114097595,
      "learning_rate": 0.0001772473532242541,
      "loss": 0.7515,
      "step": 597
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5151351094245911,
      "learning_rate": 0.00017720885466794995,
      "loss": 0.6675,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7533324360847473,
      "learning_rate": 0.00017717035611164583,
      "loss": 0.686,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6827309727668762,
      "learning_rate": 0.00017713185755534167,
      "loss": 0.5808,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8595276474952698,
      "learning_rate": 0.00017709335899903755,
      "loss": 0.5858,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6526479125022888,
      "learning_rate": 0.0001770548604427334,
      "loss": 0.6608,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7959790825843811,
      "learning_rate": 0.00017701636188642927,
      "loss": 0.6459,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9957267045974731,
      "learning_rate": 0.00017697786333012515,
      "loss": 0.7617,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1645805835723877,
      "learning_rate": 0.000176939364773821,
      "loss": 0.61,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6415759325027466,
      "learning_rate": 0.00017690086621751684,
      "loss": 0.7222,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8523719310760498,
      "learning_rate": 0.00017686236766121271,
      "loss": 0.8409,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.960444450378418,
      "learning_rate": 0.0001768238691049086,
      "loss": 0.5689,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8182255029678345,
      "learning_rate": 0.00017678537054860444,
      "loss": 0.4445,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7716516852378845,
      "learning_rate": 0.00017674687199230028,
      "loss": 0.3699,
      "step": 610
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9049159288406372,
      "learning_rate": 0.00017670837343599616,
      "loss": 0.8016,
      "step": 611
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5800634622573853,
      "learning_rate": 0.00017666987487969203,
      "loss": 0.9866,
      "step": 612
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8045703768730164,
      "learning_rate": 0.00017663137632338788,
      "loss": 0.6985,
      "step": 613
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7679507732391357,
      "learning_rate": 0.00017659287776708376,
      "loss": 0.618,
      "step": 614
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6198709011077881,
      "learning_rate": 0.0001765543792107796,
      "loss": 0.9051,
      "step": 615
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5902866721153259,
      "learning_rate": 0.00017651588065447545,
      "loss": 1.0978,
      "step": 616
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5553480386734009,
      "learning_rate": 0.00017647738209817132,
      "loss": 0.7345,
      "step": 617
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9051225781440735,
      "learning_rate": 0.0001764388835418672,
      "loss": 0.6342,
      "step": 618
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8280664682388306,
      "learning_rate": 0.00017640038498556307,
      "loss": 0.8419,
      "step": 619
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7987625002861023,
      "learning_rate": 0.0001763618864292589,
      "loss": 0.7314,
      "step": 620
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4194488525390625,
      "learning_rate": 0.00017632338787295477,
      "loss": 0.6009,
      "step": 621
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5878939032554626,
      "learning_rate": 0.00017628488931665064,
      "loss": 0.6127,
      "step": 622
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7140704989433289,
      "learning_rate": 0.0001762463907603465,
      "loss": 0.6811,
      "step": 623
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6153066754341125,
      "learning_rate": 0.00017620789220404234,
      "loss": 0.6095,
      "step": 624
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6382792592048645,
      "learning_rate": 0.0001761693936477382,
      "loss": 0.7885,
      "step": 625
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7713308334350586,
      "learning_rate": 0.0001761308950914341,
      "loss": 0.6111,
      "step": 626
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5835039615631104,
      "learning_rate": 0.00017609239653512993,
      "loss": 0.7126,
      "step": 627
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7846230864524841,
      "learning_rate": 0.0001760538979788258,
      "loss": 0.7349,
      "step": 628
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8369488716125488,
      "learning_rate": 0.00017601539942252166,
      "loss": 0.6081,
      "step": 629
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0105968713760376,
      "learning_rate": 0.00017597690086621753,
      "loss": 0.8593,
      "step": 630
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7178121209144592,
      "learning_rate": 0.00017593840230991338,
      "loss": 0.7101,
      "step": 631
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.814546525478363,
      "learning_rate": 0.00017589990375360925,
      "loss": 0.8779,
      "step": 632
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7966509461402893,
      "learning_rate": 0.00017586140519730513,
      "loss": 0.72,
      "step": 633
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8122262954711914,
      "learning_rate": 0.00017582290664100097,
      "loss": 0.5069,
      "step": 634
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8662346601486206,
      "learning_rate": 0.00017578440808469682,
      "loss": 0.6848,
      "step": 635
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.808278501033783,
      "learning_rate": 0.0001757459095283927,
      "loss": 0.668,
      "step": 636
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5995301008224487,
      "learning_rate": 0.00017570741097208857,
      "loss": 0.5213,
      "step": 637
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4677468538284302,
      "learning_rate": 0.00017566891241578442,
      "loss": 0.6333,
      "step": 638
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6823005676269531,
      "learning_rate": 0.00017563041385948027,
      "loss": 0.6939,
      "step": 639
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4946478009223938,
      "learning_rate": 0.00017559191530317614,
      "loss": 0.7331,
      "step": 640
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.585574209690094,
      "learning_rate": 0.000175553416746872,
      "loss": 0.6717,
      "step": 641
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7856736183166504,
      "learning_rate": 0.00017551491819056786,
      "loss": 0.4537,
      "step": 642
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7468209266662598,
      "learning_rate": 0.00017547641963426374,
      "loss": 0.3988,
      "step": 643
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.663483202457428,
      "learning_rate": 0.00017543792107795958,
      "loss": 0.525,
      "step": 644
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5496599674224854,
      "learning_rate": 0.00017539942252165543,
      "loss": 0.6177,
      "step": 645
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7893540859222412,
      "learning_rate": 0.0001753609239653513,
      "loss": 0.5153,
      "step": 646
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5082350969314575,
      "learning_rate": 0.00017532242540904718,
      "loss": 0.9337,
      "step": 647
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6387757658958435,
      "learning_rate": 0.00017528392685274303,
      "loss": 0.5653,
      "step": 648
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5962136387825012,
      "learning_rate": 0.00017524542829643888,
      "loss": 0.6799,
      "step": 649
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5888770818710327,
      "learning_rate": 0.00017520692974013475,
      "loss": 0.6807,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6050287485122681,
      "learning_rate": 0.00017516843118383063,
      "loss": 0.6633,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9544339776039124,
      "learning_rate": 0.00017512993262752647,
      "loss": 0.9371,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.730651319026947,
      "learning_rate": 0.00017509143407122232,
      "loss": 0.6864,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7352924942970276,
      "learning_rate": 0.0001750529355149182,
      "loss": 0.7243,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8686752319335938,
      "learning_rate": 0.00017501443695861407,
      "loss": 0.4024,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8120374083518982,
      "learning_rate": 0.00017497593840230992,
      "loss": 0.3866,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6852021217346191,
      "learning_rate": 0.0001749374398460058,
      "loss": 0.4215,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5634097456932068,
      "learning_rate": 0.00017489894128970164,
      "loss": 0.7206,
      "step": 658
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7309567332267761,
      "learning_rate": 0.0001748604427333975,
      "loss": 0.4515,
      "step": 659
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5597043037414551,
      "learning_rate": 0.00017482194417709336,
      "loss": 0.7859,
      "step": 660
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.774241030216217,
      "learning_rate": 0.00017478344562078923,
      "loss": 0.5952,
      "step": 661
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8863543272018433,
      "learning_rate": 0.0001747449470644851,
      "loss": 0.3879,
      "step": 662
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6434614658355713,
      "learning_rate": 0.00017470644850818093,
      "loss": 0.8632,
      "step": 663
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8221364617347717,
      "learning_rate": 0.0001746679499518768,
      "loss": 0.6685,
      "step": 664
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.75003981590271,
      "learning_rate": 0.00017462945139557268,
      "loss": 0.6803,
      "step": 665
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7057366371154785,
      "learning_rate": 0.00017459095283926855,
      "loss": 0.5605,
      "step": 666
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5842887163162231,
      "learning_rate": 0.0001745524542829644,
      "loss": 0.594,
      "step": 667
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5622215270996094,
      "learning_rate": 0.00017451395572666025,
      "loss": 1.0226,
      "step": 668
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6369432806968689,
      "learning_rate": 0.00017447545717035612,
      "loss": 0.9267,
      "step": 669
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5875369310379028,
      "learning_rate": 0.00017443695861405197,
      "loss": 0.743,
      "step": 670
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.951618492603302,
      "learning_rate": 0.00017439846005774784,
      "loss": 0.475,
      "step": 671
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.60471510887146,
      "learning_rate": 0.00017435996150144372,
      "loss": 0.4755,
      "step": 672
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5699655413627625,
      "learning_rate": 0.00017432146294513957,
      "loss": 0.7449,
      "step": 673
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9288299083709717,
      "learning_rate": 0.00017428296438883541,
      "loss": 0.5567,
      "step": 674
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.789043664932251,
      "learning_rate": 0.0001742444658325313,
      "loss": 0.6825,
      "step": 675
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5014984607696533,
      "learning_rate": 0.00017420596727622716,
      "loss": 0.7945,
      "step": 676
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.899013876914978,
      "learning_rate": 0.000174167468719923,
      "loss": 0.5108,
      "step": 677
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7104153037071228,
      "learning_rate": 0.00017412897016361886,
      "loss": 0.9547,
      "step": 678
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5267176628112793,
      "learning_rate": 0.00017409047160731473,
      "loss": 0.6264,
      "step": 679
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.846923291683197,
      "learning_rate": 0.0001740519730510106,
      "loss": 0.5874,
      "step": 680
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.48755204677581787,
      "learning_rate": 0.00017401347449470645,
      "loss": 0.8508,
      "step": 681
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.099907636642456,
      "learning_rate": 0.00017397497593840233,
      "loss": 0.401,
      "step": 682
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5264143943786621,
      "learning_rate": 0.00017393647738209818,
      "loss": 0.7577,
      "step": 683
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5646629333496094,
      "learning_rate": 0.00017389797882579405,
      "loss": 0.7911,
      "step": 684
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7983838319778442,
      "learning_rate": 0.0001738594802694899,
      "loss": 0.5762,
      "step": 685
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6316927671432495,
      "learning_rate": 0.00017382098171318577,
      "loss": 0.5952,
      "step": 686
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5015628933906555,
      "learning_rate": 0.00017378248315688162,
      "loss": 0.7939,
      "step": 687
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5893049836158752,
      "learning_rate": 0.00017374398460057747,
      "loss": 0.7664,
      "step": 688
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7587557435035706,
      "learning_rate": 0.00017370548604427334,
      "loss": 0.4553,
      "step": 689
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7824079990386963,
      "learning_rate": 0.00017366698748796922,
      "loss": 0.5953,
      "step": 690
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6611518263816833,
      "learning_rate": 0.0001736284889316651,
      "loss": 0.8156,
      "step": 691
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7224558591842651,
      "learning_rate": 0.0001735899903753609,
      "loss": 0.9078,
      "step": 692
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5992814898490906,
      "learning_rate": 0.00017355149181905679,
      "loss": 0.6275,
      "step": 693
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6290112137794495,
      "learning_rate": 0.00017351299326275266,
      "loss": 0.4064,
      "step": 694
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7407623529434204,
      "learning_rate": 0.0001734744947064485,
      "loss": 0.7741,
      "step": 695
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6758849024772644,
      "learning_rate": 0.00017343599615014438,
      "loss": 0.8718,
      "step": 696
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5055411458015442,
      "learning_rate": 0.00017339749759384023,
      "loss": 0.6955,
      "step": 697
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6418925523757935,
      "learning_rate": 0.0001733589990375361,
      "loss": 0.5726,
      "step": 698
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.544043242931366,
      "learning_rate": 0.00017332050048123195,
      "loss": 0.8035,
      "step": 699
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5846039652824402,
      "learning_rate": 0.00017328200192492783,
      "loss": 0.9237,
      "step": 700
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7197829484939575,
      "learning_rate": 0.0001732435033686237,
      "loss": 0.7812,
      "step": 701
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6238186955451965,
      "learning_rate": 0.00017320500481231955,
      "loss": 0.7466,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.727378785610199,
      "learning_rate": 0.0001731665062560154,
      "loss": 0.5334,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5501028299331665,
      "learning_rate": 0.00017312800769971127,
      "loss": 0.8214,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2805166244506836,
      "learning_rate": 0.00017308950914340715,
      "loss": 0.7995,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7582862973213196,
      "learning_rate": 0.000173051010587103,
      "loss": 0.6,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5532718300819397,
      "learning_rate": 0.00017301251203079884,
      "loss": 0.8732,
      "step": 707
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7867195010185242,
      "learning_rate": 0.00017297401347449471,
      "loss": 0.4442,
      "step": 708
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8325200080871582,
      "learning_rate": 0.0001729355149181906,
      "loss": 0.8357,
      "step": 709
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6667035818099976,
      "learning_rate": 0.00017289701636188644,
      "loss": 0.512,
      "step": 710
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.560309886932373,
      "learning_rate": 0.0001728585178055823,
      "loss": 0.7318,
      "step": 711
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6525481343269348,
      "learning_rate": 0.00017282001924927816,
      "loss": 0.4812,
      "step": 712
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6163297891616821,
      "learning_rate": 0.00017278152069297403,
      "loss": 0.7147,
      "step": 713
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7186746001243591,
      "learning_rate": 0.00017274302213666988,
      "loss": 0.5202,
      "step": 714
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6319488286972046,
      "learning_rate": 0.00017270452358036575,
      "loss": 0.6177,
      "step": 715
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5327817797660828,
      "learning_rate": 0.0001726660250240616,
      "loss": 0.8867,
      "step": 716
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.631850004196167,
      "learning_rate": 0.00017262752646775745,
      "loss": 0.5904,
      "step": 717
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0348049402236938,
      "learning_rate": 0.00017258902791145332,
      "loss": 0.6731,
      "step": 718
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8771058917045593,
      "learning_rate": 0.0001725505293551492,
      "loss": 0.6187,
      "step": 719
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6889843344688416,
      "learning_rate": 0.00017251203079884505,
      "loss": 0.4958,
      "step": 720
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3221871852874756,
      "learning_rate": 0.0001724735322425409,
      "loss": 0.6228,
      "step": 721
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.657353401184082,
      "learning_rate": 0.00017243503368623677,
      "loss": 0.8238,
      "step": 722
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6382782459259033,
      "learning_rate": 0.00017239653512993264,
      "loss": 0.5587,
      "step": 723
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7012105584144592,
      "learning_rate": 0.0001723580365736285,
      "loss": 0.8,
      "step": 724
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5702588558197021,
      "learning_rate": 0.00017231953801732436,
      "loss": 0.7373,
      "step": 725
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.580787181854248,
      "learning_rate": 0.0001722810394610202,
      "loss": 0.6532,
      "step": 726
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9424101710319519,
      "learning_rate": 0.0001722425409047161,
      "loss": 0.691,
      "step": 727
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5700766444206238,
      "learning_rate": 0.00017220404234841193,
      "loss": 0.9479,
      "step": 728
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8822431564331055,
      "learning_rate": 0.0001721655437921078,
      "loss": 0.7931,
      "step": 729
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.60028076171875,
      "learning_rate": 0.00017212704523580368,
      "loss": 0.853,
      "step": 730
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6144394874572754,
      "learning_rate": 0.00017208854667949953,
      "loss": 0.5604,
      "step": 731
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5580691695213318,
      "learning_rate": 0.00017205004812319538,
      "loss": 0.9066,
      "step": 732
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8239931464195251,
      "learning_rate": 0.00017201154956689125,
      "loss": 0.6029,
      "step": 733
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.631584644317627,
      "learning_rate": 0.00017197305101058713,
      "loss": 0.8749,
      "step": 734
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5895825028419495,
      "learning_rate": 0.00017193455245428297,
      "loss": 1.0,
      "step": 735
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7585741877555847,
      "learning_rate": 0.00017189605389797882,
      "loss": 0.5066,
      "step": 736
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5624192357063293,
      "learning_rate": 0.0001718575553416747,
      "loss": 0.8899,
      "step": 737
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6331326365470886,
      "learning_rate": 0.00017181905678537057,
      "loss": 0.7708,
      "step": 738
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6612368822097778,
      "learning_rate": 0.00017178055822906642,
      "loss": 0.7908,
      "step": 739
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.537795901298523,
      "learning_rate": 0.0001717420596727623,
      "loss": 1.0507,
      "step": 740
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.63994961977005,
      "learning_rate": 0.00017170356111645814,
      "loss": 0.741,
      "step": 741
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5982149243354797,
      "learning_rate": 0.000171665062560154,
      "loss": 0.9094,
      "step": 742
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6481786966323853,
      "learning_rate": 0.00017162656400384986,
      "loss": 0.8208,
      "step": 743
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7011485695838928,
      "learning_rate": 0.00017158806544754574,
      "loss": 0.5921,
      "step": 744
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5335140228271484,
      "learning_rate": 0.00017154956689124158,
      "loss": 0.6913,
      "step": 745
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5654804706573486,
      "learning_rate": 0.00017151106833493743,
      "loss": 0.6341,
      "step": 746
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7928334474563599,
      "learning_rate": 0.0001714725697786333,
      "loss": 0.6874,
      "step": 747
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.664972186088562,
      "learning_rate": 0.00017143407122232918,
      "loss": 0.3183,
      "step": 748
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.590420663356781,
      "learning_rate": 0.00017139557266602503,
      "loss": 0.6657,
      "step": 749
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6630308628082275,
      "learning_rate": 0.00017135707410972088,
      "loss": 0.5156,
      "step": 750
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.747826337814331,
      "learning_rate": 0.00017131857555341675,
      "loss": 0.6854,
      "step": 751
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6466501355171204,
      "learning_rate": 0.00017128007699711262,
      "loss": 0.4931,
      "step": 752
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5631003975868225,
      "learning_rate": 0.00017124157844080847,
      "loss": 0.7544,
      "step": 753
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7567971348762512,
      "learning_rate": 0.00017120307988450435,
      "loss": 0.6292,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7276394963264465,
      "learning_rate": 0.0001711645813282002,
      "loss": 0.7828,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7270777821540833,
      "learning_rate": 0.00017112608277189607,
      "loss": 0.7011,
      "step": 756
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7072964310646057,
      "learning_rate": 0.00017108758421559192,
      "loss": 0.8898,
      "step": 757
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6416227221488953,
      "learning_rate": 0.0001710490856592878,
      "loss": 0.7439,
      "step": 758
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6943629384040833,
      "learning_rate": 0.00017101058710298366,
      "loss": 0.3518,
      "step": 759
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6809807419776917,
      "learning_rate": 0.00017097208854667949,
      "loss": 0.5327,
      "step": 760
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6298185586929321,
      "learning_rate": 0.00017093358999037536,
      "loss": 0.4947,
      "step": 761
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6605240702629089,
      "learning_rate": 0.00017089509143407123,
      "loss": 0.7841,
      "step": 762
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6261136531829834,
      "learning_rate": 0.0001708565928777671,
      "loss": 0.6676,
      "step": 763
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6623320579528809,
      "learning_rate": 0.00017081809432146296,
      "loss": 0.4637,
      "step": 764
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5202741622924805,
      "learning_rate": 0.0001707795957651588,
      "loss": 0.6615,
      "step": 765
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.781020998954773,
      "learning_rate": 0.00017074109720885468,
      "loss": 0.4888,
      "step": 766
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7154417037963867,
      "learning_rate": 0.00017070259865255053,
      "loss": 0.7341,
      "step": 767
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7510635256767273,
      "learning_rate": 0.0001706641000962464,
      "loss": 0.7151,
      "step": 768
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7465168237686157,
      "learning_rate": 0.00017062560153994227,
      "loss": 0.451,
      "step": 769
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5354093909263611,
      "learning_rate": 0.00017058710298363812,
      "loss": 0.628,
      "step": 770
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8772189021110535,
      "learning_rate": 0.00017054860442733397,
      "loss": 0.6218,
      "step": 771
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.585827648639679,
      "learning_rate": 0.00017051010587102984,
      "loss": 0.7159,
      "step": 772
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6923907399177551,
      "learning_rate": 0.00017047160731472572,
      "loss": 0.6357,
      "step": 773
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6226284503936768,
      "learning_rate": 0.00017043310875842157,
      "loss": 1.0871,
      "step": 774
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6244713068008423,
      "learning_rate": 0.0001703946102021174,
      "loss": 0.6863,
      "step": 775
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6152127385139465,
      "learning_rate": 0.0001703561116458133,
      "loss": 0.7153,
      "step": 776
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6817339062690735,
      "learning_rate": 0.00017031761308950916,
      "loss": 0.6311,
      "step": 777
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5896717309951782,
      "learning_rate": 0.000170279114533205,
      "loss": 0.7819,
      "step": 778
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7084118127822876,
      "learning_rate": 0.00017024061597690086,
      "loss": 0.5395,
      "step": 779
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9470891356468201,
      "learning_rate": 0.00017020211742059673,
      "loss": 0.7325,
      "step": 780
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6593203544616699,
      "learning_rate": 0.0001701636188642926,
      "loss": 0.7159,
      "step": 781
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7264378070831299,
      "learning_rate": 0.00017012512030798845,
      "loss": 0.6538,
      "step": 782
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5907986164093018,
      "learning_rate": 0.00017008662175168433,
      "loss": 0.6971,
      "step": 783
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7287831902503967,
      "learning_rate": 0.00017004812319538018,
      "loss": 0.7411,
      "step": 784
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7446874976158142,
      "learning_rate": 0.00017000962463907605,
      "loss": 0.678,
      "step": 785
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7808102965354919,
      "learning_rate": 0.0001699711260827719,
      "loss": 0.5798,
      "step": 786
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7400268316268921,
      "learning_rate": 0.00016993262752646777,
      "loss": 0.6782,
      "step": 787
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6220332384109497,
      "learning_rate": 0.00016989412897016365,
      "loss": 0.5347,
      "step": 788
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6541516780853271,
      "learning_rate": 0.00016985563041385947,
      "loss": 0.6945,
      "step": 789
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.674069344997406,
      "learning_rate": 0.00016981713185755534,
      "loss": 0.839,
      "step": 790
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8589106798171997,
      "learning_rate": 0.00016977863330125122,
      "loss": 0.3321,
      "step": 791
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.650364875793457,
      "learning_rate": 0.00016974013474494706,
      "loss": 0.6517,
      "step": 792
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6298140287399292,
      "learning_rate": 0.00016970163618864294,
      "loss": 0.5756,
      "step": 793
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6950608491897583,
      "learning_rate": 0.00016966313763233879,
      "loss": 0.9298,
      "step": 794
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6557475924491882,
      "learning_rate": 0.00016962463907603466,
      "loss": 0.553,
      "step": 795
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7760496139526367,
      "learning_rate": 0.0001695861405197305,
      "loss": 0.6943,
      "step": 796
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6061364412307739,
      "learning_rate": 0.00016954764196342638,
      "loss": 0.6477,
      "step": 797
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5182318091392517,
      "learning_rate": 0.00016950914340712226,
      "loss": 0.7018,
      "step": 798
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.507469117641449,
      "learning_rate": 0.0001694706448508181,
      "loss": 0.8711,
      "step": 799
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7543202042579651,
      "learning_rate": 0.00016943214629451395,
      "loss": 0.5413,
      "step": 800
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5509201884269714,
      "learning_rate": 0.00016939364773820983,
      "loss": 0.9482,
      "step": 801
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6850157380104065,
      "learning_rate": 0.0001693551491819057,
      "loss": 0.734,
      "step": 802
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8136283755302429,
      "learning_rate": 0.00016931665062560155,
      "loss": 0.3779,
      "step": 803
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6029354333877563,
      "learning_rate": 0.0001692781520692974,
      "loss": 0.575,
      "step": 804
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7049925327301025,
      "learning_rate": 0.00016923965351299327,
      "loss": 0.4586,
      "step": 805
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.592093288898468,
      "learning_rate": 0.00016920115495668914,
      "loss": 0.4208,
      "step": 806
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5438862442970276,
      "learning_rate": 0.000169162656400385,
      "loss": 0.8563,
      "step": 807
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6113837361335754,
      "learning_rate": 0.00016912415784408087,
      "loss": 0.6691,
      "step": 808
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6554896235466003,
      "learning_rate": 0.00016908565928777671,
      "loss": 0.5728,
      "step": 809
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6518779993057251,
      "learning_rate": 0.0001690471607314726,
      "loss": 0.7557,
      "step": 810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6213161945343018,
      "learning_rate": 0.00016900866217516844,
      "loss": 0.9093,
      "step": 811
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7025657296180725,
      "learning_rate": 0.0001689701636188643,
      "loss": 0.5286,
      "step": 812
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.620762050151825,
      "learning_rate": 0.00016893166506256016,
      "loss": 0.4259,
      "step": 813
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6192619800567627,
      "learning_rate": 0.000168893166506256,
      "loss": 0.883,
      "step": 814
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5870999097824097,
      "learning_rate": 0.00016885466794995188,
      "loss": 0.4531,
      "step": 815
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6501561403274536,
      "learning_rate": 0.00016881616939364775,
      "loss": 0.526,
      "step": 816
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7252989411354065,
      "learning_rate": 0.00016877767083734363,
      "loss": 0.4033,
      "step": 817
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5101154446601868,
      "learning_rate": 0.00016873917228103945,
      "loss": 0.6646,
      "step": 818
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6377429962158203,
      "learning_rate": 0.00016870067372473532,
      "loss": 0.425,
      "step": 819
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6790304780006409,
      "learning_rate": 0.0001686621751684312,
      "loss": 0.6064,
      "step": 820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6745540499687195,
      "learning_rate": 0.00016862367661212705,
      "loss": 0.4713,
      "step": 821
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5900378823280334,
      "learning_rate": 0.00016858517805582292,
      "loss": 0.4642,
      "step": 822
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8406713008880615,
      "learning_rate": 0.00016854667949951877,
      "loss": 0.5647,
      "step": 823
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7246276140213013,
      "learning_rate": 0.00016850818094321464,
      "loss": 0.5944,
      "step": 824
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.729605495929718,
      "learning_rate": 0.0001684696823869105,
      "loss": 0.8003,
      "step": 825
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5967618227005005,
      "learning_rate": 0.00016843118383060636,
      "loss": 0.7253,
      "step": 826
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5960533022880554,
      "learning_rate": 0.00016839268527430224,
      "loss": 0.5132,
      "step": 827
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6901223063468933,
      "learning_rate": 0.00016835418671799809,
      "loss": 0.6704,
      "step": 828
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7164360880851746,
      "learning_rate": 0.00016831568816169393,
      "loss": 0.7785,
      "step": 829
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7042586207389832,
      "learning_rate": 0.0001682771896053898,
      "loss": 0.633,
      "step": 830
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7049960494041443,
      "learning_rate": 0.00016823869104908568,
      "loss": 0.6966,
      "step": 831
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.650780975818634,
      "learning_rate": 0.00016820019249278153,
      "loss": 0.9112,
      "step": 832
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7429491877555847,
      "learning_rate": 0.00016816169393647738,
      "loss": 0.451,
      "step": 833
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8485577702522278,
      "learning_rate": 0.00016812319538017325,
      "loss": 0.712,
      "step": 834
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6208774447441101,
      "learning_rate": 0.00016808469682386913,
      "loss": 0.9166,
      "step": 835
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7442309260368347,
      "learning_rate": 0.00016804619826756497,
      "loss": 0.5191,
      "step": 836
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6214428544044495,
      "learning_rate": 0.00016800769971126085,
      "loss": 1.036,
      "step": 837
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.561028003692627,
      "learning_rate": 0.0001679692011549567,
      "loss": 0.7306,
      "step": 838
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6167818307876587,
      "learning_rate": 0.00016793070259865254,
      "loss": 0.8272,
      "step": 839
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6941654682159424,
      "learning_rate": 0.00016789220404234842,
      "loss": 0.6402,
      "step": 840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8015614151954651,
      "learning_rate": 0.0001678537054860443,
      "loss": 0.5014,
      "step": 841
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5019364356994629,
      "learning_rate": 0.00016781520692974014,
      "loss": 0.6128,
      "step": 842
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.7343227863311768,
      "learning_rate": 0.000167776708373436,
      "loss": 0.8232,
      "step": 843
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8433186411857605,
      "learning_rate": 0.00016773820981713186,
      "loss": 0.6303,
      "step": 844
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9831601977348328,
      "learning_rate": 0.00016769971126082774,
      "loss": 0.5791,
      "step": 845
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6429057717323303,
      "learning_rate": 0.00016766121270452358,
      "loss": 0.723,
      "step": 846
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6961003541946411,
      "learning_rate": 0.00016762271414821943,
      "loss": 0.5658,
      "step": 847
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8514600396156311,
      "learning_rate": 0.0001675842155919153,
      "loss": 0.6071,
      "step": 848
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5562446713447571,
      "learning_rate": 0.00016754571703561118,
      "loss": 0.6296,
      "step": 849
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6539165377616882,
      "learning_rate": 0.00016750721847930703,
      "loss": 0.5737,
      "step": 850
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.685072660446167,
      "learning_rate": 0.0001674687199230029,
      "loss": 0.7883,
      "step": 851
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8172012567520142,
      "learning_rate": 0.00016743022136669875,
      "loss": 0.5847,
      "step": 852
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6637850999832153,
      "learning_rate": 0.00016739172281039462,
      "loss": 0.7267,
      "step": 853
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9587538838386536,
      "learning_rate": 0.00016735322425409047,
      "loss": 0.5408,
      "step": 854
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6579755544662476,
      "learning_rate": 0.00016731472569778635,
      "loss": 0.7071,
      "step": 855
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5417776107788086,
      "learning_rate": 0.00016727622714148222,
      "loss": 0.9095,
      "step": 856
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.77644282579422,
      "learning_rate": 0.00016723772858517807,
      "loss": 0.6109,
      "step": 857
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6420778036117554,
      "learning_rate": 0.00016719923002887392,
      "loss": 0.6785,
      "step": 858
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6844477653503418,
      "learning_rate": 0.0001671607314725698,
      "loss": 0.645,
      "step": 859
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5882246494293213,
      "learning_rate": 0.00016712223291626566,
      "loss": 0.7978,
      "step": 860
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6891993284225464,
      "learning_rate": 0.0001670837343599615,
      "loss": 0.7003,
      "step": 861
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7371298670768738,
      "learning_rate": 0.00016704523580365736,
      "loss": 0.7108,
      "step": 862
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7596960067749023,
      "learning_rate": 0.00016700673724735323,
      "loss": 0.725,
      "step": 863
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8753847479820251,
      "learning_rate": 0.0001669682386910491,
      "loss": 0.3398,
      "step": 864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5705381631851196,
      "learning_rate": 0.00016692974013474496,
      "loss": 0.6416,
      "step": 865
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5781949758529663,
      "learning_rate": 0.00016689124157844083,
      "loss": 0.7469,
      "step": 866
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7435440421104431,
      "learning_rate": 0.00016685274302213668,
      "loss": 0.5541,
      "step": 867
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6507339477539062,
      "learning_rate": 0.00016681424446583253,
      "loss": 0.7938,
      "step": 868
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7827209234237671,
      "learning_rate": 0.0001667757459095284,
      "loss": 0.7759,
      "step": 869
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7459266185760498,
      "learning_rate": 0.00016673724735322427,
      "loss": 0.5668,
      "step": 870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7030891180038452,
      "learning_rate": 0.00016669874879692012,
      "loss": 0.4744,
      "step": 871
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6184287071228027,
      "learning_rate": 0.00016666025024061597,
      "loss": 0.6239,
      "step": 872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6977325081825256,
      "learning_rate": 0.00016662175168431184,
      "loss": 0.7472,
      "step": 873
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5548222661018372,
      "learning_rate": 0.00016658325312800772,
      "loss": 0.6034,
      "step": 874
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.767720103263855,
      "learning_rate": 0.00016654475457170357,
      "loss": 0.7184,
      "step": 875
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6386733651161194,
      "learning_rate": 0.0001665062560153994,
      "loss": 1.0008,
      "step": 876
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.804498016834259,
      "learning_rate": 0.0001664677574590953,
      "loss": 0.6764,
      "step": 877
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6173493266105652,
      "learning_rate": 0.00016642925890279116,
      "loss": 0.5462,
      "step": 878
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.698773741722107,
      "learning_rate": 0.000166390760346487,
      "loss": 0.61,
      "step": 879
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7850584387779236,
      "learning_rate": 0.00016635226179018288,
      "loss": 0.7905,
      "step": 880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.732761025428772,
      "learning_rate": 0.00016631376323387873,
      "loss": 0.4881,
      "step": 881
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7245400547981262,
      "learning_rate": 0.0001662752646775746,
      "loss": 0.7452,
      "step": 882
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5255295634269714,
      "learning_rate": 0.00016623676612127045,
      "loss": 0.6612,
      "step": 883
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5276505947113037,
      "learning_rate": 0.00016619826756496633,
      "loss": 0.8135,
      "step": 884
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6914088726043701,
      "learning_rate": 0.0001661597690086622,
      "loss": 0.8099,
      "step": 885
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7663986682891846,
      "learning_rate": 0.00016612127045235802,
      "loss": 0.5437,
      "step": 886
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8458823561668396,
      "learning_rate": 0.0001660827718960539,
      "loss": 0.6179,
      "step": 887
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6551546454429626,
      "learning_rate": 0.00016604427333974977,
      "loss": 0.5903,
      "step": 888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5023525357246399,
      "learning_rate": 0.00016600577478344565,
      "loss": 0.988,
      "step": 889
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5599257946014404,
      "learning_rate": 0.0001659672762271415,
      "loss": 0.6622,
      "step": 890
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8117944598197937,
      "learning_rate": 0.00016592877767083734,
      "loss": 0.7773,
      "step": 891
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7767010927200317,
      "learning_rate": 0.00016589027911453322,
      "loss": 0.8024,
      "step": 892
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6088848114013672,
      "learning_rate": 0.00016585178055822906,
      "loss": 0.6926,
      "step": 893
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5286434888839722,
      "learning_rate": 0.00016581328200192494,
      "loss": 0.6858,
      "step": 894
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5697369575500488,
      "learning_rate": 0.0001657747834456208,
      "loss": 1.1228,
      "step": 895
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.643172025680542,
      "learning_rate": 0.00016573628488931666,
      "loss": 0.6541,
      "step": 896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8290871977806091,
      "learning_rate": 0.0001656977863330125,
      "loss": 0.6177,
      "step": 897
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6258559823036194,
      "learning_rate": 0.00016565928777670838,
      "loss": 0.8617,
      "step": 898
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.663238525390625,
      "learning_rate": 0.00016562078922040426,
      "loss": 0.6367,
      "step": 899
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.589301586151123,
      "learning_rate": 0.0001655822906641001,
      "loss": 0.6624,
      "step": 900
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6248452663421631,
      "learning_rate": 0.00016554379210779595,
      "loss": 0.8319,
      "step": 901
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.705293595790863,
      "learning_rate": 0.00016550529355149183,
      "loss": 0.6169,
      "step": 902
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6331523656845093,
      "learning_rate": 0.0001654667949951877,
      "loss": 0.7537,
      "step": 903
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7134804129600525,
      "learning_rate": 0.00016542829643888355,
      "loss": 0.3086,
      "step": 904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6021867394447327,
      "learning_rate": 0.0001653897978825794,
      "loss": 0.5772,
      "step": 905
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7428727149963379,
      "learning_rate": 0.00016535129932627527,
      "loss": 0.6407,
      "step": 906
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6161805391311646,
      "learning_rate": 0.00016531280076997114,
      "loss": 0.5114,
      "step": 907
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7714093327522278,
      "learning_rate": 0.000165274302213667,
      "loss": 0.7504,
      "step": 908
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.49686864018440247,
      "learning_rate": 0.00016523580365736287,
      "loss": 0.6508,
      "step": 909
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4398133456707001,
      "learning_rate": 0.0001651973051010587,
      "loss": 0.9456,
      "step": 910
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6514369249343872,
      "learning_rate": 0.00016515880654475456,
      "loss": 0.6558,
      "step": 911
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5922074317932129,
      "learning_rate": 0.00016512030798845044,
      "loss": 0.9348,
      "step": 912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4994887709617615,
      "learning_rate": 0.0001650818094321463,
      "loss": 0.7882,
      "step": 913
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.610044002532959,
      "learning_rate": 0.00016504331087584218,
      "loss": 0.7296,
      "step": 914
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.541244387626648,
      "learning_rate": 0.000165004812319538,
      "loss": 0.6041,
      "step": 915
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.647895097732544,
      "learning_rate": 0.00016496631376323388,
      "loss": 0.8545,
      "step": 916
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5057229399681091,
      "learning_rate": 0.00016492781520692975,
      "loss": 0.5429,
      "step": 917
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5948362946510315,
      "learning_rate": 0.0001648893166506256,
      "loss": 0.5938,
      "step": 918
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4885636270046234,
      "learning_rate": 0.00016485081809432148,
      "loss": 0.8054,
      "step": 919
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7152469754219055,
      "learning_rate": 0.00016481231953801732,
      "loss": 0.3783,
      "step": 920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7695571780204773,
      "learning_rate": 0.0001647738209817132,
      "loss": 0.8633,
      "step": 921
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6682639718055725,
      "learning_rate": 0.00016473532242540905,
      "loss": 0.4561,
      "step": 922
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5497984290122986,
      "learning_rate": 0.00016469682386910492,
      "loss": 0.8941,
      "step": 923
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5009626746177673,
      "learning_rate": 0.0001646583253128008,
      "loss": 0.7276,
      "step": 924
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6433472633361816,
      "learning_rate": 0.00016461982675649664,
      "loss": 0.779,
      "step": 925
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6610133647918701,
      "learning_rate": 0.0001645813282001925,
      "loss": 0.4956,
      "step": 926
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8454409241676331,
      "learning_rate": 0.00016454282964388836,
      "loss": 0.5986,
      "step": 927
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.823089599609375,
      "learning_rate": 0.00016450433108758424,
      "loss": 0.4776,
      "step": 928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6618831753730774,
      "learning_rate": 0.00016446583253128009,
      "loss": 1.0351,
      "step": 929
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6922567486763,
      "learning_rate": 0.00016442733397497593,
      "loss": 0.6166,
      "step": 930
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6896581649780273,
      "learning_rate": 0.0001643888354186718,
      "loss": 0.5528,
      "step": 931
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5492984652519226,
      "learning_rate": 0.00016435033686236768,
      "loss": 0.6829,
      "step": 932
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6111686825752258,
      "learning_rate": 0.00016431183830606353,
      "loss": 0.4542,
      "step": 933
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5228378176689148,
      "learning_rate": 0.0001642733397497594,
      "loss": 0.8278,
      "step": 934
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5937458872795105,
      "learning_rate": 0.00016423484119345525,
      "loss": 0.7656,
      "step": 935
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5819987058639526,
      "learning_rate": 0.00016419634263715113,
      "loss": 0.681,
      "step": 936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6114551424980164,
      "learning_rate": 0.00016415784408084697,
      "loss": 0.5076,
      "step": 937
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5311870574951172,
      "learning_rate": 0.00016411934552454285,
      "loss": 0.9386,
      "step": 938
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8823957443237305,
      "learning_rate": 0.0001640808469682387,
      "loss": 0.3993,
      "step": 939
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7315829396247864,
      "learning_rate": 0.00016404234841193454,
      "loss": 0.7517,
      "step": 940
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6242652535438538,
      "learning_rate": 0.00016400384985563042,
      "loss": 0.907,
      "step": 941
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7685766220092773,
      "learning_rate": 0.0001639653512993263,
      "loss": 0.4934,
      "step": 942
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6275731921195984,
      "learning_rate": 0.00016392685274302214,
      "loss": 0.5533,
      "step": 943
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6179074048995972,
      "learning_rate": 0.000163888354186718,
      "loss": 0.5926,
      "step": 944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9582035541534424,
      "learning_rate": 0.00016384985563041386,
      "loss": 0.406,
      "step": 945
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6250560283660889,
      "learning_rate": 0.00016381135707410974,
      "loss": 0.4709,
      "step": 946
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7713592648506165,
      "learning_rate": 0.00016377285851780558,
      "loss": 0.596,
      "step": 947
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8489186763763428,
      "learning_rate": 0.00016373435996150146,
      "loss": 0.3098,
      "step": 948
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8424249887466431,
      "learning_rate": 0.0001636958614051973,
      "loss": 0.4872,
      "step": 949
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7226042151451111,
      "learning_rate": 0.00016365736284889318,
      "loss": 0.6179,
      "step": 950
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7214240431785583,
      "learning_rate": 0.00016361886429258903,
      "loss": 0.5751,
      "step": 951
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6577856540679932,
      "learning_rate": 0.0001635803657362849,
      "loss": 0.5976,
      "step": 952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6834031343460083,
      "learning_rate": 0.00016354186717998078,
      "loss": 0.6292,
      "step": 953
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7686372995376587,
      "learning_rate": 0.00016350336862367662,
      "loss": 0.8163,
      "step": 954
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7353248000144958,
      "learning_rate": 0.00016346487006737247,
      "loss": 0.727,
      "step": 955
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4837473928928375,
      "learning_rate": 0.00016342637151106835,
      "loss": 0.8925,
      "step": 956
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6428776383399963,
      "learning_rate": 0.00016338787295476422,
      "loss": 1.0072,
      "step": 957
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6094738841056824,
      "learning_rate": 0.00016334937439846007,
      "loss": 0.6839,
      "step": 958
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.489730566740036,
      "learning_rate": 0.00016331087584215591,
      "loss": 0.6526,
      "step": 959
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5202955603599548,
      "learning_rate": 0.0001632723772858518,
      "loss": 0.7389,
      "step": 960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7180712819099426,
      "learning_rate": 0.00016323387872954766,
      "loss": 0.8853,
      "step": 961
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.583791196346283,
      "learning_rate": 0.0001631953801732435,
      "loss": 0.592,
      "step": 962
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6560325622558594,
      "learning_rate": 0.00016315688161693939,
      "loss": 0.6612,
      "step": 963
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7163086533546448,
      "learning_rate": 0.00016311838306063523,
      "loss": 0.6241,
      "step": 964
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.3557342290878296,
      "learning_rate": 0.00016307988450433108,
      "loss": 0.4299,
      "step": 965
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5866108536720276,
      "learning_rate": 0.00016304138594802696,
      "loss": 0.7868,
      "step": 966
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8693161606788635,
      "learning_rate": 0.00016300288739172283,
      "loss": 0.4393,
      "step": 967
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6918577551841736,
      "learning_rate": 0.00016296438883541868,
      "loss": 0.6609,
      "step": 968
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9720010757446289,
      "learning_rate": 0.00016292589027911452,
      "loss": 0.8191,
      "step": 969
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6472270488739014,
      "learning_rate": 0.0001628873917228104,
      "loss": 0.5592,
      "step": 970
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6011863350868225,
      "learning_rate": 0.00016284889316650627,
      "loss": 0.7172,
      "step": 971
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5597042441368103,
      "learning_rate": 0.00016281039461020212,
      "loss": 0.6144,
      "step": 972
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5586633682250977,
      "learning_rate": 0.00016277189605389797,
      "loss": 0.7462,
      "step": 973
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6528881192207336,
      "learning_rate": 0.00016273339749759384,
      "loss": 0.6172,
      "step": 974
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6383774876594543,
      "learning_rate": 0.00016269489894128972,
      "loss": 0.6746,
      "step": 975
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6202871203422546,
      "learning_rate": 0.00016265640038498556,
      "loss": 0.5734,
      "step": 976
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5673164129257202,
      "learning_rate": 0.00016261790182868144,
      "loss": 0.7574,
      "step": 977
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.668799877166748,
      "learning_rate": 0.0001625794032723773,
      "loss": 0.6404,
      "step": 978
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8498870730400085,
      "learning_rate": 0.00016254090471607316,
      "loss": 0.853,
      "step": 979
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7376070022583008,
      "learning_rate": 0.000162502406159769,
      "loss": 0.6124,
      "step": 980
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5754876732826233,
      "learning_rate": 0.00016246390760346488,
      "loss": 0.642,
      "step": 981
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6460099220275879,
      "learning_rate": 0.00016242540904716076,
      "loss": 0.6156,
      "step": 982
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6274104118347168,
      "learning_rate": 0.0001623869104908566,
      "loss": 0.4884,
      "step": 983
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8286557197570801,
      "learning_rate": 0.00016234841193455245,
      "loss": 0.6296,
      "step": 984
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7251535654067993,
      "learning_rate": 0.00016230991337824833,
      "loss": 0.7966,
      "step": 985
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7144703269004822,
      "learning_rate": 0.0001622714148219442,
      "loss": 0.7701,
      "step": 986
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5392202734947205,
      "learning_rate": 0.00016223291626564005,
      "loss": 0.7186,
      "step": 987
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5329578518867493,
      "learning_rate": 0.0001621944177093359,
      "loss": 0.6202,
      "step": 988
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7284709811210632,
      "learning_rate": 0.00016215591915303177,
      "loss": 0.8303,
      "step": 989
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7865099906921387,
      "learning_rate": 0.00016211742059672762,
      "loss": 0.7128,
      "step": 990
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8105828166007996,
      "learning_rate": 0.0001620789220404235,
      "loss": 0.6968,
      "step": 991
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6783756017684937,
      "learning_rate": 0.00016204042348411937,
      "loss": 0.7015,
      "step": 992
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.583478569984436,
      "learning_rate": 0.00016200192492781522,
      "loss": 0.7363,
      "step": 993
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49142903089523315,
      "learning_rate": 0.00016196342637151106,
      "loss": 0.7277,
      "step": 994
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5943036675453186,
      "learning_rate": 0.00016192492781520694,
      "loss": 0.7628,
      "step": 995
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7128115296363831,
      "learning_rate": 0.0001618864292589028,
      "loss": 0.8404,
      "step": 996
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6578225493431091,
      "learning_rate": 0.00016184793070259866,
      "loss": 0.8409,
      "step": 997
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6048220992088318,
      "learning_rate": 0.0001618094321462945,
      "loss": 0.6295,
      "step": 998
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5259882807731628,
      "learning_rate": 0.00016177093358999038,
      "loss": 0.7369,
      "step": 999
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5089165568351746,
      "learning_rate": 0.00016173243503368626,
      "loss": 0.9018,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 1.88667254135808e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

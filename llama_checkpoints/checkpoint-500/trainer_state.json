{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.09614922359501947,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0,
      "loss": 2.098,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.457374572753906,
      "learning_rate": 4e-05,
      "loss": 2.1917,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7966217994689941,
      "learning_rate": 8e-05,
      "loss": 2.0472,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 8e-05,
      "loss": 2.1569,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.239715099334717,
      "learning_rate": 0.00012,
      "loss": 2.1789,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.806528091430664,
      "learning_rate": 0.00016,
      "loss": 1.9093,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7827303409576416,
      "learning_rate": 0.0002,
      "loss": 1.9295,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7811224460601807,
      "learning_rate": 0.00019996150144369588,
      "loss": 1.9561,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.6722819805145264,
      "learning_rate": 0.00019992300288739173,
      "loss": 2.0285,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.1149275302886963,
      "learning_rate": 0.00019988450433108758,
      "loss": 1.6257,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.7799516916275024,
      "learning_rate": 0.00019984600577478345,
      "loss": 1.8609,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.874711513519287,
      "learning_rate": 0.00019980750721847933,
      "loss": 1.586,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.246931314468384,
      "learning_rate": 0.00019976900866217518,
      "loss": 1.5202,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0075149536132812,
      "learning_rate": 0.00019973051010587105,
      "loss": 1.2222,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4524502754211426,
      "learning_rate": 0.0001996920115495669,
      "loss": 1.2517,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.251847743988037,
      "learning_rate": 0.00019965351299326277,
      "loss": 1.2791,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.737441062927246,
      "learning_rate": 0.00019961501443695862,
      "loss": 1.2863,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.00286865234375,
      "learning_rate": 0.0001995765158806545,
      "loss": 1.103,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001995765158806545,
      "loss": 0.9747,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.114648818969727,
      "learning_rate": 0.00019953801732435037,
      "loss": 1.0495,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.003035545349121,
      "learning_rate": 0.0001994995187680462,
      "loss": 1.1688,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": Infinity,
      "learning_rate": 0.0001994995187680462,
      "loss": 0.8911,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.781760215759277,
      "learning_rate": 0.00019946102021174206,
      "loss": 1.0611,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.519819736480713,
      "learning_rate": 0.00019942252165543794,
      "loss": 0.9427,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.247189998626709,
      "learning_rate": 0.00019938402309913379,
      "loss": 0.9676,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0819637775421143,
      "learning_rate": 0.00019934552454282963,
      "loss": 0.8659,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0306124687194824,
      "learning_rate": 0.0001993070259865255,
      "loss": 0.9604,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1556403636932373,
      "learning_rate": 0.00019926852743022138,
      "loss": 1.0219,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9903797507286072,
      "learning_rate": 0.00019923002887391723,
      "loss": 0.9448,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8551985025405884,
      "learning_rate": 0.0001991915303176131,
      "loss": 0.8887,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9833319783210754,
      "learning_rate": 0.00019915303176130895,
      "loss": 0.9098,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8927335143089294,
      "learning_rate": 0.00019911453320500483,
      "loss": 0.8427,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3464423418045044,
      "learning_rate": 0.00019907603464870067,
      "loss": 0.9411,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1088123321533203,
      "learning_rate": 0.00019903753609239655,
      "loss": 0.8362,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.443970799446106,
      "learning_rate": 0.00019899903753609242,
      "loss": 0.7319,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0620180368423462,
      "learning_rate": 0.00019896053897978827,
      "loss": 0.8502,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8205506801605225,
      "learning_rate": 0.00019892204042348412,
      "loss": 0.8464,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.026169776916504,
      "learning_rate": 0.00019888354186718,
      "loss": 0.858,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7239542603492737,
      "learning_rate": 0.00019884504331087587,
      "loss": 0.8742,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8644108772277832,
      "learning_rate": 0.0001988065447545717,
      "loss": 0.7656,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6905569434165955,
      "learning_rate": 0.00019876804619826756,
      "loss": 0.8372,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8827759623527527,
      "learning_rate": 0.00019872954764196344,
      "loss": 0.7281,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5555065870285034,
      "learning_rate": 0.0001986910490856593,
      "loss": 0.8572,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42273494601249695,
      "learning_rate": 0.00019865255052935516,
      "loss": 0.8768,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5444644689559937,
      "learning_rate": 0.00019861405197305103,
      "loss": 0.7526,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6326220035552979,
      "learning_rate": 0.00019857555341674688,
      "loss": 0.6473,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6100513935089111,
      "learning_rate": 0.00019853705486044273,
      "loss": 0.7474,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8508883714675903,
      "learning_rate": 0.0001984985563041386,
      "loss": 0.8062,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.555642306804657,
      "learning_rate": 0.00019846005774783448,
      "loss": 0.7822,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6031041741371155,
      "learning_rate": 0.00019842155919153035,
      "loss": 0.9466,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.612458348274231,
      "learning_rate": 0.00019838306063522617,
      "loss": 0.8309,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6748793721199036,
      "learning_rate": 0.00019834456207892205,
      "loss": 0.8421,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4463978111743927,
      "learning_rate": 0.00019830606352261792,
      "loss": 0.6661,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6735567450523376,
      "learning_rate": 0.00019826756496631377,
      "loss": 0.7187,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5610448122024536,
      "learning_rate": 0.00019822906641000964,
      "loss": 0.7486,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.468348890542984,
      "learning_rate": 0.0001981905678537055,
      "loss": 0.9174,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49667859077453613,
      "learning_rate": 0.00019815206929740136,
      "loss": 0.8015,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.49677103757858276,
      "learning_rate": 0.0001981135707410972,
      "loss": 0.8764,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5423592329025269,
      "learning_rate": 0.00019807507218479309,
      "loss": 0.8467,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.46261122822761536,
      "learning_rate": 0.00019803657362848893,
      "loss": 0.7561,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6421524286270142,
      "learning_rate": 0.0001979980750721848,
      "loss": 0.8461,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.44534018635749817,
      "learning_rate": 0.00019795957651588065,
      "loss": 0.9544,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4680206775665283,
      "learning_rate": 0.00019792107795957653,
      "loss": 0.898,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.48604387044906616,
      "learning_rate": 0.0001978825794032724,
      "loss": 0.8691,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5105553269386292,
      "learning_rate": 0.00019784408084696825,
      "loss": 0.7244,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.41934075951576233,
      "learning_rate": 0.0001978055822906641,
      "loss": 0.9266,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4944055676460266,
      "learning_rate": 0.00019776708373435997,
      "loss": 0.7894,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4694783389568329,
      "learning_rate": 0.00019772858517805585,
      "loss": 0.9173,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4923385977745056,
      "learning_rate": 0.0001976900866217517,
      "loss": 0.8264,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.584971010684967,
      "learning_rate": 0.00019765158806544754,
      "loss": 0.7067,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.460625022649765,
      "learning_rate": 0.00019761308950914342,
      "loss": 0.7259,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5579990744590759,
      "learning_rate": 0.00019757459095283926,
      "loss": 0.6285,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43484073877334595,
      "learning_rate": 0.00019753609239653514,
      "loss": 0.7982,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.451922208070755,
      "learning_rate": 0.00019749759384023101,
      "loss": 0.8647,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5411314964294434,
      "learning_rate": 0.00019745909528392686,
      "loss": 0.7489,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.485877126455307,
      "learning_rate": 0.0001974205967276227,
      "loss": 0.6726,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43625229597091675,
      "learning_rate": 0.00019738209817131858,
      "loss": 0.7847,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4604784846305847,
      "learning_rate": 0.00019734359961501446,
      "loss": 0.6761,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.38421735167503357,
      "learning_rate": 0.0001973051010587103,
      "loss": 0.8093,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47359615564346313,
      "learning_rate": 0.00019726660250240615,
      "loss": 0.7767,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48932552337646484,
      "learning_rate": 0.00019722810394610203,
      "loss": 0.6937,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4678775668144226,
      "learning_rate": 0.0001971896053897979,
      "loss": 0.929,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49805936217308044,
      "learning_rate": 0.00019715110683349375,
      "loss": 0.6369,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5964849591255188,
      "learning_rate": 0.00019711260827718962,
      "loss": 0.6874,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5139459371566772,
      "learning_rate": 0.00019707410972088547,
      "loss": 0.9437,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5100282430648804,
      "learning_rate": 0.00019703561116458135,
      "loss": 0.7723,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.606708288192749,
      "learning_rate": 0.0001969971126082772,
      "loss": 0.86,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41680747270584106,
      "learning_rate": 0.00019695861405197307,
      "loss": 0.8129,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4841563403606415,
      "learning_rate": 0.00019692011549566891,
      "loss": 0.923,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6219584345817566,
      "learning_rate": 0.0001968816169393648,
      "loss": 0.7727,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4298764765262604,
      "learning_rate": 0.00019684311838306064,
      "loss": 0.8104,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.49360743165016174,
      "learning_rate": 0.0001968046198267565,
      "loss": 0.6325,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4630686640739441,
      "learning_rate": 0.00019676612127045239,
      "loss": 0.898,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5353219509124756,
      "learning_rate": 0.0001967276227141482,
      "loss": 0.8399,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4980505704879761,
      "learning_rate": 0.00019668912415784408,
      "loss": 0.7985,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5311594009399414,
      "learning_rate": 0.00019665062560153996,
      "loss": 0.7455,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44213631749153137,
      "learning_rate": 0.00019661212704523583,
      "loss": 0.7094,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5181998014450073,
      "learning_rate": 0.00019657362848893168,
      "loss": 0.7528,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5781349539756775,
      "learning_rate": 0.00019653512993262752,
      "loss": 0.8595,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40299394726753235,
      "learning_rate": 0.0001964966313763234,
      "loss": 0.9345,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5603666305541992,
      "learning_rate": 0.00019645813282001925,
      "loss": 0.9935,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4508861005306244,
      "learning_rate": 0.00019641963426371512,
      "loss": 0.7322,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.453523725271225,
      "learning_rate": 0.000196381135707411,
      "loss": 0.7256,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.698917806148529,
      "learning_rate": 0.00019634263715110684,
      "loss": 0.8367,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.526947021484375,
      "learning_rate": 0.0001963041385948027,
      "loss": 0.6431,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5315524339675903,
      "learning_rate": 0.00019626564003849857,
      "loss": 0.7462,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.528644323348999,
      "learning_rate": 0.00019622714148219444,
      "loss": 0.6622,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4947921633720398,
      "learning_rate": 0.0001961886429258903,
      "loss": 0.7692,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40959012508392334,
      "learning_rate": 0.00019615014436958613,
      "loss": 0.8525,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3968225419521332,
      "learning_rate": 0.000196111645813282,
      "loss": 0.9691,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.461165189743042,
      "learning_rate": 0.00019607314725697788,
      "loss": 0.8075,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43429329991340637,
      "learning_rate": 0.00019603464870067373,
      "loss": 0.7966,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45655712485313416,
      "learning_rate": 0.0001959961501443696,
      "loss": 0.6649,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41561511158943176,
      "learning_rate": 0.00019595765158806545,
      "loss": 0.9817,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5914500951766968,
      "learning_rate": 0.00019591915303176133,
      "loss": 0.6949,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4335707128047943,
      "learning_rate": 0.00019588065447545717,
      "loss": 0.8687,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.517529308795929,
      "learning_rate": 0.00019584215591915305,
      "loss": 0.8118,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5489369034767151,
      "learning_rate": 0.00019580365736284892,
      "loss": 0.9189,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5018031001091003,
      "learning_rate": 0.00019576515880654474,
      "loss": 0.7887,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5235357880592346,
      "learning_rate": 0.00019572666025024062,
      "loss": 1.0346,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.373628705739975,
      "learning_rate": 0.0001956881616939365,
      "loss": 0.5875,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.444135844707489,
      "learning_rate": 0.00019564966313763237,
      "loss": 0.7871,
      "step": 122
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45136335492134094,
      "learning_rate": 0.0001956111645813282,
      "loss": 0.6282,
      "step": 123
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5306428074836731,
      "learning_rate": 0.00019557266602502406,
      "loss": 0.7564,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4356388747692108,
      "learning_rate": 0.00019553416746871994,
      "loss": 0.6983,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4693934917449951,
      "learning_rate": 0.00019549566891241578,
      "loss": 0.7454,
      "step": 126
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6450073719024658,
      "learning_rate": 0.00019545717035611166,
      "loss": 0.6905,
      "step": 127
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4784305989742279,
      "learning_rate": 0.0001954186717998075,
      "loss": 0.6944,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39485329389572144,
      "learning_rate": 0.00019538017324350338,
      "loss": 0.9025,
      "step": 129
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.45148515701293945,
      "learning_rate": 0.00019534167468719923,
      "loss": 0.6443,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4086743891239166,
      "learning_rate": 0.0001953031761308951,
      "loss": 0.8381,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6853803992271423,
      "learning_rate": 0.00019526467757459098,
      "loss": 0.6857,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5018186569213867,
      "learning_rate": 0.00019522617901828683,
      "loss": 0.9565,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38910984992980957,
      "learning_rate": 0.00019518768046198267,
      "loss": 0.7023,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47104546427726746,
      "learning_rate": 0.00019514918190567855,
      "loss": 0.7211,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.595535159111023,
      "learning_rate": 0.00019511068334937442,
      "loss": 0.8905,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42830514907836914,
      "learning_rate": 0.00019507218479307027,
      "loss": 0.7955,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4417261779308319,
      "learning_rate": 0.00019503368623676612,
      "loss": 0.692,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42573025822639465,
      "learning_rate": 0.000194995187680462,
      "loss": 0.608,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6163130402565002,
      "learning_rate": 0.00019495668912415787,
      "loss": 0.9331,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.47019925713539124,
      "learning_rate": 0.0001949181905678537,
      "loss": 0.7338,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4294617176055908,
      "learning_rate": 0.0001948796920115496,
      "loss": 0.7916,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5744539499282837,
      "learning_rate": 0.00019484119345524543,
      "loss": 0.8113,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4397624135017395,
      "learning_rate": 0.0001948026948989413,
      "loss": 0.8047,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4419170916080475,
      "learning_rate": 0.00019476419634263716,
      "loss": 0.7949,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.408357173204422,
      "learning_rate": 0.00019472569778633303,
      "loss": 0.8878,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3972795903682709,
      "learning_rate": 0.0001946871992300289,
      "loss": 0.5689,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.402809202671051,
      "learning_rate": 0.00019464870067372473,
      "loss": 0.7868,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46714845299720764,
      "learning_rate": 0.0001946102021174206,
      "loss": 0.904,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4382963180541992,
      "learning_rate": 0.00019457170356111648,
      "loss": 0.7987,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49720799922943115,
      "learning_rate": 0.00019453320500481232,
      "loss": 0.6905,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.38201817870140076,
      "learning_rate": 0.00019449470644850817,
      "loss": 0.6079,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3585057854652405,
      "learning_rate": 0.00019445620789220404,
      "loss": 0.8645,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5370497703552246,
      "learning_rate": 0.00019441770933589992,
      "loss": 0.7726,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40534526109695435,
      "learning_rate": 0.00019437921077959577,
      "loss": 0.6871,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.40718555450439453,
      "learning_rate": 0.00019434071222329164,
      "loss": 0.8994,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6352331638336182,
      "learning_rate": 0.0001943022136669875,
      "loss": 0.8999,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4231524169445038,
      "learning_rate": 0.00019426371511068336,
      "loss": 0.674,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.51837158203125,
      "learning_rate": 0.0001942252165543792,
      "loss": 0.6869,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43487808108329773,
      "learning_rate": 0.00019418671799807509,
      "loss": 0.8495,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.478048175573349,
      "learning_rate": 0.00019414821944177096,
      "loss": 0.6706,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4871412217617035,
      "learning_rate": 0.0001941097208854668,
      "loss": 0.8534,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48025259375572205,
      "learning_rate": 0.00019407122232916265,
      "loss": 0.8734,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.376050740480423,
      "learning_rate": 0.00019403272377285853,
      "loss": 1.0056,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4277438819408417,
      "learning_rate": 0.0001939942252165544,
      "loss": 0.6711,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4798095226287842,
      "learning_rate": 0.00019395572666025025,
      "loss": 0.8112,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4388551712036133,
      "learning_rate": 0.0001939172281039461,
      "loss": 0.8392,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.633101224899292,
      "learning_rate": 0.00019387872954764197,
      "loss": 0.7927,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3662850558757782,
      "learning_rate": 0.00019384023099133785,
      "loss": 0.7108,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43001875281333923,
      "learning_rate": 0.0001938017324350337,
      "loss": 0.6524,
      "step": 170
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43889835476875305,
      "learning_rate": 0.00019376323387872957,
      "loss": 0.8804,
      "step": 171
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.449369341135025,
      "learning_rate": 0.00019372473532242542,
      "loss": 0.9322,
      "step": 172
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5520343780517578,
      "learning_rate": 0.00019368623676612126,
      "loss": 0.7627,
      "step": 173
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.42789730429649353,
      "learning_rate": 0.00019364773820981714,
      "loss": 0.7097,
      "step": 174
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5099896788597107,
      "learning_rate": 0.000193609239653513,
      "loss": 0.766,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3890852630138397,
      "learning_rate": 0.00019357074109720886,
      "loss": 0.8727,
      "step": 176
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4030917286872864,
      "learning_rate": 0.0001935322425409047,
      "loss": 0.7714,
      "step": 177
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5613992810249329,
      "learning_rate": 0.00019349374398460058,
      "loss": 0.9946,
      "step": 178
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.48699212074279785,
      "learning_rate": 0.00019345524542829646,
      "loss": 0.6841,
      "step": 179
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.43229538202285767,
      "learning_rate": 0.0001934167468719923,
      "loss": 0.6469,
      "step": 180
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.46411290764808655,
      "learning_rate": 0.00019337824831568818,
      "loss": 0.7614,
      "step": 181
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.49609866738319397,
      "learning_rate": 0.00019333974975938403,
      "loss": 0.6847,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.33297157287597656,
      "learning_rate": 0.0001933012512030799,
      "loss": 0.8576,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5082602500915527,
      "learning_rate": 0.00019326275264677575,
      "loss": 0.6907,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.48121577501296997,
      "learning_rate": 0.00019322425409047162,
      "loss": 0.8542,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3946192264556885,
      "learning_rate": 0.00019318575553416747,
      "loss": 0.6726,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41997063159942627,
      "learning_rate": 0.00019314725697786335,
      "loss": 0.6866,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4409182369709015,
      "learning_rate": 0.0001931087584215592,
      "loss": 0.7627,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3896368145942688,
      "learning_rate": 0.00019307025986525507,
      "loss": 0.7587,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42079252004623413,
      "learning_rate": 0.00019303176130895094,
      "loss": 0.6828,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4358564019203186,
      "learning_rate": 0.00019299326275264676,
      "loss": 0.7743,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47438254952430725,
      "learning_rate": 0.00019295476419634264,
      "loss": 0.7295,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3782908022403717,
      "learning_rate": 0.0001929162656400385,
      "loss": 0.7665,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3703530728816986,
      "learning_rate": 0.00019287776708373439,
      "loss": 1.006,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3743325173854828,
      "learning_rate": 0.00019283926852743023,
      "loss": 0.8885,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4332818388938904,
      "learning_rate": 0.00019280076997112608,
      "loss": 0.788,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3522750735282898,
      "learning_rate": 0.00019276227141482195,
      "loss": 0.6771,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5323351621627808,
      "learning_rate": 0.0001927237728585178,
      "loss": 0.7769,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3655940294265747,
      "learning_rate": 0.00019268527430221368,
      "loss": 0.6001,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4050886034965515,
      "learning_rate": 0.00019264677574590955,
      "loss": 0.9004,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44313961267471313,
      "learning_rate": 0.0001926082771896054,
      "loss": 0.9076,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4808651804924011,
      "learning_rate": 0.00019256977863330125,
      "loss": 0.7876,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4099526107311249,
      "learning_rate": 0.00019253128007699712,
      "loss": 0.7545,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42295604944229126,
      "learning_rate": 0.000192492781520693,
      "loss": 0.6868,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.38039496541023254,
      "learning_rate": 0.00019245428296438884,
      "loss": 0.6882,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.392062246799469,
      "learning_rate": 0.0001924157844080847,
      "loss": 0.8275,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.49568668007850647,
      "learning_rate": 0.00019237728585178056,
      "loss": 0.6282,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3389342129230499,
      "learning_rate": 0.00019233878729547644,
      "loss": 0.7987,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.43684521317481995,
      "learning_rate": 0.0001923002887391723,
      "loss": 0.8579,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46228134632110596,
      "learning_rate": 0.00019226179018286816,
      "loss": 0.8268,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.36543259024620056,
      "learning_rate": 0.000192223291626564,
      "loss": 0.8892,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3820000886917114,
      "learning_rate": 0.00019218479307025988,
      "loss": 0.7667,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47314170002937317,
      "learning_rate": 0.00019214629451395573,
      "loss": 0.7424,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4986186921596527,
      "learning_rate": 0.0001921077959576516,
      "loss": 0.6653,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40106379985809326,
      "learning_rate": 0.00019206929740134745,
      "loss": 0.6973,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5317052006721497,
      "learning_rate": 0.00019203079884504333,
      "loss": 0.7483,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4519927203655243,
      "learning_rate": 0.00019199230028873917,
      "loss": 0.872,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.44930392503738403,
      "learning_rate": 0.00019195380173243505,
      "loss": 0.7127,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5897475481033325,
      "learning_rate": 0.00019191530317613092,
      "loss": 0.9663,
      "step": 219
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4732646346092224,
      "learning_rate": 0.00019187680461982674,
      "loss": 0.7192,
      "step": 220
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.40370991826057434,
      "learning_rate": 0.00019183830606352262,
      "loss": 0.945,
      "step": 221
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5189063549041748,
      "learning_rate": 0.0001917998075072185,
      "loss": 0.9023,
      "step": 222
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4453914761543274,
      "learning_rate": 0.00019176130895091434,
      "loss": 0.8568,
      "step": 223
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4872682988643646,
      "learning_rate": 0.00019172281039461021,
      "loss": 0.6934,
      "step": 224
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4745577573776245,
      "learning_rate": 0.00019168431183830606,
      "loss": 0.785,
      "step": 225
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.452533096075058,
      "learning_rate": 0.00019164581328200194,
      "loss": 0.7228,
      "step": 226
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.42025381326675415,
      "learning_rate": 0.00019160731472569778,
      "loss": 0.8885,
      "step": 227
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.45724043250083923,
      "learning_rate": 0.00019156881616939366,
      "loss": 0.7404,
      "step": 228
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41045424342155457,
      "learning_rate": 0.00019153031761308953,
      "loss": 0.8384,
      "step": 229
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4606262743473053,
      "learning_rate": 0.00019149181905678538,
      "loss": 0.6972,
      "step": 230
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47874921560287476,
      "learning_rate": 0.00019145332050048123,
      "loss": 0.9777,
      "step": 231
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41982775926589966,
      "learning_rate": 0.0001914148219441771,
      "loss": 0.9483,
      "step": 232
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.46619105339050293,
      "learning_rate": 0.00019137632338787298,
      "loss": 0.7675,
      "step": 233
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.31501007080078125,
      "learning_rate": 0.00019133782483156882,
      "loss": 0.7628,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45184069871902466,
      "learning_rate": 0.00019129932627526467,
      "loss": 0.686,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3631167411804199,
      "learning_rate": 0.00019126082771896055,
      "loss": 0.8303,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3997798562049866,
      "learning_rate": 0.00019122232916265642,
      "loss": 0.8186,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3641427457332611,
      "learning_rate": 0.00019118383060635227,
      "loss": 0.7384,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3745492696762085,
      "learning_rate": 0.00019114533205004814,
      "loss": 0.9408,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4126112461090088,
      "learning_rate": 0.000191106833493744,
      "loss": 0.7691,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.38452523946762085,
      "learning_rate": 0.00019106833493743986,
      "loss": 0.8933,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4313470423221588,
      "learning_rate": 0.0001910298363811357,
      "loss": 0.717,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4877426326274872,
      "learning_rate": 0.0001909913378248316,
      "loss": 0.9048,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.354559063911438,
      "learning_rate": 0.00019095283926852746,
      "loss": 0.8285,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35648438334465027,
      "learning_rate": 0.00019091434071222328,
      "loss": 0.673,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3589836657047272,
      "learning_rate": 0.00019087584215591916,
      "loss": 0.7923,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3994254469871521,
      "learning_rate": 0.00019083734359961503,
      "loss": 0.7671,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4231529235839844,
      "learning_rate": 0.0001907988450433109,
      "loss": 0.6565,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4621272385120392,
      "learning_rate": 0.00019076034648700673,
      "loss": 0.6907,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3945978581905365,
      "learning_rate": 0.0001907218479307026,
      "loss": 0.7,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39729538559913635,
      "learning_rate": 0.00019068334937439847,
      "loss": 0.5096,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42322924733161926,
      "learning_rate": 0.00019064485081809432,
      "loss": 0.78,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.44383230805397034,
      "learning_rate": 0.0001906063522617902,
      "loss": 0.8083,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6045325398445129,
      "learning_rate": 0.00019056785370548604,
      "loss": 0.8649,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4234389662742615,
      "learning_rate": 0.00019052935514918192,
      "loss": 0.7185,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.381877601146698,
      "learning_rate": 0.00019049085659287777,
      "loss": 0.8355,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3730185031890869,
      "learning_rate": 0.00019045235803657364,
      "loss": 0.675,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4495980739593506,
      "learning_rate": 0.00019041385948026952,
      "loss": 0.6618,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36406174302101135,
      "learning_rate": 0.00019037536092396536,
      "loss": 0.8693,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5642045736312866,
      "learning_rate": 0.0001903368623676612,
      "loss": 0.661,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3980395197868347,
      "learning_rate": 0.00019029836381135708,
      "loss": 0.7259,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.47727033495903015,
      "learning_rate": 0.00019025986525505296,
      "loss": 0.6606,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37292900681495667,
      "learning_rate": 0.0001902213666987488,
      "loss": 0.781,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.33142971992492676,
      "learning_rate": 0.00019018286814244465,
      "loss": 0.621,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4019940197467804,
      "learning_rate": 0.00019014436958614053,
      "loss": 0.8589,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4046827554702759,
      "learning_rate": 0.0001901058710298364,
      "loss": 0.7907,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.40318140387535095,
      "learning_rate": 0.00019006737247353225,
      "loss": 0.7672,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.41678452491760254,
      "learning_rate": 0.00019002887391722812,
      "loss": 0.7602,
      "step": 268
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3626757264137268,
      "learning_rate": 0.00018999037536092397,
      "loss": 0.6203,
      "step": 269
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36802080273628235,
      "learning_rate": 0.00018995187680461982,
      "loss": 0.7684,
      "step": 270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35103940963745117,
      "learning_rate": 0.0001899133782483157,
      "loss": 0.828,
      "step": 271
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4074096381664276,
      "learning_rate": 0.00018987487969201157,
      "loss": 0.7727,
      "step": 272
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39446142315864563,
      "learning_rate": 0.00018983638113570744,
      "loss": 0.7743,
      "step": 273
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.42152348160743713,
      "learning_rate": 0.00018979788257940326,
      "loss": 0.6711,
      "step": 274
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37022072076797485,
      "learning_rate": 0.00018975938402309914,
      "loss": 0.8369,
      "step": 275
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.45802485942840576,
      "learning_rate": 0.000189720885466795,
      "loss": 0.6817,
      "step": 276
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3840475082397461,
      "learning_rate": 0.00018968238691049086,
      "loss": 0.6692,
      "step": 277
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.397205114364624,
      "learning_rate": 0.0001896438883541867,
      "loss": 0.6124,
      "step": 278
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46793362498283386,
      "learning_rate": 0.00018960538979788258,
      "loss": 0.7995,
      "step": 279
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3204089105129242,
      "learning_rate": 0.00018956689124157846,
      "loss": 0.8052,
      "step": 280
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5611957907676697,
      "learning_rate": 0.0001895283926852743,
      "loss": 0.7167,
      "step": 281
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.530852735042572,
      "learning_rate": 0.00018948989412897018,
      "loss": 0.5691,
      "step": 282
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.46891504526138306,
      "learning_rate": 0.00018945139557266603,
      "loss": 0.9886,
      "step": 283
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4694139361381531,
      "learning_rate": 0.0001894128970163619,
      "loss": 0.6444,
      "step": 284
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.39388447999954224,
      "learning_rate": 0.00018937439846005775,
      "loss": 0.7208,
      "step": 285
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4057823717594147,
      "learning_rate": 0.00018933589990375362,
      "loss": 0.6421,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.446094274520874,
      "learning_rate": 0.0001892974013474495,
      "loss": 0.9129,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4163888394832611,
      "learning_rate": 0.00018925890279114534,
      "loss": 0.9019,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.341553658246994,
      "learning_rate": 0.0001892204042348412,
      "loss": 0.7768,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4768024981021881,
      "learning_rate": 0.00018918190567853707,
      "loss": 0.6762,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.401567280292511,
      "learning_rate": 0.00018914340712223294,
      "loss": 0.8641,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44063693284988403,
      "learning_rate": 0.0001891049085659288,
      "loss": 0.5896,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3412891626358032,
      "learning_rate": 0.00018906641000962464,
      "loss": 0.8354,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3813810348510742,
      "learning_rate": 0.0001890279114533205,
      "loss": 0.708,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39346498250961304,
      "learning_rate": 0.00018898941289701638,
      "loss": 0.799,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4597877264022827,
      "learning_rate": 0.00018895091434071223,
      "loss": 0.7395,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3625764548778534,
      "learning_rate": 0.0001889124157844081,
      "loss": 0.8548,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.47845423221588135,
      "learning_rate": 0.00018887391722810395,
      "loss": 0.7139,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4290001094341278,
      "learning_rate": 0.0001888354186717998,
      "loss": 0.8762,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.374828964471817,
      "learning_rate": 0.00018879692011549568,
      "loss": 0.7665,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3916478455066681,
      "learning_rate": 0.00018875842155919155,
      "loss": 0.8444,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4357036352157593,
      "learning_rate": 0.0001887199230028874,
      "loss": 0.6959,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41867315769195557,
      "learning_rate": 0.00018868142444658325,
      "loss": 0.854,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4803310036659241,
      "learning_rate": 0.00018864292589027912,
      "loss": 0.6415,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4232359230518341,
      "learning_rate": 0.000188604427333975,
      "loss": 0.8127,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3427557647228241,
      "learning_rate": 0.00018856592877767084,
      "loss": 0.8764,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4120095670223236,
      "learning_rate": 0.00018852743022136672,
      "loss": 0.7613,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44978073239326477,
      "learning_rate": 0.00018848893166506256,
      "loss": 0.6352,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3201029598712921,
      "learning_rate": 0.00018845043310875844,
      "loss": 0.7237,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.44953957200050354,
      "learning_rate": 0.00018841193455245429,
      "loss": 0.6487,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4061507284641266,
      "learning_rate": 0.00018837343599615016,
      "loss": 0.6154,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4792279005050659,
      "learning_rate": 0.000188334937439846,
      "loss": 0.8293,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3731112480163574,
      "learning_rate": 0.00018829643888354188,
      "loss": 0.6101,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4615262448787689,
      "learning_rate": 0.00018825794032723773,
      "loss": 0.7616,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36472374200820923,
      "learning_rate": 0.0001882194417709336,
      "loss": 0.6681,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4000975489616394,
      "learning_rate": 0.00018818094321462948,
      "loss": 0.6767,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4342329800128937,
      "learning_rate": 0.0001881424446583253,
      "loss": 0.8626,
      "step": 317
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.43993252515792847,
      "learning_rate": 0.00018810394610202117,
      "loss": 0.7314,
      "step": 318
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36972469091415405,
      "learning_rate": 0.00018806544754571705,
      "loss": 0.7895,
      "step": 319
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4726084768772125,
      "learning_rate": 0.00018802694898941292,
      "loss": 0.6262,
      "step": 320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5106558203697205,
      "learning_rate": 0.00018798845043310877,
      "loss": 0.7688,
      "step": 321
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3342224955558777,
      "learning_rate": 0.00018794995187680462,
      "loss": 0.8441,
      "step": 322
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.42816826701164246,
      "learning_rate": 0.0001879114533205005,
      "loss": 0.6327,
      "step": 323
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.34864041209220886,
      "learning_rate": 0.00018787295476419634,
      "loss": 0.7377,
      "step": 324
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3308842182159424,
      "learning_rate": 0.00018783445620789221,
      "loss": 0.6719,
      "step": 325
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4306331276893616,
      "learning_rate": 0.0001877959576515881,
      "loss": 0.6301,
      "step": 326
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.39399442076683044,
      "learning_rate": 0.00018775745909528394,
      "loss": 0.7529,
      "step": 327
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4262602925300598,
      "learning_rate": 0.00018771896053897978,
      "loss": 0.8004,
      "step": 328
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5589942336082458,
      "learning_rate": 0.00018768046198267566,
      "loss": 0.8591,
      "step": 329
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.45510587096214294,
      "learning_rate": 0.00018764196342637153,
      "loss": 0.8667,
      "step": 330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.41702696681022644,
      "learning_rate": 0.00018760346487006738,
      "loss": 0.837,
      "step": 331
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49357858300209045,
      "learning_rate": 0.00018756496631376323,
      "loss": 0.6308,
      "step": 332
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.49088579416275024,
      "learning_rate": 0.0001875264677574591,
      "loss": 0.8118,
      "step": 333
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4575938582420349,
      "learning_rate": 0.00018748796920115498,
      "loss": 0.7499,
      "step": 334
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5084648132324219,
      "learning_rate": 0.00018744947064485082,
      "loss": 0.9495,
      "step": 335
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4152742922306061,
      "learning_rate": 0.0001874109720885467,
      "loss": 0.6591,
      "step": 336
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.410138875246048,
      "learning_rate": 0.00018737247353224255,
      "loss": 0.6558,
      "step": 337
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3992723822593689,
      "learning_rate": 0.00018733397497593842,
      "loss": 0.8139,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4198096990585327,
      "learning_rate": 0.00018729547641963427,
      "loss": 0.8063,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4146757423877716,
      "learning_rate": 0.00018725697786333014,
      "loss": 0.5979,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3692832291126251,
      "learning_rate": 0.000187218479307026,
      "loss": 0.8527,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37799060344696045,
      "learning_rate": 0.00018717998075072184,
      "loss": 0.8657,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3419437110424042,
      "learning_rate": 0.0001871414821944177,
      "loss": 0.7457,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4123936593532562,
      "learning_rate": 0.00018710298363811359,
      "loss": 0.6015,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3556390404701233,
      "learning_rate": 0.00018706448508180946,
      "loss": 0.952,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.43549832701683044,
      "learning_rate": 0.00018702598652550528,
      "loss": 0.7719,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44564804434776306,
      "learning_rate": 0.00018698748796920116,
      "loss": 0.7465,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4578996002674103,
      "learning_rate": 0.00018694898941289703,
      "loss": 0.7318,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5829522609710693,
      "learning_rate": 0.00018691049085659288,
      "loss": 0.6746,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.618412435054779,
      "learning_rate": 0.00018687199230028875,
      "loss": 0.6612,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.45777198672294617,
      "learning_rate": 0.0001868334937439846,
      "loss": 0.744,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47281530499458313,
      "learning_rate": 0.00018679499518768047,
      "loss": 0.7054,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933841288089752,
      "learning_rate": 0.00018675649663137632,
      "loss": 0.8044,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4211621582508087,
      "learning_rate": 0.0001867179980750722,
      "loss": 0.7529,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.504000186920166,
      "learning_rate": 0.00018667949951876807,
      "loss": 0.6154,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.40663763880729675,
      "learning_rate": 0.00018664100096246392,
      "loss": 0.7715,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3982800543308258,
      "learning_rate": 0.00018660250240615977,
      "loss": 0.8856,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39105480909347534,
      "learning_rate": 0.00018656400384985564,
      "loss": 0.5879,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4311503469944,
      "learning_rate": 0.00018652550529355151,
      "loss": 0.7208,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.46843230724334717,
      "learning_rate": 0.00018648700673724736,
      "loss": 0.8434,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.37112879753112793,
      "learning_rate": 0.0001864485081809432,
      "loss": 0.7895,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3782634139060974,
      "learning_rate": 0.00018641000962463908,
      "loss": 0.71,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.411615788936615,
      "learning_rate": 0.00018637151106833496,
      "loss": 0.692,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4585183262825012,
      "learning_rate": 0.0001863330125120308,
      "loss": 0.699,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3210856020450592,
      "learning_rate": 0.00018629451395572668,
      "loss": 0.8301,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.47548168897628784,
      "learning_rate": 0.00018625601539942253,
      "loss": 0.6627,
      "step": 366
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42618703842163086,
      "learning_rate": 0.0001862175168431184,
      "loss": 0.8115,
      "step": 367
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4956449270248413,
      "learning_rate": 0.00018617901828681425,
      "loss": 0.7461,
      "step": 368
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.373945415019989,
      "learning_rate": 0.00018614051973051012,
      "loss": 0.7387,
      "step": 369
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5128307342529297,
      "learning_rate": 0.000186102021174206,
      "loss": 0.8675,
      "step": 370
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.39190107583999634,
      "learning_rate": 0.00018606352261790182,
      "loss": 0.7088,
      "step": 371
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4019525647163391,
      "learning_rate": 0.0001860250240615977,
      "loss": 0.7208,
      "step": 372
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6033728122711182,
      "learning_rate": 0.00018598652550529357,
      "loss": 0.6698,
      "step": 373
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3933517634868622,
      "learning_rate": 0.00018594802694898942,
      "loss": 0.8102,
      "step": 374
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4288349747657776,
      "learning_rate": 0.00018590952839268526,
      "loss": 0.8585,
      "step": 375
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42410892248153687,
      "learning_rate": 0.00018587102983638114,
      "loss": 0.7242,
      "step": 376
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4902440309524536,
      "learning_rate": 0.000185832531280077,
      "loss": 0.5965,
      "step": 377
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.36604270339012146,
      "learning_rate": 0.00018579403272377286,
      "loss": 0.6267,
      "step": 378
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4615339934825897,
      "learning_rate": 0.00018575553416746873,
      "loss": 0.9455,
      "step": 379
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4348839223384857,
      "learning_rate": 0.00018571703561116458,
      "loss": 0.8513,
      "step": 380
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4273621737957001,
      "learning_rate": 0.00018567853705486046,
      "loss": 0.617,
      "step": 381
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41383039951324463,
      "learning_rate": 0.0001856400384985563,
      "loss": 0.8803,
      "step": 382
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5040608048439026,
      "learning_rate": 0.00018560153994225218,
      "loss": 0.7583,
      "step": 383
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.33960476517677307,
      "learning_rate": 0.00018556304138594805,
      "loss": 0.7595,
      "step": 384
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.44689905643463135,
      "learning_rate": 0.0001855245428296439,
      "loss": 0.7853,
      "step": 385
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.41154545545578003,
      "learning_rate": 0.00018548604427333975,
      "loss": 0.7136,
      "step": 386
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.27520662546157837,
      "learning_rate": 0.00018544754571703562,
      "loss": 0.7979,
      "step": 387
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5478206276893616,
      "learning_rate": 0.0001854090471607315,
      "loss": 0.8095,
      "step": 388
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4509338438510895,
      "learning_rate": 0.00018537054860442734,
      "loss": 0.7044,
      "step": 389
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4331468939781189,
      "learning_rate": 0.0001853320500481232,
      "loss": 0.7175,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3315088450908661,
      "learning_rate": 0.00018529355149181907,
      "loss": 0.8649,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38282105326652527,
      "learning_rate": 0.00018525505293551494,
      "loss": 0.7978,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4138413071632385,
      "learning_rate": 0.0001852165543792108,
      "loss": 0.7269,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37460705637931824,
      "learning_rate": 0.00018517805582290666,
      "loss": 0.6528,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34590426087379456,
      "learning_rate": 0.0001851395572666025,
      "loss": 0.9164,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.32010602951049805,
      "learning_rate": 0.00018510105871029836,
      "loss": 0.8575,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37327438592910767,
      "learning_rate": 0.00018506256015399423,
      "loss": 0.8753,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.316778302192688,
      "learning_rate": 0.0001850240615976901,
      "loss": 0.6793,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.403444766998291,
      "learning_rate": 0.00018498556304138598,
      "loss": 0.7541,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.491682767868042,
      "learning_rate": 0.0001849470644850818,
      "loss": 0.6667,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3501006066799164,
      "learning_rate": 0.00018490856592877768,
      "loss": 0.6655,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41489213705062866,
      "learning_rate": 0.00018487006737247355,
      "loss": 0.8568,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4158405065536499,
      "learning_rate": 0.0001848315688161694,
      "loss": 0.6591,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38367748260498047,
      "learning_rate": 0.00018479307025986525,
      "loss": 0.7529,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4363219141960144,
      "learning_rate": 0.00018475457170356112,
      "loss": 0.7413,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4521339237689972,
      "learning_rate": 0.000184716073147257,
      "loss": 0.5389,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.43186765909194946,
      "learning_rate": 0.00018467757459095284,
      "loss": 0.7304,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.40286019444465637,
      "learning_rate": 0.00018463907603464872,
      "loss": 0.865,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3767046630382538,
      "learning_rate": 0.00018460057747834456,
      "loss": 0.8971,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3247160017490387,
      "learning_rate": 0.00018456207892204044,
      "loss": 0.7793,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39206525683403015,
      "learning_rate": 0.00018452358036573629,
      "loss": 0.6463,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3634454011917114,
      "learning_rate": 0.00018448508180943216,
      "loss": 0.7576,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34959307312965393,
      "learning_rate": 0.00018444658325312803,
      "loss": 0.8257,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5340710282325745,
      "learning_rate": 0.00018440808469682388,
      "loss": 0.9475,
      "step": 414
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5003661513328552,
      "learning_rate": 0.00018436958614051973,
      "loss": 0.6891,
      "step": 415
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39330339431762695,
      "learning_rate": 0.0001843310875842156,
      "loss": 0.6483,
      "step": 416
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.35932329297065735,
      "learning_rate": 0.00018429258902791148,
      "loss": 0.6431,
      "step": 417
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4380384385585785,
      "learning_rate": 0.00018425409047160733,
      "loss": 0.8178,
      "step": 418
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37227070331573486,
      "learning_rate": 0.00018421559191530317,
      "loss": 0.8105,
      "step": 419
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41952013969421387,
      "learning_rate": 0.00018417709335899905,
      "loss": 0.7825,
      "step": 420
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3422773778438568,
      "learning_rate": 0.0001841385948026949,
      "loss": 0.9381,
      "step": 421
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3683087229728699,
      "learning_rate": 0.00018410009624639077,
      "loss": 0.6737,
      "step": 422
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3993309736251831,
      "learning_rate": 0.00018406159769008664,
      "loss": 0.7685,
      "step": 423
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.39145129919052124,
      "learning_rate": 0.0001840230991337825,
      "loss": 0.6952,
      "step": 424
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41825953125953674,
      "learning_rate": 0.00018398460057747834,
      "loss": 0.7473,
      "step": 425
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4179387092590332,
      "learning_rate": 0.00018394610202117421,
      "loss": 0.8116,
      "step": 426
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.45485833287239075,
      "learning_rate": 0.0001839076034648701,
      "loss": 0.5701,
      "step": 427
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4862624704837799,
      "learning_rate": 0.00018386910490856594,
      "loss": 0.8575,
      "step": 428
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4824470281600952,
      "learning_rate": 0.00018383060635226178,
      "loss": 0.884,
      "step": 429
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4922899305820465,
      "learning_rate": 0.00018379210779595766,
      "loss": 0.6477,
      "step": 430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4879881739616394,
      "learning_rate": 0.00018375360923965353,
      "loss": 0.7551,
      "step": 431
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5233360528945923,
      "learning_rate": 0.00018371511068334938,
      "loss": 0.7343,
      "step": 432
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5586115717887878,
      "learning_rate": 0.00018367661212704525,
      "loss": 0.6556,
      "step": 433
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4199840724468231,
      "learning_rate": 0.0001836381135707411,
      "loss": 0.7226,
      "step": 434
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.397352397441864,
      "learning_rate": 0.00018359961501443698,
      "loss": 1.0078,
      "step": 435
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4226352274417877,
      "learning_rate": 0.00018356111645813282,
      "loss": 0.8804,
      "step": 436
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4273151159286499,
      "learning_rate": 0.0001835226179018287,
      "loss": 0.7279,
      "step": 437
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4946306347846985,
      "learning_rate": 0.00018348411934552455,
      "loss": 0.7425,
      "step": 438
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.38384705781936646,
      "learning_rate": 0.00018344562078922042,
      "loss": 0.8422,
      "step": 439
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3904738426208496,
      "learning_rate": 0.00018340712223291627,
      "loss": 0.7058,
      "step": 440
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3637390732765198,
      "learning_rate": 0.00018336862367661214,
      "loss": 0.8168,
      "step": 441
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.41314783692359924,
      "learning_rate": 0.00018333012512030802,
      "loss": 0.8248,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.30208462476730347,
      "learning_rate": 0.00018329162656400384,
      "loss": 0.7856,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3953840136528015,
      "learning_rate": 0.0001832531280076997,
      "loss": 0.7159,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37532252073287964,
      "learning_rate": 0.00018321462945139559,
      "loss": 0.668,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3895621597766876,
      "learning_rate": 0.00018317613089509143,
      "loss": 0.7619,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4008345305919647,
      "learning_rate": 0.0001831376323387873,
      "loss": 0.9235,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37399378418922424,
      "learning_rate": 0.00018309913378248316,
      "loss": 0.8747,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44646504521369934,
      "learning_rate": 0.00018306063522617903,
      "loss": 0.7659,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40955376625061035,
      "learning_rate": 0.00018302213666987488,
      "loss": 0.7648,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3704189360141754,
      "learning_rate": 0.00018298363811357075,
      "loss": 0.7595,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4268467426300049,
      "learning_rate": 0.00018294513955726663,
      "loss": 0.732,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3477902412414551,
      "learning_rate": 0.00018290664100096247,
      "loss": 0.7803,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3642955720424652,
      "learning_rate": 0.00018286814244465832,
      "loss": 0.8426,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3884435296058655,
      "learning_rate": 0.0001828296438883542,
      "loss": 0.7273,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37005576491355896,
      "learning_rate": 0.00018279114533205007,
      "loss": 0.8231,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4093822240829468,
      "learning_rate": 0.00018275264677574592,
      "loss": 0.8097,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4333754777908325,
      "learning_rate": 0.00018271414821944176,
      "loss": 0.5244,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38456860184669495,
      "learning_rate": 0.00018267564966313764,
      "loss": 0.9002,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40615877509117126,
      "learning_rate": 0.00018263715110683351,
      "loss": 0.8228,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3670360743999481,
      "learning_rate": 0.00018259865255052936,
      "loss": 0.5899,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.38076573610305786,
      "learning_rate": 0.00018256015399422524,
      "loss": 0.7756,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4119761884212494,
      "learning_rate": 0.00018252165543792108,
      "loss": 0.6556,
      "step": 463
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4783891439437866,
      "learning_rate": 0.00018248315688161696,
      "loss": 1.0189,
      "step": 464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40097832679748535,
      "learning_rate": 0.0001824446583253128,
      "loss": 0.7869,
      "step": 465
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3726452887058258,
      "learning_rate": 0.00018240615976900868,
      "loss": 0.7804,
      "step": 466
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3413650393486023,
      "learning_rate": 0.00018236766121270453,
      "loss": 0.8006,
      "step": 467
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4379594027996063,
      "learning_rate": 0.00018232916265640037,
      "loss": 0.7684,
      "step": 468
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37378251552581787,
      "learning_rate": 0.00018229066410009625,
      "loss": 0.7102,
      "step": 469
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.37973713874816895,
      "learning_rate": 0.00018225216554379212,
      "loss": 0.8109,
      "step": 470
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.33865559101104736,
      "learning_rate": 0.000182213666987488,
      "loss": 0.7206,
      "step": 471
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.49138644337654114,
      "learning_rate": 0.00018217516843118382,
      "loss": 0.8076,
      "step": 472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5017513632774353,
      "learning_rate": 0.0001821366698748797,
      "loss": 0.9111,
      "step": 473
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4073384702205658,
      "learning_rate": 0.00018209817131857557,
      "loss": 0.8147,
      "step": 474
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.47447335720062256,
      "learning_rate": 0.00018205967276227142,
      "loss": 0.6633,
      "step": 475
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.406205952167511,
      "learning_rate": 0.0001820211742059673,
      "loss": 0.684,
      "step": 476
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.613382875919342,
      "learning_rate": 0.00018198267564966314,
      "loss": 0.7979,
      "step": 477
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4507606625556946,
      "learning_rate": 0.000181944177093359,
      "loss": 0.8019,
      "step": 478
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4662131667137146,
      "learning_rate": 0.00018190567853705486,
      "loss": 0.8455,
      "step": 479
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3832371234893799,
      "learning_rate": 0.00018186717998075073,
      "loss": 0.6721,
      "step": 480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4184776246547699,
      "learning_rate": 0.0001818286814244466,
      "loss": 0.8355,
      "step": 481
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.31751248240470886,
      "learning_rate": 0.00018179018286814246,
      "loss": 0.8333,
      "step": 482
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4122768044471741,
      "learning_rate": 0.0001817516843118383,
      "loss": 0.8156,
      "step": 483
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.365533709526062,
      "learning_rate": 0.00018171318575553418,
      "loss": 0.7284,
      "step": 484
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5359499454498291,
      "learning_rate": 0.00018167468719923005,
      "loss": 0.8517,
      "step": 485
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3743586540222168,
      "learning_rate": 0.0001816361886429259,
      "loss": 0.8607,
      "step": 486
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.40984785556793213,
      "learning_rate": 0.00018159769008662175,
      "loss": 0.8798,
      "step": 487
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.41061532497406006,
      "learning_rate": 0.00018155919153031762,
      "loss": 0.7626,
      "step": 488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5130647420883179,
      "learning_rate": 0.0001815206929740135,
      "loss": 0.6745,
      "step": 489
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3531906008720398,
      "learning_rate": 0.00018148219441770934,
      "loss": 0.7948,
      "step": 490
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4617935121059418,
      "learning_rate": 0.00018144369586140522,
      "loss": 0.7451,
      "step": 491
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4042561650276184,
      "learning_rate": 0.00018140519730510107,
      "loss": 0.85,
      "step": 492
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.44275152683258057,
      "learning_rate": 0.0001813666987487969,
      "loss": 0.7308,
      "step": 493
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4530651569366455,
      "learning_rate": 0.0001813282001924928,
      "loss": 0.7625,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.519067645072937,
      "learning_rate": 0.00018128970163618866,
      "loss": 0.7081,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39324527978897095,
      "learning_rate": 0.00018125120307988454,
      "loss": 0.7552,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3819272518157959,
      "learning_rate": 0.00018121270452358036,
      "loss": 0.9068,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4451203942298889,
      "learning_rate": 0.00018117420596727623,
      "loss": 0.8031,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.39822861552238464,
      "learning_rate": 0.0001811357074109721,
      "loss": 0.8524,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4579085409641266,
      "learning_rate": 0.00018109720885466795,
      "loss": 0.6518,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 2.69826118668288e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
